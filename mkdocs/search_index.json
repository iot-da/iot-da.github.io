{
    "docs": [
        {
            "location": "/",
            "text": "Internet of Things and Data Analytics\n\n\nWelcome to the Master Propio on IoT and Data Analytics. Lectures are starting the 19th October. We will be using Zoom and you can find the links in the schedule shown below.\n\n\nLooking forward to meet you all!\n\n\n3rd term\n - 19 Apr. till 3 Jun.\n\n\nAll courses will be starting at 19:00h in China Standard Time\n\n\n\n\n\n\n\n\nHours (UTC+2)\n\n\nTuesday\n\n\nWednesday\n\n\nThursday\n\n\nZoom links\n\n\n\n\n\n\n\n\n\n\n13:00-14:55\n\n\nEDGE\n\n\nEDGE\n\n\nEDGE\n\n\nZoom link\n  Meeting number: 885 4236 5522.   Passcode: 641877\n\n\n\n\n\n\n15:05-17:00\n\n\nSEC\n\n\nSEC\n\n\nSEC\n\n\nZoom link\n   Meeting number: 892 8466 4167 Passcode: 477109\n\n\n\n\n\n\n\n\n\n\nEDGE\n: \nEdge Computing\n.\n\n\nSEC\n: \nSecurity\n.\n\n\n\n\nFinal project\n\n\nFor detailed information about the final project, refer to \nthis link\n\n\nSubjects\n\n\n\n\nMDM\n: \nMassive Data Management\n.\n\n\nSID\n: \nSmart Infrastructures Design\n. \n\n\nIOTNA\n: \nIoT Node Architecture\n.\n\n\nNP1\n: \nNetworks and Protocols I\n.\n\n\nNP2\n: \nNetworks and Protocols II\n.\n\n\nIA\n: \nArtificial Intelligence\n.\n\n\nEDGE\n: \nEdge Computing\n.\n\n\nSEC\n: \nSecurity\n.\n\n\n\n\nProfessors and staff\n\n\n\n\n\n\n\n\nSubject\n\n\nProfessor\n\n\nMail\n\n\nOther\n\n\n\n\n\n\n\n\n\n\nIOTNA\n\n\nJos\u00e9 Ignacio G\u00f3mez\n\n\njigomez@ucm.es\n\n\nDirector\n\n\n\n\n\n\nMDM\n\n\nRafael Caballero\n\n\nrafa@sip.ucm.es\n\n\n-\n\n\n\n\n\n\nSID\n\n\nIv\u00e1n Garc\u00eda\n\n\nigarciam@ucm.es\n\n\n-\n\n\n\n\n\n\nNP1\n\n\nChristian Tenllado\n\n\ntenllado@ucm.es\n\n\n-\n\n\n\n\n\n\nNP2\n\n\nFrancisco Igual\n\n\nfigual@ucm.es\n\n\n-\n\n\n\n\n\n\nAI\n\n\nH\u00e9ctor Garc\u00eda de Marina\n\n\nhgarciad@ucm.es\n\n\n-\n\n\n\n\n\n\nSEC\n\n\nJoaqu\u00edn Recas\n\n\nrecas@ucm.es\n\n\n-\n\n\n\n\n\n\nSEC\n\n\nGuillermo Botella\n\n\ngbotella@ucm.es\n\n\n-\n\n\n\n\n\n\nEDGE\n\n\nCarlos Garc\u00eda\n\n\ngarsanca@ucm.es\n\n\n-\n\n\n\n\n\n\nEDGE\n\n\nLuis Pi\u00f1uel\n\n\nlpinuel@ucm.es\n\n\n-",
            "title": "Home"
        },
        {
            "location": "/#internet-of-things-and-data-analytics",
            "text": "Welcome to the Master Propio on IoT and Data Analytics. Lectures are starting the 19th October. We will be using Zoom and you can find the links in the schedule shown below.  Looking forward to meet you all!",
            "title": "Internet of Things and Data Analytics"
        },
        {
            "location": "/#3rd-term-19-apr-till-3-jun",
            "text": "All courses will be starting at 19:00h in China Standard Time     Hours (UTC+2)  Tuesday  Wednesday  Thursday  Zoom links      13:00-14:55  EDGE  EDGE  EDGE  Zoom link   Meeting number: 885 4236 5522.   Passcode: 641877    15:05-17:00  SEC  SEC  SEC  Zoom link    Meeting number: 892 8466 4167 Passcode: 477109      EDGE :  Edge Computing .  SEC :  Security .",
            "title": "3rd term - 19 Apr. till 3 Jun."
        },
        {
            "location": "/#final-project",
            "text": "For detailed information about the final project, refer to  this link",
            "title": "Final project"
        },
        {
            "location": "/#subjects",
            "text": "MDM :  Massive Data Management .  SID :  Smart Infrastructures Design .   IOTNA :  IoT Node Architecture .  NP1 :  Networks and Protocols I .  NP2 :  Networks and Protocols II .  IA :  Artificial Intelligence .  EDGE :  Edge Computing .  SEC :  Security .",
            "title": "Subjects"
        },
        {
            "location": "/#professors-and-staff",
            "text": "Subject  Professor  Mail  Other      IOTNA  Jos\u00e9 Ignacio G\u00f3mez  jigomez@ucm.es  Director    MDM  Rafael Caballero  rafa@sip.ucm.es  -    SID  Iv\u00e1n Garc\u00eda  igarciam@ucm.es  -    NP1  Christian Tenllado  tenllado@ucm.es  -    NP2  Francisco Igual  figual@ucm.es  -    AI  H\u00e9ctor Garc\u00eda de Marina  hgarciad@ucm.es  -    SEC  Joaqu\u00edn Recas  recas@ucm.es  -    SEC  Guillermo Botella  gbotella@ucm.es  -    EDGE  Carlos Garc\u00eda  garsanca@ucm.es  -    EDGE  Luis Pi\u00f1uel  lpinuel@ucm.es  -",
            "title": "Professors and staff"
        },
        {
            "location": "/Contact/",
            "text": "Contact information\n\n\nDirector: XX\n\n\nAdministrative staff: XX",
            "title": "Home"
        },
        {
            "location": "/Contact/#contact-information",
            "text": "Director: XX  Administrative staff: XX",
            "title": "Contact information"
        },
        {
            "location": "/ESO-camara/",
            "text": "C\u00e1mara de seguridad de andar por casa\n\n\n\u00bfQu\u00e9 vamos a hacer?\n\n\nVamos a montar un sistema de  detecci\u00f3n de intrusos  muy sencillo: cuando la c\u00e1mara detecte movimiento, recibiremos una fotograf\u00eda en nuestro tel\u00e9fono m\u00f3vil mediante Telegram.\n\n\n\u00bfC\u00f3mo lo haremos?\n\n\nUsaremos una  placa ESP-EYE que se puede conseguir por unos 20\u20ac (existen versiones, como la ESP-CAM, a\u00fan m\u00e1s baratas). Esta placa monta un chip ESP32 junto con una c\u00e1mara de 2 Megapixels y un micr\u00f3fono. Adem\u00e1s, incorpora WiFI y Bluetooth, lo que permite conectar el sistema f\u00e1cilmente. Hemos creado un peque\u00f1o programa, que ya est\u00e1 instalado en cada una de las placas que ten\u00e9is, que se encarga de detectar movimiento a trav\u00e9s de la c\u00e1mara.\n\n\nEn este ejercicio vamos a conectar la placa mediante WiFI a un servidor Node-Red usando el protocolo MQTT.  MQTT es un protocolo t\u00edpico del Internet de las Cosas (IoT) que funciona sobre TCP/IP y que sigue un modelo publicar/suscribir. Existen \ncanales\n (\ntopics\n) a los que podemos publicar informaci\u00f3n o a los que podemos suscribirnos para recibir informaci\u00f3n.\n\n\nNode-Red es una herramienta de programaci\u00f3n visual para aplicaciones basadas en eventos:  permite suscribirnos a \ntopics\n MQTT, procesar f\u00e1cilmente la informaci\u00f3n recibida y representarla o enviarla a otro destino. En nuestro caso, \n enviaremos las im\u00e1genes recibidas a un bot de Telegram para recibir notificaciones en nuestro tel\u00e9fono.\n\n\nConfiguraci\u00f3n del entorno Node-Red\n\n\nVamos a trabajar en una m\u00e1quina virtual en la que ya hemos instalado todas las herramientas necesarias. Los ordenadores est\u00e1n arrancados en Linux (sistema nativo) y hemos arrancado ya la m\u00e1quina virtual (con un programa gratuito llamado Virtual Box), en el que tendremos....\u00a1otro sistema Linux! (concretamente, una distribuci\u00f3n de Ubuntu).\n\n\nNecesitamos arrancar y configurar el servicio de Node-Red para que sepa a qu\u00e9 canal MQTT suscribirse y qu\u00e9 hacer con la informaci\u00f3n recibida. Vamos a ir haciendo todo paso a paso, pero aqu\u00ed est\u00e1 descrito todo el proceso por si alguien se pierde en alg\u00fan punto.\n\n\n1. Lanzar Node-Red\n\n\nVamos a abrir un Terminal para poder escribir comandos. Para ello, pulsa sobre el icono que parece una pantalla:\n\n\n\n\nEscribimos el comando \nnode-red\n en la l\u00ednea del terminal y pulsar Enter.\n\n\n\n\n2.  Abrir Firefox y conectar al servidor de Node-Red\n\n\nA continuaci\u00f3n, abrid una pesta\u00f1a de Firefox y teclead \n127.0.0.1:1880\n en la barra de direcciones.\n\n\n\n\nNode-Red tarda unos segundos (a veces casi un minuto) en lanzarse completamente, por lo que quiz\u00e1s os aparezca alg\u00fan error diciendo que no se encuentra nada. Paciencia. En alg\u00fan momento, saldr\u00e1 una web similar a esta:\n\n\n\n\n3. Configurar el canal de MQTT por el que recibiremos la informaci\u00f3n de la c\u00e1mara\n\n\nComo dec\u00edamos en la introducci\u00f3n, la c\u00e1mara enviar\u00e1 un mensaje de texto y una imagen usando el protocolo MQTT. Cada una de las c\u00e1maras est\u00e1 configurada para enviar su informaci\u00f3n a un canal diferente. Concretamente, la c\u00e1mara etiquetada como '1' env\u00eda un texto al canal \n/ucm/fdi/lab/pto1/movimiento\n y una imagen al canal  \n/ucm/fdi/lab/pto1/imagen\n. La c\u00e1mara etiquetada como '2' lo enviar\u00e1 al canal   \n/ucm/fdi/lab/pto2/movimiento\n y \n/ucm/fdi/lab/pto2/imagen\n; y as\u00ed sucesivamente.\n\n\nEl programa Node-Red que aparece por defecto est\u00e1 preparado para recibir informaci\u00f3n de la c\u00e1mara '1'. Si ten\u00e9is esa c\u00e1mara.... pod\u00e9is saltar este paso.  Si no es el caso, es necesario editar los dos nodos  MQTT que hay al comienzo de la zona de trabajo. Para ello, hacemos doble click en el primero (correspondiente el \ncanal\n  \n/ucm/fdi/lab/pto1/movimiento\n), y editaremos el campo \nTopic\n con el n\u00famero de c\u00e1mara que teng\u00e1is:\n\n\n\n\n\n\nConfiguraci\u00f3n de canales MQTT\n\n\nCambiad los dos nodos MQTT de Node-Red, tanto el que finaliza con \nmovimiento\n como el que finaliza con \nimagen\n. Aseguraos de escribid el n\u00famero de vuestra c\u00e1mara.\n\n\n\n\n4. Determinar el ID de vuestro chat en Telegram\n\n\nSi ten\u00e9is vuestro m\u00f3vil con Telegram instalado, y hab\u00e9is creado alg\u00fan \nbot\n, podr\u00e9is enlazar Node-Red con ese \nbot\n. Para ello, lo primero es determinar el \nchatID\n de vuestro \nbot\n (ojo; no es el \nToken\n que os muestra \nBotFather\n cuando cre\u00e1is un nuevo \nbot\n).\n\n\nPara conocer el \nchatID\n, vamos a crear un nodo receptor de Telegram para investigar el contenido del paquete recibido.  Empezaremos a\u00f1adiendo un nodo \nReceiver\n  desde el panel izquierdo de Node-Red (puedes teclear \"Telegram\" en la caja de b\u00fasqueda para que aparezcan solo los nodos relacionados con Telegram). \n\n\n\n\nUna vez tengamos ese nodo en nuestra zona de trabajo, haremos doble click en \u00e9l para editarlo. Aparecer\u00e1 una ventana similar a la de la imagen, y pulsaremos sobre el icono del l\u00e1piz para incluir la informaci\u00f3n del \nbot\n:\n\n\n\n\nRellenad los campos \u00b4Name\u00b4 y \u00b4Token\u00b4 con la informaci\u00f3n proporcionada por el \nBotFather\n cuando creasteis el \nbot\n en Telegram.  En mi caso es:\n\n\n\n\nGuarda la configuraci\u00f3n y vuelve al espacio de trabajo. Incluye un nodo de tipo \nDebug\n al espacio de trabajo y, a continuaci\u00f3n, \u00fanelo con el nodo \nReceiver\n anterior. Una vez hecho esto, pulsa el bot\u00f3n \nDeploy\n en la parte superior derecha de la web. Los 3 pasos si ilustran en la siguiente figura:\n\n\n\n\nAbre la ventana de depuraci\u00f3n   seleccionando \nDebug messages\n en el panel derecho:\n\n\n\n\nAhora, env\u00eda un mensaje desde tu \nbot\n de Telegram. Puede ser cualquier texto. En la figura se muestra la informaci\u00f3n que recibimos si se envi\u00f3 el mensaje \nHola\n. Entre otras cosas, conseguiremos nuestro \nchatID\n:\n\n\n\n\n5. Configurar el env\u00edo de informaci\u00f3n desde Node-Red.\n\n\nEntre los nodos que aparec\u00edan al abrir por primera vez Node-Red, deber\u00eda haber un nodo llamado \nTipo-chatId\n. Edita dicho nodo haciendo doble click sobre \u00e9l e incluye el \nchatID\n en el campo correspondiente:\n\n\n\n\nDe este modo, hemos modificado la informaci\u00f3n que nos llega desde MQTT (es decir, lo que nos env\u00eda la c\u00e1mara), para incluir en el mensaje el \nchatId\n de nuestro \nbot\n, y hacer posible la comunicaci\u00f3n con Telegram. \n\n\nA continuaci\u00f3n s\u00f3lo debemos incluir un nodo tipo \nSender\n de Telegram:\n\n\n\n\ny  editarlo para incluir la informaci\u00f3n de nuestro \nbot\n, para que reciba los mensajes que lleguen desde MQTT:\n\n\n\n\nConectad la c\u00e1mara.\n\n\nYa tenemos preparado todo el sistema de recepci\u00f3n y procesamiento de informaci\u00f3n. S\u00f3lo queda encender la c\u00e1mara para que comience a enviar los datos.\n\n\nSacad la placa de la caja y tratad de dejarla con la c\u00e1mara hacia arriba y sujeta, de modo que est\u00e9 lo m\u00e1s estable posible.\nConectad el cable microUSB al  conector de la placa.  Conectad el otro extremo a cualquier puesto del PC para alimentar la placa a trav\u00e9s de ese equipo.\n\n\nA partir de ese momento, la c\u00e1mara estar\u00e1 tomando im\u00e1genes constantemente y compar\u00e1ndolas entre s\u00ed para detectar variaciones. Si detecta un cambio, enviar\u00e1 la foto por MQTT y se quedar\u00e1 inactiva durante 5 segundos (para evitar el env\u00edo de demasiadas im\u00e1genes).\n\n\nLa conexi\u00f3n de la c\u00e1mara al PC  en este momento se hace \u00fanicamente para alimentar la c\u00e1mara, pero el PC no es necesario.  Se podr\u00eda conectar a un enchufe con un adaptador y funcionar\u00eda igualmente: la comunicaci\u00f3n de la c\u00e1mara con el PC NO se produce por USB, sino por WiFi mediante MQTT.\n\n\n\u00bfC\u00f3mo crear un bot en Telegram?\n\n\nSi tienes Telegram, puedes crear \nbots\n que permiten configurar algunas acciones de forma autom\u00e1tica. Existen aplicaciones (externas a Telegram) que ofrecen funcionalidad mediante \nbots\n (Wikipedia, YouTube. Netflix....). Pero tambi\u00e9n podemos crear nuestros propios \nbots\n y darles la funcionalidad que queramos.\n\n\nPara crear un \nbot\n primero deber\u00e1s buscar el \nBotFather\n. Una vez incluido, basta con utilizar el comando \n/newbot\n. Despu\u00e9s daremos un nombre nuestro \nbot\n (\n4eso_cam\n en mi caso) y un nombre de usuario.  Finalmente, obtendremos\n\nel \ntoken\n de este \nbot\n. que utilizaremos para interaccionar con \u00e9l desde el exterior (con un interfaz HTTP; lo que se conoce como un a API REST).\n\n\nEn la siguiente imagen se muestra el proceso de creaci\u00f3n de mi \nbot\n:\n\n\n\n\nReprogramaci\u00f3n de la c\u00e1mara\n\n\nLas c\u00e1maras (en realidad, el chip ESP32 que controla toda la placa) se programan usando los lenguajes C/C++ en un entorno llamado ESP-IDF (y ESP-WHO), desarrollados por Espressif, la compa\u00f1\u00eda que dise\u00f1a y fabrica estas placas. Hay muchos detalles del proceso que conocer\u00e9is cuando estudi\u00e9is \nIngenier\u00eda de Computadores\n en la UCM, pero hoy vamos a ver lo m\u00e1s b\u00e1sico.\n\n\nPrimero debemos configurar un terminal para poder utilizar el entorno de ESP. Para ello, abre un nuevo terminal y escribe los siguientes comandos:\n\n\nubuntu@ubuntu2004:~$ cd esp-idf\nubuntu@ubuntu2004:~$ source ./export.sh \n\n\n\n\nCon esos comandos hemos establecido el entorno necesario para poder comunicarnos con la placa. Ahora iremos al directorio en el que se encuentra el proyecto desarrollado y escribiremos la aplicaci\u00f3n nuevamente en la placa. \n\n\nPero antes de hacerlo, debemos conectar la placa (el dispositivo USB) con la m\u00e1quina virtual Ubuntu en la que estamos haciendo el trabajo.  Aseg\u00farate de tener la c\u00e1mara conectada al PC;  En el men\u00fa \nDispositivos\n (o \nDevices\n) de VirtualBox debe aparecer un dispositivo de tipo USB, llamado \nUSB to UART\n (quiz\u00e1s \nCP2102N\n). Seleccionando para que la m\u00e1quina virtual pueda acceder al dispositivo.\n\n\nAhora s\u00ed, podemos proceder a abrir una conexi\u00f3n USB con la placa mientras est\u00e1 en funcionamiento. En el mismo terminal anterior, teclearemos los siguientes comandos:\n\n\nubuntu@ubuntu2004:~$ cd\nubuntu@ubuntu2004:~$ cd  esp-who/examples/mot-detect-mqtt/terminal\nubuntu@ubuntu2004:~$ idf.py monitor\n\n\n\n\nA partir de ese momento, comenzaremos a ver informaci\u00f3n de depuraci\u00f3n que la placa est\u00e1 enviando por su puerto serie, v\u00eda USB, al PC. El env\u00edo de im\u00e1genes prosigue por WiFi mediante MQTT a Node-Red; esta informaci\u00f3n de depuraci\u00f3n es \u00fatil durante el desarrollo de la aplicaci\u00f3n.\n\n\nVamos a hacer una variaci\u00f3n en el c\u00f3digo para volver a escribirlo en la placa. Para ello, usaremos VSCode (Visual Studio Code) como editor.  Abrimos VSCode haciendo click sobre su icono:\n\n\n\n\nDeber\u00eda abrirse directamente el proyecto que est\u00e1 volcado en la placa. De entre los ficheros del proyecto, ahora nos interesa abrir el fichero \napp_main.cpp\n:\n\n\n\n\nEs un fichero escrito en C++ que contiene el bucle principal del c\u00f3digo volcado en la placa (l\u00edneas 26 a 66).\nSi modificamos cualquier cosa de este fichero (o cualquier otro fichero) del proyecto, deberemos volver a compilarlo y generar as\u00ed la imagen que volcaremos en la placa (lo que a veces se conoce como \nfirmware\n, que no es m\u00e1s que el c\u00f3digo de nuestra aplicaci\u00f3n junto con el sistema operativo FreeRTOS, que es el usado en ESP-IDF).  \n\n\nPara compilar el proyecto y posteriormente escribir la aplicaci\u00f3n modificada en la placa, escribiremos los siguientes comandos en el mismo terminal que venimos utilizando en este apartado:\n\n\nubuntu@ubuntu2004:~$ idf.py build\nubuntu@ubuntu2004:~$ idf.py flash monitor\n\n\n\n\n\n\nEjercicio final\n\n\nTratad de cambiar el canal MQTT por el que vuestra c\u00e1mara enviar\u00e1 la informaci\u00f3n. Poned el que quer\u00e1is, siempre que comience por el car\u00e1cter /. Modificadlo en el c\u00f3digo C++  y volcad el nuevo c\u00f3digo en la placa. Modificad asimismo la aplicaci\u00f3n de Node-Red y haced un nuevo \nDeploy\n. Comprobad que todo sigue funcionando correctamente.\n\n\n\n\n\n\nPara investigar...\n\n\nNuestra c\u00e1mara est\u00e1 publicando informaci\u00f3n por MQTT. La aplicaci\u00f3n Node-Red est\u00e1 suscrita a dos canales por los que espera recibir esa informaci\u00f3n. Pero.... \u00bfd\u00f3nde se env\u00eda la informaci\u00f3n?\u00bfD\u00f3nde nos suscribimos? Nos falta por hablar del papel del \nbroker\n MQTT, que es quien hace ese papel intermedio. \u00bfSabr\u00edas encontrar qu\u00e9 \nbroker\n MQTT estamos usando en este ejemplo? \u00bfSabr\u00edas localizar en qu\u00e9 pa\u00eds est\u00e1 esa m\u00e1quina?",
            "title": "Home"
        },
        {
            "location": "/ESO-camara/#camara-de-seguridad-de-andar-por-casa",
            "text": "",
            "title": "C\u00e1mara de seguridad de andar por casa"
        },
        {
            "location": "/ESO-camara/#que-vamos-a-hacer",
            "text": "Vamos a montar un sistema de  detecci\u00f3n de intrusos  muy sencillo: cuando la c\u00e1mara detecte movimiento, recibiremos una fotograf\u00eda en nuestro tel\u00e9fono m\u00f3vil mediante Telegram.",
            "title": "\u00bfQu\u00e9 vamos a hacer?"
        },
        {
            "location": "/ESO-camara/#como-lo-haremos",
            "text": "Usaremos una  placa ESP-EYE que se puede conseguir por unos 20\u20ac (existen versiones, como la ESP-CAM, a\u00fan m\u00e1s baratas). Esta placa monta un chip ESP32 junto con una c\u00e1mara de 2 Megapixels y un micr\u00f3fono. Adem\u00e1s, incorpora WiFI y Bluetooth, lo que permite conectar el sistema f\u00e1cilmente. Hemos creado un peque\u00f1o programa, que ya est\u00e1 instalado en cada una de las placas que ten\u00e9is, que se encarga de detectar movimiento a trav\u00e9s de la c\u00e1mara.  En este ejercicio vamos a conectar la placa mediante WiFI a un servidor Node-Red usando el protocolo MQTT.  MQTT es un protocolo t\u00edpico del Internet de las Cosas (IoT) que funciona sobre TCP/IP y que sigue un modelo publicar/suscribir. Existen  canales  ( topics ) a los que podemos publicar informaci\u00f3n o a los que podemos suscribirnos para recibir informaci\u00f3n.  Node-Red es una herramienta de programaci\u00f3n visual para aplicaciones basadas en eventos:  permite suscribirnos a  topics  MQTT, procesar f\u00e1cilmente la informaci\u00f3n recibida y representarla o enviarla a otro destino. En nuestro caso, \n enviaremos las im\u00e1genes recibidas a un bot de Telegram para recibir notificaciones en nuestro tel\u00e9fono.",
            "title": "\u00bfC\u00f3mo lo haremos?"
        },
        {
            "location": "/ESO-camara/#configuracion-del-entorno-node-red",
            "text": "Vamos a trabajar en una m\u00e1quina virtual en la que ya hemos instalado todas las herramientas necesarias. Los ordenadores est\u00e1n arrancados en Linux (sistema nativo) y hemos arrancado ya la m\u00e1quina virtual (con un programa gratuito llamado Virtual Box), en el que tendremos....\u00a1otro sistema Linux! (concretamente, una distribuci\u00f3n de Ubuntu).  Necesitamos arrancar y configurar el servicio de Node-Red para que sepa a qu\u00e9 canal MQTT suscribirse y qu\u00e9 hacer con la informaci\u00f3n recibida. Vamos a ir haciendo todo paso a paso, pero aqu\u00ed est\u00e1 descrito todo el proceso por si alguien se pierde en alg\u00fan punto.",
            "title": "Configuraci\u00f3n del entorno Node-Red"
        },
        {
            "location": "/ESO-camara/#1-lanzar-node-red",
            "text": "Vamos a abrir un Terminal para poder escribir comandos. Para ello, pulsa sobre el icono que parece una pantalla:   Escribimos el comando  node-red  en la l\u00ednea del terminal y pulsar Enter.",
            "title": "1. Lanzar Node-Red"
        },
        {
            "location": "/ESO-camara/#2-abrir-firefox-y-conectar-al-servidor-de-node-red",
            "text": "A continuaci\u00f3n, abrid una pesta\u00f1a de Firefox y teclead  127.0.0.1:1880  en la barra de direcciones.   Node-Red tarda unos segundos (a veces casi un minuto) en lanzarse completamente, por lo que quiz\u00e1s os aparezca alg\u00fan error diciendo que no se encuentra nada. Paciencia. En alg\u00fan momento, saldr\u00e1 una web similar a esta:",
            "title": "2.  Abrir Firefox y conectar al servidor de Node-Red"
        },
        {
            "location": "/ESO-camara/#3-configurar-el-canal-de-mqtt-por-el-que-recibiremos-la-informacion-de-la-camara",
            "text": "Como dec\u00edamos en la introducci\u00f3n, la c\u00e1mara enviar\u00e1 un mensaje de texto y una imagen usando el protocolo MQTT. Cada una de las c\u00e1maras est\u00e1 configurada para enviar su informaci\u00f3n a un canal diferente. Concretamente, la c\u00e1mara etiquetada como '1' env\u00eda un texto al canal  /ucm/fdi/lab/pto1/movimiento  y una imagen al canal   /ucm/fdi/lab/pto1/imagen . La c\u00e1mara etiquetada como '2' lo enviar\u00e1 al canal    /ucm/fdi/lab/pto2/movimiento  y  /ucm/fdi/lab/pto2/imagen ; y as\u00ed sucesivamente.  El programa Node-Red que aparece por defecto est\u00e1 preparado para recibir informaci\u00f3n de la c\u00e1mara '1'. Si ten\u00e9is esa c\u00e1mara.... pod\u00e9is saltar este paso.  Si no es el caso, es necesario editar los dos nodos  MQTT que hay al comienzo de la zona de trabajo. Para ello, hacemos doble click en el primero (correspondiente el  canal    /ucm/fdi/lab/pto1/movimiento ), y editaremos el campo  Topic  con el n\u00famero de c\u00e1mara que teng\u00e1is:    Configuraci\u00f3n de canales MQTT  Cambiad los dos nodos MQTT de Node-Red, tanto el que finaliza con  movimiento  como el que finaliza con  imagen . Aseguraos de escribid el n\u00famero de vuestra c\u00e1mara.",
            "title": "3. Configurar el canal de MQTT por el que recibiremos la informaci\u00f3n de la c\u00e1mara"
        },
        {
            "location": "/ESO-camara/#4-determinar-el-id-de-vuestro-chat-en-telegram",
            "text": "Si ten\u00e9is vuestro m\u00f3vil con Telegram instalado, y hab\u00e9is creado alg\u00fan  bot , podr\u00e9is enlazar Node-Red con ese  bot . Para ello, lo primero es determinar el  chatID  de vuestro  bot  (ojo; no es el  Token  que os muestra  BotFather  cuando cre\u00e1is un nuevo  bot ).  Para conocer el  chatID , vamos a crear un nodo receptor de Telegram para investigar el contenido del paquete recibido.  Empezaremos a\u00f1adiendo un nodo  Receiver   desde el panel izquierdo de Node-Red (puedes teclear \"Telegram\" en la caja de b\u00fasqueda para que aparezcan solo los nodos relacionados con Telegram).    Una vez tengamos ese nodo en nuestra zona de trabajo, haremos doble click en \u00e9l para editarlo. Aparecer\u00e1 una ventana similar a la de la imagen, y pulsaremos sobre el icono del l\u00e1piz para incluir la informaci\u00f3n del  bot :   Rellenad los campos \u00b4Name\u00b4 y \u00b4Token\u00b4 con la informaci\u00f3n proporcionada por el  BotFather  cuando creasteis el  bot  en Telegram.  En mi caso es:   Guarda la configuraci\u00f3n y vuelve al espacio de trabajo. Incluye un nodo de tipo  Debug  al espacio de trabajo y, a continuaci\u00f3n, \u00fanelo con el nodo  Receiver  anterior. Una vez hecho esto, pulsa el bot\u00f3n  Deploy  en la parte superior derecha de la web. Los 3 pasos si ilustran en la siguiente figura:   Abre la ventana de depuraci\u00f3n   seleccionando  Debug messages  en el panel derecho:   Ahora, env\u00eda un mensaje desde tu  bot  de Telegram. Puede ser cualquier texto. En la figura se muestra la informaci\u00f3n que recibimos si se envi\u00f3 el mensaje  Hola . Entre otras cosas, conseguiremos nuestro  chatID :",
            "title": "4. Determinar el ID de vuestro chat en Telegram"
        },
        {
            "location": "/ESO-camara/#5-configurar-el-envio-de-informacion-desde-node-red",
            "text": "Entre los nodos que aparec\u00edan al abrir por primera vez Node-Red, deber\u00eda haber un nodo llamado  Tipo-chatId . Edita dicho nodo haciendo doble click sobre \u00e9l e incluye el  chatID  en el campo correspondiente:   De este modo, hemos modificado la informaci\u00f3n que nos llega desde MQTT (es decir, lo que nos env\u00eda la c\u00e1mara), para incluir en el mensaje el  chatId  de nuestro  bot , y hacer posible la comunicaci\u00f3n con Telegram.   A continuaci\u00f3n s\u00f3lo debemos incluir un nodo tipo  Sender  de Telegram:   y  editarlo para incluir la informaci\u00f3n de nuestro  bot , para que reciba los mensajes que lleguen desde MQTT:",
            "title": "5. Configurar el env\u00edo de informaci\u00f3n desde Node-Red."
        },
        {
            "location": "/ESO-camara/#conectad-la-camara",
            "text": "Ya tenemos preparado todo el sistema de recepci\u00f3n y procesamiento de informaci\u00f3n. S\u00f3lo queda encender la c\u00e1mara para que comience a enviar los datos.  Sacad la placa de la caja y tratad de dejarla con la c\u00e1mara hacia arriba y sujeta, de modo que est\u00e9 lo m\u00e1s estable posible.\nConectad el cable microUSB al  conector de la placa.  Conectad el otro extremo a cualquier puesto del PC para alimentar la placa a trav\u00e9s de ese equipo.  A partir de ese momento, la c\u00e1mara estar\u00e1 tomando im\u00e1genes constantemente y compar\u00e1ndolas entre s\u00ed para detectar variaciones. Si detecta un cambio, enviar\u00e1 la foto por MQTT y se quedar\u00e1 inactiva durante 5 segundos (para evitar el env\u00edo de demasiadas im\u00e1genes).  La conexi\u00f3n de la c\u00e1mara al PC  en este momento se hace \u00fanicamente para alimentar la c\u00e1mara, pero el PC no es necesario.  Se podr\u00eda conectar a un enchufe con un adaptador y funcionar\u00eda igualmente: la comunicaci\u00f3n de la c\u00e1mara con el PC NO se produce por USB, sino por WiFi mediante MQTT.",
            "title": "Conectad la c\u00e1mara."
        },
        {
            "location": "/ESO-camara/#como-crear-un-bot-en-telegram",
            "text": "Si tienes Telegram, puedes crear  bots  que permiten configurar algunas acciones de forma autom\u00e1tica. Existen aplicaciones (externas a Telegram) que ofrecen funcionalidad mediante  bots  (Wikipedia, YouTube. Netflix....). Pero tambi\u00e9n podemos crear nuestros propios  bots  y darles la funcionalidad que queramos.  Para crear un  bot  primero deber\u00e1s buscar el  BotFather . Una vez incluido, basta con utilizar el comando  /newbot . Despu\u00e9s daremos un nombre nuestro  bot  ( 4eso_cam  en mi caso) y un nombre de usuario.  Finalmente, obtendremos \nel  token  de este  bot . que utilizaremos para interaccionar con \u00e9l desde el exterior (con un interfaz HTTP; lo que se conoce como un a API REST).  En la siguiente imagen se muestra el proceso de creaci\u00f3n de mi  bot :",
            "title": "\u00bfC\u00f3mo crear un bot en Telegram?"
        },
        {
            "location": "/ESO-camara/#reprogramacion-de-la-camara",
            "text": "Las c\u00e1maras (en realidad, el chip ESP32 que controla toda la placa) se programan usando los lenguajes C/C++ en un entorno llamado ESP-IDF (y ESP-WHO), desarrollados por Espressif, la compa\u00f1\u00eda que dise\u00f1a y fabrica estas placas. Hay muchos detalles del proceso que conocer\u00e9is cuando estudi\u00e9is  Ingenier\u00eda de Computadores  en la UCM, pero hoy vamos a ver lo m\u00e1s b\u00e1sico.  Primero debemos configurar un terminal para poder utilizar el entorno de ESP. Para ello, abre un nuevo terminal y escribe los siguientes comandos:  ubuntu@ubuntu2004:~$ cd esp-idf\nubuntu@ubuntu2004:~$ source ./export.sh   Con esos comandos hemos establecido el entorno necesario para poder comunicarnos con la placa. Ahora iremos al directorio en el que se encuentra el proyecto desarrollado y escribiremos la aplicaci\u00f3n nuevamente en la placa.   Pero antes de hacerlo, debemos conectar la placa (el dispositivo USB) con la m\u00e1quina virtual Ubuntu en la que estamos haciendo el trabajo.  Aseg\u00farate de tener la c\u00e1mara conectada al PC;  En el men\u00fa  Dispositivos  (o  Devices ) de VirtualBox debe aparecer un dispositivo de tipo USB, llamado  USB to UART  (quiz\u00e1s  CP2102N ). Seleccionando para que la m\u00e1quina virtual pueda acceder al dispositivo.  Ahora s\u00ed, podemos proceder a abrir una conexi\u00f3n USB con la placa mientras est\u00e1 en funcionamiento. En el mismo terminal anterior, teclearemos los siguientes comandos:  ubuntu@ubuntu2004:~$ cd\nubuntu@ubuntu2004:~$ cd  esp-who/examples/mot-detect-mqtt/terminal\nubuntu@ubuntu2004:~$ idf.py monitor  A partir de ese momento, comenzaremos a ver informaci\u00f3n de depuraci\u00f3n que la placa est\u00e1 enviando por su puerto serie, v\u00eda USB, al PC. El env\u00edo de im\u00e1genes prosigue por WiFi mediante MQTT a Node-Red; esta informaci\u00f3n de depuraci\u00f3n es \u00fatil durante el desarrollo de la aplicaci\u00f3n.  Vamos a hacer una variaci\u00f3n en el c\u00f3digo para volver a escribirlo en la placa. Para ello, usaremos VSCode (Visual Studio Code) como editor.  Abrimos VSCode haciendo click sobre su icono:   Deber\u00eda abrirse directamente el proyecto que est\u00e1 volcado en la placa. De entre los ficheros del proyecto, ahora nos interesa abrir el fichero  app_main.cpp :   Es un fichero escrito en C++ que contiene el bucle principal del c\u00f3digo volcado en la placa (l\u00edneas 26 a 66).\nSi modificamos cualquier cosa de este fichero (o cualquier otro fichero) del proyecto, deberemos volver a compilarlo y generar as\u00ed la imagen que volcaremos en la placa (lo que a veces se conoce como  firmware , que no es m\u00e1s que el c\u00f3digo de nuestra aplicaci\u00f3n junto con el sistema operativo FreeRTOS, que es el usado en ESP-IDF).    Para compilar el proyecto y posteriormente escribir la aplicaci\u00f3n modificada en la placa, escribiremos los siguientes comandos en el mismo terminal que venimos utilizando en este apartado:  ubuntu@ubuntu2004:~$ idf.py build\nubuntu@ubuntu2004:~$ idf.py flash monitor   Ejercicio final  Tratad de cambiar el canal MQTT por el que vuestra c\u00e1mara enviar\u00e1 la informaci\u00f3n. Poned el que quer\u00e1is, siempre que comience por el car\u00e1cter /. Modificadlo en el c\u00f3digo C++  y volcad el nuevo c\u00f3digo en la placa. Modificad asimismo la aplicaci\u00f3n de Node-Red y haced un nuevo  Deploy . Comprobad que todo sigue funcionando correctamente.    Para investigar...  Nuestra c\u00e1mara est\u00e1 publicando informaci\u00f3n por MQTT. La aplicaci\u00f3n Node-Red est\u00e1 suscrita a dos canales por los que espera recibir esa informaci\u00f3n. Pero.... \u00bfd\u00f3nde se env\u00eda la informaci\u00f3n?\u00bfD\u00f3nde nos suscribimos? Nos falta por hablar del papel del  broker  MQTT, que es quien hace ese papel intermedio. \u00bfSabr\u00edas encontrar qu\u00e9  broker  MQTT estamos usando en este ejemplo? \u00bfSabr\u00edas localizar en qu\u00e9 pa\u00eds est\u00e1 esa m\u00e1quina?",
            "title": "Reprogramaci\u00f3n de la c\u00e1mara"
        },
        {
            "location": "/General/TFM/",
            "text": "Final project proposals\n\n\nImportant dates\n\n\n\n\nDeadline for proposal selection: \nFebruary 10\n\n\nDeadline for proposal notifications: \nFebruary 17\n\n\nDeadline for final deliverables (PDF report, video presentation and supplementary material): \nJune 27\n\n\nFinal defenses: \nJuly 11-15\n\n\n\n\nDescription and rules\n\n\nThe Final Project is a research or development work that aims at demonstrating\nthat the student has acquired the necessary knowledge and skills \nassociated to the Master's Degree, and it will be developed \n\nin groups of three students\n under the supervision of one \nor more professors.\n\n\nThe contents to develop for each project proposal will depend on the specific\nselected topic, and they will range from designing and developing\na specific IoT application/deployment, service or system within\nthe field of Internet of Things, or theoretical in-depth \nstudies of state-of-the-art topics related with IoT. \nIn all cases, the contents will extend and integrate knowledge \nand skills studied throughout the different subjects.\n\n\nThe project will allow the students to relate practical aspects\nand professional issues with the topics covered within the development\nof one or more of the subjects covered in the Master, adapted to the\ninterests of the student. \n\n\nThe Advisor will define the topic and tasks to fulfill, and will guide\nthe students throughout the development of the work and the goals to\nachieve. He/she will organize activities to control the correct\ndevelopment of the work.\n\n\nThe estimated amount of time for each student is \n300 hours of personal work\n.\n\n\nEvaluation\n\n\nThe evaluation of the Project will be carried out by a Committee that\nwill be composed by professors of the different subjects. In order\nto defend the work, the students will need to pass all the subjects in\nthe Master, and he/she will need a signed agreement from the Advisor\nstating his/her consent to proceed with the defense. This consent report\nwill include all the considerations necessary to assist the Committee\nin the evaluation of the work. \n\n\nThe students will present a report written in English, that will include,\nat least, an introduction, goal description and work plan (including a\ntask distribution among members of the group), together\nwith a critical discussion of the develped work and results, conclusions\nand related bibliography. The suggested length of the report is\n\n50 pages\n.\n\n\nThe defense of the work will be carried out in two stages:\n\n\n\n\nVideo presentation delivered before the final deadline.\n\n\nPublic live session in which the members of the Committe will share with \nthe students the necessary questions and comments that help evaluating the \ndeveloped work. Questions will be addressed in general to all members of \nthe group, and also specifically to each member of the group.\n\n\n\n\nIn the following, we propose a number of topics proposed by professors\ncovering topics of interest. Up to two groups of 3 students can select\neach project. This selection will be communicated to \nJos\u00e9 Ignacio G\u00f3mez (jigomez@ucm.es) and Francisco Igual (figual@ucm.es) by mail\n\nbefore February 10\n.\n\n\nThe work needs to be original and developed in groups of 3 students, clearly\ndefining the tasks to develop by each member of the group, in a balanced fashion.\nPlagiarism (from other students or third parties) will determine a fail\nin the final grade of the work for all members of the group.\n\n\nDeliverables\n\n\nEach group will deliver three evidences of the developed work before the final\ndeadline:\n\n\n\n\nReport in PDF format.\n\n\nPresentation video of up to 30 mins. of duration.\n\n\nDeveloped code (if applicable).\n\n\n\n\nThe dates and mechanisms to deliver the final report and to proceed with\nthe defense will be announced with enough time before the deadline.\n\n\nProposals\n\n\nProposal 1\n\n\n\n\nTitle:\n \nRelation between air pollution, weather and traffic\n\n\nRequirements:\n good programming skills.\n\n\nProfessor:\n Rafael Caballero Rold\u00e1n (rafacr@ucm.es)\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nThe goal is to predict the pollution in a particular point of a city for the next few hours. The prediction will take as input from the data collected by sensors of air pollution and number of vehicles. We will train different models and evaluate the results to choose the best predictions in each case. The project includes:\n\n\n\n\nBasic data management to prepare the data\n\n\nBasic statistics to understand the data and detect outliers\n\n\nClustering for selecting days with similar pollution/traffic conditions\n\n\nFeature selection\n\n\nHiperparameter tunning\n\n\nModel Selection\n\n\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nQiuji Chen\n\n\nXiaolan Li\n\n\nZhao Hu\n\n\n\n\n\n\n\n\nProposal 2\n\n\n\n\nTitle:\n \nMachine Learning Ensamble Methods\n\n\nRequirements:\n good programming skills.\n\n\nProfessor:\n Rafael Caballero Rold\u00e1n (rafacr@ucm.es)\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nThe ensemble Methods combine several \nweak learners\n to build a more efficient method. The main goal is to implement in Spark the three main Methods (bagging, stacking and Boosting). On particular the project will include:\n\n\n\n\nA complete description of the tecniques\n\n\nA Spark function implementing them\n\n\nA benchmark using some datasets of the course to compare their efficiency\n\n\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nYan Zhao\n\n\nJiePing You\n\n\n\n\n\n\n\n\n\n\nProposal 3\n\n\n\n\nTitle:\n \nIoT devices or services for well-being\n\n\nProfessor:\n Iv\u00e1n Garc\u00eda-Magari\u00f1o Garc\u00eda (igarciam@ucm.es)\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nWell-being is usually desired by most people, and smart watches and smart bands are growing in\npopularity for such purpose. However, other IoT devices and services can help users to provide\naccurate perspectives of certain well-being aspects in order to provide personalized advices for\nincreasing the well-being. For example, smart beds can help you in tracking you sleeping, door\nsensors could measure the time spent in outdoor activities or the times you eat meals at home. All\nthis information related with emotional information could feed an intelligent system to output the\nright advices for increasing the well-being. This work could be conducted from either (1) a research\nperspective being relevant the analysis of existing works in this topic and the proposal of novel ideas,\nor (2) from a technical perspective addressing to program some intelligent system for providing well-\nbeing advices based on information from IoT devices.\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nLiu Jinhua\n\n\nDuan Zhen\n\n\nHu Hao\n\n\n\n\n\n\n\n\nProposal 4\n\n\n\n\nTitle:\n \nIoT devices or services for healthcare\n\n\nProfessor:\n Iv\u00e1n Garc\u00eda-Magari\u00f1o Garc\u00eda (igarciam@ucm.es)\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nHealthcare is benefiting from the growing of IoT. For instance, smart homes could track the progress\nof certain symptoms. Smart IoT dispensers can help patients in reminding their medication to avoid\nboth missing it and forgetting whether certain medication has been taken. This work could be\nconducted from either (1) a research perspective being relevant the analysis of existing works in this\ntopic and the proposal of novel ideas, or (2) from a technical perspective addressing to prototype a\ncertain IoT device or service and program the necessary software for providing a system that could\nhelp in some aspect of healthcare.\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nShuishi Zhou\n\n\nYang Chu\n\n\nWenyan Liao\n\n\n\n\n\n\n2\n\n\nDongyang Xu\n\n\nXueqing Zhao\n\n\nYujuan Huang\n\n\n\n\n\n\n\n\nProposal 5\n\n\n\n\nTitle:\n \nOpenData iniciatives in China: situation, perspectives and use cases\n\n\nProfessors:\n Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)\n\n\nRequirements:\n recommended, but not mandatory, basic programming skills.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nOpenData initiatives pursue offering data sources in an open, royalty-free and accessible manner. It follows a similar philosophy as that of Open Source or Open Hardware, and aims at facilitating data analysis to the community taken from official channels, both from Local or National Goverments, or from companies.\n\n\nThe goal of the project is two-fold: first, to provide a global, in-depth study and discussion of the OpenData initiatives in China, both from the Government and from Private Companies; second, to select a set of realistic use cases to perform specific data analysis oriented to real-world applications, mainly based on or with application to the IoT paradigm. \n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nJunyan Guo\n\n\nJianchuang Zhang\n\n\nGuanjie Xiao\n\n\n\n\n\n\n2\n\n\nYinghua Liao\n\n\nJiali Gao\n\n\nXionglan Luo\n\n\n\n\n\n\n\n\nProposal 6\n\n\n\n\nTitle:\n \nSmartCities: requirements, infrastructure and use cases\n\n\nProfessors:\n Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)\n\n\nRequirements:\n no programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nWe have been using the term \nSmart Cities\n for many years now, but it still looks like a \nto be defined\n concept. There are many flavours in Smart Cities initiatives and many actors that play different roles in the process of implementing them.  Focusing on IoT, there is always a need to deploy an infrastructure that may represent a huge economical investment with some return expected (economic, social...).\n\n\nThe goal of this project is to deep into the idea of Smart Cities, starting with a general description of its typical topics: smart mobility, smart buildings, smart grid (energy distribution and savings), smart health, water supply, waste disposal facilities...  The students will choose two of those topic and provide an in-depth study of the requirements (sensors, nodes, edge computing, servers...) including the deployment and maintenance process.  The study must include at least two examples of existing cities implementing initiatives in the topics chosen (one Chinese and one European city, if possible). There are many questions this study may answer: how is a given project improving the quality of life of the citizens? Who is paying the cost of the infrastructure? What is the expected \"Return Of Investment\" (ROI)? Will there be shared infrastructures? (i.e. companies that deploy a sensor network and rent it to other companies/public organisations as a \"service\")\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nZhijun Hao\n\n\nHongbiao Cao\n\n\nYuanshuang Sha\n\n\n\n\n\n\n2\n\n\nJiayun Pan\n\n\nWeiLin Zhang\n\n\nYongTao He\n\n\n\n\n\n\n\n\nProposal 7\n\n\n\n\nTitle:\n \nBuilding meshes with WiFi\n\n\nProfessors:\n Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)\n\n\nRequirements:\n good programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nESP-IDF provides a proprietary protocol, called \nESP-WIFI-MESH\n, that allows  numerous devices spread over a large physical area (both indoors and outdoors) to be interconnected under a single WLAN (Wireless Local-Area Network). ESP-WIFI-MESH is self-organizing and self-healing meaning the network can be built and maintained autonomously. \nYou can find information about ESP-WIFI-MESH in this link\n.\n\n\nSome of those nodes (but not necessarily all of them) may have access to a router (border router) that provides access to the internet. The far-away nodes (those outside the range of the router) may still connect to the internet asking the intermediate nodes to relay their transmissions.\n\n\nESP-IDF also provides an API to access \nThread\n, an IPv6-based mesh networking technology for IoT. Once again, it allows a mesh of nodes to gain access to the internet even if they are not close to a border router. \nMore information about Thread can be found in this link\n.\n\n\nThe goal of this project is to build a mesh of ESP32 nodes using both technologies to comparte their APIs, capabilities and performance. The nodes will run simple applications (sensing temperature, for example) and will try to send the information to an external server using MQTT. Some of the nodes will be close to a router providing access to the internet (and thus, to the external server), while some others will be out of the range of the router signal.\n\n\nThe study should compare both implementations, trying to figure out the overheads of each implementation, relative performance, ease of use...\n\n\nIMPORTANT\n: to perform this project, you will need more than 2 ESP32 boards, so the team partners should live close enough to physically meet to make tests.\n\n\nProposal 8\n\n\n\n\nTitle:\n \nLightweight Cryptography Applicable to IoT Devices\n\n\nProfessors:\n Joaquin Recas (recas@ucm.es) and Guillermo Botella (gbotella@ucm.es)\n\n\nRequirements:\n good programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nCryptography in IoT requires a compromise between security, performance and cost. Performance refers to power consumption, latency, and throughput; the cost, to memory and CPU. The more secure an algorithm or protocol is, the more negative impact it will have on cost and performance. Similarly, if you want to improve performance or lower cost, you will have a negative impact on security.\n\n\nThe objective of this project is to test different publicly accessible encryption implementations that can be used in IoT systems and to make a comparative study on the three factors described above: security, performance and cost.\n\n\nProposal 9\n\n\n\n\nTitle:\n \nSDR and GNU Radio to explore IoT vulnerabilities\n\n\nProfessors:\n Joaquin Recas (recas@ucm.es) and Guillermo Botella (gbotella@ucm.es)\n\n\nRequirements:\n good programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nWireless communications still keep growing, becoming part of our daily lives with the aim of making it easier. For example through the use of wireless devices, home automation, industrial environments, among others that make up the Internet of Things. Sometimes, manufacturers of IoT devices focus to improve their functionality and make them more competitive in the market and do not pay sufficient attention to the security issue. Normally, the common user is not aware of the vulnerabilities of communications that are propagated by the air as used by IoT devices.\nThis work pretends to show the use of SDR and GNU Radio as tools to study and analyzing vulnerabilities over IoT communications through Radio Frequencies protocols (RF), getting interesting information such as operation frequency, modulation, applying reverse engineering and replay attack.\n\n\nProposal 10\n\n\n\n\nTitle:\n \nExploring Open Source IoT frameworks: Eclipse IoT and Zephyr OS\n\n\nProfessors:\n Christian Tenllado (tenllado@ucm.es)\n\n\nRequirements:\n no programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nThe fast growth of IoT in recent years has lead to massive publications of tools and frameworks developed to work at different levels of the IoT ecosystem. A relevant part of them have ben released as Open Source, so they are specially interesting for small companies and start-ups wanting to contribute in this domain. \nEclipse IoT\n is an initiative to gather a huge plethora of IoT technologies, backed up by the most relevant companies in this sector.  \nZephyr\n is  a Linux Foundation project releasing an open-source, product-ready RTOS (real-time operating system) for embedded systems (sensor nodes). \n\n\nThis project will extensively document the Eclipse IoT project, enumerating the existing projects and locating them in their target IoT system level: sensor node, gateway, edge, fog or cloud. Zephyr will be also considered in the studay, to explore how it fits the other existing projects. Once the most relevant  are described, several use cases will be considered, illustrating how a combination of different projects may help to develop a full IoT application, from sensor node programming, deployment, management, data collection  and processing.\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nZhang Yi\n\n\nLi Tianfeng\n\n\nRe Wei\n\n\n\n\n\n\n2\n\n\nXiazu Hu\n\n\nQinghong Yu\n\n\nSuishi Liu\n\n\n\n\n\n\n\n\nProposal 11\n\n\n\n\nTitle:\n \nAccelerators in Edge Computing\n\n\nProfessors:\n Carlos Garc\u00eda (cgarcia@ucm.es)\n\n\nRequirements:\n no programming skills necessary.\n\n\nAvailable slots:\n 2 groups\n\n\nDescription:\n\n\n\n\nOn one hand, the use of accelerators has been gaining importance in the context of the High Performance Computing arena to improve workload performance. On the other hand, with the exponential growth of data generation joint to the irruption of IoT devices at the edge, has meant the consideration of the use of accelerators in another context where accelerators were not initially designed. The future of computing is driven by the need to process data cost-effectively close to the data production. A single example of this tendency is the design and commercialization of specific ASICs to process powerful IA algorithms to speedup the response times with less power requirements.\n\n\nThis project proposal will research the use of accelerators such as GPUs, FPGAs, SMART-NICs in an IoT ecosystem. The project will not only focus on the diversity of hardware devices but also deepen on other aspects such as programmability, efficient execution workloads, real cases adoptions, and infrastructure integration among others. Software aspects as frameworks and toolchain infrastructure for deploying a solution should be also evaluated, as well as the integration on the IoT dashboards for collection and analyzing\n\n\nAssigned groups:\n\n\n\n\n\n\n\n\nGroup\n\n\nMember 1\n\n\nMember 2\n\n\nMember 3\n\n\n\n\n\n\n\n\n\n\n1\n\n\nGongLu Zou\n\n\nFengfeng Gu\n\n\nBinz Zhang\n\n\n\n\n\n\n2\n\n\nYouran Tian\n\n\nJun Shou",
            "title": "TFM"
        },
        {
            "location": "/General/TFM/#final-project-proposals",
            "text": "",
            "title": "Final project proposals"
        },
        {
            "location": "/General/TFM/#important-dates",
            "text": "Deadline for proposal selection:  February 10  Deadline for proposal notifications:  February 17  Deadline for final deliverables (PDF report, video presentation and supplementary material):  June 27  Final defenses:  July 11-15",
            "title": "Important dates"
        },
        {
            "location": "/General/TFM/#description-and-rules",
            "text": "The Final Project is a research or development work that aims at demonstrating\nthat the student has acquired the necessary knowledge and skills \nassociated to the Master's Degree, and it will be developed  in groups of three students  under the supervision of one \nor more professors.  The contents to develop for each project proposal will depend on the specific\nselected topic, and they will range from designing and developing\na specific IoT application/deployment, service or system within\nthe field of Internet of Things, or theoretical in-depth \nstudies of state-of-the-art topics related with IoT. \nIn all cases, the contents will extend and integrate knowledge \nand skills studied throughout the different subjects.  The project will allow the students to relate practical aspects\nand professional issues with the topics covered within the development\nof one or more of the subjects covered in the Master, adapted to the\ninterests of the student.   The Advisor will define the topic and tasks to fulfill, and will guide\nthe students throughout the development of the work and the goals to\nachieve. He/she will organize activities to control the correct\ndevelopment of the work.  The estimated amount of time for each student is  300 hours of personal work .",
            "title": "Description and rules"
        },
        {
            "location": "/General/TFM/#evaluation",
            "text": "The evaluation of the Project will be carried out by a Committee that\nwill be composed by professors of the different subjects. In order\nto defend the work, the students will need to pass all the subjects in\nthe Master, and he/she will need a signed agreement from the Advisor\nstating his/her consent to proceed with the defense. This consent report\nwill include all the considerations necessary to assist the Committee\nin the evaluation of the work.   The students will present a report written in English, that will include,\nat least, an introduction, goal description and work plan (including a\ntask distribution among members of the group), together\nwith a critical discussion of the develped work and results, conclusions\nand related bibliography. The suggested length of the report is 50 pages .  The defense of the work will be carried out in two stages:   Video presentation delivered before the final deadline.  Public live session in which the members of the Committe will share with \nthe students the necessary questions and comments that help evaluating the \ndeveloped work. Questions will be addressed in general to all members of \nthe group, and also specifically to each member of the group.   In the following, we propose a number of topics proposed by professors\ncovering topics of interest. Up to two groups of 3 students can select\neach project. This selection will be communicated to \nJos\u00e9 Ignacio G\u00f3mez (jigomez@ucm.es) and Francisco Igual (figual@ucm.es) by mail before February 10 .  The work needs to be original and developed in groups of 3 students, clearly\ndefining the tasks to develop by each member of the group, in a balanced fashion.\nPlagiarism (from other students or third parties) will determine a fail\nin the final grade of the work for all members of the group.",
            "title": "Evaluation"
        },
        {
            "location": "/General/TFM/#deliverables",
            "text": "Each group will deliver three evidences of the developed work before the final\ndeadline:   Report in PDF format.  Presentation video of up to 30 mins. of duration.  Developed code (if applicable).   The dates and mechanisms to deliver the final report and to proceed with\nthe defense will be announced with enough time before the deadline.",
            "title": "Deliverables"
        },
        {
            "location": "/General/TFM/#proposals",
            "text": "",
            "title": "Proposals"
        },
        {
            "location": "/General/TFM/#proposal-1",
            "text": "Title:   Relation between air pollution, weather and traffic  Requirements:  good programming skills.  Professor:  Rafael Caballero Rold\u00e1n (rafacr@ucm.es)  Available slots:  2 groups  Description:   The goal is to predict the pollution in a particular point of a city for the next few hours. The prediction will take as input from the data collected by sensors of air pollution and number of vehicles. We will train different models and evaluate the results to choose the best predictions in each case. The project includes:   Basic data management to prepare the data  Basic statistics to understand the data and detect outliers  Clustering for selecting days with similar pollution/traffic conditions  Feature selection  Hiperparameter tunning  Model Selection   Assigned groups:     Group  Member 1  Member 2  Member 3      1  Qiuji Chen  Xiaolan Li  Zhao Hu",
            "title": "Proposal 1"
        },
        {
            "location": "/General/TFM/#proposal-2",
            "text": "Title:   Machine Learning Ensamble Methods  Requirements:  good programming skills.  Professor:  Rafael Caballero Rold\u00e1n (rafacr@ucm.es)  Available slots:  2 groups  Description:   The ensemble Methods combine several  weak learners  to build a more efficient method. The main goal is to implement in Spark the three main Methods (bagging, stacking and Boosting). On particular the project will include:   A complete description of the tecniques  A Spark function implementing them  A benchmark using some datasets of the course to compare their efficiency   Assigned groups:     Group  Member 1  Member 2  Member 3      1  Yan Zhao  JiePing You",
            "title": "Proposal 2"
        },
        {
            "location": "/General/TFM/#proposal-3",
            "text": "Title:   IoT devices or services for well-being  Professor:  Iv\u00e1n Garc\u00eda-Magari\u00f1o Garc\u00eda (igarciam@ucm.es)  Available slots:  2 groups  Description:   Well-being is usually desired by most people, and smart watches and smart bands are growing in\npopularity for such purpose. However, other IoT devices and services can help users to provide\naccurate perspectives of certain well-being aspects in order to provide personalized advices for\nincreasing the well-being. For example, smart beds can help you in tracking you sleeping, door\nsensors could measure the time spent in outdoor activities or the times you eat meals at home. All\nthis information related with emotional information could feed an intelligent system to output the\nright advices for increasing the well-being. This work could be conducted from either (1) a research\nperspective being relevant the analysis of existing works in this topic and the proposal of novel ideas,\nor (2) from a technical perspective addressing to program some intelligent system for providing well-\nbeing advices based on information from IoT devices.  Assigned groups:     Group  Member 1  Member 2  Member 3      1  Liu Jinhua  Duan Zhen  Hu Hao",
            "title": "Proposal 3"
        },
        {
            "location": "/General/TFM/#proposal-4",
            "text": "Title:   IoT devices or services for healthcare  Professor:  Iv\u00e1n Garc\u00eda-Magari\u00f1o Garc\u00eda (igarciam@ucm.es)  Available slots:  2 groups  Description:   Healthcare is benefiting from the growing of IoT. For instance, smart homes could track the progress\nof certain symptoms. Smart IoT dispensers can help patients in reminding their medication to avoid\nboth missing it and forgetting whether certain medication has been taken. This work could be\nconducted from either (1) a research perspective being relevant the analysis of existing works in this\ntopic and the proposal of novel ideas, or (2) from a technical perspective addressing to prototype a\ncertain IoT device or service and program the necessary software for providing a system that could\nhelp in some aspect of healthcare.  Assigned groups:     Group  Member 1  Member 2  Member 3      1  Shuishi Zhou  Yang Chu  Wenyan Liao    2  Dongyang Xu  Xueqing Zhao  Yujuan Huang",
            "title": "Proposal 4"
        },
        {
            "location": "/General/TFM/#proposal-5",
            "text": "Title:   OpenData iniciatives in China: situation, perspectives and use cases  Professors:  Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)  Requirements:  recommended, but not mandatory, basic programming skills.  Available slots:  2 groups  Description:   OpenData initiatives pursue offering data sources in an open, royalty-free and accessible manner. It follows a similar philosophy as that of Open Source or Open Hardware, and aims at facilitating data analysis to the community taken from official channels, both from Local or National Goverments, or from companies.  The goal of the project is two-fold: first, to provide a global, in-depth study and discussion of the OpenData initiatives in China, both from the Government and from Private Companies; second, to select a set of realistic use cases to perform specific data analysis oriented to real-world applications, mainly based on or with application to the IoT paradigm.   Assigned groups:     Group  Member 1  Member 2  Member 3      1  Junyan Guo  Jianchuang Zhang  Guanjie Xiao    2  Yinghua Liao  Jiali Gao  Xionglan Luo",
            "title": "Proposal 5"
        },
        {
            "location": "/General/TFM/#proposal-6",
            "text": "Title:   SmartCities: requirements, infrastructure and use cases  Professors:  Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)  Requirements:  no programming skills necessary.  Available slots:  2 groups  Description:   We have been using the term  Smart Cities  for many years now, but it still looks like a  to be defined  concept. There are many flavours in Smart Cities initiatives and many actors that play different roles in the process of implementing them.  Focusing on IoT, there is always a need to deploy an infrastructure that may represent a huge economical investment with some return expected (economic, social...).  The goal of this project is to deep into the idea of Smart Cities, starting with a general description of its typical topics: smart mobility, smart buildings, smart grid (energy distribution and savings), smart health, water supply, waste disposal facilities...  The students will choose two of those topic and provide an in-depth study of the requirements (sensors, nodes, edge computing, servers...) including the deployment and maintenance process.  The study must include at least two examples of existing cities implementing initiatives in the topics chosen (one Chinese and one European city, if possible). There are many questions this study may answer: how is a given project improving the quality of life of the citizens? Who is paying the cost of the infrastructure? What is the expected \"Return Of Investment\" (ROI)? Will there be shared infrastructures? (i.e. companies that deploy a sensor network and rent it to other companies/public organisations as a \"service\")  Assigned groups:     Group  Member 1  Member 2  Member 3      1  Zhijun Hao  Hongbiao Cao  Yuanshuang Sha    2  Jiayun Pan  WeiLin Zhang  YongTao He",
            "title": "Proposal 6"
        },
        {
            "location": "/General/TFM/#proposal-7",
            "text": "Title:   Building meshes with WiFi  Professors:  Francisco Igual and J. Ignacio G\u00f3mez (figual@ucm.es and jigomez@ucm.es)  Requirements:  good programming skills necessary.  Available slots:  2 groups  Description:   ESP-IDF provides a proprietary protocol, called  ESP-WIFI-MESH , that allows  numerous devices spread over a large physical area (both indoors and outdoors) to be interconnected under a single WLAN (Wireless Local-Area Network). ESP-WIFI-MESH is self-organizing and self-healing meaning the network can be built and maintained autonomously.  You can find information about ESP-WIFI-MESH in this link .  Some of those nodes (but not necessarily all of them) may have access to a router (border router) that provides access to the internet. The far-away nodes (those outside the range of the router) may still connect to the internet asking the intermediate nodes to relay their transmissions.  ESP-IDF also provides an API to access  Thread , an IPv6-based mesh networking technology for IoT. Once again, it allows a mesh of nodes to gain access to the internet even if they are not close to a border router.  More information about Thread can be found in this link .  The goal of this project is to build a mesh of ESP32 nodes using both technologies to comparte their APIs, capabilities and performance. The nodes will run simple applications (sensing temperature, for example) and will try to send the information to an external server using MQTT. Some of the nodes will be close to a router providing access to the internet (and thus, to the external server), while some others will be out of the range of the router signal.  The study should compare both implementations, trying to figure out the overheads of each implementation, relative performance, ease of use...  IMPORTANT : to perform this project, you will need more than 2 ESP32 boards, so the team partners should live close enough to physically meet to make tests.",
            "title": "Proposal 7"
        },
        {
            "location": "/General/TFM/#proposal-8",
            "text": "Title:   Lightweight Cryptography Applicable to IoT Devices  Professors:  Joaquin Recas (recas@ucm.es) and Guillermo Botella (gbotella@ucm.es)  Requirements:  good programming skills necessary.  Available slots:  2 groups  Description:   Cryptography in IoT requires a compromise between security, performance and cost. Performance refers to power consumption, latency, and throughput; the cost, to memory and CPU. The more secure an algorithm or protocol is, the more negative impact it will have on cost and performance. Similarly, if you want to improve performance or lower cost, you will have a negative impact on security.  The objective of this project is to test different publicly accessible encryption implementations that can be used in IoT systems and to make a comparative study on the three factors described above: security, performance and cost.",
            "title": "Proposal 8"
        },
        {
            "location": "/General/TFM/#proposal-9",
            "text": "Title:   SDR and GNU Radio to explore IoT vulnerabilities  Professors:  Joaquin Recas (recas@ucm.es) and Guillermo Botella (gbotella@ucm.es)  Requirements:  good programming skills necessary.  Available slots:  2 groups  Description:   Wireless communications still keep growing, becoming part of our daily lives with the aim of making it easier. For example through the use of wireless devices, home automation, industrial environments, among others that make up the Internet of Things. Sometimes, manufacturers of IoT devices focus to improve their functionality and make them more competitive in the market and do not pay sufficient attention to the security issue. Normally, the common user is not aware of the vulnerabilities of communications that are propagated by the air as used by IoT devices.\nThis work pretends to show the use of SDR and GNU Radio as tools to study and analyzing vulnerabilities over IoT communications through Radio Frequencies protocols (RF), getting interesting information such as operation frequency, modulation, applying reverse engineering and replay attack.",
            "title": "Proposal 9"
        },
        {
            "location": "/General/TFM/#proposal-10",
            "text": "Title:   Exploring Open Source IoT frameworks: Eclipse IoT and Zephyr OS  Professors:  Christian Tenllado (tenllado@ucm.es)  Requirements:  no programming skills necessary.  Available slots:  2 groups  Description:   The fast growth of IoT in recent years has lead to massive publications of tools and frameworks developed to work at different levels of the IoT ecosystem. A relevant part of them have ben released as Open Source, so they are specially interesting for small companies and start-ups wanting to contribute in this domain.  Eclipse IoT  is an initiative to gather a huge plethora of IoT technologies, backed up by the most relevant companies in this sector.   Zephyr  is  a Linux Foundation project releasing an open-source, product-ready RTOS (real-time operating system) for embedded systems (sensor nodes).   This project will extensively document the Eclipse IoT project, enumerating the existing projects and locating them in their target IoT system level: sensor node, gateway, edge, fog or cloud. Zephyr will be also considered in the studay, to explore how it fits the other existing projects. Once the most relevant  are described, several use cases will be considered, illustrating how a combination of different projects may help to develop a full IoT application, from sensor node programming, deployment, management, data collection  and processing.  Assigned groups:     Group  Member 1  Member 2  Member 3      1  Zhang Yi  Li Tianfeng  Re Wei    2  Xiazu Hu  Qinghong Yu  Suishi Liu",
            "title": "Proposal 10"
        },
        {
            "location": "/General/TFM/#proposal-11",
            "text": "Title:   Accelerators in Edge Computing  Professors:  Carlos Garc\u00eda (cgarcia@ucm.es)  Requirements:  no programming skills necessary.  Available slots:  2 groups  Description:   On one hand, the use of accelerators has been gaining importance in the context of the High Performance Computing arena to improve workload performance. On the other hand, with the exponential growth of data generation joint to the irruption of IoT devices at the edge, has meant the consideration of the use of accelerators in another context where accelerators were not initially designed. The future of computing is driven by the need to process data cost-effectively close to the data production. A single example of this tendency is the design and commercialization of specific ASICs to process powerful IA algorithms to speedup the response times with less power requirements.  This project proposal will research the use of accelerators such as GPUs, FPGAs, SMART-NICs in an IoT ecosystem. The project will not only focus on the diversity of hardware devices but also deepen on other aspects such as programmability, efficient execution workloads, real cases adoptions, and infrastructure integration among others. Software aspects as frameworks and toolchain infrastructure for deploying a solution should be also evaluated, as well as the integration on the IoT dashboards for collection and analyzing  Assigned groups:     Group  Member 1  Member 2  Member 3      1  GongLu Zou  Fengfeng Gu  Binz Zhang    2  Youran Tian  Jun Shou",
            "title": "Proposal 11"
        },
        {
            "location": "/General/",
            "text": "General information\n\n\n1st term\n - 19th Oct. 2021  till  13th Jan 2022\n\n\nUntil 31st October, Spanish time is UTC+2, so the FIRST TWO WEEKS courses will be starting at 18:00h in China Standard Time. Starting November, Spanish time will be UTC+1, so courses will be starting at 19:00h in China Standard Time.\n\n\n\n\n\n\n\n\nHours (Spanish time)\n\n\nTuesday\n\n\nWednesday\n\n\nThursday\n\n\n\n\n\n\n\n\n\n\n12:00-13:55\n\n\nMDM\n\n\nIOTNA\n\n\nMDM\n\n\n\n\n\n\n14:05-16:00\n\n\nSID\n\n\nSID\n\n\nIOTNA\n\n\n\n\n\n\n\n\n\n\nMDM\n: \nMassive Data Management\n.\n\n\nSID\n: \nSmart Infrastructures Design\n. \n\n\nIOTNA\n: \nIoT Node Architecture\n.\n\n\n\n\n2nd term \n - 18th Jan. 2022 till 7th Apr. 2022\n\n\nFrom 28th March, Spanish time will become UTC+2 again. Most of the courses of this term will take place at 19:00h  in China Standard Time.  But, the LAST TWO WEEKS will  be starting at 18:00h in China Standard Time.\n\n\n\n\n\n\n\n\nHours (Spanish time)\n\n\nTuesday\n\n\nWednesday\n\n\nThursday\n\n\n\n\n\n\n\n\n\n\n12:00-13:55\n\n\nNP2\n\n\nIA\n\n\nNP1\n\n\n\n\n\n\n14:05-16:00\n\n\nIA\n\n\nNP1\n\n\nNP2\n\n\n\n\n\n\n\n\n\n\nNP1\n: \nNetworks and Protocols I\n.\n\n\nNP2\n: \nNetworks and Protocols II\n.\n\n\nIA\n: \nArtificial Intelligence\n.\n\n\n\n\n3rd term\n - 19 Apr. till 3 Jun.\n\n\nAll courses will be starting at 19:00h in China Standard Time\n\n\n\n\n\n\n\n\nHours (UTC+2)\n\n\nTuesday\n\n\nWednesday\n\n\nThursday\n\n\n\n\n\n\n\n\n\n\n13:00-14:55\n\n\nEDGE\n\n\nEDGE\n\n\nEDGE\n\n\n\n\n\n\n15:05-17:00\n\n\nSEC\n\n\nSEC\n\n\nSEC\n\n\n\n\n\n\n\n\n\n\nEDGE\n: \nEdge Computing\n.\n\n\nSEC\n: \nSecurity\n.",
            "title": "Home"
        },
        {
            "location": "/General/#general-information",
            "text": "",
            "title": "General information"
        },
        {
            "location": "/General/#1st-term-19th-oct-2021-till-13th-jan-2022",
            "text": "Until 31st October, Spanish time is UTC+2, so the FIRST TWO WEEKS courses will be starting at 18:00h in China Standard Time. Starting November, Spanish time will be UTC+1, so courses will be starting at 19:00h in China Standard Time.     Hours (Spanish time)  Tuesday  Wednesday  Thursday      12:00-13:55  MDM  IOTNA  MDM    14:05-16:00  SID  SID  IOTNA      MDM :  Massive Data Management .  SID :  Smart Infrastructures Design .   IOTNA :  IoT Node Architecture .",
            "title": "1st term - 19th Oct. 2021  till  13th Jan 2022"
        },
        {
            "location": "/General/#2nd-term-18th-jan-2022-till-7th-apr-2022",
            "text": "From 28th March, Spanish time will become UTC+2 again. Most of the courses of this term will take place at 19:00h  in China Standard Time.  But, the LAST TWO WEEKS will  be starting at 18:00h in China Standard Time.     Hours (Spanish time)  Tuesday  Wednesday  Thursday      12:00-13:55  NP2  IA  NP1    14:05-16:00  IA  NP1  NP2      NP1 :  Networks and Protocols I .  NP2 :  Networks and Protocols II .  IA :  Artificial Intelligence .",
            "title": "2nd term  - 18th Jan. 2022 till 7th Apr. 2022"
        },
        {
            "location": "/General/#3rd-term-19-apr-till-3-jun",
            "text": "All courses will be starting at 19:00h in China Standard Time     Hours (UTC+2)  Tuesday  Wednesday  Thursday      13:00-14:55  EDGE  EDGE  EDGE    15:05-17:00  SEC  SEC  SEC      EDGE :  Edge Computing .  SEC :  Security .",
            "title": "3rd term - 19 Apr. till 3 Jun."
        },
        {
            "location": "/News/",
            "text": "News and announcements\n\n\n\n\nTest announcement - Jan 1st\n\n\nThis is a test announcement.\n\n\n\n\n\n\nTest alert - Jan 1st\n\n\nThis is a test alert.",
            "title": "Home"
        },
        {
            "location": "/News/#news-and-announcements",
            "text": "Test announcement - Jan 1st  This is a test announcement.    Test alert - Jan 1st  This is a test alert.",
            "title": "News and announcements"
        },
        {
            "location": "/Subjects/EDGE/groups/",
            "text": "Groups for lecture assignments\n\n\nWe will be using the stable groups from EDGE to work during lab lectures.\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\n\n\nGroup 2\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nLiu Jinhua\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nWeilin Zhang\n\n\n\n\n\n\nContributor\n\n\nDuan Zhen\n\n\n\n\n\n\nContributor\n\n\nYouran Tian\n\n\n\n\n\n\nContributor\n\n\nHuang Yujuan\n\n\n\n\n\n\nContributor\n\n\nJun Shou\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nYuanShuang Sha\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\nContributor\n\n\nLIAO  Yinghua\n\n\n\n\n\n\nContributor\n\n\nPAN Jiayun\n\n\n\n\n\n\nContributor\n\n\nZHANG  Yi\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nWEI REN\n\n\n\n\n\n\nContributor\n\n\nXIAZU HU\n\n\n\n\n\n\n\n\nGroup 5\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nShuishi Zhou\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nAuditor\n\n\nWENYAN LIAO\n\n\n\n\n\n\nContributor\n\n\nFENGFENG GU\n\n\n\n\n\n\nContributor\n\n\nBIN ZHANG\n\n\n\n\n\n\nContributor\n\n\nHONGBIAO CAO\n\n\n\n\n\n\nContributor\n\n\nGONGLU ZOU\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nXionglan Luo\n\n\n\n\n\n\nAuditor\n\n\nQiuji Chen\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang\n\n\n\n\n\n\nContributor\n\n\nYan Zhao\n\n\n\n\n\n\nContributor\n\n\nYongtao He\n\n\n\n\n\n\nContributor\n\n\nZhao Hu",
            "title": "Groups"
        },
        {
            "location": "/Subjects/EDGE/groups/#groups-for-lecture-assignments",
            "text": "We will be using the stable groups from EDGE to work during lab lectures.",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-1",
            "text": "Rol  Full name      Speaker  ZHOU Ping",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-2",
            "text": "Rol  Full name      Speaker  Liu Jinhua    Recorder  Hu Haho    Auditor  Weilin Zhang    Contributor  Duan Zhen    Contributor  Youran Tian    Contributor  Huang Yujuan    Contributor  Jun Shou",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-3",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  YuanShuang Sha    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao    Contributor  LIAO  Yinghua    Contributor  PAN Jiayun    Contributor  ZHANG  Yi",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-4",
            "text": "Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG YU    Auditor  SUIZHI LIU    Contributor  TIANFENG LI    Contributor  WEI REN    Contributor  XIAZU HU",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-5",
            "text": "Rol  Full name      Speaker  Shuishi Zhou    Contributor  Yang Chu    Auditor  WENYAN LIAO    Contributor  FENGFENG GU    Contributor  BIN ZHANG    Contributor  HONGBIAO CAO    Contributor  GONGLU ZOU",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/EDGE/groups/#group-6",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Xionglan Luo    Auditor  Qiuji Chen    Contributor  Jianchuang Zhang    Contributor  Yan Zhao    Contributor  Yongtao He    Contributor  Zhao Hu",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/EDGE/",
            "text": "EDGE\n\n\nGeneral information\n\n\nThis subject will cover concepts related to edge computing. On the one hand, the new processing paradigm close to its generation will be presented, and on the other, the Jetson-Nano development board will be experimented with these concepts. These board allows not only processing information with an internal accelerator as GPU but also transfered it through the Internet.\n\n\nSubject program and evaluation methodology\n\n\nProgram and evaluation\n\n\nWork groups (for regular lab assignments)\n\n\nHere you can find the \ncurrent work groups\n\n\nProfessors\n\n\nLuis Pi\u00f1uel Moreno (lpinuel@ucm.es) and Carlos Garc\u00eda S\u00e1nchez (garsanca@ucm.es)\n\n\nQuizzes\n\n\nFor all quizzes will you are requested to use your e-mail address as name. All of them can be accessed directly from this \nlink\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay\n\n\nTopic\n\n\nLab instructions\n\n\nDeliverable\n\n\nProfessor\n\n\n\n\n\n\n\n\n\n\n19/4\n\n\nIntroduction Edge-Computing\n\n\nWeek1\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n20/4\n\n\nSetup Jetson-Nano\n\n\nInstallation\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n21/4\n\n\nIntro Inference Hw\n\n\n\n\n\n\nL. Pi\u00f1uel\n\n\n\n\n\n\n26/4\n\n\nArtificial Inteligence\n\n\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n27/4\n\n\nSetup Raspberry-Pi camera\n\n\nSetup\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n28/4\n\n\nInference Hw\n\n\n\n\n\n\nL. Pi\u00f1uel\n\n\n\n\n\n\n3/5\n\n\nContainers\n\n\nSetup\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n4/5\n\n\nContainers ML\n\n\nSetupML\n\n\nTasks\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n5/5\n\n\nVideo-presentation (Hw inference)\n\n\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n10/5\n\n\nOpenCV with Jetson\n\n\nNotebooks BO\n\n\nQUIZ Lab1\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n11/5\n\n\nOpenCV with Jetson\n\n\npython examples\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n12/5\n\n\nOpenCV with Jetson\n\n\nNotebooks IP\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n17/5\n\n\nOpenCV with Jetson\n\n\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n18/5\n\n\nOpenCV with Jetson\n\n\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n19/5\n\n\nOpenCV with Jetson\n\n\n\n\nTasks\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n24/5\n\n\nInference Image Classifying\n\n\nModels\n for Image Classification\n\n\nQUIZ Lab2\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n25/5\n\n\nOwn Image Recognition\n\n\nCat_Dog Dataset\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n26/5\n\n\nOwn Image Recognition\n\n\n\n\nIoT Mask\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n31/5\n\n\nObject Detection\n\n\nModels\n\n\nQUIZ Lab3\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n1/5\n\n\nOwn object Detection\n\n\n\n\n\n\nC. Garc\u00eda\n\n\n\n\n\n\n2/5\n\n\nBuild a IoT problem\n\n\n\n\nQUIZ Lab4\n\n\nC. Garc\u00eda",
            "title": "Home"
        },
        {
            "location": "/Subjects/EDGE/#edge",
            "text": "",
            "title": "EDGE"
        },
        {
            "location": "/Subjects/EDGE/#general-information",
            "text": "This subject will cover concepts related to edge computing. On the one hand, the new processing paradigm close to its generation will be presented, and on the other, the Jetson-Nano development board will be experimented with these concepts. These board allows not only processing information with an internal accelerator as GPU but also transfered it through the Internet.",
            "title": "General information"
        },
        {
            "location": "/Subjects/EDGE/#subject-program-and-evaluation-methodology",
            "text": "Program and evaluation",
            "title": "Subject program and evaluation methodology"
        },
        {
            "location": "/Subjects/EDGE/#work-groups-for-regular-lab-assignments",
            "text": "Here you can find the  current work groups",
            "title": "Work groups (for regular lab assignments)"
        },
        {
            "location": "/Subjects/EDGE/#professors",
            "text": "Luis Pi\u00f1uel Moreno (lpinuel@ucm.es) and Carlos Garc\u00eda S\u00e1nchez (garsanca@ucm.es)",
            "title": "Professors"
        },
        {
            "location": "/Subjects/EDGE/#quizzes",
            "text": "For all quizzes will you are requested to use your e-mail address as name. All of them can be accessed directly from this  link",
            "title": "Quizzes"
        },
        {
            "location": "/Subjects/EDGE/#schedule",
            "text": "Day  Topic  Lab instructions  Deliverable  Professor      19/4  Introduction Edge-Computing  Week1   C. Garc\u00eda    20/4  Setup Jetson-Nano  Installation   C. Garc\u00eda    21/4  Intro Inference Hw    L. Pi\u00f1uel    26/4  Artificial Inteligence    C. Garc\u00eda    27/4  Setup Raspberry-Pi camera  Setup   C. Garc\u00eda    28/4  Inference Hw    L. Pi\u00f1uel    3/5  Containers  Setup   C. Garc\u00eda    4/5  Containers ML  SetupML  Tasks  C. Garc\u00eda    5/5  Video-presentation (Hw inference)    C. Garc\u00eda    10/5  OpenCV with Jetson  Notebooks BO  QUIZ Lab1  C. Garc\u00eda    11/5  OpenCV with Jetson  python examples   C. Garc\u00eda    12/5  OpenCV with Jetson  Notebooks IP   C. Garc\u00eda    17/5  OpenCV with Jetson    C. Garc\u00eda    18/5  OpenCV with Jetson    C. Garc\u00eda    19/5  OpenCV with Jetson   Tasks  C. Garc\u00eda    24/5  Inference Image Classifying  Models  for Image Classification  QUIZ Lab2  C. Garc\u00eda    25/5  Own Image Recognition  Cat_Dog Dataset   C. Garc\u00eda    26/5  Own Image Recognition   IoT Mask  C. Garc\u00eda    31/5  Object Detection  Models  QUIZ Lab3  C. Garc\u00eda    1/5  Own object Detection    C. Garc\u00eda    2/5  Build a IoT problem   QUIZ Lab4  C. Garc\u00eda",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/EDGE/Week1/assigments_Jetson-Nano/",
            "text": "Week1&2&3: Introduction & Setup JetsonNano\n\n\nSumary\n\n\n\n\nSetting up Jetson with JetPack\n\n\nRunning the Docker Container\n\n\nThe containers use the \nl4t-pytorch\n base container, so support for transfer learning / re-training is already included\n\n\n\n\n\n\nHow to connect CSI Camera\n to the Jetson-Nano can be followed \n\n\n\n\nAssigments\n\n\n\n\nAll the assigments related to the setup of Jetson-Nano should be sent to professor by email. As a \nSubject\n write \"[IoT-DA Edge] Assignments Weeks1&2&3\"\n\n\n\n\n\n\nAssign 1\n\n\n\n\nImage classification using the \nimagenet\n script with an input example \nimages/strawberry_0.jpg\n\n\n\n\n\n\n\n\nAssign 2\n\n\n\n\nTest Pedestrian Detection example running the \ndetectnet\n script with an input example data/images/peds_3.jpg\n\n\nDownload test video with the next command and test *\ndetectnet\n with pedestrians as output\n\n\n\n\n\n\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# wget https://nvidia.box.com/shared/static/veuuimq6pwvd62p9fresqhrrmfqz0e2f.mp4 -O images/pedestrians.mp4\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/pedestrians.mp4 images/test/pedestrians.mp4\n\n\n\n\n\n\n\nAssign 3\n\n\n\n\nCreate a \nJupyter Notebook\n that \n\n\nPrints on the screen \"Hello World\" with the python command \nprint\n. More info about how to use \nprint\n could be found in the \nlink\n\n\nGiven to vectors \nx = [5, 10, -5, 6, 9]\n and \ny = [4, -7, -1, 0.5, 8]\n write a for-loop that compute the dot product of x and y",
            "title": "assigments Jetson Nano"
        },
        {
            "location": "/Subjects/EDGE/Week1/assigments_Jetson-Nano/#week123-introduction-setup-jetsonnano",
            "text": "",
            "title": "Week1&amp;2&amp;3: Introduction &amp; Setup JetsonNano"
        },
        {
            "location": "/Subjects/EDGE/Week1/assigments_Jetson-Nano/#sumary",
            "text": "Setting up Jetson with JetPack  Running the Docker Container  The containers use the  l4t-pytorch  base container, so support for transfer learning / re-training is already included    How to connect CSI Camera  to the Jetson-Nano can be followed",
            "title": "Sumary"
        },
        {
            "location": "/Subjects/EDGE/Week1/assigments_Jetson-Nano/#assigments",
            "text": "All the assigments related to the setup of Jetson-Nano should be sent to professor by email. As a  Subject  write \"[IoT-DA Edge] Assignments Weeks1&2&3\"    Assign 1   Image classification using the  imagenet  script with an input example  images/strawberry_0.jpg     Assign 2   Test Pedestrian Detection example running the  detectnet  script with an input example data/images/peds_3.jpg  Download test video with the next command and test * detectnet  with pedestrians as output    root@jetson-nano:/jetson-inference/build/aarch64/bin# wget https://nvidia.box.com/shared/static/veuuimq6pwvd62p9fresqhrrmfqz0e2f.mp4 -O images/pedestrians.mp4\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/pedestrians.mp4 images/test/pedestrians.mp4   Assign 3   Create a  Jupyter Notebook  that   Prints on the screen \"Hello World\" with the python command  print . More info about how to use  print  could be found in the  link  Given to vectors  x = [5, 10, -5, 6, 9]  and  y = [4, -7, -1, 0.5, 8]  write a for-loop that compute the dot product of x and y",
            "title": "Assigments"
        },
        {
            "location": "/Subjects/EDGE/Week1/",
            "text": "Week1: Introduction\n\n\nIntroduction\n\n\n\n\nStudents can find two pdf file with the slides corresponding to Introduction:\n\n\nA general \nIntroduction\n of Edge Computing with the motivation and evolution of IoT tecnology\n\n\nMoreover, in the \nArtificial Inteligence\n slides, a brief introduction to artificial intelligence, as well as the difference between machine learning and deep-learning will be deepened. Finally, in this group of slides, the trend in the use of hardware systems in edge computing where the use of AI is widespread will be addressed to present the Jetson-Nano device on which most of the subject will be carried out.\n\n\n\n\n\n\n\n\nJetson-Nano Setup\n\n\n\n\nStudents will have a Jetson Nano device to perform the tasks related with the subject. This developer kit should be configured properly, a microSD image can be downloaded from the \nlink\n. This image can be \nflashed into an SD card\n to dispose the Jetson-Nano running properly. However, the following transparencies available sumarized the process:\n\n\nInstallation guide\n and manual setup of the system image\n\n\nA tutorial is also available to \nconfigure the Raspberry-Pi camera",
            "title": "Home"
        },
        {
            "location": "/Subjects/EDGE/Week1/#week1-introduction",
            "text": "",
            "title": "Week1: Introduction"
        },
        {
            "location": "/Subjects/EDGE/Week1/#introduction",
            "text": "Students can find two pdf file with the slides corresponding to Introduction:  A general  Introduction  of Edge Computing with the motivation and evolution of IoT tecnology  Moreover, in the  Artificial Inteligence  slides, a brief introduction to artificial intelligence, as well as the difference between machine learning and deep-learning will be deepened. Finally, in this group of slides, the trend in the use of hardware systems in edge computing where the use of AI is widespread will be addressed to present the Jetson-Nano device on which most of the subject will be carried out.",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/EDGE/Week1/#jetson-nano-setup",
            "text": "Students will have a Jetson Nano device to perform the tasks related with the subject. This developer kit should be configured properly, a microSD image can be downloaded from the  link . This image can be  flashed into an SD card  to dispose the Jetson-Nano running properly. However, the following transparencies available sumarized the process:  Installation guide  and manual setup of the system image  A tutorial is also available to  configure the Raspberry-Pi camera",
            "title": "Jetson-Nano Setup"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/",
            "text": "Week1: Introduction & Setup JetsonNano\n\n\n\n\nMost of this workshop is available in \nYouTube\n. Fell free to watch by yourself\n\n\n\n\nSystem Installation\n\n\n\n\nSetting up Jetson with JetPack\n\n\n\n\nGet Stated\n\n\n\n\nWrite Image to the microSD Card\n\n\nSetup and First Boot\n\n\n\n\nWrite Image to the microSD Card\n\n\n\n\nDownload SD image from \\url{https://developer.nvidia.com/embedded/downloads}\n\n\nIMPORTANT: if you have Jetson-Nano 2GB please download \nJetson Nano 2GB Developer Kit SD Card Image v4.6.1\n\n\n\n\n\n\nBurn the image in a SD Card depending on you own PC Operating System\n\n\nFor Windows link\n \n\n\nFor MacOS link\n \n\n\nFor Linux link\n\n\n\n\n\n\n\n\nBurning tool\n\n\n\n\nFlash OS image to SD card with \nbalena\n\n\nSuperuser rights\n are required \n\n\n\n\n\n\nSetup and First Boot\n\n\n\n\nConnect the Jetson-Nano board to HDMI connector\n\n\nInsert the SD-Card \npreviously burnt\n\n\nPower on your computer display and connect it\n\n\nConnect the USB \nkeyboard\n and \nmouse\n\n\nIt is mandatory to first boot\n\n\n\n\n\n\nConnect your Micro-USB power supply \n\n\nThe developer kit will power on and boot automatically\n\n\n\n\n\n\n\n\n\n\nFirst Boot\n\n\n\n\nGreen LED will be lighted on\n\n\nWhen you boot the first time, the developer kit will take you through some initial setup, including:\n\n\nReview and accept NVIDIA Jetson software EULA\n\n\nSelect system language, keyboard layout, and time zone\n\n\nCreate username, password, and computer name (user: \nnano\n, passwd: \nnano_pass\n)\n\n\nSelect APP partition size-it is recommended to use the max size suggested\n\n\n\n\n\n\n\n\nSteps\n\n\nStep 1\n\n\n\n\nReview and accept NVIDIA Jetson software EULA\n\n\n\n\n\n\nStep 2\n\n\n\n\nSelect system language, keyboard layout, and time zone\n\n\n\n\n\n\nStep 3\n\n\n\n\nCreate username, password, and computer name (user: \nnano\n, passwd: \nnano_pass\n)\n\n\n\n\n\n\nStep 4\n\n\n\n\nSelect APP partition size-it is recommended to use the max size suggested\n\n\n\n\n\n\n\n\n\n\nStep 5\n\n\n\n\nFinal system configuration\n\n\n\n\n\n\n\n\nDesktop\n\n\n\n\nUpdating the system\n\n\nnano@jetson-nano~:$ sudo apt-get update\nnano@jetson-nano~:$ sudo apt-get upgrade",
            "title": "install Jetson Nano"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#week1-introduction-setup-jetsonnano",
            "text": "Most of this workshop is available in  YouTube . Fell free to watch by yourself",
            "title": "Week1: Introduction &amp; Setup JetsonNano"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#system-installation",
            "text": "Setting up Jetson with JetPack",
            "title": "System Installation"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#get-stated",
            "text": "Write Image to the microSD Card  Setup and First Boot",
            "title": "Get Stated"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#write-image-to-the-microsd-card",
            "text": "Download SD image from \\url{https://developer.nvidia.com/embedded/downloads}  IMPORTANT: if you have Jetson-Nano 2GB please download  Jetson Nano 2GB Developer Kit SD Card Image v4.6.1    Burn the image in a SD Card depending on you own PC Operating System  For Windows link    For MacOS link    For Linux link",
            "title": "Write Image to the microSD Card"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#burning-tool",
            "text": "Flash OS image to SD card with  balena  Superuser rights  are required",
            "title": "Burning tool"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#setup-and-first-boot",
            "text": "Connect the Jetson-Nano board to HDMI connector  Insert the SD-Card  previously burnt  Power on your computer display and connect it  Connect the USB  keyboard  and  mouse  It is mandatory to first boot    Connect your Micro-USB power supply   The developer kit will power on and boot automatically",
            "title": "Setup and First Boot"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#first-boot",
            "text": "Green LED will be lighted on  When you boot the first time, the developer kit will take you through some initial setup, including:  Review and accept NVIDIA Jetson software EULA  Select system language, keyboard layout, and time zone  Create username, password, and computer name (user:  nano , passwd:  nano_pass )  Select APP partition size-it is recommended to use the max size suggested",
            "title": "First Boot"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#steps",
            "text": "",
            "title": "Steps"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#step-1",
            "text": "Review and accept NVIDIA Jetson software EULA",
            "title": "Step 1"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#step-2",
            "text": "Select system language, keyboard layout, and time zone",
            "title": "Step 2"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#step-3",
            "text": "Create username, password, and computer name (user:  nano , passwd:  nano_pass )",
            "title": "Step 3"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#step-4",
            "text": "Select APP partition size-it is recommended to use the max size suggested",
            "title": "Step 4"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#step-5",
            "text": "Final system configuration",
            "title": "Step 5"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#desktop",
            "text": "",
            "title": "Desktop"
        },
        {
            "location": "/Subjects/EDGE/Week1/install_Jetson-Nano/#updating-the-system",
            "text": "nano@jetson-nano~:$ sudo apt-get update\nnano@jetson-nano~:$ sudo apt-get upgrade",
            "title": "Updating the system"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/",
            "text": "Week1&2: Introduction & Setup JetsonNano\n\n\n\n\nMost of this workshop is available in \nYouTube\n. Fell free to watch by yourself\n\n\n\n\nHello AI World\n\n\nHello AI World can be run completely onboard your Jetson, including inferencing with TensorRT and transfer learning with PyTorch.  The inference portion of Hello AI World - which includes coding your own image classification and object detection applications for Python or C++, and live camera demos - can be run on your Jetson in roughly two hours or less, while transfer learning is best left to leave running overnight.\n\n\nSystem Setup (previously done)\n\n\n\n\nSetting up Jetson with JetPack\n\n\nRunning the Docker Container\n\n\n\n\nCamera Setup\n\n\n\n\nInstruction about \nHow to connect CSI Camera\n to the Jetson-Nano can be followed \n\n\n\n\n\n\nAssignment 1\n\n\nTest your camera is running according as the new instructions.\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\n\n\nTesting your camera running. Most of the information is extracted from \nthis link\n\n\nTo check CSI camera, you can run \nnvgstcapture-1.0\n, which will start capture and preview display it on the screen:\n\n\n\n\n\n\n\n\nnano@jetson-nano:~$ nvgstcapture-1.0 \nEncoder null, cannot set bitrate!\nEncoder Profile = High\nSupported resolutions in case of ARGUS Camera\n  (2) : 640x480\n  (3) : 1280x720\n  (4) : 1920x1080\n.....\n\n\n\n\n\n\nCheck rotation \n\n\nThis example command will rotate the image 180 degrees (vertical flip)\n\n\n\n\nnano@jetson-nano:~$ nvgstcapture-1.0 --orientation 2\n.....\n\n\n\n\nTake a picture and save to disk\n\n\n\n\nConnect CSI camera\n\n\nExecute in a shell the command \nnvgstcapture-1.0 --automate --capture-auto\n\n\nOpen File with \neog nvcamtest_XX.jpg\n\n\n\n\nCapture a video and save to disk\n\n\n\n\nConnect CSI camera\n\n\nExecute in a shell the command \nnvgstcapture-1.0 --mode=2 --automate --capture-auto\n\n\nApplication will record 10 seconds of video\n\n\nPlay File recorded with \ntotem nvcamtest_XX.mp4\n\n\n\n\n\n\nHomework (Optional)\n\n\nAccording to the \noptions available in the nvgstcapture-1.0 functionality\n, control and adjust the lighting conditions\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\nSetup Container\n\n\n\n\nThere are several pre-configured containers to be able to use the Jetson-Nano board\n\n\nThe most common are related to their use for artificial intelligence and machine learning. The most \npopular containers\n hosted on NVIDIA GPU Cloud (NGC) are the following Docker container images for machine learning on Jetson:\n\n\nl4t-ml\n\n\nl4t-pytorch\n\n\nl4t-tensorflow\n\n\n\n\n\n\n\n\nRunning Docker Container\n\n\n\n\nThe \npre-built Docker container images\n for this lab are hosted on \nDockerHub\n\n\nThe containers use the \nl4t-pytorch\n base container, so support for transfer learning / re-training is already included\n\n\n\n\n\n\n\n\n\n\nInference instructions\n\n\n\n\nFollow the \ngithub repo instructions\n to install the docker image in the Jetson-Nano\n\n\n\n\nnano@jetson-nano:~$ git clone --recursive https://github.com/dusty-nv/jetson-inference\nCloning into 'jetson-inference'...\nremote: Enumerating objects: 20861, done.\n....\n\n\n\n\nLaunching the Container\n\n\n\n\nIt's recommended to use the script \ndocker/run.sh\n script to run the container\n\n\ndocker/run.sh\n will automatically pull the correct container tag from DockerHub based on your currently-installed version of JetPack-L4T\n\n\nIMPORTANT: if you are using CSI (Rpi Camera): \n--volume /tmp/argus_socket:/tmp/argus_socket\n\n\n\n\n\n\n\n\nnano@jetson-nano:~$ cd jetson-inference/\nnano@jetson-nano:~/jetson-inference$ docker/run.sh --volume /tmp/argus_socket:/tmp/argus_socket\nreading L4T version from /etc/nv_tegra_release\nL4T BSP Version:  L4T R32.6.1\n[sudo] password for nano: \nsize of data/networks:  79397 bytes\n.....\n\n\n\n\n\n\nFor reference, the following paths automatically get mounted from your host device into the container:\n\n\njetson-inference/data\n (stores the network models, serialized TensorRT engines, and test images)\n\n\njetson-inference/python/training/classification/data\n (stores classification training datasets)\n\n\njetson-inference/python/training/classification/models\n (stores classification models trained by PyTorch)\n\n\njetson-inference/python/training/detection/ssd/data\n (stores detection training datasets)\n\n\njetson-inference/python/training/detection/ssd/models\n (stores detection models trained by PyTorch)\n\n\n\n\n\n\n\n\nRunning applications\n\n\n\n\nOnce the container is up and running, you can then run example programs from the tutorial like normal inside the container:\n\n\n\n\nroot@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./video-viewer\n# (press Ctrl+D to exit the container)\n\n\n\n\n\n\nAssignment 3\n\n\nTest your camera is running in the Docker Image through the \nvideo-viewer\n script\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\nInference of Image Classification\n\n\nroot@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/jellyfish.jpg images/test/jellyfish.jpg\n\n\n\n\n\n\nNote that \nimagenet\n app \nclassifies\n the image \njellyfish.jpg\n as a \njellyfish\n and store the image solution in the path \ndata/images/test\n with a confidence of 99.85%\n\n\n\n\n\n\n\n\nAssignment 4\n\n\nTest Image Classification example running in the Docker Image through the \nimagenet\n script\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\nInference of Object Detection\n\n\nroot@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/peds_0.jpg images/test/peds_0.jpg\n\n\n\n\n\n\nNote that \ndetectnet\n app detects four persons with a confidence of 70.0%, 97.6%, 98.4% and 86.1% and store the image solution in path \ndata/images/test\n\n\n\n\n\n\n\n\nAssignment 5\n\n\nTest Pedestrian Detection example running in the Docker Image through the \ndetectnet\n script\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\nUsing other IA Models\n\n\n\n\nYou can Download other models with the script \ndownload-models.sh\n\n\n\n\n\n\nnano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh\n\n\n\n\n\n\nHomework (Optional)\n\n\nYou can test other image classification models, object detection, etc. by making use of the \ndownload-models.sh\n script and launching the inference with the option \n--network\n\n\n\n\nPlease send a message to the professor as soon as you finished",
            "title": "setup Jetson Nano"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#week12-introduction-setup-jetsonnano",
            "text": "Most of this workshop is available in  YouTube . Fell free to watch by yourself",
            "title": "Week1&amp;2: Introduction &amp; Setup JetsonNano"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#hello-ai-world",
            "text": "Hello AI World can be run completely onboard your Jetson, including inferencing with TensorRT and transfer learning with PyTorch.  The inference portion of Hello AI World - which includes coding your own image classification and object detection applications for Python or C++, and live camera demos - can be run on your Jetson in roughly two hours or less, while transfer learning is best left to leave running overnight.",
            "title": "Hello AI World"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#system-setup-previously-done",
            "text": "Setting up Jetson with JetPack  Running the Docker Container",
            "title": "System Setup (previously done)"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#camera-setup",
            "text": "Instruction about  How to connect CSI Camera  to the Jetson-Nano can be followed     Assignment 1  Test your camera is running according as the new instructions.   Please send a message to the professor as soon as you finished   Testing your camera running. Most of the information is extracted from  this link  To check CSI camera, you can run  nvgstcapture-1.0 , which will start capture and preview display it on the screen:     nano@jetson-nano:~$ nvgstcapture-1.0 \nEncoder null, cannot set bitrate!\nEncoder Profile = High\nSupported resolutions in case of ARGUS Camera\n  (2) : 640x480\n  (3) : 1280x720\n  (4) : 1920x1080\n.....   Check rotation   This example command will rotate the image 180 degrees (vertical flip)   nano@jetson-nano:~$ nvgstcapture-1.0 --orientation 2\n.....",
            "title": "Camera Setup"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#take-a-picture-and-save-to-disk",
            "text": "Connect CSI camera  Execute in a shell the command  nvgstcapture-1.0 --automate --capture-auto  Open File with  eog nvcamtest_XX.jpg",
            "title": "Take a picture and save to disk"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#capture-a-video-and-save-to-disk",
            "text": "Connect CSI camera  Execute in a shell the command  nvgstcapture-1.0 --mode=2 --automate --capture-auto  Application will record 10 seconds of video  Play File recorded with  totem nvcamtest_XX.mp4    Homework (Optional)  According to the  options available in the nvgstcapture-1.0 functionality , control and adjust the lighting conditions   Please send a message to the professor as soon as you finished",
            "title": "Capture a video and save to disk"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#setup-container",
            "text": "There are several pre-configured containers to be able to use the Jetson-Nano board  The most common are related to their use for artificial intelligence and machine learning. The most  popular containers  hosted on NVIDIA GPU Cloud (NGC) are the following Docker container images for machine learning on Jetson:  l4t-ml  l4t-pytorch  l4t-tensorflow",
            "title": "Setup Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#running-docker-container",
            "text": "The  pre-built Docker container images  for this lab are hosted on  DockerHub  The containers use the  l4t-pytorch  base container, so support for transfer learning / re-training is already included",
            "title": "Running Docker Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#inference-instructions",
            "text": "Follow the  github repo instructions  to install the docker image in the Jetson-Nano   nano@jetson-nano:~$ git clone --recursive https://github.com/dusty-nv/jetson-inference\nCloning into 'jetson-inference'...\nremote: Enumerating objects: 20861, done.\n....",
            "title": "Inference instructions"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#launching-the-container",
            "text": "It's recommended to use the script  docker/run.sh  script to run the container  docker/run.sh  will automatically pull the correct container tag from DockerHub based on your currently-installed version of JetPack-L4T  IMPORTANT: if you are using CSI (Rpi Camera):  --volume /tmp/argus_socket:/tmp/argus_socket     nano@jetson-nano:~$ cd jetson-inference/\nnano@jetson-nano:~/jetson-inference$ docker/run.sh --volume /tmp/argus_socket:/tmp/argus_socket\nreading L4T version from /etc/nv_tegra_release\nL4T BSP Version:  L4T R32.6.1\n[sudo] password for nano: \nsize of data/networks:  79397 bytes\n.....   For reference, the following paths automatically get mounted from your host device into the container:  jetson-inference/data  (stores the network models, serialized TensorRT engines, and test images)  jetson-inference/python/training/classification/data  (stores classification training datasets)  jetson-inference/python/training/classification/models  (stores classification models trained by PyTorch)  jetson-inference/python/training/detection/ssd/data  (stores detection training datasets)  jetson-inference/python/training/detection/ssd/models  (stores detection models trained by PyTorch)",
            "title": "Launching the Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#running-applications",
            "text": "Once the container is up and running, you can then run example programs from the tutorial like normal inside the container:   root@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./video-viewer\n# (press Ctrl+D to exit the container)   Assignment 3  Test your camera is running in the Docker Image through the  video-viewer  script   Please send a message to the professor as soon as you finished",
            "title": "Running applications"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#inference-of-image-classification",
            "text": "root@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/jellyfish.jpg images/test/jellyfish.jpg   Note that  imagenet  app  classifies  the image  jellyfish.jpg  as a  jellyfish  and store the image solution in the path  data/images/test  with a confidence of 99.85%     Assignment 4  Test Image Classification example running in the Docker Image through the  imagenet  script   Please send a message to the professor as soon as you finished",
            "title": "Inference of Image Classification"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#inference-of-object-detection",
            "text": "root@jetson-nano:/jetson-inference# cd build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/peds_0.jpg images/test/peds_0.jpg   Note that  detectnet  app detects four persons with a confidence of 70.0%, 97.6%, 98.4% and 86.1% and store the image solution in path  data/images/test     Assignment 5  Test Pedestrian Detection example running in the Docker Image through the  detectnet  script   Please send a message to the professor as soon as you finished",
            "title": "Inference of Object Detection"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_Jetson-Nano/#using-other-ia-models",
            "text": "You can Download other models with the script  download-models.sh    nano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh   Homework (Optional)  You can test other image classification models, object detection, etc. by making use of the  download-models.sh  script and launching the inference with the option  --network   Please send a message to the professor as soon as you finished",
            "title": "Using other IA Models"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/",
            "text": "Week3: Setup ML Container\n\n\n\n\nThe l4t-ml docker image contains TensorFlow, PyTorch, JupyterLab, and other popular ML and data science frameworks such as scikit-learn, scipy, and Pandas pre-installed in a Python 3 environment. You can find all information in \nNVIDIA L4T ML\n\n\n\n\nMachine Learning Container\n\n\n\n\nThe \nl4t-ml\n docker image contains \nTensorFlow\n, \nPyTorch\n, \nJupyterLab\n, and other popular ML and data science frameworks such as scikit-learn, scipy, and Pandas pre-installed in a Python 3.6 environment\n\n\nLatest \nl4t-ml:r32.6.1-py3\n\n\nTensorFlow 1.15.5\n\n\nPyTorch v1.9.0\n\n\ntorchvision v0.10.0\n\n\ntorchaudio v0.9.0\n\n\nonnx 1.8.0\n\n\nCuPy 9.2.0\n\n\nnumpy 1.19.5\n\n\nnumba 0.53.1\n\n\nOpenCV 4.5.0 (with CUDA)\n\n\npandas 1.1.5\n\n\nscipy 1.5.4\n\n\nscikit-learn 0.23.2\n\n\nJupyterLab 2.2.9\n\n\n\n\n\n\n\n\n\n\n\n\nRunning the Container on your Jetson-Nano\n\n\n\n\nFirst pull one of the \nl4t-ml\n container:\n\n\n\n\nnano@jetson-nano:~$ sudo docker pull nvcr.io/nvidia/l4t-ml:r32.6.1-py3\n....\n\n\n\n\n\n\nThen to start an interactive session in the container, run the following command:\n\n\n\n\nnano@jetson-nano:~$ sudo docker run -it --gpus all -e DISPLAY=:0 -v /tmp/.X11-unix:/tmp/.X11-unix --network host nvcr.io/nvidia/l4t-ml:r32.6.1-py3\n\n\n\n\nMounting Directories\n\n\n\n\nTo mount scripts, data, ect. from your Jetson's filesystem to run inside the container, use Docker's -v flag when starting your Docker instance:\n\n\n\n\nnano@jetson-nano:~$ sudo docker run -it --rm --runtime nvidia --network host -v /home/user/project:/location/in/container nvcr.io/nvidia/l4t-ml:r32.6.1-py3\n\n\n\n\n\n\nNote that you should change the path directories and adapt to your installation\n: \n-v\n flag adds the mecanism to share a folder between host and docker image running, the path \"/home/user/project\" corresponds to host path (adapt to your installation \"/home/nano/l4t-ml-data\"), and \"/location/in/container\" corresponds to docker path (you could change to \"/home/l4t-ml-data\")\n\n\nNow, you should then be able to start a Python3 interpreter\n\n\n\n\nConnecting to JupyterLab Server\n\n\n\n\nA JupyterLab server instance is automatically started along with the container.\n\n\nYou can connect \nhttp://localhost:8888\n (or substitute the IP address of your Jetson device)\n\n\nPassword: \nnvidia\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 1\n\n\nRun the \nJupyter Notebook\n on Jetson Nano. You can look for more information about how to use the \nJupyter-Notebook\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\n\n\nAssignment 2\n\n\nTry to follow the examples of \nFirst Steps of Jupyter and Python\n on your Jetson Nano.\n\n\n\n\nPlease send a message to the professor as soon as you finished",
            "title": "setup MLcontainer"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/#week3-setup-ml-container",
            "text": "The l4t-ml docker image contains TensorFlow, PyTorch, JupyterLab, and other popular ML and data science frameworks such as scikit-learn, scipy, and Pandas pre-installed in a Python 3 environment. You can find all information in  NVIDIA L4T ML",
            "title": "Week3: Setup ML Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/#machine-learning-container",
            "text": "The  l4t-ml  docker image contains  TensorFlow ,  PyTorch ,  JupyterLab , and other popular ML and data science frameworks such as scikit-learn, scipy, and Pandas pre-installed in a Python 3.6 environment  Latest  l4t-ml:r32.6.1-py3  TensorFlow 1.15.5  PyTorch v1.9.0  torchvision v0.10.0  torchaudio v0.9.0  onnx 1.8.0  CuPy 9.2.0  numpy 1.19.5  numba 0.53.1  OpenCV 4.5.0 (with CUDA)  pandas 1.1.5  scipy 1.5.4  scikit-learn 0.23.2  JupyterLab 2.2.9",
            "title": "Machine Learning Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/#running-the-container-on-your-jetson-nano",
            "text": "First pull one of the  l4t-ml  container:   nano@jetson-nano:~$ sudo docker pull nvcr.io/nvidia/l4t-ml:r32.6.1-py3\n....   Then to start an interactive session in the container, run the following command:   nano@jetson-nano:~$ sudo docker run -it --gpus all -e DISPLAY=:0 -v /tmp/.X11-unix:/tmp/.X11-unix --network host nvcr.io/nvidia/l4t-ml:r32.6.1-py3",
            "title": "Running the Container on your Jetson-Nano"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/#mounting-directories",
            "text": "To mount scripts, data, ect. from your Jetson's filesystem to run inside the container, use Docker's -v flag when starting your Docker instance:   nano@jetson-nano:~$ sudo docker run -it --rm --runtime nvidia --network host -v /home/user/project:/location/in/container nvcr.io/nvidia/l4t-ml:r32.6.1-py3   Note that you should change the path directories and adapt to your installation :  -v  flag adds the mecanism to share a folder between host and docker image running, the path \"/home/user/project\" corresponds to host path (adapt to your installation \"/home/nano/l4t-ml-data\"), and \"/location/in/container\" corresponds to docker path (you could change to \"/home/l4t-ml-data\")  Now, you should then be able to start a Python3 interpreter",
            "title": "Mounting Directories"
        },
        {
            "location": "/Subjects/EDGE/Week1/setup_MLcontainer/#connecting-to-jupyterlab-server",
            "text": "A JupyterLab server instance is automatically started along with the container.  You can connect  http://localhost:8888  (or substitute the IP address of your Jetson device)  Password:  nvidia       Assignment 1  Run the  Jupyter Notebook  on Jetson Nano. You can look for more information about how to use the  Jupyter-Notebook   Please send a message to the professor as soon as you finished   Assignment 2  Try to follow the examples of  First Steps of Jupyter and Python  on your Jetson Nano.   Please send a message to the professor as soon as you finished",
            "title": "Connecting to JupyterLab Server"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/",
            "text": "Back\n | \nNext\n | \nContents\n\n\n\n\nSystem Setup\n  \n\n\nRunning the Docker Container\n\n\nPre-built Docker container images for this project are hosted on \nDockerHub\n.  Alternatively, you can \nBuild the Project from Source\n.   \n\n\nBelow are the currently available container tags:\n\n\n\n\n\n\n\n\nContainer Tag\n\n\nL4T version\n\n\nJetPack version\n\n\n\n\n\n\n\n\n\n\ndustynv/jetson-inference:r32.7.1\n\n\nL4T R32.7.1\n\n\nJetPack 4.6.1\n\n\n\n\n\n\ndustynv/jetson-inference:r32.6.1\n\n\nL4T R32.6.1\n\n\nJetPack 4.6\n\n\n\n\n\n\ndustynv/jetson-inference:r32.5.0\n\n\nL4T R32.5.0\n\n\nJetPack 4.5\n\n\n\n\n\n\ndustynv/jetson-inference:r32.4.4\n\n\nL4T R32.4.4\n\n\nJetPack 4.4.1\n\n\n\n\n\n\ndustynv/jetson-inference:r32.4.3\n\n\nL4T R32.4.3\n\n\nJetPack 4.4\n\n\n\n\n\n\n\n\n\n\nnote:\n the version of JetPack-L4T that you have installed on your Jetson needs to match the tag above.  If you have a different version of JetPack-L4T installed, either upgrade to the latest JetPack or \nBuild the Project from Source\n to compile the project directly. \n\n\n\n\nThese containers use the \nl4t-pytorch\n base container, so support for transfer learning / re-training is already included.\n\n\nLaunching the Container\n\n\nDue to various mounts and devices needed to run the container, it's recommended to use the \ndocker/run.sh\n script to run the container:\n\n\n$ git clone --recursive https://github.com/dusty-nv/jetson-inference\n$ cd jetson-inference\n$ docker/run.sh\n\n\n\n\n\n\nnote:\n  because of the Docker scripts used and the data directory structure that gets mounted into the container, you should still clone the project on your host device (i.e. even if not intending to build/install the project natively)\n\n\n\n\ndocker/run.sh\n will automatically pull the correct container tag from DockerHub based on your currently-installed version of JetPack-L4T, and mount the appropriate data directories and devices so that you can use cameras/display/ect from within the container.  It will also prompt you to \ndownload DNN models\n if you haven't already done so, which get mounted into the container to load.  This initial setup is only done once.\n\n\nMounted Data Volumes\n\n\nFor reference, the following paths automatically get mounted from your host device into the container:\n\n\n\n\njetson-inference/data\n (stores the network models, serialized TensorRT engines, and test images)\n\n\njetson-inference/python/training/classification/data\n (stores classification training datasets)\n\n\njetson-inference/python/training/classification/models\n (stores classification models trained by PyTorch)\n\n\njetson-inference/python/training/detection/ssd/data\n (stores detection training datasets)\n\n\njetson-inference/python/training/detection/ssd/models\n (stores detection models trained by PyTorch)\n\n\n\n\nThese mounted volumes assure that the models and datasets are stored outside the container, and aren't lost when the container is shut down.\n\n\nIf you wish to mount your own directory into the container, you can use the \n--volume HOST_DIR:MOUNT_DIR\n argument to \ndocker/run.sh\n:\n\n\n$ docker/run.sh --volume /my/host/path:/my/container/path    # these should be absolute paths\n\n\n\n\nFor more info, run \ndocker/run.sh --help\n or see the help text inside \ndocker/run.sh\n\n\nRunning Applications\n\n\nOnce the container is up and running, you can then run example programs from the tutorial like normal inside the container:\n\n\n# cd build/aarch64/bin\n# ./video-viewer /dev/video0\n# ./imagenet images/jellyfish.jpg images/test/jellyfish.jpg\n# ./detectnet images/peds_0.jpg images/test/peds_0.jpg\n# (press Ctrl+D to exit the container)\n\n\n\n\n\n\nnote:\n when you are saving images from one of the sample programs (like imagenet or detectnet), it's recommended to save them to \nimages/test\n.  These images will then be easily viewable from your host device in the \njetson-inference/data/images/test\n directory.  \n\n\n\n\nBuilding the Container\n\n\nIf you are following the Hello AI World tutorial, you can ignore this section and skip ahead to the next step.  But if you wish to re-build the container or build your own, you can use the \ndocker/build.sh\n script which builds the project's \nDockerfile\n:\n\n\n$ docker/build.sh\n\n\n\n\n\n\nnote:\n you should first set your default \ndocker-runtime\n to nvidia, see \nhere\n for the details.\n\n\n\n\nYou can also base your own container on this one by using the line \nFROM dustynv/jetson-inference:r32.4.3\n in your own Dockerfile.\n\n\nGetting Started\n\n\nIf you have chosen to run the project inside the Docker container, you can proceed to \nClassifying Images with ImageNet\n.\n\n\nHowever, if you would prefer to install the project directly on your Jetson (outside of container), go to \nBuilding the Project from Source\n.\n\n\n\n\nNext | \nBuilding the Project from Source\n\n\n\nBack | \nSetting up Jetson with JetPack\n\n\n\u00a9 2016-2020 NVIDIA | \nTable of Contents",
            "title": "Aux docker"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#running-the-docker-container",
            "text": "Pre-built Docker container images for this project are hosted on  DockerHub .  Alternatively, you can  Build the Project from Source .     Below are the currently available container tags:     Container Tag  L4T version  JetPack version      dustynv/jetson-inference:r32.7.1  L4T R32.7.1  JetPack 4.6.1    dustynv/jetson-inference:r32.6.1  L4T R32.6.1  JetPack 4.6    dustynv/jetson-inference:r32.5.0  L4T R32.5.0  JetPack 4.5    dustynv/jetson-inference:r32.4.4  L4T R32.4.4  JetPack 4.4.1    dustynv/jetson-inference:r32.4.3  L4T R32.4.3  JetPack 4.4      note:  the version of JetPack-L4T that you have installed on your Jetson needs to match the tag above.  If you have a different version of JetPack-L4T installed, either upgrade to the latest JetPack or  Build the Project from Source  to compile the project directly.    These containers use the  l4t-pytorch  base container, so support for transfer learning / re-training is already included.",
            "title": "Running the Docker Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#launching-the-container",
            "text": "Due to various mounts and devices needed to run the container, it's recommended to use the  docker/run.sh  script to run the container:  $ git clone --recursive https://github.com/dusty-nv/jetson-inference\n$ cd jetson-inference\n$ docker/run.sh   note:   because of the Docker scripts used and the data directory structure that gets mounted into the container, you should still clone the project on your host device (i.e. even if not intending to build/install the project natively)   docker/run.sh  will automatically pull the correct container tag from DockerHub based on your currently-installed version of JetPack-L4T, and mount the appropriate data directories and devices so that you can use cameras/display/ect from within the container.  It will also prompt you to  download DNN models  if you haven't already done so, which get mounted into the container to load.  This initial setup is only done once.",
            "title": "Launching the Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#mounted-data-volumes",
            "text": "For reference, the following paths automatically get mounted from your host device into the container:   jetson-inference/data  (stores the network models, serialized TensorRT engines, and test images)  jetson-inference/python/training/classification/data  (stores classification training datasets)  jetson-inference/python/training/classification/models  (stores classification models trained by PyTorch)  jetson-inference/python/training/detection/ssd/data  (stores detection training datasets)  jetson-inference/python/training/detection/ssd/models  (stores detection models trained by PyTorch)   These mounted volumes assure that the models and datasets are stored outside the container, and aren't lost when the container is shut down.  If you wish to mount your own directory into the container, you can use the  --volume HOST_DIR:MOUNT_DIR  argument to  docker/run.sh :  $ docker/run.sh --volume /my/host/path:/my/container/path    # these should be absolute paths  For more info, run  docker/run.sh --help  or see the help text inside  docker/run.sh",
            "title": "Mounted Data Volumes"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#running-applications",
            "text": "Once the container is up and running, you can then run example programs from the tutorial like normal inside the container:  # cd build/aarch64/bin\n# ./video-viewer /dev/video0\n# ./imagenet images/jellyfish.jpg images/test/jellyfish.jpg\n# ./detectnet images/peds_0.jpg images/test/peds_0.jpg\n# (press Ctrl+D to exit the container)   note:  when you are saving images from one of the sample programs (like imagenet or detectnet), it's recommended to save them to  images/test .  These images will then be easily viewable from your host device in the  jetson-inference/data/images/test  directory.",
            "title": "Running Applications"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#building-the-container",
            "text": "If you are following the Hello AI World tutorial, you can ignore this section and skip ahead to the next step.  But if you wish to re-build the container or build your own, you can use the  docker/build.sh  script which builds the project's  Dockerfile :  $ docker/build.sh   note:  you should first set your default  docker-runtime  to nvidia, see  here  for the details.   You can also base your own container on this one by using the line  FROM dustynv/jetson-inference:r32.4.3  in your own Dockerfile.",
            "title": "Building the Container"
        },
        {
            "location": "/Subjects/EDGE/Week1/docs/aux-docker/#getting-started",
            "text": "If you have chosen to run the project inside the Docker container, you can proceed to  Classifying Images with ImageNet .  However, if you would prefer to install the project directly on your Jetson (outside of container), go to  Building the Project from Source .",
            "title": "Getting Started"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/",
            "text": "Week4: Introduction to OpenCV\n\n\nSumary\n\n\n\n\nDuring this week we have worked on the OpenCV image processing library that allows us to interact with images and perform transformations.\n\n\n\n\nAssigments\n\n\n\n\nAll the assigments related to the setup of Jetson-Nano should be sent to professor by email. As a \nSubject\n write \"[IoT-DA Edge] Assignments Weeks4\"\n\n\n\n\nBasic Operations\n\n\n\n\nAssign 1\n\n\n\n\nInspect the pixel x=300, y=25 of \n../images/input.jpg\n\n\nWhich values have the RGB channels?\n\n\n\n\n\n\n\n\n\n\n\n\nAssign 2\n\n\n\n\nCrop the image \"input.jpg\" to centered rectangle with half the width and half the height of the \npyramid\n in the photo\n\n\n\n\n\n\n\n\nAssign 3\n\n\n\n\nDevelop a script which create a puzzle of an image (swapping four regions of a picture in clockwise), and one of the quarter only is shown the green channel as in the example\n\n\nTaking as input the Lena image avaliable in images directory\n\n\n\n\n\n\n\n\n\n\n\n\n    2. As an output the image (swapped) should be created\n\n\n\n\n\nImage Processing\n\n\n\n\nAssign 4\n\n\n\n\nDetecting lane lines on a binary mask\n\n\nCreate a masks to be applied e.g. ROI (trapezoid) to lane detection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssign 5\n\n\n\n\nCreate a code that segmentated the ball of a video using \ncv2.inRange\n function\n\n\nA video can be found in the \nlink\n \n\n\n\n\n\n\n\n\n\n\nAssign 6\n\n\n\n\nCreate an application that count the number of coins through an image as in the following images\n\n\nExtra: can be extended using CSI camera in real-time and counting\n\n\n\n\n\n\n\n\n\n\n\n\nAssign 7\n\n\n\n\nDetecting lane lines on a binary mask\n\n\nCreate a masks to be applied e.g. ROI (trapezoid) to lane detection\n\n\nDetect lane from the road appling the Hough transform\n\n\n\n\n\n\n\n\nAssign 8\n\n\n\n\nUsing Hough transform, it is also possible to detect \ncircles\n\n\nUse the OpenCV function \nHoughCircles()\n to detect circles in an image. Take as input images the coins examples\n\n\nMore info related to \nHoughCircles\n function can be found in \nOpenCV documentation",
            "title": "assigments OpenCV"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/#week4-introduction-to-opencv",
            "text": "",
            "title": "Week4: Introduction to OpenCV"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/#sumary",
            "text": "During this week we have worked on the OpenCV image processing library that allows us to interact with images and perform transformations.",
            "title": "Sumary"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/#assigments",
            "text": "All the assigments related to the setup of Jetson-Nano should be sent to professor by email. As a  Subject  write \"[IoT-DA Edge] Assignments Weeks4\"",
            "title": "Assigments"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/#basic-operations",
            "text": "Assign 1   Inspect the pixel x=300, y=25 of  ../images/input.jpg  Which values have the RGB channels?       Assign 2   Crop the image \"input.jpg\" to centered rectangle with half the width and half the height of the  pyramid  in the photo     Assign 3   Develop a script which create a puzzle of an image (swapping four regions of a picture in clockwise), and one of the quarter only is shown the green channel as in the example  Taking as input the Lena image avaliable in images directory           2. As an output the image (swapped) should be created",
            "title": "Basic Operations"
        },
        {
            "location": "/Subjects/EDGE/Week4/assigments_OpenCV/#image-processing",
            "text": "Assign 4   Detecting lane lines on a binary mask  Create a masks to be applied e.g. ROI (trapezoid) to lane detection        Assign 5   Create a code that segmentated the ball of a video using  cv2.inRange  function  A video can be found in the  link        Assign 6   Create an application that count the number of coins through an image as in the following images  Extra: can be extended using CSI camera in real-time and counting       Assign 7   Detecting lane lines on a binary mask  Create a masks to be applied e.g. ROI (trapezoid) to lane detection  Detect lane from the road appling the Hough transform     Assign 8   Using Hough transform, it is also possible to detect  circles  Use the OpenCV function  HoughCircles()  to detect circles in an image. Take as input images the coins examples  More info related to  HoughCircles  function can be found in  OpenCV documentation",
            "title": "Image Processing"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/",
            "text": "Assigment\n\n\nIntro\n\n\nTaking into account the global situation with the pandemic and COVID-19, create an IoT system that detects if a person is wearing a medical mask using the CSI Camera\n\n\nSteps\n\n\nCreate your own dataset\n\n\n\n\nCreate a label file: (1) none, (2) no_mask, (3) with_mask\n\n\nCreate your dataset \n\n\n\n\n\n\n\n\n\n\nRe-training\n\n\n\n\nRe-training the ResNet-18 Model with your input Dataset \n\n\nNote that apart from training, you should converting the Model to ONNX\n\n\n\n\n\n\n\n\nInference\n\n\n\n\nInvoke the inference with your model create by yourself. Use the CSI camera to create an IoT system to identify an access control (person worn a mask)\n\n\n\n\nClick Here to download\n the demo video of IoT System",
            "title": "Assigment"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#assigment",
            "text": "",
            "title": "Assigment"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#intro",
            "text": "Taking into account the global situation with the pandemic and COVID-19, create an IoT system that detects if a person is wearing a medical mask using the CSI Camera",
            "title": "Intro"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#steps",
            "text": "",
            "title": "Steps"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#create-your-own-dataset",
            "text": "Create a label file: (1) none, (2) no_mask, (3) with_mask  Create your dataset",
            "title": "Create your own dataset"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#re-training",
            "text": "Re-training the ResNet-18 Model with your input Dataset   Note that apart from training, you should converting the Model to ONNX",
            "title": "Re-training"
        },
        {
            "location": "/Subjects/EDGE/Week6/assigment/#inference",
            "text": "Invoke the inference with your model create by yourself. Use the CSI camera to create an IoT system to identify an access control (person worn a mask)   Click Here to download  the demo video of IoT System",
            "title": "Inference"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/",
            "text": "Re-training a Model with an input Dataset\n\n\n\n\nNote:\n information extracted from \nNVIDIA laboratories\n \n\n\nIn this lab you should learn:\n\n\nHow to download a prepared dataset to retrained a model\n\n\nTrain a CNN ResNet-18 with \nPyTorch\n (it could be done in a server/cloud system)\n\n\nConvert the model trained to ONNX format to be run on the Jetson-Nano\n\n\nPerform an inference in the Jetson-Nano (single image, a batch of images or using the CSI Camera)\n\n\nCreate your own dataset and repeat the training/inference process\n\n\n\n\n\n\n\n\nRe-training on the Cat/Dog Dataset\n\n\nThe model that we'll be re-training is a simple model that recognizes two classes:  cat or dog.\n\n\n\n\nProvided below is an 800MB data-set that includes 5000 training images, 1000 validation images, and 200 test images, each evenly split between the cat and dog classes.  The set of training images is used for transfer learning, while the validation set is used to evaluate classification accuracy during training, and the test images are to be used by us after training completes.  The network is never directly trained on the validation and test sets, only the training set.\n\n\nThe images from the data-set are made up of many different breeds of dogs and cats, including large felines like tigers and mountain lions since the amount of cat images available was a bit lower than dogs.  Some of the images also picture humans, which the detector is essentially trained to ignore as background and focus on the cat vs. dog content.\n\n\nTo get started, first make sure that you have \nPyTorch installed\n on your Jetson, then download the dataset below and kick off the training script.  After that, we'll test the re-trained model in TensorRT on some static images and a live camera feed. \n\n\nDownloading the Data\n\n\nDuring this tutorial, we'll store the datasets on the host device under \njetson-inference/python/training/classification/data\n, which is one of the directories that is automatically mounted into the container.  This way the dataset won't be lost when you shutdown the container.\n\n\nnano@jetson-nano:~$ cd jetson-inference/python/training/classification/data\nnano@jetson-nano:~/jetson-inference/python/training/classification/data$ wget https://nvidia.box.com/shared/static/o577zd8yp3lmxf5zhm38svrbrv45am3y.gz -O cat_dog.tar.gz\nnano@jetson-nano:~/jetson-inference/python/training/classification/data$ tar xvzf cat_dog.tar.gz\n\n\n\n\nMirrors of the dataset are available here:\n\n\n\n\nhttps://drive.google.com/file/d/16E3yFvVS2DouwgIl4TPFJvMlhGpnYWKF/view?usp=sharing\n\n\nhttps://nvidia.box.com/s/o577zd8yp3lmxf5zhm38svrbrv45am3y\n\n\n\n\nRe-training ResNet-18 Model\n\n\nThe PyTorch training scripts are located in the repo under \njetson-inference/python/training/classification/\n.  These scripts aren't specific to any one dataset, so we'll use the same PyTorch code with each of the example datasets from this tutorial.  By default it's set to train a ResNet-18 model, but you can change that with the \n--arch\n flag.\n\n\nTo launch the training, run the following commands:\n\n\nnano@jetson-nano:~/jetson-inference$ sudo init 3\nnano@jetson-nano:~/jetson-inference$ docker/run.sh\nroot@jetson-nano:/jetson-inference# cd python/training/classification\nroot@jetson-nano:/jetson-inference/python/training/classification# python3 train.py --batch-size=2 --workers=1  --model-dir=models/cat_dog data/cat_dog\nUse GPU: 0 for training\n=> dataset classes:  2 ['cat', 'dog']\n=> using pre-trained model 'resnet18'\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100.0%\n=> reshaped ResNet fully-connected layer with: Linear(in_features=512, out_features=2, bias=True)\n\n\n\n\n\n\nnote:\n if you run out of memory or your process is \"killed\" during training, try \nMounting SWAP\n and \nDisabling the Desktop GUI\n. \n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 to save memory, you can also reduce the \n--batch-size\n (default 8) and \n--workers\n (default 2)\n\n\n\n\nAs training begins, you should see text appear from the console like the following:\n\n\nUse GPU: 0 for training\n=> dataset classes:  2 ['cat', 'dog']\n=> using pre-trained model 'resnet18'\n=> reshaped ResNet fully-connected layer with: Linear(in_features=512, out_features=2, bias=True)\nEpoch: [0][   0/2500]  Time 95.370 (95.370)  Data  4.801 ( 4.801)  Loss 6.3362e-01 (6.3362e-01)  Acc@1  50.00 ( 50.00)  Acc@5 100.00 (100.00)\nEpoch: [0][  10/2500]  Time  0.225 ( 9.306)  Data  0.000 ( 0.709)  Loss 0.0000e+00 (1.6583e+01)  Acc@1 100.00 ( 50.00)  Acc@5 100.00 (100.00)\nEpoch: [0][  20/2500]  Time  0.222 ( 4.981)  Data  0.000 ( 0.377)  Loss 2.5114e+02 (6.3377e+01)  Acc@1  50.00 ( 57.14)  Acc@5 100.00 (100.00)\nEpoch: [0][  30/2500]  Time  0.223 ( 3.446)  Data  0.000 ( 0.260)  Loss 1.0363e+01 (5.5885e+01)  Acc@1  50.00 ( 58.06)  Acc@5 100.00 (100.00)\nEpoch: [0][  40/2500]  Time  0.226 ( 2.660)  Data  0.000 ( 0.199)  Loss 2.2514e+00 (4.3716e+01)  Acc@1   0.00 ( 52.44)  Acc@5 100.00 (100.00)\n\n\n\n\n\nTo stop training at any time, you can press \nCtrl+C\n.  You can also restart the training again later using the \n--resume\n and \n--epoch-start\n flags, so you don't need to wait for training to complete before testing out the model.  \n\n\nRun \npython3 train.py --help\n for more information about each option that's available for you to use, including other networks that you can try with the \n--arch\n flag.\n\n\nTraining Metrics\n\n\nThe statistics output above during the training process correspond to the following info:\n\n\n\n\nEpoch:  an epoch is one complete training pass over the dataset\n\n\nEpoch: [N]\n means you are currently on epoch 0, 1, 2, ect.\n\n\nThe default is to run for 35 epochs (you can change this with the \n--epochs=N\n flag)\n\n\n\n\n\n\n[N/625]\n is the current image batch from the epoch that you are on\n\n\nTraining images are processed in mini-batches to improve performance\n\n\nThe default batch size is 8 images, which can be set with the \n--batch=N\n flag\n\n\nMultiply the numbers in brackets by the batch size (e.g. batch \n[100/625]\n -> image \n[800/5000]\n)\n\n\n\n\n\n\nTime:  processing time of the current image batch (in seconds)\n\n\nData:  disk loading time of the current image batch (in seconds)\n\n\nLoss:  the accumulated errors that the model made (expected vs. predicted)\n\n\nAcc@1\n:  the Top-1 classification accuracy over the batch\n\n\nTop-1, meaning that the model predicted exactly the correct class\n\n\n\n\n\n\nAcc@5\n:  the Top-5 classification accuracy over the batch\n\n\nTop-5, meaning that the correct class was one of the Top 5 outputs the model predicted\n\n\nSince this Cat/Dog example only has 2 classes (Cat and Dog), Top-5 is always 100%\n\n\nOther datasets from the tutorial have more than 5 classes, where Top-5 is valid \n\n\n\n\n\n\n\n\nYou can keep an eye on these statistics during training to gauge how well the model is trained, and if you want to keep going or stop and test.  As mentioned above, you can restart training again later if you desire.\n\n\nModel Accuracy\n\n\nOn this dataset of 5000 images, training ResNet-18 takes approximately ~7-8 minutes per epoch on Jetson Nano, or around 4 hours to train the model to 35 epochs and 80% classification accuracy.  Below is a graph for analyzing the training progression of epochs versus model accuracy:\n\n\n\n\n\nAt around epoch 30, the ResNet-18 model reaches 80% accuracy, and at epoch 65 it converges on 82.5% accuracy.  With additional training time, you could further improve the accuracy by increasing the size of the dataset or by trying more complex models.\n\n\nBy default the training script is set to run for 35 epochs, but if you don't wish to wait that long to test out your model, you can exit training early and proceed to the next step (optionally re-starting the training again later from where you left off).  You can also download this completed model that was trained for a full 100 epochs from here:\n\n\n\n\nhttps://nvidia.box.com/s/zlvb4y43djygotpjn6azjhwu0r3j0yxc\n\n\n\n\nNote that the models are saved under \njetson-inference/python/training/classification/models/cat_dog/\n, including a checkpoint from the latest epoch and the best-performing model that has the highest classification accuracy.  This \nclassification/models\n directory is automatically mounted into the container, so your trained models will persist after the container is shutdown.\n\n\nConverting the Model to ONNX\n\n\nTo run our re-trained ResNet-18 model with TensorRT for testing and realtime inference, first we need to convert the PyTorch model into \nONNX format\n format so that TensorRT can load it.  ONNX is an open model format that supports many of the popular ML frameworks, including PyTorch, TensorFlow, TensorRT, and others, so it simplifies transferring models between tools.\n\n\nPyTorch comes with built-in support for exporting PyTorch models to ONNX, so run the following command to convert our Cat/Dog model with the provided \nonnx_export.py\n script:\n\n\nroot@jetson-nano:/jetson-inference/python/training/classification# python3 onnx_export.py --model-dir=models/cat_dog\nNamespace(input='model_best.pth.tar', model_dir='models/cat_dog', no_softmax=False, output='')\nrunning on device cuda:0\nloading checkpoint:  models/cat_dog/model_best.pth.tar\nusing model:  resnet18\n....\nexporting model to ONNX...\n....\nmodel exported to:  models/cat_dog/resnet18.onnx\n....\n\n\n\n\nThis will create a model called \nresnet18.onnx\n under \njetson-inference/python/training/classification/models/cat_dog/\n\n\nProcessing Images with TensorRT\n\n\nTo classify some static test images, we'll use the extended command-line parameters to \nimagenet\n to load our customized ResNet-18 model that we re-trained above.  To run these commands, the working directory of your terminal should still be located in:  \njetson-inference/python/training/classification/\n\n\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# NET=/jetson-inference/python/training/classification/models/cat_dog\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# DATASET=/jetson-inference/python/training/classification/data/cat_dog\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# imagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt $DATASET/test/cat/01.jpg images/test/my_cat.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# imagenet.py --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt $DATASET/test/cat/01.jpg images/test/my_cat.jpg\n\n\n\n\n\n\nProcessing all the Test Images\n\n\nThere are 200 test images included with the dataset between the cat and dog classes, or you can download your own pictures to try.  You can process them all like this:\n\n\nmkdir $DATASET/test_output_cat $DATASET/test_output_dog\n\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/../labels.txt \\\n           $DATASET/test/cat $DATASET/test_output_cat\n\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/../labels.txt \\\n           $DATASET/test/dog $DATASET/test_output_dog\n\n\n\n\nIn this instance, all the images will be read from the dataset's \ntest/\n directory, and saved to the \ntest_output/\n directory.  \n\n\nFor more info about loading/saving sequences of images, see the \nCamera Streaming and Multimedia\n.\n\n\nNext, we'll try running our re-trained model on a live camera feed.\n\n\nRunning the Live Camera Program\n\n\nIf you have a furry friend at home, you can run the camera program and see how it works!  Like the previous step, \nimagenet\n supports extended command-line parameters for loading customized models:\n\n\n# C++ (MIPI CSI)\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt csi://0\n\n# Python (MIPI CSI)\nimagenet.py --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt csi://0\n\n\n\n\n\n\nnote:\n for information about supported video streams and protocols, please see the \nCamera Streaming and Multimedia\n page.\n\n\n\n\n\n\nCreating your own Classification Datasets\n\n\nIn order to collect your own datasets for training customized models to classify objects or scenes of your choosing, we've created an easy-to-use tool called \ncamera-capture\n (NOTE: /jetson-inference/build/aarch64/bin/camera-capture) for capturing and labeling images on your Jetson from live video:\n\n\n\n\nThe tool will create datasets with the following directory structure on disk:\n\n\n\u2023 train/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...\n\u2023 val/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...\n\u2023 test/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...\n\n\n\n\nwhere \nclass-A\n, \nclass-B\n, ect. will be subdirectories containing the data for each object class that you've defined in a class label file.  The names of these class subdirectories will match the class label names that we'll create below.  These subdirectories will automatically be populated by the tool for the \ntrain\n, \nval\n, and \ntest\n sets from the classes listed in the label file, and a sequence of JPEG images will be saved under each.\n\n\nNote that above is the organization structure expected by the PyTorch training script that we've been using.  If you inspect the Cat/Dog and PlantCLEF datasets, they're also organized in the same way.\n\n\nCreating the Label File\n\n\nUnder \njetson-inference/python/training/classification/data\n, create an empty directory for storing your dataset and a text file that will define the class labels (usually called \nlabels.txt\n).  The label file contains one class label per line, and is alphabetized (this is important so the ordering of the classes in the label file matches the ordering of the corresponding subdirectories on disk).\n\n\nHere's an example \nlabels.txt\n file with 3 classes:\n\n\nclass-A\nclass-B\nclass-C\n\n\n\n\nAnd here's the corresponding directory structure that the tool will create:\n\n\n\u2023 train/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/\n\u2023 val/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/\n\u2023 test/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/\n\n\n\n\nAssignments\n\n\n\n\nIf you have finished all the steps mentioned before, you are ready to perform the task.\n\n\nTaking into account the global situation with the pandemic and COVID-19, create an IoT system that detects if a person is wearing a medical mask using the CSI Camera\n\n\n\n\n\n\nAssignment 1\n\n\nCreate your own dataset with the \ncamera-capture\n tool, for example a database with three objects: (1) No person, (2) Yourself, (3) Yourself with a medical mask worn.\n\n\n\n\n\n\nAssignment 2\n\n\nTrain the ResNet-18 Model with your own dataset. Note that apart from training, you should converting the Model to ONNX\n\n\n\n\n\n\nAssignment 3\n\n\nInvoke the inference with your model create by yourself. The IoT system should detect if a person is wearing a medical mask using an image classifier based on ResNet-18 using the CSI camera",
            "title": "imageRecognition"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#re-training-a-model-with-an-input-dataset",
            "text": "Note:  information extracted from  NVIDIA laboratories    In this lab you should learn:  How to download a prepared dataset to retrained a model  Train a CNN ResNet-18 with  PyTorch  (it could be done in a server/cloud system)  Convert the model trained to ONNX format to be run on the Jetson-Nano  Perform an inference in the Jetson-Nano (single image, a batch of images or using the CSI Camera)  Create your own dataset and repeat the training/inference process",
            "title": "Re-training a Model with an input Dataset"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#re-training-on-the-catdog-dataset",
            "text": "The model that we'll be re-training is a simple model that recognizes two classes:  cat or dog.   Provided below is an 800MB data-set that includes 5000 training images, 1000 validation images, and 200 test images, each evenly split between the cat and dog classes.  The set of training images is used for transfer learning, while the validation set is used to evaluate classification accuracy during training, and the test images are to be used by us after training completes.  The network is never directly trained on the validation and test sets, only the training set.  The images from the data-set are made up of many different breeds of dogs and cats, including large felines like tigers and mountain lions since the amount of cat images available was a bit lower than dogs.  Some of the images also picture humans, which the detector is essentially trained to ignore as background and focus on the cat vs. dog content.  To get started, first make sure that you have  PyTorch installed  on your Jetson, then download the dataset below and kick off the training script.  After that, we'll test the re-trained model in TensorRT on some static images and a live camera feed.",
            "title": "Re-training on the Cat/Dog Dataset"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#downloading-the-data",
            "text": "During this tutorial, we'll store the datasets on the host device under  jetson-inference/python/training/classification/data , which is one of the directories that is automatically mounted into the container.  This way the dataset won't be lost when you shutdown the container.  nano@jetson-nano:~$ cd jetson-inference/python/training/classification/data\nnano@jetson-nano:~/jetson-inference/python/training/classification/data$ wget https://nvidia.box.com/shared/static/o577zd8yp3lmxf5zhm38svrbrv45am3y.gz -O cat_dog.tar.gz\nnano@jetson-nano:~/jetson-inference/python/training/classification/data$ tar xvzf cat_dog.tar.gz  Mirrors of the dataset are available here:   https://drive.google.com/file/d/16E3yFvVS2DouwgIl4TPFJvMlhGpnYWKF/view?usp=sharing  https://nvidia.box.com/s/o577zd8yp3lmxf5zhm38svrbrv45am3y",
            "title": "Downloading the Data"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#re-training-resnet-18-model",
            "text": "The PyTorch training scripts are located in the repo under  jetson-inference/python/training/classification/ .  These scripts aren't specific to any one dataset, so we'll use the same PyTorch code with each of the example datasets from this tutorial.  By default it's set to train a ResNet-18 model, but you can change that with the  --arch  flag.  To launch the training, run the following commands:  nano@jetson-nano:~/jetson-inference$ sudo init 3\nnano@jetson-nano:~/jetson-inference$ docker/run.sh\nroot@jetson-nano:/jetson-inference# cd python/training/classification\nroot@jetson-nano:/jetson-inference/python/training/classification# python3 train.py --batch-size=2 --workers=1  --model-dir=models/cat_dog data/cat_dog\nUse GPU: 0 for training\n=> dataset classes:  2 ['cat', 'dog']\n=> using pre-trained model 'resnet18'\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100.0%\n=> reshaped ResNet fully-connected layer with: Linear(in_features=512, out_features=2, bias=True)   note:  if you run out of memory or your process is \"killed\" during training, try  Mounting SWAP  and  Disabling the Desktop GUI .  \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 to save memory, you can also reduce the  --batch-size  (default 8) and  --workers  (default 2)   As training begins, you should see text appear from the console like the following:  Use GPU: 0 for training\n=> dataset classes:  2 ['cat', 'dog']\n=> using pre-trained model 'resnet18'\n=> reshaped ResNet fully-connected layer with: Linear(in_features=512, out_features=2, bias=True)\nEpoch: [0][   0/2500]  Time 95.370 (95.370)  Data  4.801 ( 4.801)  Loss 6.3362e-01 (6.3362e-01)  Acc@1  50.00 ( 50.00)  Acc@5 100.00 (100.00)\nEpoch: [0][  10/2500]  Time  0.225 ( 9.306)  Data  0.000 ( 0.709)  Loss 0.0000e+00 (1.6583e+01)  Acc@1 100.00 ( 50.00)  Acc@5 100.00 (100.00)\nEpoch: [0][  20/2500]  Time  0.222 ( 4.981)  Data  0.000 ( 0.377)  Loss 2.5114e+02 (6.3377e+01)  Acc@1  50.00 ( 57.14)  Acc@5 100.00 (100.00)\nEpoch: [0][  30/2500]  Time  0.223 ( 3.446)  Data  0.000 ( 0.260)  Loss 1.0363e+01 (5.5885e+01)  Acc@1  50.00 ( 58.06)  Acc@5 100.00 (100.00)\nEpoch: [0][  40/2500]  Time  0.226 ( 2.660)  Data  0.000 ( 0.199)  Loss 2.2514e+00 (4.3716e+01)  Acc@1   0.00 ( 52.44)  Acc@5 100.00 (100.00)  To stop training at any time, you can press  Ctrl+C .  You can also restart the training again later using the  --resume  and  --epoch-start  flags, so you don't need to wait for training to complete before testing out the model.    Run  python3 train.py --help  for more information about each option that's available for you to use, including other networks that you can try with the  --arch  flag.",
            "title": "Re-training ResNet-18 Model"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#training-metrics",
            "text": "The statistics output above during the training process correspond to the following info:   Epoch:  an epoch is one complete training pass over the dataset  Epoch: [N]  means you are currently on epoch 0, 1, 2, ect.  The default is to run for 35 epochs (you can change this with the  --epochs=N  flag)    [N/625]  is the current image batch from the epoch that you are on  Training images are processed in mini-batches to improve performance  The default batch size is 8 images, which can be set with the  --batch=N  flag  Multiply the numbers in brackets by the batch size (e.g. batch  [100/625]  -> image  [800/5000] )    Time:  processing time of the current image batch (in seconds)  Data:  disk loading time of the current image batch (in seconds)  Loss:  the accumulated errors that the model made (expected vs. predicted)  Acc@1 :  the Top-1 classification accuracy over the batch  Top-1, meaning that the model predicted exactly the correct class    Acc@5 :  the Top-5 classification accuracy over the batch  Top-5, meaning that the correct class was one of the Top 5 outputs the model predicted  Since this Cat/Dog example only has 2 classes (Cat and Dog), Top-5 is always 100%  Other datasets from the tutorial have more than 5 classes, where Top-5 is valid      You can keep an eye on these statistics during training to gauge how well the model is trained, and if you want to keep going or stop and test.  As mentioned above, you can restart training again later if you desire.",
            "title": "Training Metrics"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#model-accuracy",
            "text": "On this dataset of 5000 images, training ResNet-18 takes approximately ~7-8 minutes per epoch on Jetson Nano, or around 4 hours to train the model to 35 epochs and 80% classification accuracy.  Below is a graph for analyzing the training progression of epochs versus model accuracy:   At around epoch 30, the ResNet-18 model reaches 80% accuracy, and at epoch 65 it converges on 82.5% accuracy.  With additional training time, you could further improve the accuracy by increasing the size of the dataset or by trying more complex models.  By default the training script is set to run for 35 epochs, but if you don't wish to wait that long to test out your model, you can exit training early and proceed to the next step (optionally re-starting the training again later from where you left off).  You can also download this completed model that was trained for a full 100 epochs from here:   https://nvidia.box.com/s/zlvb4y43djygotpjn6azjhwu0r3j0yxc   Note that the models are saved under  jetson-inference/python/training/classification/models/cat_dog/ , including a checkpoint from the latest epoch and the best-performing model that has the highest classification accuracy.  This  classification/models  directory is automatically mounted into the container, so your trained models will persist after the container is shutdown.",
            "title": "Model Accuracy"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#converting-the-model-to-onnx",
            "text": "To run our re-trained ResNet-18 model with TensorRT for testing and realtime inference, first we need to convert the PyTorch model into  ONNX format  format so that TensorRT can load it.  ONNX is an open model format that supports many of the popular ML frameworks, including PyTorch, TensorFlow, TensorRT, and others, so it simplifies transferring models between tools.  PyTorch comes with built-in support for exporting PyTorch models to ONNX, so run the following command to convert our Cat/Dog model with the provided  onnx_export.py  script:  root@jetson-nano:/jetson-inference/python/training/classification# python3 onnx_export.py --model-dir=models/cat_dog\nNamespace(input='model_best.pth.tar', model_dir='models/cat_dog', no_softmax=False, output='')\nrunning on device cuda:0\nloading checkpoint:  models/cat_dog/model_best.pth.tar\nusing model:  resnet18\n....\nexporting model to ONNX...\n....\nmodel exported to:  models/cat_dog/resnet18.onnx\n....  This will create a model called  resnet18.onnx  under  jetson-inference/python/training/classification/models/cat_dog/",
            "title": "Converting the Model to ONNX"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#processing-images-with-tensorrt",
            "text": "To classify some static test images, we'll use the extended command-line parameters to  imagenet  to load our customized ResNet-18 model that we re-trained above.  To run these commands, the working directory of your terminal should still be located in:   jetson-inference/python/training/classification/  root@jetson-nano:/jetson-inference/build/aarch64/bin# NET=/jetson-inference/python/training/classification/models/cat_dog\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# DATASET=/jetson-inference/python/training/classification/data/cat_dog\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# imagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt $DATASET/test/cat/01.jpg images/test/my_cat.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# imagenet.py --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt $DATASET/test/cat/01.jpg images/test/my_cat.jpg",
            "title": "Processing Images with TensorRT"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#processing-all-the-test-images",
            "text": "There are 200 test images included with the dataset between the cat and dog classes, or you can download your own pictures to try.  You can process them all like this:  mkdir $DATASET/test_output_cat $DATASET/test_output_dog\n\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/../labels.txt \\\n           $DATASET/test/cat $DATASET/test_output_cat\n\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/../labels.txt \\\n           $DATASET/test/dog $DATASET/test_output_dog  In this instance, all the images will be read from the dataset's  test/  directory, and saved to the  test_output/  directory.    For more info about loading/saving sequences of images, see the  Camera Streaming and Multimedia .  Next, we'll try running our re-trained model on a live camera feed.",
            "title": "Processing all the Test Images"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#running-the-live-camera-program",
            "text": "If you have a furry friend at home, you can run the camera program and see how it works!  Like the previous step,  imagenet  supports extended command-line parameters for loading customized models:  # C++ (MIPI CSI)\nimagenet --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt csi://0\n\n# Python (MIPI CSI)\nimagenet.py --model=$NET/resnet18.onnx --input_blob=input_0 --output_blob=output_0 --labels=$DATASET/labels.txt csi://0   note:  for information about supported video streams and protocols, please see the  Camera Streaming and Multimedia  page.",
            "title": "Running the Live Camera Program"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#creating-your-own-classification-datasets",
            "text": "In order to collect your own datasets for training customized models to classify objects or scenes of your choosing, we've created an easy-to-use tool called  camera-capture  (NOTE: /jetson-inference/build/aarch64/bin/camera-capture) for capturing and labeling images on your Jetson from live video:   The tool will create datasets with the following directory structure on disk:  \u2023 train/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...\n\u2023 val/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...\n\u2023 test/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 ...  where  class-A ,  class-B , ect. will be subdirectories containing the data for each object class that you've defined in a class label file.  The names of these class subdirectories will match the class label names that we'll create below.  These subdirectories will automatically be populated by the tool for the  train ,  val , and  test  sets from the classes listed in the label file, and a sequence of JPEG images will be saved under each.  Note that above is the organization structure expected by the PyTorch training script that we've been using.  If you inspect the Cat/Dog and PlantCLEF datasets, they're also organized in the same way.",
            "title": "Creating your own Classification Datasets"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#creating-the-label-file",
            "text": "Under  jetson-inference/python/training/classification/data , create an empty directory for storing your dataset and a text file that will define the class labels (usually called  labels.txt ).  The label file contains one class label per line, and is alphabetized (this is important so the ordering of the classes in the label file matches the ordering of the corresponding subdirectories on disk).  Here's an example  labels.txt  file with 3 classes:  class-A\nclass-B\nclass-C  And here's the corresponding directory structure that the tool will create:  \u2023 train/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/\n\u2023 val/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/\n\u2023 test/\n    \u2022 class-A/\n    \u2022 class-B/\n    \u2022 class-C/",
            "title": "Creating the Label File"
        },
        {
            "location": "/Subjects/EDGE/Week6/imageRecognition/#assignments",
            "text": "If you have finished all the steps mentioned before, you are ready to perform the task.  Taking into account the global situation with the pandemic and COVID-19, create an IoT system that detects if a person is wearing a medical mask using the CSI Camera    Assignment 1  Create your own dataset with the  camera-capture  tool, for example a database with three objects: (1) No person, (2) Yourself, (3) Yourself with a medical mask worn.    Assignment 2  Train the ResNet-18 Model with your own dataset. Note that apart from training, you should converting the Model to ONNX    Assignment 3  Invoke the inference with your model create by yourself. The IoT system should detect if a person is wearing a medical mask using an image classifier based on ResNet-18 using the CSI camera",
            "title": "Assignments"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/",
            "text": "Classifying Images with ImageNet\n\n\n\n\nNote:\n information extracted from \nNVIDIA laboratories\n \n\n\n\n\nThere are multiple types of deep learning networks available, including recognition, detection/localization, and semantic segmentation.  The first deep learning capability we're highlighting in this tutorial is \nimage recognition\n, using classifcation networks that have been trained on large datasets to identify scenes and objects.\n\n\n\n\nThe \nimageNet\n object accepts an input image and outputs the probability for each class.  Having been trained on the ImageNet ILSVRC dataset of \n1000 objects\n, the GoogleNet and ResNet-18 models were automatically downloaded during the build step.\n\n\nAs an example of using the \nimageNet\n class, we provide sample programs for C++ and Python:\n\n\n\n\nimagenet.cpp\n (C++) \n\n\nimagenet.py\n (Python) \n\n\n\n\nThese samples are able to classify images, videos, and camera feeds. \n\n\nHow to use ImageNet Program on Jetson\n\n\nFirst, let's try using the \nimagenet\n program to test imageNet recognition on some example images.  It loads an image (or images), uses TensorRT and the \nimageNet\n class to perform the inference, then overlays the classification result and saves the output image. The project comes with sample images for you to use located under the \nimages/\n directory.\n\n\nAfter \nbuilding\n the project, make sure your terminal is located in the \naarch64/bin\n directory:\n\n\nnano@jetson-nano:~$ cd jetson-inference/\nnano@jetson-nano:~/jetson-inference$ docker/run.sh \nroot@jetson-nano:/jetson-inference# cd jetson-inference/build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#\n\n\n\n\nNext, let's classify an example image with the \nimagenet\n program, using either the \nC++\n or \nPython\n variants. The \nDocker container\n have the \nimages/test\n mounted directory.  These images will then be easily viewable from your host device in the \njetson-inference/data/images/test\n directory.  \n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/orange_0.jpg images/test/output_0.jpg  # (default network is googlenet)\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet.py images/orange_0.jpg images/test/output_0.jpg  # (default network is googlenet)\n\n\n\n\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/strawberry_0.jpg images/test/output_1.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet.py images/strawberry_0.jpg images/test/output_1.jpg\n\n\n\n\n\n\nDownloading Other Classification Models\n\n\nBy default, the project will download the GoogleNet and ResNet-18 networks during the build step.\n\n\nThere are other pre-trained models that you can use as well, you could use the \ndownload-models.sh\n script to download them:\n\n\n\n\n\n\n\n\nNetwork\n\n\nCLI argument\n\n\nNetworkType enum\n\n\n\n\n\n\n\n\n\n\nAlexNet\n\n\nalexnet\n\n\nALEXNET\n\n\n\n\n\n\nGoogleNet\n\n\ngooglenet\n\n\nGOOGLENET\n\n\n\n\n\n\nGoogleNet-12\n\n\ngooglenet-12\n\n\nGOOGLENET_12\n\n\n\n\n\n\nResNet-18\n\n\nresnet-18\n\n\nRESNET_18\n\n\n\n\n\n\nResNet-50\n\n\nresnet-50\n\n\nRESNET_50\n\n\n\n\n\n\nResNet-101\n\n\nresnet-101\n\n\nRESNET_101\n\n\n\n\n\n\nResNet-152\n\n\nresnet-152\n\n\nRESNET_152\n\n\n\n\n\n\nVGG-16\n\n\nvgg-16\n\n\nVGG-16\n\n\n\n\n\n\nVGG-19\n\n\nvgg-19\n\n\nVGG-19\n\n\n\n\n\n\nInception-v4\n\n\ninception-v4\n\n\nINCEPTION_V4\n\n\n\n\n\n\n\n\n\n\nnano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh\n\n\n\n\nGenerally the more complex networks can have greater classification accuracy, with increased runtime.\n\n\nUsing Different Classification Models\n\n\nYou can specify which model to load by setting the \n--network\n flag on the command line to one of the corresponding CLI arguments from the table above.  By default, GoogleNet is loaded if the optional \n--network\n flag isn't specified.\n\n\nBelow are some examples of using the ResNet-18 model:\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg\n\n\n\n\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg\n\n\n\n\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/coral.jpg images/test/output_coral.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/coral.jpg images/test/output_coral.jpg\n\n\n\n\n\n\nProcessing a Video\n\n\nThe \nCamera Streaming and Multimedia\n can pass the video directly to \nimagenet\n.  \n\n\nHere is an example of running it on a video from disk:\n\n\n# Download test video (thanks to jell.yfish.us)\n$ wget https://nvidia.box.com/shared/static/tlswont1jnyu3ix2tbf7utaekpzcx4rc.mkv -O jellyfish.mkv\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv\n\n\n\n\n\n\nAssignment\n\n\nEvaluate the accuracy and inference time of \nfruit_0.jpg\n, \nstrawberry_1.jpg\n for the image classification models launching the inference with the option \n--network\n for AlexNet, GoogleNet, ResNet-50, VGG-16, Inception-v4\n\n\n\n\nPlease send a message to the professor as soon as you finished",
            "title": "inferenceImageClassifying"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/#classifying-images-with-imagenet",
            "text": "Note:  information extracted from  NVIDIA laboratories     There are multiple types of deep learning networks available, including recognition, detection/localization, and semantic segmentation.  The first deep learning capability we're highlighting in this tutorial is  image recognition , using classifcation networks that have been trained on large datasets to identify scenes and objects.   The  imageNet  object accepts an input image and outputs the probability for each class.  Having been trained on the ImageNet ILSVRC dataset of  1000 objects , the GoogleNet and ResNet-18 models were automatically downloaded during the build step.  As an example of using the  imageNet  class, we provide sample programs for C++ and Python:   imagenet.cpp  (C++)   imagenet.py  (Python)    These samples are able to classify images, videos, and camera feeds.",
            "title": "Classifying Images with ImageNet"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/#how-to-use-imagenet-program-on-jetson",
            "text": "First, let's try using the  imagenet  program to test imageNet recognition on some example images.  It loads an image (or images), uses TensorRT and the  imageNet  class to perform the inference, then overlays the classification result and saves the output image. The project comes with sample images for you to use located under the  images/  directory.  After  building  the project, make sure your terminal is located in the  aarch64/bin  directory:  nano@jetson-nano:~$ cd jetson-inference/\nnano@jetson-nano:~/jetson-inference$ docker/run.sh \nroot@jetson-nano:/jetson-inference# cd jetson-inference/build/aarch64/bin\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  Next, let's classify an example image with the  imagenet  program, using either the  C++  or  Python  variants. The  Docker container  have the  images/test  mounted directory.  These images will then be easily viewable from your host device in the  jetson-inference/data/images/test  directory.    # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/orange_0.jpg images/test/output_0.jpg  # (default network is googlenet)\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet.py images/orange_0.jpg images/test/output_0.jpg  # (default network is googlenet)   # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet images/strawberry_0.jpg images/test/output_1.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./imagenet.py images/strawberry_0.jpg images/test/output_1.jpg",
            "title": "How to use ImageNet Program on Jetson"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/#downloading-other-classification-models",
            "text": "By default, the project will download the GoogleNet and ResNet-18 networks during the build step.  There are other pre-trained models that you can use as well, you could use the  download-models.sh  script to download them:     Network  CLI argument  NetworkType enum      AlexNet  alexnet  ALEXNET    GoogleNet  googlenet  GOOGLENET    GoogleNet-12  googlenet-12  GOOGLENET_12    ResNet-18  resnet-18  RESNET_18    ResNet-50  resnet-50  RESNET_50    ResNet-101  resnet-101  RESNET_101    ResNet-152  resnet-152  RESNET_152    VGG-16  vgg-16  VGG-16    VGG-19  vgg-19  VGG-19    Inception-v4  inception-v4  INCEPTION_V4      nano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh  Generally the more complex networks can have greater classification accuracy, with increased runtime.",
            "title": "Downloading Other Classification Models"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/#using-different-classification-models",
            "text": "You can specify which model to load by setting the  --network  flag on the command line to one of the corresponding CLI arguments from the table above.  By default, GoogleNet is loaded if the optional  --network  flag isn't specified.  Below are some examples of using the ResNet-18 model:  # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/jellyfish.jpg images/test/output_jellyfish.jpg   # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/stingray.jpg images/test/output_stingray.jpg   # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 images/coral.jpg images/test/output_coral.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 images/coral.jpg images/test/output_coral.jpg",
            "title": "Using Different Classification Models"
        },
        {
            "location": "/Subjects/EDGE/Week6/inferenceImageClassifying/#processing-a-video",
            "text": "The  Camera Streaming and Multimedia  can pass the video directly to  imagenet .    Here is an example of running it on a video from disk:  # Download test video (thanks to jell.yfish.us)\n$ wget https://nvidia.box.com/shared/static/tlswont1jnyu3ix2tbf7utaekpzcx4rc.mkv -O jellyfish.mkv\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin#  ./imagenet.py --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv   Assignment  Evaluate the accuracy and inference time of  fruit_0.jpg ,  strawberry_1.jpg  for the image classification models launching the inference with the option  --network  for AlexNet, GoogleNet, ResNet-50, VGG-16, Inception-v4   Please send a message to the professor as soon as you finished",
            "title": "Processing a Video"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/",
            "text": "Understanding Source Code\n\n\nCoding Your Own Object Detection Program\n\n\nIn this step of the tutorial, we'll walk through the creation of the previous example for realtime object detection on a live camera feed in only 10 lines of Python code.  The program will load the detection network with the \ndetectNet\n object, capture video frames and process them, and then render the detected objects to the display.\n\n\nFor your convenience and reference, the completed source is available in the \npython/examples/my-detection.py\n file of the repo, but the guide below will act like they reside in the user's home directory or in an arbitrary directory of your choosing.  \n\n\nHere's a quick preview of the Python code we'll be walking through:\n\n\nimport jetson.inference\nimport jetson.utils\n\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\ncamera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2\ndisplay = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    img = camera.Capture()\n    detections = net.Detect(img)\n    display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))\n\n\n\n\nThere's also a video screencast of this coding tutorial available on YouTube:\n\n\n\n\nSource Code\n\n\nImporting Modules\n\n\nAt the top of the source file, we'll import the Python modules that we're going to use in the script.  Add \nimport\n statements to load the \njetson.inference\n and \njetson.utils\n modules used for object detection and camera capture.\n\n\nimport jetson.inference\nimport jetson.utils\n\n\n\n\nLoading the Detection Model\n\n\nNext use the following line to create a \ndetectNet\n object instance that loads the \n91-class\n SSD-Mobilenet-v2 model:\n\n\n# load the object detection model\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\n\n\n\n\nNote that you can change the model string to one of the values from \nthis table\n to load a different detection model.  We also set the detection threshold here to the default of \n0.5\n for illustrative purposes - you can tweak it later if needed.\n\n\nOpening the Camera Stream\n\n\nTo connect to the camera device for streaming, we'll create an instance of the \nvideoSource\n object:\n\n\ncamera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2\n\n\n\n\nThe string passed to \nvideoSource()\n can actually be any valid resource URI, whether it be a camera, video file, or network stream.  \n\n\nDisplay Loop\n\n\nNext, we'll create a video output interface with the \nvideoOutput\n object and create a main loop that will run until the user exits:\n\n\ndisplay = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    # main loop will go here\n\n\n\n\nCamera Capture\n\n\nThe first thing that happens in the main loop is to capture the next video frame from the camera.  \ncamera.Capture()\n will wait until the next frame has been sent from the camera and loaded into GPU memory.\n\n\n    img = camera.Capture()\n\n\n\n\nThe returned image will be a \njetson.utils.cudaImage\n object that contains attributes like width, height, and pixel format:\n\n\n<jetson.utils.cudaImage>\n  .ptr      # memory address (not typically used)\n  .size     # size in bytes\n  .shape    # (height,width,channels) tuple\n  .width    # width in pixels\n  .height   # height in pixels\n  .channels # number of color channels\n  .format   # format string\n  .mapped   # true if ZeroCopy\n\n\n\n\nDetecting Objects\n\n\nNext the detection network processes the image with the \nnet.Detect()\n function.  It takes in the image from \ncamera.Capture()\n and returns a list of detections:\n\n\n    detections = net.Detect(img)\n\n\n\n\nThis function will also automatically overlay the detection results on top of the input image.\n\n\nIf you want, you can add a \nprint(detections)\n statement here, and the coordinates, confidence, and class info will be printed out to the terminal for each detection result.  Also see the \ndetectNet\n documentation for info about the different members of the \nDetection\n structures that are returned for accessing them directly in a custom application.\n\n\nDetection = <type 'jetson.inference.detectNet.Detection'>\nObject Detection Result\n\n----------------------------------------------------------------------\nData descriptors defined here:\n\nArea\n    Area of bounding box\n\nBottom\n    Bottom bounding box coordinate\n\nCenter\n    Center (x,y) coordinate of bounding box\n\nClassID\n    Class index of the detected object\n\nConfidence\n    Confidence value of the detected object\n\nHeight\n    Height of bounding box\n\nInstance\n    Instance index of the detected object\n\nLeft\n    Left bounding box coordinate\n\nRight\n    Right bounding box coordinate\n\nTop\n    Top bounding box coordinate\n\nWidth\n     Width of bounding box\n\n\n\n\nRendering\n\n\nFinally we'll visualize the results with OpenGL and update the title of the window to display the current peformance:\n\n\n    display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))\n\n\n\n\nThe \nRender()\n function will automatically flip the backbuffer and present the image on-screen.\n\n\nSource Listing\n\n\nThat's it!  For completness, here's the full source of the Python script that we just created:\n\n\nimport jetson.inference\nimport jetson.utils\n\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\ncamera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2\ndisplay = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    img = camera.Capture()\n    detections = net.Detect(img)\n    display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))\n\n\n\n\nNote that this version assumes you are using a MIPI CSI camera.\n\n\nRunning the Program\n\n\nTo run the application we just coded, simply launch it from a terminal with the Python interpreter:\n\n\n$ python3 my-detection.py\n\n\n\n\nAssignment\n\n\nImportant aspects to take into account\n\n\n\n\nThe file \nmy-detection.py\n located in the path \n/jetson-inference/python/examples\n is always \nreset when the container is started\n. For this reason it should be copied to a durable Jetson-Nano file system zone. \ndata\n directory is not reset, so this path could be one of the candidate.\n\n\nThe invocation \ndetections = net.Detect(img)\n create a tensor in \ndetections\n. Information of each 'detection' could be consulted (see the section \nDetecting Objects\n). \n\n\nSo, you can access to \nClassID, Confidence, Instance, Left, Right, Bottom, Top\n values\n\n\nIn the last \nassignment\n accuracy and inference times were evaluated choosing different models.\n\n\n\n\n\n\nAssignment1\n\n\nModify the code \nmy-detection.py\n so that, the bounding boxes and identifiers associated with each object are displayed for each frame on the console\n\n\n\n\nPlease send a message to the professor as soon as you finished\n\n\n\n\n\n\nAssignment 2: system that counts people crossing the entry or exit like in the photo\n\n\nModify the code \nmy-detection.py\n so that, design and implement a solution to monitor the crossing of people in the direction of entry and exit at an entrance to a venue. Thus, a camera located perpendicular to the entrance to the enclosure will be assumed, so that the people who access it will enter the scene through one of the ends and leave through the opposite. The people who leave the enclosure will run through the image in the opposite direction. The system is requested to store the number of people who have entered and left the premises, as well as the moment in which they have done so.",
            "title": "codeObjectDetection"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#understanding-source-code",
            "text": "",
            "title": "Understanding Source Code"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#coding-your-own-object-detection-program",
            "text": "In this step of the tutorial, we'll walk through the creation of the previous example for realtime object detection on a live camera feed in only 10 lines of Python code.  The program will load the detection network with the  detectNet  object, capture video frames and process them, and then render the detected objects to the display.  For your convenience and reference, the completed source is available in the  python/examples/my-detection.py  file of the repo, but the guide below will act like they reside in the user's home directory or in an arbitrary directory of your choosing.    Here's a quick preview of the Python code we'll be walking through:  import jetson.inference\nimport jetson.utils\n\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\ncamera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2\ndisplay = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    img = camera.Capture()\n    detections = net.Detect(img)\n    display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))  There's also a video screencast of this coding tutorial available on YouTube:",
            "title": "Coding Your Own Object Detection Program"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#source-code",
            "text": "",
            "title": "Source Code"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#importing-modules",
            "text": "At the top of the source file, we'll import the Python modules that we're going to use in the script.  Add  import  statements to load the  jetson.inference  and  jetson.utils  modules used for object detection and camera capture.  import jetson.inference\nimport jetson.utils",
            "title": "Importing Modules"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#loading-the-detection-model",
            "text": "Next use the following line to create a  detectNet  object instance that loads the  91-class  SSD-Mobilenet-v2 model:  # load the object detection model\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)  Note that you can change the model string to one of the values from  this table  to load a different detection model.  We also set the detection threshold here to the default of  0.5  for illustrative purposes - you can tweak it later if needed.",
            "title": "Loading the Detection Model"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#opening-the-camera-stream",
            "text": "To connect to the camera device for streaming, we'll create an instance of the  videoSource  object:  camera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2  The string passed to  videoSource()  can actually be any valid resource URI, whether it be a camera, video file, or network stream.",
            "title": "Opening the Camera Stream"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#display-loop",
            "text": "Next, we'll create a video output interface with the  videoOutput  object and create a main loop that will run until the user exits:  display = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    # main loop will go here",
            "title": "Display Loop"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#camera-capture",
            "text": "The first thing that happens in the main loop is to capture the next video frame from the camera.   camera.Capture()  will wait until the next frame has been sent from the camera and loaded into GPU memory.      img = camera.Capture()  The returned image will be a  jetson.utils.cudaImage  object that contains attributes like width, height, and pixel format:  <jetson.utils.cudaImage>\n  .ptr      # memory address (not typically used)\n  .size     # size in bytes\n  .shape    # (height,width,channels) tuple\n  .width    # width in pixels\n  .height   # height in pixels\n  .channels # number of color channels\n  .format   # format string\n  .mapped   # true if ZeroCopy",
            "title": "Camera Capture"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#detecting-objects",
            "text": "Next the detection network processes the image with the  net.Detect()  function.  It takes in the image from  camera.Capture()  and returns a list of detections:      detections = net.Detect(img)  This function will also automatically overlay the detection results on top of the input image.  If you want, you can add a  print(detections)  statement here, and the coordinates, confidence, and class info will be printed out to the terminal for each detection result.  Also see the  detectNet  documentation for info about the different members of the  Detection  structures that are returned for accessing them directly in a custom application.  Detection = <type 'jetson.inference.detectNet.Detection'>\nObject Detection Result\n\n----------------------------------------------------------------------\nData descriptors defined here:\n\nArea\n    Area of bounding box\n\nBottom\n    Bottom bounding box coordinate\n\nCenter\n    Center (x,y) coordinate of bounding box\n\nClassID\n    Class index of the detected object\n\nConfidence\n    Confidence value of the detected object\n\nHeight\n    Height of bounding box\n\nInstance\n    Instance index of the detected object\n\nLeft\n    Left bounding box coordinate\n\nRight\n    Right bounding box coordinate\n\nTop\n    Top bounding box coordinate\n\nWidth\n     Width of bounding box",
            "title": "Detecting Objects"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#rendering",
            "text": "Finally we'll visualize the results with OpenGL and update the title of the window to display the current peformance:      display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))  The  Render()  function will automatically flip the backbuffer and present the image on-screen.",
            "title": "Rendering"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#source-listing",
            "text": "That's it!  For completness, here's the full source of the Python script that we just created:  import jetson.inference\nimport jetson.utils\n\nnet = jetson.inference.detectNet(\"ssd-mobilenet-v2\", threshold=0.5)\ncamera = jetson.utils.videoSource(\"csi://0\")      # '/dev/video0' for V4L2\ndisplay = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file\n\nwhile display.IsStreaming():\n    img = camera.Capture()\n    detections = net.Detect(img)\n    display.Render(img)\n    display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))  Note that this version assumes you are using a MIPI CSI camera.",
            "title": "Source Listing"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#running-the-program",
            "text": "To run the application we just coded, simply launch it from a terminal with the Python interpreter:  $ python3 my-detection.py",
            "title": "Running the Program"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#assignment",
            "text": "",
            "title": "Assignment"
        },
        {
            "location": "/Subjects/EDGE/Week7/codeObjectDetection/#important-aspects-to-take-into-account",
            "text": "The file  my-detection.py  located in the path  /jetson-inference/python/examples  is always  reset when the container is started . For this reason it should be copied to a durable Jetson-Nano file system zone.  data  directory is not reset, so this path could be one of the candidate.  The invocation  detections = net.Detect(img)  create a tensor in  detections . Information of each 'detection' could be consulted (see the section  Detecting Objects ).   So, you can access to  ClassID, Confidence, Instance, Left, Right, Bottom, Top  values  In the last  assignment  accuracy and inference times were evaluated choosing different models.    Assignment1  Modify the code  my-detection.py  so that, the bounding boxes and identifiers associated with each object are displayed for each frame on the console   Please send a message to the professor as soon as you finished    Assignment 2: system that counts people crossing the entry or exit like in the photo  Modify the code  my-detection.py  so that, design and implement a solution to monitor the crossing of people in the direction of entry and exit at an entrance to a venue. Thus, a camera located perpendicular to the entrance to the enclosure will be assumed, so that the people who access it will enter the scene through one of the ends and leave through the opposite. The people who leave the enclosure will run through the image in the opposite direction. The system is requested to store the number of people who have entered and left the premises, as well as the moment in which they have done so.",
            "title": "Important aspects to take into account"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/",
            "text": "Objects Detection with DetectNet\n\n\nThe previous recognition examples output class probabilities representing the entire input image.  Next we're going to focus on \nobject detection\n, and finding where in the frame various objects are located by extracting their bounding boxes.  Unlike image classification, object detection networks are capable of detecting many different objects per frame.\n\n\n\n\nThe \ndetectNet\n object accepts an image as input, and outputs a list of coordinates of the detected bounding boxes along with their classes and confidence values.  \ndetectNet\n is available to use from \nPython\n and \nC++\n.  See below for various \npre-trained detection models\n  available for download.  The default model used is a \n91-class\n SSD-Mobilenet-v2 model trained on the MS COCO dataset, which achieves realtime inferencing performance on Jetson with TensorRT. \n\n\nAs examples of using the \ndetectNet\n class, we provide sample programs for C++ and Python:\n\n\n\n\ndetectnet.cpp\n (C++) \n\n\ndetectnet.py\n (Python) \n\n\n\n\nThese samples are able to detect objects in images, videos, and camera feeds. The \nCamera Streaming and Multimedia\n can pass the video directly to \ndetectNet\n.  \n\n\nDetecting Objects from Images\n\n\nFirst, let's try using the \ndetectnet\n program to locates objects in static images.  In addition to the input/output paths, there are some additional command-line options:\n\n\n\n\noptional \n--network\n flag which changes the \ndetection model\n being used (the default is SSD-Mobilenet-v2).\n\n\noptional \n--overlay\n flag which can be comma-separated combinations of \nbox\n, \nlines\n, \nlabels\n, \nconf\n, and \nnone\n\n\nThe default is \n--overlay=box,labels,conf\n which displays boxes, labels, and confidence values\n\n\nThe \nbox\n option draws filled bounding boxes, while \nlines\n draws just the unfilled outlines\n\n\n\n\n\n\noptional \n--alpha\n value which sets the alpha blending value used during overlay (the default is \n120\n).\n\n\noptional \n--threshold\n value which sets the minimum threshold for detection (the default is \n0.5\n).  \n\n\n\n\nIf you're using the \nDocker container\n, it's recommended to save the output images to the \nimages/test\n mounted directory.  These images will then be easily viewable from your host device under \njetson-inference/data/images/test\n. \n\n\nHere are some examples of detecting pedestrians in images with the default SSD-Mobilenet-v2 model:\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output.jpg     # --network flag is optional\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output.jpg     # --network flag is optional\n\n\n\n\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/peds_1.jpg images/test/output.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py images/peds_1.jpg images/test/output.jpg\n\n\n\n\n\n\n\n\nnote\n:  the first time you run each model, TensorRT will take a few minutes to optimize the network. \n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0this optimized network file is then cached to disk, so future runs using the model will load faster.\n\n\n\n\nBelow are more detection examples output from the console programs.  The \n91-class\n MS COCO dataset that the SSD-based models were trained on include people, vehicles, animals, and assorted types of household objects to detect.\n\n\n\n\nVarious images are found under \nimages/\n for testing, such as \ncat_*.jpg\n, \ndog_*.jpg\n, \nhorse_*.jpg\n, \npeds_*.jpg\n, ect. \n\n\nProcessing Video Files\n\n\nYou can also process videos from disk. \n\n\n# Download test video\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# cd images\nroot@jetson-nano:/jetson-inference/build/aarch64/bin/images# wget https://nvidia.box.com/shared/static/veuuimq6pwvd62p9fresqhrrmfqz0e2f.mp4 -O pedestrians.mp4\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet pedestrians.mp4 images/test/pedestrians_ssd.mp4\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py pedestrians.mp4 images/test/pedestrians_ssd.mp4\n\n\n\n\n\n\n# Download test video\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# cd images\nroot@jetson-nano:/jetson-inference/build/aarch64/bin/images# wget https://nvidia.box.com/shared/static/i5i81mkd9wdh4j7wx04th961zks0lfh9.avi -O parking.avi\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet parking.avi images/test/parking_ssd.avi\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py parking.avi images/test/parking_ssd.avi\n\n\n\n\n\n\nRemember that you can use the \n--threshold\n setting to change the detection sensitivity up or down (the default is 0.5).\n\n\nPre-trained Detection Models Available\n\n\nBelow is a table of the pre-trained object detection networks available for \ndownload\n, and the associated \n--network\n argument to \ndetectnet\n used for loading the pre-trained models:\n\n\n\n\n\n\n\n\nModel\n\n\nCLI argument\n\n\nNetworkType enum\n\n\nObject classes\n\n\n\n\n\n\n\n\n\n\nSSD-Mobilenet-v1\n\n\nssd-mobilenet-v1\n\n\nSSD_MOBILENET_V1\n\n\n91 (\nCOCO classes\n)\n\n\n\n\n\n\nSSD-Mobilenet-v2\n\n\nssd-mobilenet-v2\n\n\nSSD_MOBILENET_V2\n\n\n91 (\nCOCO classes\n)\n\n\n\n\n\n\nSSD-Inception-v2\n\n\nssd-inception-v2\n\n\nSSD_INCEPTION_V2\n\n\n91 (\nCOCO classes\n)\n\n\n\n\n\n\nDetectNet-COCO-Dog\n\n\ncoco-dog\n\n\nCOCO_DOG\n\n\ndogs\n\n\n\n\n\n\nDetectNet-COCO-Bottle\n\n\ncoco-bottle\n\n\nCOCO_BOTTLE\n\n\nbottles\n\n\n\n\n\n\nDetectNet-COCO-Chair\n\n\ncoco-chair\n\n\nCOCO_CHAIR\n\n\nchairs\n\n\n\n\n\n\nDetectNet-COCO-Airplane\n\n\ncoco-airplane\n\n\nCOCO_AIRPLANE\n\n\nairplanes\n\n\n\n\n\n\nped-100\n\n\npednet\n\n\nPEDNET\n\n\npedestrians\n\n\n\n\n\n\nmultiped-500\n\n\nmultiped\n\n\nPEDNET_MULTI\n\n\npedestrians, luggage\n\n\n\n\n\n\nfacenet-120\n\n\nfacenet\n\n\nFACENET\n\n\nfaces\n\n\n\n\n\n\n\n\n\n\nnano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh\n\n\n\n\nRunning Different Detection Models\n\n\nYou can specify which model to load by setting the \n--network\n flag on the command line to one of the corresponding CLI arguments from the table above.  By default, SSD-Mobilenet-v2 if the optional \n--network\n flag isn't specified.\n\n\nFor example, if you chose to download SSD-Inception-v2 with the \nModel Downloader\n tool, you can use it like so:\n\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-inception-v2 input.jpg output.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py --network=ssd-inception-v2 input.jpg output.jpg\n\n\n\n\n\n\nAssignment\n\n\nEvaluate the accuracy and inference time of \npeds_3.jpg\n, \nhumans_7.jpg\n for the object detection models launching the inference with the option \n--network\n for PedNet, SSD-Mobilenet-v2, SSD-Inception-v2, MultiPed\n\n\n\n\nPlease send a message to the professor as soon as you finished",
            "title": "objectDetection"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/#objects-detection-with-detectnet",
            "text": "The previous recognition examples output class probabilities representing the entire input image.  Next we're going to focus on  object detection , and finding where in the frame various objects are located by extracting their bounding boxes.  Unlike image classification, object detection networks are capable of detecting many different objects per frame.   The  detectNet  object accepts an image as input, and outputs a list of coordinates of the detected bounding boxes along with their classes and confidence values.   detectNet  is available to use from  Python  and  C++ .  See below for various  pre-trained detection models   available for download.  The default model used is a  91-class  SSD-Mobilenet-v2 model trained on the MS COCO dataset, which achieves realtime inferencing performance on Jetson with TensorRT.   As examples of using the  detectNet  class, we provide sample programs for C++ and Python:   detectnet.cpp  (C++)   detectnet.py  (Python)    These samples are able to detect objects in images, videos, and camera feeds. The  Camera Streaming and Multimedia  can pass the video directly to  detectNet .",
            "title": "Objects Detection with DetectNet"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/#detecting-objects-from-images",
            "text": "First, let's try using the  detectnet  program to locates objects in static images.  In addition to the input/output paths, there are some additional command-line options:   optional  --network  flag which changes the  detection model  being used (the default is SSD-Mobilenet-v2).  optional  --overlay  flag which can be comma-separated combinations of  box ,  lines ,  labels ,  conf , and  none  The default is  --overlay=box,labels,conf  which displays boxes, labels, and confidence values  The  box  option draws filled bounding boxes, while  lines  draws just the unfilled outlines    optional  --alpha  value which sets the alpha blending value used during overlay (the default is  120 ).  optional  --threshold  value which sets the minimum threshold for detection (the default is  0.5 ).     If you're using the  Docker container , it's recommended to save the output images to the  images/test  mounted directory.  These images will then be easily viewable from your host device under  jetson-inference/data/images/test .   Here are some examples of detecting pedestrians in images with the default SSD-Mobilenet-v2 model:  # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output.jpg     # --network flag is optional\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-mobilenet-v2 images/peds_0.jpg images/test/output.jpg     # --network flag is optional   # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet images/peds_1.jpg images/test/output.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py images/peds_1.jpg images/test/output.jpg    note :  the first time you run each model, TensorRT will take a few minutes to optimize the network.  \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0this optimized network file is then cached to disk, so future runs using the model will load faster.   Below are more detection examples output from the console programs.  The  91-class  MS COCO dataset that the SSD-based models were trained on include people, vehicles, animals, and assorted types of household objects to detect.   Various images are found under  images/  for testing, such as  cat_*.jpg ,  dog_*.jpg ,  horse_*.jpg ,  peds_*.jpg , ect.",
            "title": "Detecting Objects from Images"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/#processing-video-files",
            "text": "You can also process videos from disk.   # Download test video\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# cd images\nroot@jetson-nano:/jetson-inference/build/aarch64/bin/images# wget https://nvidia.box.com/shared/static/veuuimq6pwvd62p9fresqhrrmfqz0e2f.mp4 -O pedestrians.mp4\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet pedestrians.mp4 images/test/pedestrians_ssd.mp4\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py pedestrians.mp4 images/test/pedestrians_ssd.mp4   # Download test video\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# cd images\nroot@jetson-nano:/jetson-inference/build/aarch64/bin/images# wget https://nvidia.box.com/shared/static/i5i81mkd9wdh4j7wx04th961zks0lfh9.avi -O parking.avi\n\n# C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet parking.avi images/test/parking_ssd.avi\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py parking.avi images/test/parking_ssd.avi   Remember that you can use the  --threshold  setting to change the detection sensitivity up or down (the default is 0.5).",
            "title": "Processing Video Files"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/#pre-trained-detection-models-available",
            "text": "Below is a table of the pre-trained object detection networks available for  download , and the associated  --network  argument to  detectnet  used for loading the pre-trained models:     Model  CLI argument  NetworkType enum  Object classes      SSD-Mobilenet-v1  ssd-mobilenet-v1  SSD_MOBILENET_V1  91 ( COCO classes )    SSD-Mobilenet-v2  ssd-mobilenet-v2  SSD_MOBILENET_V2  91 ( COCO classes )    SSD-Inception-v2  ssd-inception-v2  SSD_INCEPTION_V2  91 ( COCO classes )    DetectNet-COCO-Dog  coco-dog  COCO_DOG  dogs    DetectNet-COCO-Bottle  coco-bottle  COCO_BOTTLE  bottles    DetectNet-COCO-Chair  coco-chair  COCO_CHAIR  chairs    DetectNet-COCO-Airplane  coco-airplane  COCO_AIRPLANE  airplanes    ped-100  pednet  PEDNET  pedestrians    multiped-500  multiped  PEDNET_MULTI  pedestrians, luggage    facenet-120  facenet  FACENET  faces      nano@jetson-nano:~$ cd jetson-inference/tools\nnano@jetson-nano:~/jetson-inference$ ./download-models.sh",
            "title": "Pre-trained Detection Models Available"
        },
        {
            "location": "/Subjects/EDGE/Week7/objectDetection/#running-different-detection-models",
            "text": "You can specify which model to load by setting the  --network  flag on the command line to one of the corresponding CLI arguments from the table above.  By default, SSD-Mobilenet-v2 if the optional  --network  flag isn't specified.  For example, if you chose to download SSD-Inception-v2 with the  Model Downloader  tool, you can use it like so:  # C++\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet --network=ssd-inception-v2 input.jpg output.jpg\n\n# Python\nroot@jetson-nano:/jetson-inference/build/aarch64/bin# ./detectnet.py --network=ssd-inception-v2 input.jpg output.jpg   Assignment  Evaluate the accuracy and inference time of  peds_3.jpg ,  humans_7.jpg  for the object detection models launching the inference with the option  --network  for PedNet, SSD-Mobilenet-v2, SSD-Inception-v2, MultiPed   Please send a message to the professor as soon as you finished",
            "title": "Running Different Detection Models"
        },
        {
            "location": "/Subjects/IA/groups/",
            "text": "Groups for lecture assignments\n\n\nWe will be using the stable groups from NP1 to work during lectures (and after\nclass).\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nBIN ZHANG\n\n\n\n\n\n\nRecorder\n\n\nFENGFENG GU\n\n\n\n\n\n\nAuditor\n\n\nGONGLU ZOU\n\n\n\n\n\n\nContributor\n\n\nWENYAN LIAO\n\n\n\n\n\n\n\n\nGroup 2\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nDuan Zhen\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nLiu Jinhua\n\n\n\n\n\n\nContributor\n\n\nYouran Tian\n\n\n\n\n\n\nContributor\n\n\nWeilin Zhang\n\n\n\n\n\n\nContributor\n\n\nHuang Yujuan\n\n\n\n\n\n\nContributor\n\n\nJun Shou\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nShaYuan Shuang\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nWEI REN\n\n\n\n\n\n\nContributor\n\n\nXIAZU HU\n\n\n\n\n\n\n\n\nGroup 5\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\nSpeaker (2)\n\n\nLIAO Yinghua\n\n\n\n\n\n\nRecorder\n\n\nPAN Jiayun\n\n\n\n\n\n\nAuditor\n\n\nZHANG  Yi\n\n\n\n\n\n\nContributor\n\n\nShuishi Zhou\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nContributor\n\n\nHongbiao Cao\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nXionglan Luo\n\n\n\n\n\n\nAuditor\n\n\nQiuji Chen\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang\n\n\n\n\n\n\nContributor\n\n\nYan Zhao\n\n\n\n\n\n\nContributor\n\n\nYongtao He\n\n\n\n\n\n\nContributor\n\n\nZhao Hu",
            "title": "Groups"
        },
        {
            "location": "/Subjects/IA/groups/#groups-for-lecture-assignments",
            "text": "We will be using the stable groups from NP1 to work during lectures (and after\nclass).",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/IA/groups/#group-1",
            "text": "Rol  Full name      Speaker  BIN ZHANG    Recorder  FENGFENG GU    Auditor  GONGLU ZOU    Contributor  WENYAN LIAO",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/IA/groups/#group-2",
            "text": "Rol  Full name      Speaker  Duan Zhen    Recorder  Hu Haho    Auditor  Liu Jinhua    Contributor  Youran Tian    Contributor  Weilin Zhang    Contributor  Huang Yujuan    Contributor  Jun Shou",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/IA/groups/#group-3",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  ShaYuan Shuang    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/IA/groups/#group-4",
            "text": "Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG YU    Auditor  SUIZHI LIU    Contributor  TIANFENG LI    Contributor  WEI REN    Contributor  XIAZU HU",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/IA/groups/#group-5",
            "text": "Rol  Full name      Speaker  ZHOU Ping    Speaker (2)  LIAO Yinghua    Recorder  PAN Jiayun    Auditor  ZHANG  Yi    Contributor  Shuishi Zhou    Contributor  Yang Chu    Contributor  Hongbiao Cao",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/IA/groups/#group-6",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Xionglan Luo    Auditor  Qiuji Chen    Contributor  Jianchuang Zhang    Contributor  Yan Zhao    Contributor  Yongtao He    Contributor  Zhao Hu",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/IA/",
            "text": "ARTIFICIAL INTELLIGENCE\n\n\nGeneral Information\n\n\nThis subject will introduce you to artificial intelligence techniques, mostly from a practical point of view.\n\n\nProfessor\n\n\nHector Garcia de Marina (hgarciad@ucm.es)\n\n\nEvaluation\n\n\nThe final grade will consist of a number of quizzes during the the course, and a final project during the last two weeks of the course.\n\n\nSoftware requirements\n\n\nUbuntu 20.04 & Python\n\n\nInstructions to set up the required software\n\n\nrequirements.txt\n\n\nWork groups\n\n\nThe groups are the same as for NP1, please check them \nhere\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay/Month\n\n\nTopic\n\n\nDeliverable\n\n\nQuizz\n\n\n\n\n\n\n\n\n\n\n18/01\n\n\nIntroduction\n\n\n\n\n\n\n\n\n\n\n19/01\n\n\nMath recap for AI and NumPy, \nJupyter excercises\n, \nSample image\n, \nJupyter classroom notes\n\n\n\n\n\n\n\n\n\n\n25/01\n\n\nNeural Networks from scratch\n\n\n\n\n\n\n\n\n\n\n26/01\n\n\nNeural Networks from scratch 2\n\n\n\n\n\n\n\n\n\n\n08/02\n\n\nNeural Networks with pyTorch\n\n\nExercise on Neural Networks from Scratch\n\n\nQuizz on Neural Networks from scratch\n\n\n\n\n\n\n09/02\n\n\nNeural Network exercise with pyTorch\n\n\n\n\n\n\n\n\n\n\n15/02\n\n\nNeural Network regression with pyTorch\n\n\n\n\n\n\n\n\n\n\n16/02\n\n\nSupport-vector machine\n\n\n\n\n\n\n\n\n\n\n22/02\n\n\nSupport-vector machine assignment\n\n\n\n\n\n\n\n\n\n\n23/02\n\n\nGenetic algorithm\n\n\nGenetic algorithm slides\n\n\nQuizz on Support-vector machines\n\n\n\n\n\n\n01/03\n\n\nK-nearest neighbors\n, \ndata.txt\n, \ntargets.txt\n\n\nK-nearest neighbors slides\n\n\n\n\n\n\n\n\n02/03\n\n\n\n\n\n\n\n\n\n\n\n\n08/03\n\n\nPID controller\n\n\nPID controller slides\n\n\n\n\n\n\n\n\n09/03\n\n\n\n\n\n\n\n\n\n\n\n\n15/03\n\n\nPath following\n\n\nPath following slides\n\n\nPath following (sine trajectory)\n\n\n\n\n\n\n16/03\n\n\n\n\n\n\n\n\n\n\n\n\n22/03\n\n\nWork on Final Project\n\n\nFinal project exercises\n\n\n\n\n\n\n\n\n23/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n29/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n30/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n05/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n06/03\n\n\nWork on Final Project",
            "title": "Home"
        },
        {
            "location": "/Subjects/IA/#artificial-intelligence",
            "text": "",
            "title": "ARTIFICIAL INTELLIGENCE"
        },
        {
            "location": "/Subjects/IA/#general-information",
            "text": "This subject will introduce you to artificial intelligence techniques, mostly from a practical point of view.",
            "title": "General Information"
        },
        {
            "location": "/Subjects/IA/#professor",
            "text": "Hector Garcia de Marina (hgarciad@ucm.es)",
            "title": "Professor"
        },
        {
            "location": "/Subjects/IA/#evaluation",
            "text": "The final grade will consist of a number of quizzes during the the course, and a final project during the last two weeks of the course.",
            "title": "Evaluation"
        },
        {
            "location": "/Subjects/IA/#software-requirements",
            "text": "Ubuntu 20.04 & Python  Instructions to set up the required software  requirements.txt",
            "title": "Software requirements"
        },
        {
            "location": "/Subjects/IA/#work-groups",
            "text": "The groups are the same as for NP1, please check them  here",
            "title": "Work groups"
        },
        {
            "location": "/Subjects/IA/#schedule",
            "text": "Day/Month  Topic  Deliverable  Quizz      18/01  Introduction      19/01  Math recap for AI and NumPy,  Jupyter excercises ,  Sample image ,  Jupyter classroom notes      25/01  Neural Networks from scratch      26/01  Neural Networks from scratch 2      08/02  Neural Networks with pyTorch  Exercise on Neural Networks from Scratch  Quizz on Neural Networks from scratch    09/02  Neural Network exercise with pyTorch      15/02  Neural Network regression with pyTorch      16/02  Support-vector machine      22/02  Support-vector machine assignment      23/02  Genetic algorithm  Genetic algorithm slides  Quizz on Support-vector machines    01/03  K-nearest neighbors ,  data.txt ,  targets.txt  K-nearest neighbors slides     02/03       08/03  PID controller  PID controller slides     09/03       15/03  Path following  Path following slides  Path following (sine trajectory)    16/03       22/03  Work on Final Project  Final project exercises     23/03  Work on Final Project      29/03  Work on Final Project      30/03  Work on Final Project      05/03  Work on Final Project      06/03  Work on Final Project",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/IOTNA/groups/",
            "text": "Groups for lecture assignments\n\n\nAs explained during last lectures, we will be forming stable groups to work during lectures (and after class).\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nAyiqiqieke    Kaisaier\n\n\n\n\n\n\nSpeaker (2)\n\n\nYouran Tian\n\n\n\n\n\n\nRecorder\n\n\nJun Shou\n\n\n\n\n\n\nAuditor\n\n\nTangRenJie\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nContributor\n\n\nShuishi Zhou\n\n\n\n\n\n\n\n\nGroup 2\n\n\nThis group is randomly assigned, since I had no notice\nfrom any of the integrants.\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nBIN     ZHANG\n\n\n\n\n\n\nRecorder\n\n\nFENGFENG  GU\n\n\n\n\n\n\nAuditor\n\n\nGONGLU ZOU\n\n\n\n\n\n\nContributor\n\n\nHONGBIAO   CAO\n\n\n\n\n\n\nContributor\n\n\nWENYAN   LIAO\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nDuan     Zhen\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nLiu  Jinhua\n\n\n\n\n\n\nContributor\n\n\nWeilin  Zhang\n\n\n\n\n\n\nContributor\n\n\nHuang    Yujuan\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nShaYuan Shuang\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\n\n\nGroup 5\n\n\nThis group is randomly assigned, since I had no notice\nfrom any of the integrants.\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG  YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI  LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nWEI  REN\n\n\n\n\n\n\nContributor\n\n\nXIAZU   HU\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\nSpeaker (2)\n\n\nLIAO  Yinghua\n\n\n\n\n\n\nRecorder\n\n\nZHAO Yan\n\n\n\n\n\n\nAuditor\n\n\nHE Yongtao\n\n\n\n\n\n\nContributor\n\n\nPAN Jiayun\n\n\n\n\n\n\nContributor\n\n\nZhao  Hu\n\n\n\n\n\n\nContributor\n\n\nZHANG  Yi\n\n\n\n\n\n\n\n\nGroup 7\n\n\nThis group is canceled. Previous members have been distributed in other groups.\n\n\nGroup 8\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nQiuji Chen\n\n\n\n\n\n\nAuditor\n\n\nXionglan Luo\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang",
            "title": "Groups"
        },
        {
            "location": "/Subjects/IOTNA/groups/#groups-for-lecture-assignments",
            "text": "As explained during last lectures, we will be forming stable groups to work during lectures (and after class).",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-1",
            "text": "Rol  Full name      Speaker  Ayiqiqieke    Kaisaier    Speaker (2)  Youran Tian    Recorder  Jun Shou    Auditor  TangRenJie    Contributor  Yang Chu    Contributor  Shuishi Zhou",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-2",
            "text": "This group is randomly assigned, since I had no notice\nfrom any of the integrants.     Rol  Full name      Speaker  BIN     ZHANG    Recorder  FENGFENG  GU    Auditor  GONGLU ZOU    Contributor  HONGBIAO   CAO    Contributor  WENYAN   LIAO",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-3",
            "text": "Rol  Full name      Speaker  Duan     Zhen    Recorder  Hu Haho    Auditor  Liu  Jinhua    Contributor  Weilin  Zhang    Contributor  Huang    Yujuan",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-4",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  ShaYuan Shuang    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-5",
            "text": "This group is randomly assigned, since I had no notice\nfrom any of the integrants.     Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG  YU    Auditor  SUIZHI  LIU    Contributor  TIANFENG LI    Contributor  WEI  REN    Contributor  XIAZU   HU",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-6",
            "text": "Rol  Full name      Speaker  ZHOU Ping    Speaker (2)  LIAO  Yinghua    Recorder  ZHAO Yan    Auditor  HE Yongtao    Contributor  PAN Jiayun    Contributor  Zhao  Hu    Contributor  ZHANG  Yi",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-7",
            "text": "This group is canceled. Previous members have been distributed in other groups.",
            "title": "Group 7"
        },
        {
            "location": "/Subjects/IOTNA/groups/#group-8",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Qiuji Chen    Auditor  Xionglan Luo    Contributor  Jianchuang Zhang",
            "title": "Group 8"
        },
        {
            "location": "/Subjects/IOTNA/",
            "text": "IoT Node Architecture\n\n\nGeneral information\n\n\nThis subject will cover several topics regarding embedded system programmings. Specifically, we will learn to develop IoT projects using \nESP-IDF\n, a framework built onto \nFreeRTOS\n.  Some specific goals if this subject are:\n\n\n\n\nGet a global view of a safe application  development cycle.\n\n\nMeet the main components of an IoT device\n\n\nLearn basic components of Real Time Operating Systems (RTOS)\n\n\nWork with sensors and learn the most common interfaces\n\n\n\n\nSubject program and evaluation methodology\n\n\nProgram and evaluation\n\n\nProfessors\n\n\nJose Ignacio Gomez (jigomez@ucm.es) and Katzalin Olcoz  (katzalin@ucm.es )\n\n\nWork groups (for regular lab assignments)\n\n\nHere you can find the current work groups\n\n\nPersonal paper project assignment\n\n\nHere you can find  description about this individual assignment\n\n\nFinal programming project (teams of 2 people)\n\n\nHere you can find  description about this  assignment\n\n\nQuizzes\n\n\nAll quizzes will be done in \nthis link\n. The name of the room is IOTUCM.\nYou MUST enter your email to answer the quizzes (the email address where you received mails from me).\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay\n\n\nTopic\n\n\nLab instructions\n\n\nDeliverable\n\n\n\n\n\n\n\n\n\n\n20/10\n\n\nIntroduction: boards, SoC\n\n\nC Exercises\n\n\n\n\n\n\n\n\n21/10\n\n\nESP-IDF environment\n\n\nOnline DEMO\n\n\n\n\n\n\n\n\n27/10\n\n\nESP-IDF\n\n\n1. Starting ESP-IDF \n\n\n\n\n\n\n\n\n28/10\n\n\nESP32 Memory map\n\n\n1. Starting ESP-IDF \n\n\n\n\n\n\n\n\n03/11\n\n\nESP-IDF Tasks Scheduler\n\n\n2. Tasks: matrix multiply \n\n\n\n\n\n\n\n\n04/11\n\n\nESP-IDF Tasks Scheduler\n\n\n2. Tasks: matrix multiply \n\n\n\n\n\n\n\n\n10/11\n\n\nEvents and task notifications\n\n\n2. Tasks: matrix multiply  \n\n\n\n\n\n\n\n\n11/11\n\n\nInput/Output\n -  \nPolling/Interrupts\n -  \nGPIO\n\n\n3. Chronometer\n\n\n\n\n\n\n\n\n17/11\n\n\nTimers\n\n\n3. Chronometer\n\n\n\n\n\n\n\n\n18/11\n\n\nEvent based programming\n\n\n3. Chronometer\n\n\nLab 2 deadline\n\n\n\n\n\n\n24/11\n\n\nEvent based programming. \nNAND/NOR Flash\n\n\n3. Chronometer\n\n\n\n\n\n\n\n\n25/11\n\n\nFile system\n. \nSystem Log\n\n\n4. Log in flash\n\n\n\n\n\n\n\n\n01/12\n\n\nWatchdog\n\n\n4. Log in flash\n\n\nLab 3 deadline\n\n\n\n\n\n\n02/12\n\n\nSensors\n.\n\n\n4. Log in flash\n\n\n\n\n\n\n\n\n08/12\n\n\nNO LECTURE (non working day)\n\n\nSpain National Holiday\n\n\n\n\n\n\n\n\n09/12\n\n\nSerial buses: I2C, SPI, UART\n\n\n4. Log in flash\n\n\n\n\n\n\n\n\n15/12\n\n\nQUIZ\n.  \nESP-IDF I2C API\n\n\n5. Built-in sensors\n.   \nHTS221 Datasheet\n\n\nLab4 deadline\n\n\n\n\n\n\n16/12\n\n\nI2C\n\n\n5. Built-in sensors\n .  \nHTS221 Datasheet\n\n\n\n\n\n\n\n\n22/12\n\n\nEnergy consumption\n. \nPowering the system\n\n\n5. Built-in sensors\n\n\n\n\n\n\n\n\n23/12\n\n\nQUIZ\n. \nESP32 power modes\n\n\n6. Low power modes\n\n\nLabs 5  deadline\n\n\n\n\n\n\n12/01\n\n\nFinal Programming project  (groups of 2)\n\n\n7. Final Project\n\n\nPaper project deadline\n\n\n\n\n\n\n13/01\n\n\nQUIZ\n. Final Programming project\n\n\n7. Final Project\n\n\nLab 6 deadline\n\n\n\n\n\n\n\n\nThe final programming project, will be due before 24th Jan. 2022",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/#iot-node-architecture",
            "text": "",
            "title": "IoT Node Architecture"
        },
        {
            "location": "/Subjects/IOTNA/#general-information",
            "text": "This subject will cover several topics regarding embedded system programmings. Specifically, we will learn to develop IoT projects using  ESP-IDF , a framework built onto  FreeRTOS .  Some specific goals if this subject are:   Get a global view of a safe application  development cycle.  Meet the main components of an IoT device  Learn basic components of Real Time Operating Systems (RTOS)  Work with sensors and learn the most common interfaces",
            "title": "General information"
        },
        {
            "location": "/Subjects/IOTNA/#subject-program-and-evaluation-methodology",
            "text": "Program and evaluation",
            "title": "Subject program and evaluation methodology"
        },
        {
            "location": "/Subjects/IOTNA/#professors",
            "text": "Jose Ignacio Gomez (jigomez@ucm.es) and Katzalin Olcoz  (katzalin@ucm.es )",
            "title": "Professors"
        },
        {
            "location": "/Subjects/IOTNA/#work-groups-for-regular-lab-assignments",
            "text": "Here you can find the current work groups",
            "title": "Work groups (for regular lab assignments)"
        },
        {
            "location": "/Subjects/IOTNA/#personal-paper-project-assignment",
            "text": "Here you can find  description about this individual assignment",
            "title": "Personal paper project assignment"
        },
        {
            "location": "/Subjects/IOTNA/#final-programming-project-teams-of-2-people",
            "text": "Here you can find  description about this  assignment",
            "title": "Final programming project (teams of 2 people)"
        },
        {
            "location": "/Subjects/IOTNA/#quizzes",
            "text": "All quizzes will be done in  this link . The name of the room is IOTUCM.\nYou MUST enter your email to answer the quizzes (the email address where you received mails from me).",
            "title": "Quizzes"
        },
        {
            "location": "/Subjects/IOTNA/#schedule",
            "text": "Day  Topic  Lab instructions  Deliverable      20/10  Introduction: boards, SoC  C Exercises     21/10  ESP-IDF environment  Online DEMO     27/10  ESP-IDF  1. Starting ESP-IDF      28/10  ESP32 Memory map  1. Starting ESP-IDF      03/11  ESP-IDF Tasks Scheduler  2. Tasks: matrix multiply      04/11  ESP-IDF Tasks Scheduler  2. Tasks: matrix multiply      10/11  Events and task notifications  2. Tasks: matrix multiply       11/11  Input/Output  -   Polling/Interrupts  -   GPIO  3. Chronometer     17/11  Timers  3. Chronometer     18/11  Event based programming  3. Chronometer  Lab 2 deadline    24/11  Event based programming.  NAND/NOR Flash  3. Chronometer     25/11  File system .  System Log  4. Log in flash     01/12  Watchdog  4. Log in flash  Lab 3 deadline    02/12  Sensors .  4. Log in flash     08/12  NO LECTURE (non working day)  Spain National Holiday     09/12  Serial buses: I2C, SPI, UART  4. Log in flash     15/12  QUIZ .   ESP-IDF I2C API  5. Built-in sensors .    HTS221 Datasheet  Lab4 deadline    16/12  I2C  5. Built-in sensors  .   HTS221 Datasheet     22/12  Energy consumption .  Powering the system  5. Built-in sensors     23/12  QUIZ .  ESP32 power modes  6. Low power modes  Labs 5  deadline    12/01  Final Programming project  (groups of 2)  7. Final Project  Paper project deadline    13/01  QUIZ . Final Programming project  7. Final Project  Lab 6 deadline     The final programming project, will be due before 24th Jan. 2022",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/",
            "text": "Personal paper project\n\n\nAs I explained the first day of course (and you can find in the provided slides), \nyou need to develop a personal (individual) paper project\n. Here I copy the guidelines that you can also find in the \nSoC slides\n\n\nDeadline\n\n\nOriginally 20th Dec. \nEXTENDED deadline to 10th January 2022.\n\n\nProject description\n\n\nFirst, you need to imagine a specific scenario where IoT could help. Think on a \nsmall\n application of any typical IoT use case (smart cities, home automation, eHealth, smart agriculture...).\n\n\nThen you need to perform a theoretical study about the required hardware components, including:\n\n\n\n\nWhich node would you buy?  Which SoC? Which prototype board for the initial tests?  Include several candidates in your study and motivate why you choose one of them\n\n\nWhich sensors do you require? You need to specify which kind of sensor and also which exact model\n\n\nHow much computation would you need to perform in the node?\n\n\nWhich RTOS (Real Time Operating System)? Which IDE to develop?\n\n\nWhich are the communication requirements? (how often do you communicate data, how much data...)\n\n\nWhere will be energy spent? How are you powering the system?\n\n\nThink about the final packaging of the system (a plastic box built with a 3D printer? Any specific material?)\n\n\nInclude the (approximate) total budget. Include links to online shops where you could buy the material\n\n\n\n\nIMPORTANTE: there is NO code to be develop. Only paper work.\n\n\nWork extension\n\n\nYou need to motivate each decision (why do you choose a specific SoC and not another one?) but I do not expect the work to be extra-long. Definitely \nno more than 10 pages\n.\n\n\nDelivering the project\n\n\nOnce finished, please send me an email (to jigomez@ucm.es)",
            "title": "paperProject"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/#personal-paper-project",
            "text": "As I explained the first day of course (and you can find in the provided slides),  you need to develop a personal (individual) paper project . Here I copy the guidelines that you can also find in the  SoC slides",
            "title": "Personal paper project"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/#deadline",
            "text": "Originally 20th Dec.  EXTENDED deadline to 10th January 2022.",
            "title": "Deadline"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/#project-description",
            "text": "First, you need to imagine a specific scenario where IoT could help. Think on a  small  application of any typical IoT use case (smart cities, home automation, eHealth, smart agriculture...).  Then you need to perform a theoretical study about the required hardware components, including:   Which node would you buy?  Which SoC? Which prototype board for the initial tests?  Include several candidates in your study and motivate why you choose one of them  Which sensors do you require? You need to specify which kind of sensor and also which exact model  How much computation would you need to perform in the node?  Which RTOS (Real Time Operating System)? Which IDE to develop?  Which are the communication requirements? (how often do you communicate data, how much data...)  Where will be energy spent? How are you powering the system?  Think about the final packaging of the system (a plastic box built with a 3D printer? Any specific material?)  Include the (approximate) total budget. Include links to online shops where you could buy the material   IMPORTANTE: there is NO code to be develop. Only paper work.",
            "title": "Project description"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/#work-extension",
            "text": "You need to motivate each decision (why do you choose a specific SoC and not another one?) but I do not expect the work to be extra-long. Definitely  no more than 10 pages .",
            "title": "Work extension"
        },
        {
            "location": "/Subjects/IOTNA/paperProject/#delivering-the-project",
            "text": "Once finished, please send me an email (to jigomez@ucm.es)",
            "title": "Delivering the project"
        },
        {
            "location": "/Subjects/IOTNA/P1/",
            "text": "Introduction to ESP-IDF and Platform IO. First project\n\n\nGoals\n\n\n\n\nBuild your first project using PlatformIO\n\n\nConnect your ESP32 meshkit-sense  board to the computer and upload a simple application\n\n\nMonitor your application using the serial port\n\n\n\n\nCreate a PlatformIO project\n\n\nWhenever you want to create a new project, you can add it using the PlatformIO interface.  First, click the \nPlatformIo Home\n icon:\n\n\n\n\nFrom the \"PIO Home\" tab, select \"New Project\" and the \nProject Wizard\n window will show up:\n\n\n\n\nIn that window:\n\n\n\n\nWrite your  project name (do not use white spaces)\n\n\nSelect \nEspressif ESP32 Dev Module\n  as \nBoard\n\n\nSelect \nEspressif IoT Development framework\n as \nFramework\n\n\nIf you want to choose an \nad-hoc\n location for your project, unselect \nUse default location\n\n\nPress \nFinish\n\n\n\n\nYou are done! Your first ESP-IDF project in PlatformIO is already created.\n\n\n\n\nStop and Sync\n\n\nIf you reach this step, please contact the instructor in the chat to let him/her know. \n\n\n\n\nProject configuration\n\n\nBefore proceeding with the application coding, you should configure the project so the framework knows where to find the device and how to communicate with it. There are two main options that we need to specify in the project configuration. Follow the next steps to do it;\n\n\n\n\nDouble click the file \nplatformio.ini\n to open it in the editor.\n\n\nBy default it has three options included: \nplatform\n, \nboard\n, \nframework\n. We are going to include two more below those three:\n\n\nmonitor_speed = 115200\n\n\nupload_port = /tty/USB1\n\n\n\n\n\n\n\n\nNote that the \nupload_port\n specified above is the one used by default in the Virtual Machine provided. If you are not using it, make sure you write the correct port name.\n\n\nIncluding source code\n\n\nThe new project will automatically create a \nsrc\n folder, including a default \nmain.c\n file with the following content:\n\n\nvoid app_main()\n{\n}\n\n\n\n\nWe are going to write a very simple \nHello World\n application. Write the following code in \nmain.c\n file:\n\n\n#include <stdio.h>\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n\nvoid app_main(void)\n{\n\n   while (1) {\n    printf(\"Hello world!\\n\");\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n  }\n  vTaskDelete(NULL);\n}\n\n\n\n\nOnce you have written the source code, you can proceed to build the project.  To do so, you can display the  \nProject Tasks\n (\nView->Command Palette\n) and execute  \nPlatformIO: Build\n. You could also press the \nBuild\n button (\ncheck\n button in the bottom pane).\n\n\n\n\nIf the building process works ok (it may take a few minutes the first time)  you should see a message similar to:\n\n\n\n\n\n\nStop and Sync\n\n\nIf you reach this step, please contact the instructor in the chat to let him/her know. \n\n\n\n\nFlashing the project\n\n\nOnce we have our application built (note that our source code is linked with the whole ESP-IDF environment, including \nFreeRTOS\n), we are ready to upload it to our ESP32 device (this operation is commonly known as \nflash\n because we will be writing the binary file in flash memory). \n\n\nFirst, plug the ESP32 MeshKit to the ESP-Prog board with the provided connection.  Then, connect the microUSB wire to the corresponding ESP-Prog port and plug the USB end of the wire to your computes USB port. If you are using a virtual machine, you will need to claim the device from the virtual machine, as the host will very likely keep the device by default.\n\n\nOnce you are done physically connecting the devices, you can proceed with the uploading. You can use the  \nPlatformIO: Upload\n task from \nProject Tasks\n or click in the corresponding button of the bottom pane:\n\n\n\n\nMonitoring the project\n\n\nFinally, you can open a serial connection from your computer to the device to monitor the progress.  You can select \nPlatformIO: Monitor\n from the \nProject Tasks\n or click the \nplug\n button in the bottom pane:\n\n\n\n\nOnce done, you should see the message *Hello World\" in your screen once every second.\n\n\nCongrats! You have uploaded your first ESP32 project!\n\n\n\n\nStop and Sync\n\n\nIf you reach this step, please contact the instructor in the chat to let him/her know. \n\n\n\n\nTasks / Homework (28/10/2021)\n\n\n\n\nTask\n\n\nKeep a snapshot of your screen at the end of every section (i.e. whenever a \nStop and Sync\n message appears in these instructions) and paste them in a PDF file including the information of your group (names of each of the members of the group). Send the PDF file to the instructor (jigomez@ucm.es) \nby the end of this session\n (just one file per group).\n\n\n\n\n\n\nHomework\n\n\nModify the \nHello World\n project so that it prints 10 messages, then it waits for 5 seconds and finally restarts the system. You can find which function you could use for the reset in the \nofficial ESP-IDF documentation\n. Send the modified source code (only the file \nmain.c\n) to the instructor before the start of next session (just one file per group).\n\n\n\n\nExtra (OPTIONAL): Memory Map\n\n\nOur ESP32 has several memory types (details can be found \nin this link\n and with more details in the \nTechnical Reference Manuel (Chapter 1)\n\n\nMost of the code will be placed in the external, flash based memory (SPI flash).  But we can also used some other modules. The most relevant are:\n\n\n\n\n\n\nData RAM\n. Global variables (non-constant) are assigned to this SRAM (Static RAM) memory.   Remaining space in this region is used for the runtime heap. This space is mapped to the \nInternal SRAM 2\n (200KB) starting at address 0x3FFA_E000 and could also use \nInternal SRAM 1\n (128KB) starting at 0x3FFE_0000. Note that SRAM1 could be also used as instruction memory.\n\n\n\n\n\n\nDROM\n (data stored in Flash). By default, constant data is placed by the linker into a region mapped to the MMU flash cache. \n\n\n\n\n\n\nInstruction RAM\n ESP-IDF allocates part of Internal SRAM0 region for instruction RAM. It allows us to use the range 0x4008_0000 to 0x400A_0000 to store parts of the application which need to run from RAM instead of Flash (for example, interrupt handlers are good candidates since they need to run as fast as possible). In order to place code in IRAM we may use the \nIRAM_ATTR\n macro:\n\n\n\n\n\n\n #include \"esp_attr.h\"\n\nvoid IRAM_ATTR gpio_isr_handler(void* arg)\n{\n        // ...\n}\n\n\n\n\nHeap memory allocation\n\n\nSince FreeRTOS is mult-threaded, each RTOS task has its own stack. By default, each of these stacks is allocated from the heap when the task is created. \n\n\nSince there are multiple types of RAM, there are also several heaps with different capabilities. \nMost of the time, you can rely in the standard libc calls (\nmalloc()\n, \nfree()\n....). But you may explicitly ask for certain capabilities when allocating memory using \nheap_caps_malloc()\n. Please check \nthe documentation in this link for more details\n\n\n\n\nHomework (Optional)\n\n\nCreate a new project to explore the addresses of different variables. Declare different variables: g lobal variables with initial value, global variables without initial value, global \nconst\n variables, local variables (stack), allocate memory in the heap using both \nmalloc()\nand \nheap_caps_malloc()\n and try to allocate some function in IRAM. Then print the address of all these symbols (variables, functions...) and check in which memories they are actually allocated.",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P1/#introduction-to-esp-idf-and-platform-io-first-project",
            "text": "",
            "title": "Introduction to ESP-IDF and Platform IO. First project"
        },
        {
            "location": "/Subjects/IOTNA/P1/#goals",
            "text": "Build your first project using PlatformIO  Connect your ESP32 meshkit-sense  board to the computer and upload a simple application  Monitor your application using the serial port",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P1/#create-a-platformio-project",
            "text": "Whenever you want to create a new project, you can add it using the PlatformIO interface.  First, click the  PlatformIo Home  icon:   From the \"PIO Home\" tab, select \"New Project\" and the  Project Wizard  window will show up:   In that window:   Write your  project name (do not use white spaces)  Select  Espressif ESP32 Dev Module   as  Board  Select  Espressif IoT Development framework  as  Framework  If you want to choose an  ad-hoc  location for your project, unselect  Use default location  Press  Finish   You are done! Your first ESP-IDF project in PlatformIO is already created.   Stop and Sync  If you reach this step, please contact the instructor in the chat to let him/her know.",
            "title": "Create a PlatformIO project"
        },
        {
            "location": "/Subjects/IOTNA/P1/#project-configuration",
            "text": "Before proceeding with the application coding, you should configure the project so the framework knows where to find the device and how to communicate with it. There are two main options that we need to specify in the project configuration. Follow the next steps to do it;   Double click the file  platformio.ini  to open it in the editor.  By default it has three options included:  platform ,  board ,  framework . We are going to include two more below those three:  monitor_speed = 115200  upload_port = /tty/USB1     Note that the  upload_port  specified above is the one used by default in the Virtual Machine provided. If you are not using it, make sure you write the correct port name.",
            "title": "Project configuration"
        },
        {
            "location": "/Subjects/IOTNA/P1/#including-source-code",
            "text": "The new project will automatically create a  src  folder, including a default  main.c  file with the following content:  void app_main()\n{\n}  We are going to write a very simple  Hello World  application. Write the following code in  main.c  file:  #include <stdio.h>\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n\nvoid app_main(void)\n{\n\n   while (1) {\n    printf(\"Hello world!\\n\");\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n  }\n  vTaskDelete(NULL);\n}  Once you have written the source code, you can proceed to build the project.  To do so, you can display the   Project Tasks  ( View->Command Palette ) and execute   PlatformIO: Build . You could also press the  Build  button ( check  button in the bottom pane).   If the building process works ok (it may take a few minutes the first time)  you should see a message similar to:    Stop and Sync  If you reach this step, please contact the instructor in the chat to let him/her know.",
            "title": "Including source code"
        },
        {
            "location": "/Subjects/IOTNA/P1/#flashing-the-project",
            "text": "Once we have our application built (note that our source code is linked with the whole ESP-IDF environment, including  FreeRTOS ), we are ready to upload it to our ESP32 device (this operation is commonly known as  flash  because we will be writing the binary file in flash memory).   First, plug the ESP32 MeshKit to the ESP-Prog board with the provided connection.  Then, connect the microUSB wire to the corresponding ESP-Prog port and plug the USB end of the wire to your computes USB port. If you are using a virtual machine, you will need to claim the device from the virtual machine, as the host will very likely keep the device by default.  Once you are done physically connecting the devices, you can proceed with the uploading. You can use the   PlatformIO: Upload  task from  Project Tasks  or click in the corresponding button of the bottom pane:",
            "title": "Flashing the project"
        },
        {
            "location": "/Subjects/IOTNA/P1/#monitoring-the-project",
            "text": "Finally, you can open a serial connection from your computer to the device to monitor the progress.  You can select  PlatformIO: Monitor  from the  Project Tasks  or click the  plug  button in the bottom pane:   Once done, you should see the message *Hello World\" in your screen once every second.  Congrats! You have uploaded your first ESP32 project!   Stop and Sync  If you reach this step, please contact the instructor in the chat to let him/her know.",
            "title": "Monitoring the project"
        },
        {
            "location": "/Subjects/IOTNA/P1/#tasks-homework-28102021",
            "text": "Task  Keep a snapshot of your screen at the end of every section (i.e. whenever a  Stop and Sync  message appears in these instructions) and paste them in a PDF file including the information of your group (names of each of the members of the group). Send the PDF file to the instructor (jigomez@ucm.es)  by the end of this session  (just one file per group).    Homework  Modify the  Hello World  project so that it prints 10 messages, then it waits for 5 seconds and finally restarts the system. You can find which function you could use for the reset in the  official ESP-IDF documentation . Send the modified source code (only the file  main.c ) to the instructor before the start of next session (just one file per group).",
            "title": "Tasks / Homework (28/10/2021)"
        },
        {
            "location": "/Subjects/IOTNA/P1/#extra-optional-memory-map",
            "text": "Our ESP32 has several memory types (details can be found  in this link  and with more details in the  Technical Reference Manuel (Chapter 1)  Most of the code will be placed in the external, flash based memory (SPI flash).  But we can also used some other modules. The most relevant are:    Data RAM . Global variables (non-constant) are assigned to this SRAM (Static RAM) memory.   Remaining space in this region is used for the runtime heap. This space is mapped to the  Internal SRAM 2  (200KB) starting at address 0x3FFA_E000 and could also use  Internal SRAM 1  (128KB) starting at 0x3FFE_0000. Note that SRAM1 could be also used as instruction memory.    DROM  (data stored in Flash). By default, constant data is placed by the linker into a region mapped to the MMU flash cache.     Instruction RAM  ESP-IDF allocates part of Internal SRAM0 region for instruction RAM. It allows us to use the range 0x4008_0000 to 0x400A_0000 to store parts of the application which need to run from RAM instead of Flash (for example, interrupt handlers are good candidates since they need to run as fast as possible). In order to place code in IRAM we may use the  IRAM_ATTR  macro:     #include \"esp_attr.h\"\n\nvoid IRAM_ATTR gpio_isr_handler(void* arg)\n{\n        // ...\n}",
            "title": "Extra (OPTIONAL): Memory Map"
        },
        {
            "location": "/Subjects/IOTNA/P1/#heap-memory-allocation",
            "text": "Since FreeRTOS is mult-threaded, each RTOS task has its own stack. By default, each of these stacks is allocated from the heap when the task is created.   Since there are multiple types of RAM, there are also several heaps with different capabilities. \nMost of the time, you can rely in the standard libc calls ( malloc() ,  free() ....). But you may explicitly ask for certain capabilities when allocating memory using  heap_caps_malloc() . Please check  the documentation in this link for more details   Homework (Optional)  Create a new project to explore the addresses of different variables. Declare different variables: g lobal variables with initial value, global variables without initial value, global  const  variables, local variables (stack), allocate memory in the heap using both  malloc() and  heap_caps_malloc()  and try to allocate some function in IRAM. Then print the address of all these symbols (variables, functions...) and check in which memories they are actually allocated.",
            "title": "Heap memory allocation"
        },
        {
            "location": "/Subjects/IOTNA/P2/",
            "text": "Task management in FreeRTOS (ESP-IDF)\n\n\nGoals\n\n\n\n\nLearn the task related API offered by ESP-IDF\n\n\nCreate multi-tasked applications where tasks effectively cooperate to a common goal.\n\n\n\n\nMatrix multiplication\n\n\nMatrix multiplication is a key kernel in many applications (for example, in Neural Network training and inference). \nIt is an example of a massively parallel computation, where all the elements of the output matrix (\nC\n in the image below) can be computed in parallel.\n\n\n\n\nThe most basic pseudo-code of the matrix multiplication is shown below:\n\n\nfor i = 0 to N\n  for j = 0 to M\n      C[i][j] = 0\n      for k=0 to K\n         C[i][j] += A[i][k]*B[k][j]\n\n\n\n\nwhere loops \ni\n and \nj\n are fully parallel. \n\n\n\n\nAssignment 1\n\n\nCreate a new project and write a function that will multiply two matrix (received as input arguments) and write the result in a third matrix (also provided as argument). You can choose N=8, M= 8, K =8 and \nuint32_t\n as element type. To make it easier to check the output, you can initialize B matrix as the identity matrix. \nPlease send a message to the professor as soon as you finished\n\n\n\n\nSimple parallelisation\n\n\nIn this exercise you will create two tasks. The first task will process the even rows of \nA\n (\ni=0,2,4,6...\n) and the second task will take care of the even rows.\n\n\nThe main task (the one executing \napp_main()\n) will simply create both task and then destroy itself.\n\n\n\n\nAssignment 2\n\n\nCreate a new project and implement the simple parallelization. Check the result with your previous sequential version. \nPlease send a message to the professor as soon as you finished\n\n\n\n\nWork dispatching\n\n\nIn this last (optional) exercise, you will implement a different parallelisation strategy: a \nController\n task ) will write pairs \n in a queue (from 0 to N-1).  A set of \nWorker tasks\n will read from that queue, obtain one pair \n and multiply row \ni\n of matrix A by column \nj\n of matrix B, and write the result as element \n[i,j]\n of matrix C.\n\n\nThe \nController\n task will insert all the pairs in the queue and then \nwait\n in a semaphore for the \nWorker\n tasks to complete. \n\n\n\n\nHomework (Optional)\n\n\nCreate a new project and implement this alternative. Try creating a different number of \nWorker\n tasks (from 1 to 4, for example) and measure the execution time. You may use\nesp_timer_get_time()\n to compute the total time.",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P2/#task-management-in-freertos-esp-idf",
            "text": "",
            "title": "Task management in FreeRTOS (ESP-IDF)"
        },
        {
            "location": "/Subjects/IOTNA/P2/#goals",
            "text": "Learn the task related API offered by ESP-IDF  Create multi-tasked applications where tasks effectively cooperate to a common goal.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P2/#matrix-multiplication",
            "text": "Matrix multiplication is a key kernel in many applications (for example, in Neural Network training and inference). \nIt is an example of a massively parallel computation, where all the elements of the output matrix ( C  in the image below) can be computed in parallel.   The most basic pseudo-code of the matrix multiplication is shown below:  for i = 0 to N\n  for j = 0 to M\n      C[i][j] = 0\n      for k=0 to K\n         C[i][j] += A[i][k]*B[k][j]  where loops  i  and  j  are fully parallel.    Assignment 1  Create a new project and write a function that will multiply two matrix (received as input arguments) and write the result in a third matrix (also provided as argument). You can choose N=8, M= 8, K =8 and  uint32_t  as element type. To make it easier to check the output, you can initialize B matrix as the identity matrix.  Please send a message to the professor as soon as you finished",
            "title": "Matrix multiplication"
        },
        {
            "location": "/Subjects/IOTNA/P2/#simple-parallelisation",
            "text": "In this exercise you will create two tasks. The first task will process the even rows of  A  ( i=0,2,4,6... ) and the second task will take care of the even rows.  The main task (the one executing  app_main() ) will simply create both task and then destroy itself.   Assignment 2  Create a new project and implement the simple parallelization. Check the result with your previous sequential version.  Please send a message to the professor as soon as you finished",
            "title": "Simple parallelisation"
        },
        {
            "location": "/Subjects/IOTNA/P2/#work-dispatching",
            "text": "In this last (optional) exercise, you will implement a different parallelisation strategy: a  Controller  task ) will write pairs   in a queue (from 0 to N-1).  A set of  Worker tasks  will read from that queue, obtain one pair   and multiply row  i  of matrix A by column  j  of matrix B, and write the result as element  [i,j]  of matrix C.  The  Controller  task will insert all the pairs in the queue and then  wait  in a semaphore for the  Worker  tasks to complete.    Homework (Optional)  Create a new project and implement this alternative. Try creating a different number of  Worker  tasks (from 1 to 4, for example) and measure the execution time. You may use esp_timer_get_time()  to compute the total time.",
            "title": "Work dispatching"
        },
        {
            "location": "/Subjects/IOTNA/P3/",
            "text": "Basic Input/output in ESP-IDF\n\n\nGoals\n\n\n\n\nLearn the basics of input/output, using polling and interrupts\n\n\nConfiguring and use GPIO pins as input/output\n\n\nProgram \ntimers\n to schedule periodic events\n\n\n\n\nDocumentation\n\n\nTo complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:\n\n\n\n\nGPIO\n\n*\u00a0\nTimers\n\n\n\n\nUsing GPIO\n\n\nChecking connections\n\n\nThe first step when using external peripherals connected to our SoC (ESP32) is to learn how are they connected. The module exposes a series of pines from the core and the operating system (ESP-IDF) assigns them a number. We need then to find out which pin number correspond to every relevant connection to us.\n\n\nIn this fist step, you must find out the GPIO number for the button and LED.  The information is usually included in the documentation of the SoC and the board: we need to check both, the SoC and the board. In our case, part of the information may be found in the brief \nonline documentation\n.  If you don't find all the information there, try to look it up carefully in the board itself. Sometimes, this information is printed on the PCB...\n\n\nSimple GPIO polling: button\n\n\nThe next step will be to set up the button to use it as an input for our system. First, you will need to configure the GPIO pin:\n\n\n\n\nConfigure the pin as INPUT.\n\n\nDisable interrupts.\n\n\nEnable pull-ip mode.\n\n\n\n\nCheck the slides and documentation to learn how to do this configuration in ESP-IDF. Remember that you need to declare a variable of type \ngpio_config_t\n, assign the relevant fields of such variable and finally call \ngpio_config( )\n  to complete the configuration.\n\n\nOnce the configuration of the GPIO is done, you can write a simple sampling loop. Write and endless \nwhile\n loop where you poll the status of the button, print a message if the button is pressed and wait for 250ms before polling again. A \npseudo-code\n for such loop could be the following:\n\n\nwhile (1) {\n   int status = gpio_get_level(GPIO_BUTTON_PIN);\n   if (status == BUTTON_PRESSED)\n      printf(\"Button pressed!!\\n\");\n   delay(250);\n}\n\n\n\n\nGPIO input and output: button + LED\n\n\nIn the next step, you will configure a GPIO pin as an output in order to control the LEDs.  Similar to the button configuration, the first step is to configure the respective pins (there are two LEDs available):\n\n\n\n\nConfigure the pin(s) as OUTPUT.\n\n\nDisable interrupts.\n\n\nDisable pull-up and pull-down modes.\n\n\n\n\nRemember to use  a variable of type \ngpio_config_t\n and complete the configuration with a call to \ngpio_config( )\n.\n\n\nOnce both the three pins (one input, two outputs) are correctly configured, you will develop a very simple program that will switch one of the LEDs (on/off) every time the \nbutton is pressed. The \npseudo-code\n may be similar to:\n\n\nwhile (1) {\n   int status = gpio_get_level(GPIO_BUTTON_PIN);\n   if (status == BUTTON_PRESSED) {\n        if LED_IS_ON \n       gpio_set_level(GPIO_LED_PIN, OFF);\n    else\n           gpio_set_level(GPIO_LED_PIN, ON);\n   }\n\n    delay(250);\n}\n\n\n\n\n\n\nStop and sync \n\n\nPlease send a message in Zoom chat  to the professor as soon as you finished\n\n\n\n\nGPIO interrupts\n\n\nIn this subsection you will change the polling mechanism and use interrupts instead. Starting from the configuration you already have for the button GPIO pin, you need to do certain modifications:\n\n\n\n\nEnable interrupts (for example, \nPOSEDGE\n). You may change the edge/level later using \ngpio_set_intr_type()\n.\n\n\nRegister the ISR that will be executed when the interrupt rises. You will need to call \ngpio_install_isr_service()\n and \ngpio_isr_handler_add\n.\n\n\n\n\nOnce the new configuration is done, you need to write the ISR for the button interrupts. Remember to use the correct protoype: \nstatic void IRAM_ATTR gpio_isr_handler(void* arg)\n(you may change the name of the ISR itself, but not its prototype).\n\n\nFinally, adapt the previous code (LED switching) to work with the new code. How are you going to notify you main loop about a new interrupt?\n\n\nExtending button functionality\n\n\nJust to play a bit longer with interrupts, let's extend the functionality of our application. Adapt your code so you can identify if the button was pressed \nnormally\n or if it was hold at least for 4 seconds:\n\n\n\n\nIf the button was just pressed (less than 4 seconds) you will switch the green LED.\n\n\nIf the button was pressed and hold for more than 4 seconds, you will switch the red LED.\n\n\n\n\nNote that, if both LEDs are on, you will see a yellow light.\n\n\n\n\nStop and sync \n\n\nPlease send a message (using Zoom) to the professor as soon as you finished.\n\n\n\n\nTimers\n\n\nNow we will include timers in our design.  Read again the slides and \nAPI documentation\n to remember how to declare and configure a timer in ESP-IDF.\n\n\nLED blink\n\n\nThen, create a timer that will blink the red LED every second (i.e. the red LED will be on for one second, then off for another second and so on). The green LED will still be controlled with the button (but keep your code detecting when the button was pressed for more than 4 seconds; you will use it later).\n\n\nControlling blinking frequency\n\n\nWe will define several blinking periods: 500ms,  1s or 2s. When your program starts, the red LED will be blinking every 500ms.  Then, your code must do the following:\n\n\n\n\nWhen the button is pressed, the period will increase, first to 1 second, then to 2 seconds.\n\n\nIf the button is pressed when the period is already 2 seconds, nothing changes.\n\n\nWhen the button is held pressed for more than 4 seconds, the period will decrease (from 2s to 1s and then to 500ms).\n\n\nIf the button is held pressed for more than 4 seconds when the period is 500ms, nothing changes.\n\n\n\n\n\n\nStop and sync \n\n\nAll previous exercises \nmust be finished DURING the lecture (not afterwards)\n and shown to the teacher during the Zoom meeting. AFTER they are shown to be working during the lecture, the \nRecorder\n of the group will send an email with the source code of the last section (\nControlling blinking frequency\n). Remind that plagiarism is strictly prohibited: the code of each group must be solely developed by members of that group.\n\n\n\n\nChronometer (optional)\n\n\nThis assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment. You will need to implement a simple chronometer with the following functionality:\n\n\n\n\nThe chronometer counts minutes and seconds.\n\n\nPressing the button starts/stops counting.\n\n\nHolding pressed the button for more than 4 seconds resets the count to 0.\n\n\nEvery second, the actual count (in a format MM:SS) will be shown in the terminal (using \nprintf()\n).\n\n\n\n\n\n\nHomework (Optional)\n\n\nImplement the chronometer using, at least, one \ntimer\n. Once finished, the \nSpeaker\n will contact me to \nexplain (orally) the code developed",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P3/#basic-inputoutput-in-esp-idf",
            "text": "",
            "title": "Basic Input/output in ESP-IDF"
        },
        {
            "location": "/Subjects/IOTNA/P3/#goals",
            "text": "Learn the basics of input/output, using polling and interrupts  Configuring and use GPIO pins as input/output  Program  timers  to schedule periodic events",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P3/#documentation",
            "text": "To complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:   GPIO \n*\u00a0 Timers",
            "title": "Documentation"
        },
        {
            "location": "/Subjects/IOTNA/P3/#using-gpio",
            "text": "",
            "title": "Using GPIO"
        },
        {
            "location": "/Subjects/IOTNA/P3/#checking-connections",
            "text": "The first step when using external peripherals connected to our SoC (ESP32) is to learn how are they connected. The module exposes a series of pines from the core and the operating system (ESP-IDF) assigns them a number. We need then to find out which pin number correspond to every relevant connection to us.  In this fist step, you must find out the GPIO number for the button and LED.  The information is usually included in the documentation of the SoC and the board: we need to check both, the SoC and the board. In our case, part of the information may be found in the brief  online documentation .  If you don't find all the information there, try to look it up carefully in the board itself. Sometimes, this information is printed on the PCB...",
            "title": "Checking connections"
        },
        {
            "location": "/Subjects/IOTNA/P3/#simple-gpio-polling-button",
            "text": "The next step will be to set up the button to use it as an input for our system. First, you will need to configure the GPIO pin:   Configure the pin as INPUT.  Disable interrupts.  Enable pull-ip mode.   Check the slides and documentation to learn how to do this configuration in ESP-IDF. Remember that you need to declare a variable of type  gpio_config_t , assign the relevant fields of such variable and finally call  gpio_config( )   to complete the configuration.  Once the configuration of the GPIO is done, you can write a simple sampling loop. Write and endless  while  loop where you poll the status of the button, print a message if the button is pressed and wait for 250ms before polling again. A  pseudo-code  for such loop could be the following:  while (1) {\n   int status = gpio_get_level(GPIO_BUTTON_PIN);\n   if (status == BUTTON_PRESSED)\n      printf(\"Button pressed!!\\n\");\n   delay(250);\n}",
            "title": "Simple GPIO polling: button"
        },
        {
            "location": "/Subjects/IOTNA/P3/#gpio-input-and-output-button-led",
            "text": "In the next step, you will configure a GPIO pin as an output in order to control the LEDs.  Similar to the button configuration, the first step is to configure the respective pins (there are two LEDs available):   Configure the pin(s) as OUTPUT.  Disable interrupts.  Disable pull-up and pull-down modes.   Remember to use  a variable of type  gpio_config_t  and complete the configuration with a call to  gpio_config( ) .  Once both the three pins (one input, two outputs) are correctly configured, you will develop a very simple program that will switch one of the LEDs (on/off) every time the \nbutton is pressed. The  pseudo-code  may be similar to:  while (1) {\n   int status = gpio_get_level(GPIO_BUTTON_PIN);\n   if (status == BUTTON_PRESSED) {\n        if LED_IS_ON \n       gpio_set_level(GPIO_LED_PIN, OFF);\n    else\n           gpio_set_level(GPIO_LED_PIN, ON);\n   }\n\n    delay(250);\n}   Stop and sync   Please send a message in Zoom chat  to the professor as soon as you finished",
            "title": "GPIO input and output: button + LED"
        },
        {
            "location": "/Subjects/IOTNA/P3/#gpio-interrupts",
            "text": "In this subsection you will change the polling mechanism and use interrupts instead. Starting from the configuration you already have for the button GPIO pin, you need to do certain modifications:   Enable interrupts (for example,  POSEDGE ). You may change the edge/level later using  gpio_set_intr_type() .  Register the ISR that will be executed when the interrupt rises. You will need to call  gpio_install_isr_service()  and  gpio_isr_handler_add .   Once the new configuration is done, you need to write the ISR for the button interrupts. Remember to use the correct protoype:  static void IRAM_ATTR gpio_isr_handler(void* arg) (you may change the name of the ISR itself, but not its prototype).  Finally, adapt the previous code (LED switching) to work with the new code. How are you going to notify you main loop about a new interrupt?",
            "title": "GPIO interrupts"
        },
        {
            "location": "/Subjects/IOTNA/P3/#extending-button-functionality",
            "text": "Just to play a bit longer with interrupts, let's extend the functionality of our application. Adapt your code so you can identify if the button was pressed  normally  or if it was hold at least for 4 seconds:   If the button was just pressed (less than 4 seconds) you will switch the green LED.  If the button was pressed and hold for more than 4 seconds, you will switch the red LED.   Note that, if both LEDs are on, you will see a yellow light.   Stop and sync   Please send a message (using Zoom) to the professor as soon as you finished.",
            "title": "Extending button functionality"
        },
        {
            "location": "/Subjects/IOTNA/P3/#timers",
            "text": "Now we will include timers in our design.  Read again the slides and  API documentation  to remember how to declare and configure a timer in ESP-IDF.",
            "title": "Timers"
        },
        {
            "location": "/Subjects/IOTNA/P3/#led-blink",
            "text": "Then, create a timer that will blink the red LED every second (i.e. the red LED will be on for one second, then off for another second and so on). The green LED will still be controlled with the button (but keep your code detecting when the button was pressed for more than 4 seconds; you will use it later).",
            "title": "LED blink"
        },
        {
            "location": "/Subjects/IOTNA/P3/#controlling-blinking-frequency",
            "text": "We will define several blinking periods: 500ms,  1s or 2s. When your program starts, the red LED will be blinking every 500ms.  Then, your code must do the following:   When the button is pressed, the period will increase, first to 1 second, then to 2 seconds.  If the button is pressed when the period is already 2 seconds, nothing changes.  When the button is held pressed for more than 4 seconds, the period will decrease (from 2s to 1s and then to 500ms).  If the button is held pressed for more than 4 seconds when the period is 500ms, nothing changes.    Stop and sync   All previous exercises  must be finished DURING the lecture (not afterwards)  and shown to the teacher during the Zoom meeting. AFTER they are shown to be working during the lecture, the  Recorder  of the group will send an email with the source code of the last section ( Controlling blinking frequency ). Remind that plagiarism is strictly prohibited: the code of each group must be solely developed by members of that group.",
            "title": "Controlling blinking frequency"
        },
        {
            "location": "/Subjects/IOTNA/P3/#chronometer-optional",
            "text": "This assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment. You will need to implement a simple chronometer with the following functionality:   The chronometer counts minutes and seconds.  Pressing the button starts/stops counting.  Holding pressed the button for more than 4 seconds resets the count to 0.  Every second, the actual count (in a format MM:SS) will be shown in the terminal (using  printf() ).    Homework (Optional)  Implement the chronometer using, at least, one  timer . Once finished, the  Speaker  will contact me to  explain (orally) the code developed",
            "title": "Chronometer (optional)"
        },
        {
            "location": "/Subjects/IOTNA/P4/",
            "text": "Logging and flash filesystem\n\n\nGoals\n\n\n\n\nLearn the logging mechanisms provided by ESP-IDF\n\n\nCreate your own partitions in SPI FLASH memory\n\n\nMount a filesystem in FLASH memory\n\n\n\n\nDocumentation\n\n\nTo complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:\n\n\n\n\nLog\n\n\nSPI Flash and partitions\n\n\nFAT filesystem\n\n\nWear levelling API\n\n\n\n\nLogging to UART\n\n\nBasic logging\n\n\nStart from your basic (single-task) matrix multiply code (Lab 2). Insert \nESP_LOG\n calls at least at 3 levels: ERROR, INFO and VERBOSE. \n\n\nModify logging level via menuconfig\n\n\nUse \nmenuconfig\n to select INFO as the minimum log level. Check that the VERBOSE messages are not shown\n\n\nMultimodule\n\n\nCreate a new .c file in your project. Include there a couple of functions from your code. Remind to declare. a new TAG there. Include LOG macros in both files. \n\n\nModify logging level at runtime\n\n\nUse \nesp_log_level_set()\nto set WARNING as the log level for the main file and VERBOSE for the other file. Check that the log output is correct.\n\n\n\n\nStop and sync \n\n\nAll previous exercises \nmust be finished DURING the lecture (not afterwards)\n and shown to the teacher during the Zoom meeting. AFTER they are shown to be working during the lecture, the \nRecorder\n of the group will send an email with the source code of the last section (\nModify logging level at runtime\n). \n Remind that plagiarism is strictly prohibited: the code of each group must be solely developed by members of that group.\n\n\n\n\nMounting FAT filesystem\n\n\nIn this step you will mount a FAT filesystem in a new partition created in the SPI FLASH existing in the board. \nFollow the example \nWear Levelling\n ( [wear levelling example])https://github.com/espressif/esp-idf/tree/master/examples/storage/wear_levelling) ) and create a PlatformIO project to run it in your board:\n\n\n\n\nCreate the PlatformIO project and copy the source code from the \nWear Levelling\n example.\n\n\nCopy the file \npartitions_example.csv\n in the root folder of your project. Rename it as \npartitions.csv\n\n\nModify the file \nplatformio.ini\n to include:\n\n\nmonitor_port = /dev/ttyUSB1\n\n\nupload_port = /dev/ttyUSB1\n\n\nboard_build.partitions = partitions.csv\n\n\n\n\n\n\nRun \nmenuconfig\n (type \npio run -t menuconfig\n in a PlatformIO terminal)\n\n\nPartition Table\n --> \nPartitionTable\n --> \nCustom partition table CSV\n\n\nCheck that the name of the \nCustom parition CSV file\n in \nmenuconfig\n is \npartitions.csv\n\n\nSave the new configuration (press \nS\n) and quit (press \nQ\n)\n\n\n\n\n\n\n\n\nBuild, upload and execute. Monitor the output and check that the messages are the ones expected.\n\n\n\n\nQuestions \n\n\nOnce you finished the code, try to answer the following questions. Include them in the report of this assignment.\n\n\n\n\nWhat is the name of the file you are creating in this example?\n\n\nWhat is the path of the file? Why? When was that \nfolder\n created?\n\n\nWhat is the difference between \nprintf()\n and \nfprintf()\n\n\nWhy there are two calls to `fopen()? What is the difference between them?   \n\n\nWhat is \nfgets()\ndoing? \n\n\nWrite a code that creates a new file called \ntimestamp.txt\n whose content is a timestamp (time elapsed since boot). How can we later modify its content?\n\n\nTry to open a file after the call \u00e8sp_vfs_fat_spiflash_umount()*. What happens?\n\n\n\n\n\n\nRedirecting the log to FLASH (optional)\n\n\nThis assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment. \n\n\nStarting from your chronometer code (or equivalent), include LOG messages (using ESP_LOG macros) and redirect the log to a file called \nlog.txt\n that you will create in a FAT partition in SPI FLAG. Use \nesp_log_set_vprintf()\n to do the redirection. You should LOG:\n\n\n\n\nEvery 5 seconds of the chronometer running, you must LOG a message.\n\n\nEvery time the button is pressed\n\n\nEvery time there is a \nlong\n press (more than 4 seconds).\n\n\n\n\nNote that you can still use \nprintf()\n to write to the terminal.\n\n\nAlso, after 1 minute of functioning, you will read the first 5 lines of the log file and write them to the terminal (using \nprintf()\n).\n\n\n\n\nHomework (Optional)\n\n\nOnce finished, the \nSpeaker\n will contact me to \nexplain (orally) the code developed",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P4/#logging-and-flash-filesystem",
            "text": "",
            "title": "Logging and flash filesystem"
        },
        {
            "location": "/Subjects/IOTNA/P4/#goals",
            "text": "Learn the logging mechanisms provided by ESP-IDF  Create your own partitions in SPI FLASH memory  Mount a filesystem in FLASH memory",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P4/#documentation",
            "text": "To complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:   Log  SPI Flash and partitions  FAT filesystem  Wear levelling API",
            "title": "Documentation"
        },
        {
            "location": "/Subjects/IOTNA/P4/#logging-to-uart",
            "text": "",
            "title": "Logging to UART"
        },
        {
            "location": "/Subjects/IOTNA/P4/#basic-logging",
            "text": "Start from your basic (single-task) matrix multiply code (Lab 2). Insert  ESP_LOG  calls at least at 3 levels: ERROR, INFO and VERBOSE.",
            "title": "Basic logging"
        },
        {
            "location": "/Subjects/IOTNA/P4/#modify-logging-level-via-menuconfig",
            "text": "Use  menuconfig  to select INFO as the minimum log level. Check that the VERBOSE messages are not shown",
            "title": "Modify logging level via menuconfig"
        },
        {
            "location": "/Subjects/IOTNA/P4/#multimodule",
            "text": "Create a new .c file in your project. Include there a couple of functions from your code. Remind to declare. a new TAG there. Include LOG macros in both files.",
            "title": "Multimodule"
        },
        {
            "location": "/Subjects/IOTNA/P4/#modify-logging-level-at-runtime",
            "text": "Use  esp_log_level_set() to set WARNING as the log level for the main file and VERBOSE for the other file. Check that the log output is correct.   Stop and sync   All previous exercises  must be finished DURING the lecture (not afterwards)  and shown to the teacher during the Zoom meeting. AFTER they are shown to be working during the lecture, the  Recorder  of the group will send an email with the source code of the last section ( Modify logging level at runtime ). \n Remind that plagiarism is strictly prohibited: the code of each group must be solely developed by members of that group.",
            "title": "Modify logging level at runtime"
        },
        {
            "location": "/Subjects/IOTNA/P4/#mounting-fat-filesystem",
            "text": "In this step you will mount a FAT filesystem in a new partition created in the SPI FLASH existing in the board. \nFollow the example  Wear Levelling  ( [wear levelling example])https://github.com/espressif/esp-idf/tree/master/examples/storage/wear_levelling) ) and create a PlatformIO project to run it in your board:   Create the PlatformIO project and copy the source code from the  Wear Levelling  example.  Copy the file  partitions_example.csv  in the root folder of your project. Rename it as  partitions.csv  Modify the file  platformio.ini  to include:  monitor_port = /dev/ttyUSB1  upload_port = /dev/ttyUSB1  board_build.partitions = partitions.csv    Run  menuconfig  (type  pio run -t menuconfig  in a PlatformIO terminal)  Partition Table  -->  PartitionTable  -->  Custom partition table CSV  Check that the name of the  Custom parition CSV file  in  menuconfig  is  partitions.csv  Save the new configuration (press  S ) and quit (press  Q )     Build, upload and execute. Monitor the output and check that the messages are the ones expected.   Questions   Once you finished the code, try to answer the following questions. Include them in the report of this assignment.   What is the name of the file you are creating in this example?  What is the path of the file? Why? When was that  folder  created?  What is the difference between  printf()  and  fprintf()  Why there are two calls to `fopen()? What is the difference between them?     What is  fgets() doing?   Write a code that creates a new file called  timestamp.txt  whose content is a timestamp (time elapsed since boot). How can we later modify its content?  Try to open a file after the call \u00e8sp_vfs_fat_spiflash_umount()*. What happens?",
            "title": "Mounting FAT filesystem"
        },
        {
            "location": "/Subjects/IOTNA/P4/#redirecting-the-log-to-flash-optional",
            "text": "This assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment.   Starting from your chronometer code (or equivalent), include LOG messages (using ESP_LOG macros) and redirect the log to a file called  log.txt  that you will create in a FAT partition in SPI FLAG. Use  esp_log_set_vprintf()  to do the redirection. You should LOG:   Every 5 seconds of the chronometer running, you must LOG a message.  Every time the button is pressed  Every time there is a  long  press (more than 4 seconds).   Note that you can still use  printf()  to write to the terminal.  Also, after 1 minute of functioning, you will read the first 5 lines of the log file and write them to the terminal (using  printf() ).   Homework (Optional)  Once finished, the  Speaker  will contact me to  explain (orally) the code developed",
            "title": "Redirecting the log to FLASH (optional)"
        },
        {
            "location": "/Subjects/IOTNA/P5/",
            "text": "Reading sensors using I2C\n\n\nGoals\n\n\n\n\nLearn to use the API provided by ESP-IDF for the I2C serial buses\n\n\nRead the temperature from sensor HTS221 in the board\n\n\n\n\nDocumentation\n\n\nTo complete this assignment, you may need to check the slides discussed in the lectures and the official API documentation:\n\n\n\n\nESP-IDF API for I2C\n\n\nHTS221 sensor data sheet\n\n\nSoC reference\n\n\n\n\nReading the temperature sensor\n\n\nObtaining information about the sensor\n\n\nUsing the data sheet, search the infomation required to read the sensor using I2C bus: slave address, addresses of the control registers, number of bytes needed to read the temperature.\nUsing the information from the SoC and the pin numbers writen in  the lower side of the board, find the information about: gpio pins connected to SDA, SCL and to the sensors VDD.\nUsing the API reference, find how to perform a write and a read through I2C.\n\n\n\n\nQuestions\n\n\nAll previous exercises \nmust be finished DURING the lecture (not afterwards)\n and shown to the teacher during the Zoom meeting. \n\n\n\n\nReading the device identification\n\n\nIn this step you will use the I2C bus to read the device identificaci\u00f3n of the temperature sensor, that is stored in its WHO_AM_I register.\nNote that you must write a 0 in the GPIO pin that controls the VDD signal of the sensors. If not, the sensors will be in power-off state.\n\n\n\n\nStop and sycn \n\n\nOnce you finished the code, show it to the teacher\n\n\n\n\nReading the temperature from the sensor\n\n\nIn this step you will use the I2C bus to read the raw temperature from the sensor.\n\n\n\n\nStop and sycn \n\n\nOnce you finished the code, show it to the teacher\n\n\n\n\nReading the temperature in celsius (optional)\n\n\nThis assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment. \n\n\nUse the calibration mechanism to obtain the real value of temperature.\n\n\n\n\nHomework (Optional)\n\n\nOnce finished, the \nSpeaker\n will contact me to \nexplain (orally) the code developed",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P5/#reading-sensors-using-i2c",
            "text": "",
            "title": "Reading sensors using I2C"
        },
        {
            "location": "/Subjects/IOTNA/P5/#goals",
            "text": "Learn to use the API provided by ESP-IDF for the I2C serial buses  Read the temperature from sensor HTS221 in the board",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P5/#documentation",
            "text": "To complete this assignment, you may need to check the slides discussed in the lectures and the official API documentation:   ESP-IDF API for I2C  HTS221 sensor data sheet  SoC reference",
            "title": "Documentation"
        },
        {
            "location": "/Subjects/IOTNA/P5/#reading-the-temperature-sensor",
            "text": "",
            "title": "Reading the temperature sensor"
        },
        {
            "location": "/Subjects/IOTNA/P5/#obtaining-information-about-the-sensor",
            "text": "Using the data sheet, search the infomation required to read the sensor using I2C bus: slave address, addresses of the control registers, number of bytes needed to read the temperature.\nUsing the information from the SoC and the pin numbers writen in  the lower side of the board, find the information about: gpio pins connected to SDA, SCL and to the sensors VDD.\nUsing the API reference, find how to perform a write and a read through I2C.   Questions  All previous exercises  must be finished DURING the lecture (not afterwards)  and shown to the teacher during the Zoom meeting.",
            "title": "Obtaining information about the sensor"
        },
        {
            "location": "/Subjects/IOTNA/P5/#reading-the-device-identification",
            "text": "In this step you will use the I2C bus to read the device identificaci\u00f3n of the temperature sensor, that is stored in its WHO_AM_I register.\nNote that you must write a 0 in the GPIO pin that controls the VDD signal of the sensors. If not, the sensors will be in power-off state.   Stop and sycn   Once you finished the code, show it to the teacher",
            "title": "Reading the device identification"
        },
        {
            "location": "/Subjects/IOTNA/P5/#reading-the-temperature-from-the-sensor",
            "text": "In this step you will use the I2C bus to read the raw temperature from the sensor.   Stop and sycn   Once you finished the code, show it to the teacher",
            "title": "Reading the temperature from the sensor"
        },
        {
            "location": "/Subjects/IOTNA/P5/#reading-the-temperature-in-celsius-optional",
            "text": "This assignment is optional, but required if you want to obtain more than 6 / 10 in this assignment.   Use the calibration mechanism to obtain the real value of temperature.   Homework (Optional)  Once finished, the  Speaker  will contact me to  explain (orally) the code developed",
            "title": "Reading the temperature in celsius (optional)"
        },
        {
            "location": "/Subjects/IOTNA/P6/",
            "text": "Lab 6. Energy saving modes\n\n\nGoals\n\n\nLearn the mechanisms provided by ESP-IDF to exploit the different energy modes existing in ESP32 SoCs:\n\n\n\n\nExplicit moving into \nlight sleep\n and \ndeep sleep\n modes\n\n\nDiscover wakeup reasons.\n\n\nConfiguring and using the automatic power manager in ESP-IDF.\n\n\n\n\nDocumentation\n\n\nTo complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:\n\n\n\n\nSleep modes\n\n\nPower manager\n\n\n\n\nIt is also relevant to check the examples provided in GitHub:\n\n\n\n\nLight sleep\n\n\nDeep sleep\n\n\nWifi Power save\n\n\n\n\nExplicitly moving to low power modes\n\n\nWe will start from a basic code monitoring any input device (like the button or the temperature sensor), where the main program is in an endless loop reading, periodically, the device status. The structure of the starting code could be similar to:\n\n\nwhile (1) {\n    med = read_device(); // Could be button, sensor...\n    ESP_LOGI(TAG,\"Medida: %f\", med);\n    vTaskDelay(pdMS_TO_TICKS(DELAY));\n}\n\n\n\n\nImplement the following modifications:\n\n\n\n\nInclude a explicit call to enter \nlight sleep\n after 5 iterations. Previously, you will configure the \nwakeup\n mechanism to be the \ntimer\n and instruct it to wake the system up after 10 seconds.\n\n\nRepeat the previous point but entering \ndeep sleep\n\n\nInclude code to determine the cause of the \nwakeup\n for both previous cases.\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhat difference do you observe when entering \ndeep sleep\n compared with \nlight sleep\n? What does it happen after 10 seconds in each case?\n\n\nWhere do you need to include the code to determine the \nwakeup\n cause in each of the two cases?\n\n\n\n\n\n\nUsing the Power Manager\n\n\nStarting from the same simple code of previous section, we will be using the \nPower Manager\n provided by ESP-IDF. \n\n\nIn order to do so, we must enable \nDynamic frequency scaling\n (DFS). We can enable it with \nmenuconfig\n -> \nComponent config -> Power Management -> Support for Power Management -> Enable DFS at startup\n.  It is also possible to configure it in our own code using the call \nesp_pm_configure()\n. \n\n\nYou will use this latter method (\nesp_pm_configure()\n) and define:\n\n Max. frequency of 240MHz\n\n Min. frequency of 40MHz\n\n Enable automatic entering \nlight sleep mode*\n\n\nTo enable automatic entering \nlight sleep mode\n we must activate the corresponding option in \nmenuconfig\n:  \nComponent config -> FreeRTOS -> Tickless Idle Support\n (this option is only visible if the \nEnable DFS at startup\n option is also enabled).\n\n\nFollowing the earlier pseudo-code, modify your code in order to guess the \nwakeup\n cause. The structure of code could be now similar to:\n\n\nwhile (1) {\n    med = read_device(); // Could be button, sensor...\n    ESP_LOGI(TAG,\"Medida: %f\", med);\n    vTaskDelay(pdMS_TO_TICKS(DELAY));\n    cause =  get_wakeup_cause();\n}\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhich mechanism is waking the system up when using the \nPower Manager\n?\n\n\n\n\n\n\nUsing High Resolution Timers (OPTIONAL)\n\n\nModify your code to monitor the device (sensor, button...) using a \nHigh Resolution Timer\n instead of using the call to \nvTaskDelay(pdMS_TO_TICKS(DELAY))\n.  The main task will configure the high resolution timer and then go to sleep for 100 seconds in and endless loop.\n\n\nEntering light sleep mode manually\n\n\nModify your code to enter \nlight sleep mode\n (calling  \nesp_light_sleep_start()\n)   after 3 executions of the \nhigh resolution timer\n callback. Set the high resolution timer to trigger every 3 seconds, and program the system to wake up after 10 seconds. Include a log message in the callback function which prints the number of times the callback function has been called.\n\n\n\n\nQuestions\n\n\n\n\nCall  \nesp_light_sleep_start()\n outside the callback function of the high resolution timer.  What happens when the system wakes up? Are there log messages lost? Do they happen when they should happen?\n\n\nNo call  \nesp_light_sleep_start()\n inside the callback function of the high resolution timer. Do you observe any difference?\n\n\n\n\n\n\nAutomatically entering light sleep mode\n\n\nRepeat previous experiments using the Power Manager. \n\n\n\n\nQuestions\n\n\n\n\nNote that, since you do not manually enter the sleep mode, you will not move into \nlight sleep\n after 3 executions of the high resolution timer. When is the system moving to \nlight sleep\n?\n\n\nWhat happens with the callback log messages? Do they happen when they should happen?\n\n\n\n\n\n\nDelivering the assignment\n\n\nOnce you finish the complete assignment (at least the first two sections), please send an email to Prof. Jose Ignacio (jigomez@ucm.es) with the codes develop for each section and a text file (text or PDF) with your answers to the questions. Please send only one email per group.\n\n\nDEADLINE: 12th January 2022",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P6/#lab-6-energy-saving-modes",
            "text": "",
            "title": "Lab 6. Energy saving modes"
        },
        {
            "location": "/Subjects/IOTNA/P6/#goals",
            "text": "Learn the mechanisms provided by ESP-IDF to exploit the different energy modes existing in ESP32 SoCs:   Explicit moving into  light sleep  and  deep sleep  modes  Discover wakeup reasons.  Configuring and using the automatic power manager in ESP-IDF.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/P6/#documentation",
            "text": "To complete this assignment, you may need to check the slides discuss in the lectures and the official API documentation:   Sleep modes  Power manager   It is also relevant to check the examples provided in GitHub:   Light sleep  Deep sleep  Wifi Power save",
            "title": "Documentation"
        },
        {
            "location": "/Subjects/IOTNA/P6/#explicitly-moving-to-low-power-modes",
            "text": "We will start from a basic code monitoring any input device (like the button or the temperature sensor), where the main program is in an endless loop reading, periodically, the device status. The structure of the starting code could be similar to:  while (1) {\n    med = read_device(); // Could be button, sensor...\n    ESP_LOGI(TAG,\"Medida: %f\", med);\n    vTaskDelay(pdMS_TO_TICKS(DELAY));\n}  Implement the following modifications:   Include a explicit call to enter  light sleep  after 5 iterations. Previously, you will configure the  wakeup  mechanism to be the  timer  and instruct it to wake the system up after 10 seconds.  Repeat the previous point but entering  deep sleep  Include code to determine the cause of the  wakeup  for both previous cases.    Questions   What difference do you observe when entering  deep sleep  compared with  light sleep ? What does it happen after 10 seconds in each case?  Where do you need to include the code to determine the  wakeup  cause in each of the two cases?",
            "title": "Explicitly moving to low power modes"
        },
        {
            "location": "/Subjects/IOTNA/P6/#using-the-power-manager",
            "text": "Starting from the same simple code of previous section, we will be using the  Power Manager  provided by ESP-IDF.   In order to do so, we must enable  Dynamic frequency scaling  (DFS). We can enable it with  menuconfig  ->  Component config -> Power Management -> Support for Power Management -> Enable DFS at startup .  It is also possible to configure it in our own code using the call  esp_pm_configure() .   You will use this latter method ( esp_pm_configure() ) and define:  Max. frequency of 240MHz  Min. frequency of 40MHz  Enable automatic entering  light sleep mode*  To enable automatic entering  light sleep mode  we must activate the corresponding option in  menuconfig :   Component config -> FreeRTOS -> Tickless Idle Support  (this option is only visible if the  Enable DFS at startup  option is also enabled).  Following the earlier pseudo-code, modify your code in order to guess the  wakeup  cause. The structure of code could be now similar to:  while (1) {\n    med = read_device(); // Could be button, sensor...\n    ESP_LOGI(TAG,\"Medida: %f\", med);\n    vTaskDelay(pdMS_TO_TICKS(DELAY));\n    cause =  get_wakeup_cause();\n}   Questions   Which mechanism is waking the system up when using the  Power Manager ?",
            "title": "Using the Power Manager"
        },
        {
            "location": "/Subjects/IOTNA/P6/#using-high-resolution-timers-optional",
            "text": "Modify your code to monitor the device (sensor, button...) using a  High Resolution Timer  instead of using the call to  vTaskDelay(pdMS_TO_TICKS(DELAY)) .  The main task will configure the high resolution timer and then go to sleep for 100 seconds in and endless loop.",
            "title": "Using High Resolution Timers (OPTIONAL)"
        },
        {
            "location": "/Subjects/IOTNA/P6/#entering-light-sleep-mode-manually",
            "text": "Modify your code to enter  light sleep mode  (calling   esp_light_sleep_start() )   after 3 executions of the  high resolution timer  callback. Set the high resolution timer to trigger every 3 seconds, and program the system to wake up after 10 seconds. Include a log message in the callback function which prints the number of times the callback function has been called.   Questions   Call   esp_light_sleep_start()  outside the callback function of the high resolution timer.  What happens when the system wakes up? Are there log messages lost? Do they happen when they should happen?  No call   esp_light_sleep_start()  inside the callback function of the high resolution timer. Do you observe any difference?",
            "title": "Entering light sleep mode manually"
        },
        {
            "location": "/Subjects/IOTNA/P6/#automatically-entering-light-sleep-mode",
            "text": "Repeat previous experiments using the Power Manager.    Questions   Note that, since you do not manually enter the sleep mode, you will not move into  light sleep  after 3 executions of the high resolution timer. When is the system moving to  light sleep ?  What happens with the callback log messages? Do they happen when they should happen?",
            "title": "Automatically entering light sleep mode"
        },
        {
            "location": "/Subjects/IOTNA/P6/#delivering-the-assignment",
            "text": "Once you finish the complete assignment (at least the first two sections), please send an email to Prof. Jose Ignacio (jigomez@ucm.es) with the codes develop for each section and a text file (text or PDF) with your answers to the questions. Please send only one email per group.  DEADLINE: 12th January 2022",
            "title": "Delivering the assignment"
        },
        {
            "location": "/Subjects/IOTNA/P7/",
            "text": "Final programming project\n\n\nThe final development (programming) project will be finally carried on \nin teams of 2 people\n.\n\n\nProject description\n\n\nThe project must provide the following features:\n\n\n\n\nIt must periodically  monitor   two I2C sensors of the ESP32-MeshKit-Sense board,  the temperature sensor (HTS221) and the ambient light sensor (BH1750FVI).  You will read the temperature sensor every 5 seconds and the light sensor every 2 seconds. \n\n\nThe \npower manager\n will be configured to enter light sleep whenever possible.\n\n\nThere will be a LOG (level INFO) every 10 seconds informing of the last temperature and ambient light (illuminance, measured in lux) readings\n\n\nLED IO12 should be blinking every second to inform that the system is running. \n\n\nIf the ambient light sensor lux lecture goes below a certain threshold (decided by you), the LED IO2 will be on and LED IO12 will go off. \n\n\nIf the ambient light sensor readings remain under the threshold for more than 10 minutes, the system will enter deep sleep for 30 minutes.\n\n\n\n\nOptional parts\n\n\nOPTIONALLY you could include all/some of the  following features:\n\n\n\n\nDesign the system using the Finite State Machine (FSM) presented in the lectures.\n\n\nInstead of informing of the last temperature/illuminance reading, log the average of the readings since the last log.\n\n\nBefore entering deep sleep, the system will write the current temperature and luminance reading in Flash, using the NVS partition. After waking up, and only if we are returning from a deep sleep,  there will be a LOG message informing of the stored temperature and illuminance before starting to read the sensors again.\n\n\nLED IO12 could be controlled using a PWM signal so its intensity changes depending on the current illuminance: if the illuminance is high, the LED IO12 will bright more. When the illuminance is less, the LED IO12 will be dimmer. You can check the \nESP-IDF documentation and examples for PWM\n (in the documentation, PWM is used to control motors and servomotors. But the same signal could drive the LED, controlling its intensity).\n\n\n\n\nImportant dates\n\n\n\n\nGroup notifications\n. Remember that this assignment has to be done in a team of 2 people, so the \ncurrent groups are no longer valid\n. Please send an email to Prof. Jose Ignacio him about your team for this project \nbefore 29th Dec 2021\n\n\nDuring the week of 10th January 2022, you will be able to work on this project during IOTNA lectures. You will be able to ask your questions to the Professor during those sessions. \n\n\nDEADLINE\n: 24th January 2022.\n\n\n\n\nDelivery instructions\n\n\nYou must send your code (.c and .h files) to Prof. Jose Ignacio by email (jigomez@ucm.es) before the deadline expires.\n\n\nGroups for the final project\n\n\n\n\n\n\n\n\nGroup\n\n\nName 1\n\n\nName   2\n\n\n\n\n\n\n\n\n\n\n1\n\n\nSHUISHI   ZHOU\n\n\nYANG    CHU\n\n\n\n\n\n\n2\n\n\nYANG  ZHAO\n\n\nHU   ZHAO\n\n\n\n\n\n\n3\n\n\nXIAOLAN   LI\n\n\nQIUJI    CHEN\n\n\n\n\n\n\n4\n\n\nXIONGLAN  LUO.\n\n\nJIANCHUANG  ZHANG\n\n\n\n\n\n\n5\n\n\nWEILIN    ZHANG.\n\n\nYONGTAO    HE\n\n\n\n\n\n\n6\n\n\nJUNYAN   GUO\n\n\nZHIJUN    HAO\n\n\n\n\n\n\n7\n\n\nGONGLU    ZOU.\n\n\nHONGBIAO CAO\n\n\n\n\n\n\n8\n\n\nJIAYUN    PAN\n\n\nJIALI GAO\n\n\n\n\n\n\n9\n\n\nLiu   JINHUA\n\n\nHUANG    YUJUAN\n\n\n\n\n\n\n10\n\n\nDUAN  ZHEN\n\n\nHU HAO\n\n\n\n\n\n\n11\n\n\nGUANJIE   XIAO\n\n\nYUANSHUANG   SHA\n\n\n\n\n\n\n12\n\n\nDongyang  Xu\n\n\nXUEQING ZHAO\n\n\n\n\n\n\n13\n\n\nWEI   REN\n\n\nSUIZHI  LIU\n\n\n\n\n\n\n14\n\n\nYOURAN  TIAN\n\n\nJUN     SHOU\n\n\n\n\n\n\n15\n\n\nTIANFENG   LI\n\n\nYI  ZHANG\n\n\n\n\n\n\n16\n\n\nFengfen GU\n\n\nWenyan  Liao\n\n\n\n\n\n\n17\n\n\nBin  Zhang\n\n\nYINGHUA  LIAO\n\n\n\n\n\n\n\n\nGroup 18 will have 3 members: JIEPING YOU, QINGHONG YUHUAN and XIAZU HU",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/P7/#final-programming-project",
            "text": "The final development (programming) project will be finally carried on  in teams of 2 people .",
            "title": "Final programming project"
        },
        {
            "location": "/Subjects/IOTNA/P7/#project-description",
            "text": "The project must provide the following features:   It must periodically  monitor   two I2C sensors of the ESP32-MeshKit-Sense board,  the temperature sensor (HTS221) and the ambient light sensor (BH1750FVI).  You will read the temperature sensor every 5 seconds and the light sensor every 2 seconds.   The  power manager  will be configured to enter light sleep whenever possible.  There will be a LOG (level INFO) every 10 seconds informing of the last temperature and ambient light (illuminance, measured in lux) readings  LED IO12 should be blinking every second to inform that the system is running.   If the ambient light sensor lux lecture goes below a certain threshold (decided by you), the LED IO2 will be on and LED IO12 will go off.   If the ambient light sensor readings remain under the threshold for more than 10 minutes, the system will enter deep sleep for 30 minutes.",
            "title": "Project description"
        },
        {
            "location": "/Subjects/IOTNA/P7/#optional-parts",
            "text": "OPTIONALLY you could include all/some of the  following features:   Design the system using the Finite State Machine (FSM) presented in the lectures.  Instead of informing of the last temperature/illuminance reading, log the average of the readings since the last log.  Before entering deep sleep, the system will write the current temperature and luminance reading in Flash, using the NVS partition. After waking up, and only if we are returning from a deep sleep,  there will be a LOG message informing of the stored temperature and illuminance before starting to read the sensors again.  LED IO12 could be controlled using a PWM signal so its intensity changes depending on the current illuminance: if the illuminance is high, the LED IO12 will bright more. When the illuminance is less, the LED IO12 will be dimmer. You can check the  ESP-IDF documentation and examples for PWM  (in the documentation, PWM is used to control motors and servomotors. But the same signal could drive the LED, controlling its intensity).",
            "title": "Optional parts"
        },
        {
            "location": "/Subjects/IOTNA/P7/#important-dates",
            "text": "Group notifications . Remember that this assignment has to be done in a team of 2 people, so the  current groups are no longer valid . Please send an email to Prof. Jose Ignacio him about your team for this project  before 29th Dec 2021  During the week of 10th January 2022, you will be able to work on this project during IOTNA lectures. You will be able to ask your questions to the Professor during those sessions.   DEADLINE : 24th January 2022.",
            "title": "Important dates"
        },
        {
            "location": "/Subjects/IOTNA/P7/#delivery-instructions",
            "text": "You must send your code (.c and .h files) to Prof. Jose Ignacio by email (jigomez@ucm.es) before the deadline expires.",
            "title": "Delivery instructions"
        },
        {
            "location": "/Subjects/IOTNA/P7/#groups-for-the-final-project",
            "text": "Group  Name 1  Name   2      1  SHUISHI   ZHOU  YANG    CHU    2  YANG  ZHAO  HU   ZHAO    3  XIAOLAN   LI  QIUJI    CHEN    4  XIONGLAN  LUO.  JIANCHUANG  ZHANG    5  WEILIN    ZHANG.  YONGTAO    HE    6  JUNYAN   GUO  ZHIJUN    HAO    7  GONGLU    ZOU.  HONGBIAO CAO    8  JIAYUN    PAN  JIALI GAO    9  Liu   JINHUA  HUANG    YUJUAN    10  DUAN  ZHEN  HU HAO    11  GUANJIE   XIAO  YUANSHUANG   SHA    12  Dongyang  Xu  XUEQING ZHAO    13  WEI   REN  SUIZHI  LIU    14  YOURAN  TIAN  JUN     SHOU    15  TIANFENG   LI  YI  ZHANG    16  Fengfen GU  Wenyan  Liao    17  Bin  Zhang  YINGHUA  LIAO     Group 18 will have 3 members: JIEPING YOU, QINGHONG YUHUAN and XIAZU HU",
            "title": "Groups for the final project"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/",
            "text": "C programming. Exercises\n\n\nThere are many good C/C++ tutorials online. You can find one in \nthis link\n.\n\n\nNext, there are several examples that we will use during the lectures to talk about different aspects of C language.\n\n\nYou can \ndownload a ZIP with the examples here\n\n\nCompilation (headers, macros...)\n\n\n#include <stdio.h>\n\n/******** QUESTIONS/TASKS *****\n* 1. Compile and execute the code\n* 2. Later, apply only the preprocessor  (-E flag) and redirect the output\n* to a file called hello.i\n* 3. What happened to the call min()?\n* 4. What did the directive  #include <stdio.h> produced?\n*****************/\n#define N 5\n\n#define min(x,y) ( (x<y)?x:y )\nint a = 7;\nint b = 9;\nint main() {\n\n char* cad = \"Hello world\";\n int i;\n\n for (i=0;i<N;i++) {\n   printf(\"%s \\t a= %d b= %d\\n\",cad,a,b);\n   a++;\n   a = min(a,b);            \n }\n return 0;\n}\n\n\n\n\nData types. Sizes\n\n\n#include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the first \"printf\" prints different values for the same variable 'a'?\n * 2. How large is a 'char' variable?\n * 3. Why the value of 'a' changes that much when adding 1?  \n * 4. If \"long\" and \"double\" have the same size, what's the difference?\n *****/\nchar a = 127;\nint b = 41;\nint main() {\n\n    printf(\"a = %d a = %c \\n\", a,a);\n    a++;\n    printf(\"a = %d a = %c b=%d  b=%c\\n\", a,a,b,b);\n    printf(\"Size of int: %lu\\n\",sizeof(int ) );\n    printf(\"Size of char: %lu\\n\",sizeof( char) );\n    printf(\"Size of float: %lu\\n\",sizeof(float ) );\n    printf(\"Size of double: %lu\\n\",sizeof( double) );\n    printf(\"Size of long: %lu\\n\",sizeof(long ) );\n    printf(\"Size of short: %lu\\n\",sizeof( short) );\n    printf(\"Size of void*: %lu\\n\",sizeof( void*) );\n\n}\n\n\n\n\n#include <stdio.h>\n\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Is there a compilation problem or a execution problem?\n * 2. Why is it complaining? Fix it and compila again.\n * 3. a,b,c, y x are declared one after the other. Are their addresses consecutive in memory?\n * 4. What does the modifier \"%lu\" means in printf()? \n * 5. Which address is \"pc\" pointed to? Is the address of any other variable? Are those two the same size?\n * 6. Does the size of \"array1\" matches the number of elements? Why?\n * 7. Do \"cadena1\" and \"cadena2 \"point to the same address? \n * 8. Why sizes (according to sizeof()) of cadena1 and cadena2 are different?\n *************/\n\n#define ARRAY_SIZE  10\n\nint a = 7;\nunsigned long b = 8;\nshort c;\nchar x;\nchar* pc;\n\nint array1[ARRAY_SIZE];\nint array2[a]; \n\nchar* cadena1 = \"CADENA DE CARACTERES\"; \nchar cadena2[] = \"CADENA DE CARACTERES\";\nint main() {\n    pc =&x;\n    a = 16;\n    printf(\"Adress of a: %p Tam: %lu \\n\",&a,sizeof(a));\n    printf(\"Adress of b: %p Tam: %lu \\n\",&b,sizeof(b));\n    printf(\"Adress of c: %p Tam: %lu \\n\",&c,sizeof(c));\n    printf(\"Adress of x: %p Tam: %lu \\n\",&x,sizeof(x));\n    printf(\"Adress of pc: %p Adress pointed by pc: %p Tam: %lu \\n\",&pc,pc,sizeof(pc));\n    printf(\"Adress of array: %p Adress of elem 0: %p Tam de array: %lu \\n\",array1, &array1[0], sizeof(array1));\n    printf(\"Adress of cadena1: %p Adress pointed by: %p Tam: %lu \\n\",&cadena1,cadena1,sizeof(cadena1));\n    printf(\"Adress of cadena2: %p DAdress pointed by: %p Tam: %lu \\n\",&cadena2,cadena2,sizeof(cadena2));    \nreturn 0;\n}\n\n\n\n\nUsing Arrays.\n\n\n#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Should we use \"&list\" to get the address of the array?\n * 2. What is actually stored in the address of \"list\"?\n * 3. Why are we including the lentgh of the array as parameter to \"init_array\"?\n * 4. Why the sizeof() output is different for the array in \"init_array\" and the one in main()?\n * 5. Why aren't we including a second parameter in init_array2?\n * 6. Do sizeof() outuput now match with the array in init_array2()?\n ***************/\n\n#define N 5\n\nvoid init_array(int array[], int size) ;\nvoid init_array2(int array[N]);\n\nint main(void) {\n    int i,list[N];\n    printf(\"Dir de list %p Dir de list[0]: %p  Dir de list[1]: %p. Sizeof list %lu \\n\",list,&list[0],&list[1],sizeof(list));\n\n    init_array(list, N);\n    for (i = 0; i < N; i++)\n        printf(\"next: %d \", list[i]);\n    printf(\"\\n-------------------------\\n\");\n\n    init_array2(list);\n    for (i = 0; i < N; i++)\n        printf(\"next: %d \", list[i]);\n    printf(\"\\n-------------------------\\n\");\n}\n\nvoid init_array(int array[], int size) { \n    int i;\n    printf(\"Direccion de array: %p Sizeof array %lu \\n\", array, sizeof(array));\n    for (i = 0; i < size; i++)\n        array[i] = i;\n    printf(\"Array initialized\\n\\n\");\n}\n\nvoid init_array2(int array[N]) { \n    int i;\n    printf(\"Direccion de array: %p Sizeof array %lu \\n\", array, sizeof(array));\n    for (i = 0; i < N; i++)\n        array[i] = i*2;\n    printf(\"Array initialized\\n\\n\");\n}\n\n\n\n\n#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Does the copy of the array works? Why? \n *  2. Fix it.\n *  3. Uncommnet the call to function \"tom\". Compile again and execute.\n *  4. The problem that arises, is it in compilation or execution time? Why?\n *  5. Find a value for MAXVALID (greater than 4) when the problem does not happen. Why does it work?\n*******************/\n\n#define N 10\n#define MAXELEM 5000\n#define MAXVALID 100\n\nvoid printArray(int v[],int size) {\n    int i;\n    printf(\"-------------------\\n\");\n    for (i=0;i<size;i++)\n        printf(\"%d \",v[i]);\n    printf(\"\\n\\n\");\n\n}\n\nvoid copyArray(int src[],int dst[],int size) {\n    dst = src;\n}\n\nvoid tmo() {\n    int x = -1; \n    int a[4] = {0,1,2,3};    \n    int b = 10000;\n    int c = -1;\n    int i;\n\n    for  (i=4;i<MAXVALID;i++)\n        a[i]=i;\n\n    printf(\"x %d b %d c %d\\n\", x,b,c);\n\n\n}\n\nint main() {\n    int A[N] = {4,3,8,5,6,9,0,1,7,2};\n    int B[N];\n\n    //tmo();\n    copyArray(A,B,N);\n    printArray(B,N);\n\n}\n\n\n\n\nPointers\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Which operand should we use to declae a variable as a ponter?\n * 2. How do we obtain the address of a variable?\n * 3. How do we read/write into the address pointed by a pointer? \n * 4. There \u00a1s a bug in the code. Is it a compile-time or executiontime errror? Why does it happen?\n  ***********/\nint c = 7;\nint main(void) {\n\n    int *ptr;\n    printf(\"Address of ptr %p. ptr apunta a %p. Address of c: %p Valor of c %d\\n\",&ptr,ptr,&c,c);   \n\n    ptr = &c;\n    printf(\"Address of ptr %p,. ptr apunta a %p. Address of c: %p Value of c %d\\n\",&ptr,ptr,&c,c);  \n\n    *ptr=4;\n    printf(\"ptr apunta a %p. Content of address of ptr: %d Address of c: %p Value of c %d\\n\",ptr,*ptr,&c,c);    \n\n    ptr =  (int*) 0x600a48;\n    printf(\"Address of ptr %p. Value of c %d\\n\",ptr,c); \n\n    *ptr =13;\n    printf(\"Address of ptr %p. Value of c %d\\n\",ptr,c); \n\nreturn 0;\n\n}\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. How many bytes are allocated in memory with the malloc() call?\n *  2. Which are the addresses of the first and last bytes of the allocated area?\n *  3. Why the content of the address pointed by \"ptr\" is 7 and not 5 in the first printf()?\n *  4. Why the content of ptrg[1] is modified after the sentence *ptr2=15 ?\n *  5. Suggest two different ways of writting the value 13 in the address of ptr[100] \n *  6. There is a bug in the code. Even if nothing goes wrong,the bug is there. Where?\n *  ***********/\nint nelem;\n\nint main(void) {\n    int *ptr;\n    int * ptr2; \n\n    nelem = 127;\n    ptr = (int*) malloc(nelem*sizeof(int));\n    *ptr = 5;\n    ptr[0] = 7;\n    ptr2 = ptr;\n\n    printf(\"Address pointed by ptr %p. Content of that address: %d \\n\",ptr,*ptr);   \n\n    ptr[1] = 10;    \n    printf(\"Address pointed by ptr[1] %p. Content of that address: %d \\n\",&ptr[1],ptr[1]);  \n\n    ptr2++;\n    *ptr2 = 15;\n    printf(\"Address pointed by ptr[1] %p. Content of that address: %d \\n\",&ptr[1],ptr[1]);  \n\n\n    free(ptr);  \n    *ptr = 3;\n    printf(\"Address pointed by ptr %p. Content of that address: %d \\n\",ptr,*ptr);   \n}\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Why the value of ptr[13] is changed after the sentence ptr = &c;\n *  2. This code has (at least) one bug. Compile or run-timer error? Why?\n *  3. What happens with the memory allocated by malloc()  after the assignment ptr=&c? \n *     How can we reach that memory again? How can we free it?\n *  ***********/\nint nelem;\nint c;\nint main(void) {\n    int *ptr;\n    int i;\n    c = 37; \n    nelem = 127;\n    ptr = (int*) malloc(nelem*sizeof(int));\n    for (i=0; i<nelem; i++)\n        ptr[i] = i;\n\n    printf(\"ptr[0]= %d ptr[13]=%d \\n\",ptr[0],ptr[13]);  \n\n    ptr = &c;\n    printf(\"ptr[0]= %d ptr[13]=%d \\n\",ptr[0],ptr[13]);  \n\n    free(ptr);\n}\n\n\n\n\n#include <stdio.h>\n#include <stdlib.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Why the second printf() prints a different value for 'd'?\n *  2. What is 'f'? A variable? A function?\n *  3. Use the function 'opera()' to perform the first addition. Then, use it again to perform a substraction.\n *  4. Using typedef, build a type called ptrToFunc with the same prototype thatn 'f'\n *  5. Creat a function 'choose()' that will return, alternatively, a pointer to \"add()\" and \"sub()\" \n *     every time it is called\n *  ***********/\n\nint add (int x, int y);\nint sub(int x, int y);\n\nint (*f)(int a, int b);\n\nint add(int x, int y) {\n    return x+y;\n}\n\nint sub(int x, int y) {\n    return x-y;\n}\n\nint opera(int x, int y, int (*g)(int, int)) {\n    return g(x,y);\n}\n\nint main(void) {\n\n    int a = 12;\n    int b =  8;\n    int c,d;\n\n    f = add;\n    c = add(a,b);\n    d = f(a,b);\n    printf(\"c = %d d= %d \\n\",c,d);  \n    f = sub;\n    d = f(a,b);\n    printf(\"c = %d d= %d \\n\",c,d);\n}\n\n\n\n\nArguments\n\n\n#include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the value of 'xc' is not changed after the call to sumC()? \n *     Where do the write operations happen?\n * 2. Comment  the two forwarded declarations of sum() and sumC(). Compile again. What happens?\n *******************/\n/* Struct type */\nstruct _complex_ {\n    float re;\n    float im;\n};\n\n/* Forward declarations */\nint sum(int a, int b);\nstruct _complex_  sumC( struct _complex_ a,  struct _complex_ b);\n\n\nint main(void){\n    int x = 4,y = 5;\n    struct _complex_  xc = {.re = 1.0, .im = 2.0};\n    struct _complex_  yc = {.re = 3.0, .im = 1.0};\n    struct _complex_  zc; \n\n    zc = sumC(xc,yc);\n\n    int total = sum(x,y); \n\n    printf(\"Suma de complejos. (%f,%f i) + (%f,%f i) =(%f,%f i)\\n\",xc.re,xc.im,yc.re,yc.im,zc.re,zc.im);\n    printf(\"Suma de enteros:  x +y = %d + %d = %d \\n\",x,y, total);\n    return 0;\n}\n\nint sum(int x, int y) {  \n    int c;\n    c = x +y;\n    x = 7;\n    y =3;  \n    return c;         \n}\n\n\nstruct _complex_  sumC( struct _complex_ a,  struct _complex_ b) {\n        struct _complex_ r;\n        r.re = a.re + b.re;\n        r.im = a.im + b.im;\n        // Try to change the first parameter\n        a.re = 12.5;\n        a.im = 13.4;\n        return r;\n}\n\n\n\n\n#include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why does the value of 'y' changes after the call to sum()?\n * 2. Why sometimes we use operator '.' and other times '->'?\n * 3. Why the vauue of 'zc' gets wrong without further using it in the code?\n * 4. Fix the code to avoid the bug in 'zc' shown in previous point\n *******************/\nstruct _complex_ {\n    float re;\n    float im;\n};\n\nint sum(int *pa, int *pb);\nstruct _complex_ * sumC( struct _complex_ *a,  struct _complex_ *b);\n\n\nint main(void){\n    int x = 4,y = 5;\n    int* ptr = &y;\n    struct _complex_  xc = {.re = 1.0, .im = 2.0};\n    struct _complex_  yc = {.re = 3.0, .im = 1.0};\n    struct _complex_  *zc; \n\n\n    printf(\"Complex addition (%f,%f i) + (%f,%f i) = \",     xc.re,xc.im,yc.re,yc.im);\n    zc = sumC(&xc,&yc);\n    printf(\"(%f,%f i)\\n\",zc->re,zc->im);\n    int total = sum(&x,ptr); \n\n    printf(\"Complex addition:  x +y = %d + %d = %d \\n\",x,y, total);\n    printf(\"xc = (%f,%f i)  yc = (%f,%f i) zc = (%f,%f i)\\n\",xc.re,xc.im,yc.re,yc.im,zc->re,zc->im);\n    return 0;\n}\n\nint sum(int *pa, int *pb) {  \n   /* args passed by reference */\n  int c = *pa + *pb;\n  int buf[256] = {0};\n  *pa = 7;\n  *pb = 8;  \n   return c;      /* return by value */\n}\n\n\nstruct _complex_ * sumC( struct _complex_* a,  struct _complex_* b) {\n        struct _complex_ r;\n        r.re = a->re + b->re;\n        r.im = a->im + b->im;\n        a->re = 12.5;\n        a->im = 13.4;\n        return &r;\n}\n\n\n\n\nStrings\n\n\n#include <stdio.h>\n#include <string.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. The code has a bug. Compile or run-time? Why?\n * Fix the bug commenting the line(s) that produce it. Compile and execute again. \n * 2. Which is the address of letter 'B' in the chain \"Bonjour\"? And letter 'j'?\n * 3. After the assignment p=msg2; how can we get back the address of \"Bonjour\"?\n * 4. Why the length of strings 'p' and 'msg2' are 2 after the third assignment?\n *    3 bytes are assigned to 'p', but then the length is only 2 !!\n * 5. Why strlen() returns a different value than sizeof()?\n * 6. Why the string stored in 'msg' in line 36 is bad-printed in the last printf()?\n ************** */\nint main() {\n\nchar msg[10]; /* array of 10 chars */\nchar *p;          /* pointer to a char */\n\nchar msg2[28]=\"Hello\";  /* msg2 = 'H' 'e' 'l' 'l' 'o' '\\0' */\n\n    p   = \"Bonjour\"; \n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"dir de msg: %p, dir de p: %p, dir de msg2: %p\\n\",msg,p,msg2);\n\n    p = msg2;\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"dir de msg: %p, dir de p: %p, dir de msg2: %p\\n\",msg,p,msg2);\n\n    p[0] = 'H', p[1] = 'i',p[2]='\\0';\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"msg len: %lu p len %lu msg2 len %lu\\n\", strlen(msg),strlen(p),strlen(msg2));\n    printf(\"msg size: %lu p size %lu msg2 size %lu\\n\", sizeof(msg),sizeof(p),sizeof(msg2));\n\n    msg[0] = 'B', msg[1] = 'y';\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n\n    msg = \"Goodbye\";\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n}\n\n\n\n\n#include <stdio.h>\n#include <string.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. The code of fcuntion 'copy' does not work. Why?\n * 2. Use now 'copy2()'. Does the copy actually work?\n * 3. Suggest a valid implementation for a copy\n * 4. What does function \"mod\" do? \n * 5. Uncomment last line of code (call to mod()). Compile and execute. Why is there an error now?\n ************** */\n\nvoid copy2(char* org, char** dst) {\n    *dst = org;\n}\n\nvoid copy(char* org, char* dst) {\n    dst = org;\n}\n\nvoid mod(char* org, char* dst) {\n    int i;\n\n    for (i=0;i<strlen(org);i++)\n        dst[i] = org[i] - 32;\n\n}\n\nint main() {\n\n    char* cad1 = \"original\";          \n    char* cad2 = \"other\";\n    char cad3[32];\n\n    copy(cad1,cad2);\n    //copy2(cad1,&cad2);\n    printf(\"cad1 %s cad2 %s\\n\", cad1,cad2);\n\n    mod(cad1,cad3);\n    printf(\"cad1 %s cad3 %s\\n\", cad1,cad3);\n\n    //mod(cad1,cad1);\n}\n\n\n\n\nBitwaise operations\n\n\n#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * Study the syntax of the different bit-level operators\n * and make sure you understand  the result of every operation\n ************** */\n\nint a,b,c;\n\nint main() {\n\n    a = 7;\n    b = 9;\n    c = a & b;\n    printf(\"%x AND %x = %x\\n\",a,b,c);\n\n    c= a | b;\n    printf(\"%x OR %x = %x\\n\",a,b,c);\n\n    c = a ^ b;\n    printf(\"%x XOR %x = %x\\n\",a,b,c);\n\n    c = ~a;\n    printf(\"NOT %x = %x\\n\",a,c);\n\n    c = a << 2;\n    printf(\" %x << 2 = %x\\n\",a,c);\n\n    c = a >> 1;\n    printf(\" %x >> 1 = %x\\n\",a,c);\n\n    c = a & 0xFB;\n    printf(\" %x bit 2 to 0 -> %x\\n\",a,c);\n\n    c = a | 0x40;\n    printf(\" %x bit 6 to 1 -> %x\\n\",a,c);\n\n    c = (a & 0x1C) >> 2;\n    printf(\"bits 4-3-2 of %x: %x\\n\",a,c);   \n}\n\n\n\n\n#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the assignment using pointer 'p' does not overwrite completely 'a'?\n * 2. How is modified the address pointed by 'p' after the assignment p=p+1\n * 3. How would it be different if 'p' is declared as 'short *'\n *\n ************** */\nint a = 3;\nint b;\nchar * p;\nint c;\nint main() {\n\n    printf(\"a = %x Address of a: %p \\n\",a,&a);\n    p = (char*) &a;\n    p=p+1;\n    *p= 0x1f;\n    printf(\"a = %x. Address pointed by p:%p \\n\",a,p);\n\n    a = 3;\n    b = 0x00001f00;\n    a= a | b;\n\n    printf(\"a = %x. Address pointed by p:%p \\n\",a,p);\n}",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#c-programming-exercises",
            "text": "There are many good C/C++ tutorials online. You can find one in  this link .  Next, there are several examples that we will use during the lectures to talk about different aspects of C language.  You can  download a ZIP with the examples here",
            "title": "C programming. Exercises"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#compilation-headers-macros",
            "text": "#include <stdio.h>\n\n/******** QUESTIONS/TASKS *****\n* 1. Compile and execute the code\n* 2. Later, apply only the preprocessor  (-E flag) and redirect the output\n* to a file called hello.i\n* 3. What happened to the call min()?\n* 4. What did the directive  #include <stdio.h> produced?\n*****************/\n#define N 5\n\n#define min(x,y) ( (x<y)?x:y )\nint a = 7;\nint b = 9;\nint main() {\n\n char* cad = \"Hello world\";\n int i;\n\n for (i=0;i<N;i++) {\n   printf(\"%s \\t a= %d b= %d\\n\",cad,a,b);\n   a++;\n   a = min(a,b);            \n }\n return 0;\n}",
            "title": "Compilation (headers, macros...)"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#data-types-sizes",
            "text": "#include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the first \"printf\" prints different values for the same variable 'a'?\n * 2. How large is a 'char' variable?\n * 3. Why the value of 'a' changes that much when adding 1?  \n * 4. If \"long\" and \"double\" have the same size, what's the difference?\n *****/\nchar a = 127;\nint b = 41;\nint main() {\n\n    printf(\"a = %d a = %c \\n\", a,a);\n    a++;\n    printf(\"a = %d a = %c b=%d  b=%c\\n\", a,a,b,b);\n    printf(\"Size of int: %lu\\n\",sizeof(int ) );\n    printf(\"Size of char: %lu\\n\",sizeof( char) );\n    printf(\"Size of float: %lu\\n\",sizeof(float ) );\n    printf(\"Size of double: %lu\\n\",sizeof( double) );\n    printf(\"Size of long: %lu\\n\",sizeof(long ) );\n    printf(\"Size of short: %lu\\n\",sizeof( short) );\n    printf(\"Size of void*: %lu\\n\",sizeof( void*) );\n\n}  #include <stdio.h>\n\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Is there a compilation problem or a execution problem?\n * 2. Why is it complaining? Fix it and compila again.\n * 3. a,b,c, y x are declared one after the other. Are their addresses consecutive in memory?\n * 4. What does the modifier \"%lu\" means in printf()? \n * 5. Which address is \"pc\" pointed to? Is the address of any other variable? Are those two the same size?\n * 6. Does the size of \"array1\" matches the number of elements? Why?\n * 7. Do \"cadena1\" and \"cadena2 \"point to the same address? \n * 8. Why sizes (according to sizeof()) of cadena1 and cadena2 are different?\n *************/\n\n#define ARRAY_SIZE  10\n\nint a = 7;\nunsigned long b = 8;\nshort c;\nchar x;\nchar* pc;\n\nint array1[ARRAY_SIZE];\nint array2[a]; \n\nchar* cadena1 = \"CADENA DE CARACTERES\"; \nchar cadena2[] = \"CADENA DE CARACTERES\";\nint main() {\n    pc =&x;\n    a = 16;\n    printf(\"Adress of a: %p Tam: %lu \\n\",&a,sizeof(a));\n    printf(\"Adress of b: %p Tam: %lu \\n\",&b,sizeof(b));\n    printf(\"Adress of c: %p Tam: %lu \\n\",&c,sizeof(c));\n    printf(\"Adress of x: %p Tam: %lu \\n\",&x,sizeof(x));\n    printf(\"Adress of pc: %p Adress pointed by pc: %p Tam: %lu \\n\",&pc,pc,sizeof(pc));\n    printf(\"Adress of array: %p Adress of elem 0: %p Tam de array: %lu \\n\",array1, &array1[0], sizeof(array1));\n    printf(\"Adress of cadena1: %p Adress pointed by: %p Tam: %lu \\n\",&cadena1,cadena1,sizeof(cadena1));\n    printf(\"Adress of cadena2: %p DAdress pointed by: %p Tam: %lu \\n\",&cadena2,cadena2,sizeof(cadena2));    \nreturn 0;\n}",
            "title": "Data types. Sizes"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#using-arrays",
            "text": "#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Should we use \"&list\" to get the address of the array?\n * 2. What is actually stored in the address of \"list\"?\n * 3. Why are we including the lentgh of the array as parameter to \"init_array\"?\n * 4. Why the sizeof() output is different for the array in \"init_array\" and the one in main()?\n * 5. Why aren't we including a second parameter in init_array2?\n * 6. Do sizeof() outuput now match with the array in init_array2()?\n ***************/\n\n#define N 5\n\nvoid init_array(int array[], int size) ;\nvoid init_array2(int array[N]);\n\nint main(void) {\n    int i,list[N];\n    printf(\"Dir de list %p Dir de list[0]: %p  Dir de list[1]: %p. Sizeof list %lu \\n\",list,&list[0],&list[1],sizeof(list));\n\n    init_array(list, N);\n    for (i = 0; i < N; i++)\n        printf(\"next: %d \", list[i]);\n    printf(\"\\n-------------------------\\n\");\n\n    init_array2(list);\n    for (i = 0; i < N; i++)\n        printf(\"next: %d \", list[i]);\n    printf(\"\\n-------------------------\\n\");\n}\n\nvoid init_array(int array[], int size) { \n    int i;\n    printf(\"Direccion de array: %p Sizeof array %lu \\n\", array, sizeof(array));\n    for (i = 0; i < size; i++)\n        array[i] = i;\n    printf(\"Array initialized\\n\\n\");\n}\n\nvoid init_array2(int array[N]) { \n    int i;\n    printf(\"Direccion de array: %p Sizeof array %lu \\n\", array, sizeof(array));\n    for (i = 0; i < N; i++)\n        array[i] = i*2;\n    printf(\"Array initialized\\n\\n\");\n}  #include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Does the copy of the array works? Why? \n *  2. Fix it.\n *  3. Uncommnet the call to function \"tom\". Compile again and execute.\n *  4. The problem that arises, is it in compilation or execution time? Why?\n *  5. Find a value for MAXVALID (greater than 4) when the problem does not happen. Why does it work?\n*******************/\n\n#define N 10\n#define MAXELEM 5000\n#define MAXVALID 100\n\nvoid printArray(int v[],int size) {\n    int i;\n    printf(\"-------------------\\n\");\n    for (i=0;i<size;i++)\n        printf(\"%d \",v[i]);\n    printf(\"\\n\\n\");\n\n}\n\nvoid copyArray(int src[],int dst[],int size) {\n    dst = src;\n}\n\nvoid tmo() {\n    int x = -1; \n    int a[4] = {0,1,2,3};    \n    int b = 10000;\n    int c = -1;\n    int i;\n\n    for  (i=4;i<MAXVALID;i++)\n        a[i]=i;\n\n    printf(\"x %d b %d c %d\\n\", x,b,c);\n\n\n}\n\nint main() {\n    int A[N] = {4,3,8,5,6,9,0,1,7,2};\n    int B[N];\n\n    //tmo();\n    copyArray(A,B,N);\n    printArray(B,N);\n\n}",
            "title": "Using Arrays."
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#pointers",
            "text": "#include <stdio.h>\n#include <stdlib.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Which operand should we use to declae a variable as a ponter?\n * 2. How do we obtain the address of a variable?\n * 3. How do we read/write into the address pointed by a pointer? \n * 4. There \u00a1s a bug in the code. Is it a compile-time or executiontime errror? Why does it happen?\n  ***********/\nint c = 7;\nint main(void) {\n\n    int *ptr;\n    printf(\"Address of ptr %p. ptr apunta a %p. Address of c: %p Valor of c %d\\n\",&ptr,ptr,&c,c);   \n\n    ptr = &c;\n    printf(\"Address of ptr %p,. ptr apunta a %p. Address of c: %p Value of c %d\\n\",&ptr,ptr,&c,c);  \n\n    *ptr=4;\n    printf(\"ptr apunta a %p. Content of address of ptr: %d Address of c: %p Value of c %d\\n\",ptr,*ptr,&c,c);    \n\n    ptr =  (int*) 0x600a48;\n    printf(\"Address of ptr %p. Value of c %d\\n\",ptr,c); \n\n    *ptr =13;\n    printf(\"Address of ptr %p. Value of c %d\\n\",ptr,c); \n\nreturn 0;\n\n}  #include <stdio.h>\n#include <stdlib.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. How many bytes are allocated in memory with the malloc() call?\n *  2. Which are the addresses of the first and last bytes of the allocated area?\n *  3. Why the content of the address pointed by \"ptr\" is 7 and not 5 in the first printf()?\n *  4. Why the content of ptrg[1] is modified after the sentence *ptr2=15 ?\n *  5. Suggest two different ways of writting the value 13 in the address of ptr[100] \n *  6. There is a bug in the code. Even if nothing goes wrong,the bug is there. Where?\n *  ***********/\nint nelem;\n\nint main(void) {\n    int *ptr;\n    int * ptr2; \n\n    nelem = 127;\n    ptr = (int*) malloc(nelem*sizeof(int));\n    *ptr = 5;\n    ptr[0] = 7;\n    ptr2 = ptr;\n\n    printf(\"Address pointed by ptr %p. Content of that address: %d \\n\",ptr,*ptr);   \n\n    ptr[1] = 10;    \n    printf(\"Address pointed by ptr[1] %p. Content of that address: %d \\n\",&ptr[1],ptr[1]);  \n\n    ptr2++;\n    *ptr2 = 15;\n    printf(\"Address pointed by ptr[1] %p. Content of that address: %d \\n\",&ptr[1],ptr[1]);  \n\n\n    free(ptr);  \n    *ptr = 3;\n    printf(\"Address pointed by ptr %p. Content of that address: %d \\n\",ptr,*ptr);   \n}  #include <stdio.h>\n#include <stdlib.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Why the value of ptr[13] is changed after the sentence ptr = &c;\n *  2. This code has (at least) one bug. Compile or run-timer error? Why?\n *  3. What happens with the memory allocated by malloc()  after the assignment ptr=&c? \n *     How can we reach that memory again? How can we free it?\n *  ***********/\nint nelem;\nint c;\nint main(void) {\n    int *ptr;\n    int i;\n    c = 37; \n    nelem = 127;\n    ptr = (int*) malloc(nelem*sizeof(int));\n    for (i=0; i<nelem; i++)\n        ptr[i] = i;\n\n    printf(\"ptr[0]= %d ptr[13]=%d \\n\",ptr[0],ptr[13]);  \n\n    ptr = &c;\n    printf(\"ptr[0]= %d ptr[13]=%d \\n\",ptr[0],ptr[13]);  \n\n    free(ptr);\n}  #include <stdio.h>\n#include <stdlib.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n *  1. Why the second printf() prints a different value for 'd'?\n *  2. What is 'f'? A variable? A function?\n *  3. Use the function 'opera()' to perform the first addition. Then, use it again to perform a substraction.\n *  4. Using typedef, build a type called ptrToFunc with the same prototype thatn 'f'\n *  5. Creat a function 'choose()' that will return, alternatively, a pointer to \"add()\" and \"sub()\" \n *     every time it is called\n *  ***********/\n\nint add (int x, int y);\nint sub(int x, int y);\n\nint (*f)(int a, int b);\n\nint add(int x, int y) {\n    return x+y;\n}\n\nint sub(int x, int y) {\n    return x-y;\n}\n\nint opera(int x, int y, int (*g)(int, int)) {\n    return g(x,y);\n}\n\nint main(void) {\n\n    int a = 12;\n    int b =  8;\n    int c,d;\n\n    f = add;\n    c = add(a,b);\n    d = f(a,b);\n    printf(\"c = %d d= %d \\n\",c,d);  \n    f = sub;\n    d = f(a,b);\n    printf(\"c = %d d= %d \\n\",c,d);\n}",
            "title": "Pointers"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#arguments",
            "text": "#include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the value of 'xc' is not changed after the call to sumC()? \n *     Where do the write operations happen?\n * 2. Comment  the two forwarded declarations of sum() and sumC(). Compile again. What happens?\n *******************/\n/* Struct type */\nstruct _complex_ {\n    float re;\n    float im;\n};\n\n/* Forward declarations */\nint sum(int a, int b);\nstruct _complex_  sumC( struct _complex_ a,  struct _complex_ b);\n\n\nint main(void){\n    int x = 4,y = 5;\n    struct _complex_  xc = {.re = 1.0, .im = 2.0};\n    struct _complex_  yc = {.re = 3.0, .im = 1.0};\n    struct _complex_  zc; \n\n    zc = sumC(xc,yc);\n\n    int total = sum(x,y); \n\n    printf(\"Suma de complejos. (%f,%f i) + (%f,%f i) =(%f,%f i)\\n\",xc.re,xc.im,yc.re,yc.im,zc.re,zc.im);\n    printf(\"Suma de enteros:  x +y = %d + %d = %d \\n\",x,y, total);\n    return 0;\n}\n\nint sum(int x, int y) {  \n    int c;\n    c = x +y;\n    x = 7;\n    y =3;  \n    return c;         \n}\n\n\nstruct _complex_  sumC( struct _complex_ a,  struct _complex_ b) {\n        struct _complex_ r;\n        r.re = a.re + b.re;\n        r.im = a.im + b.im;\n        // Try to change the first parameter\n        a.re = 12.5;\n        a.im = 13.4;\n        return r;\n}  #include <stdio.h>\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why does the value of 'y' changes after the call to sum()?\n * 2. Why sometimes we use operator '.' and other times '->'?\n * 3. Why the vauue of 'zc' gets wrong without further using it in the code?\n * 4. Fix the code to avoid the bug in 'zc' shown in previous point\n *******************/\nstruct _complex_ {\n    float re;\n    float im;\n};\n\nint sum(int *pa, int *pb);\nstruct _complex_ * sumC( struct _complex_ *a,  struct _complex_ *b);\n\n\nint main(void){\n    int x = 4,y = 5;\n    int* ptr = &y;\n    struct _complex_  xc = {.re = 1.0, .im = 2.0};\n    struct _complex_  yc = {.re = 3.0, .im = 1.0};\n    struct _complex_  *zc; \n\n\n    printf(\"Complex addition (%f,%f i) + (%f,%f i) = \",     xc.re,xc.im,yc.re,yc.im);\n    zc = sumC(&xc,&yc);\n    printf(\"(%f,%f i)\\n\",zc->re,zc->im);\n    int total = sum(&x,ptr); \n\n    printf(\"Complex addition:  x +y = %d + %d = %d \\n\",x,y, total);\n    printf(\"xc = (%f,%f i)  yc = (%f,%f i) zc = (%f,%f i)\\n\",xc.re,xc.im,yc.re,yc.im,zc->re,zc->im);\n    return 0;\n}\n\nint sum(int *pa, int *pb) {  \n   /* args passed by reference */\n  int c = *pa + *pb;\n  int buf[256] = {0};\n  *pa = 7;\n  *pb = 8;  \n   return c;      /* return by value */\n}\n\n\nstruct _complex_ * sumC( struct _complex_* a,  struct _complex_* b) {\n        struct _complex_ r;\n        r.re = a->re + b->re;\n        r.im = a->im + b->im;\n        a->re = 12.5;\n        a->im = 13.4;\n        return &r;\n}",
            "title": "Arguments"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#strings",
            "text": "#include <stdio.h>\n#include <string.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. The code has a bug. Compile or run-time? Why?\n * Fix the bug commenting the line(s) that produce it. Compile and execute again. \n * 2. Which is the address of letter 'B' in the chain \"Bonjour\"? And letter 'j'?\n * 3. After the assignment p=msg2; how can we get back the address of \"Bonjour\"?\n * 4. Why the length of strings 'p' and 'msg2' are 2 after the third assignment?\n *    3 bytes are assigned to 'p', but then the length is only 2 !!\n * 5. Why strlen() returns a different value than sizeof()?\n * 6. Why the string stored in 'msg' in line 36 is bad-printed in the last printf()?\n ************** */\nint main() {\n\nchar msg[10]; /* array of 10 chars */\nchar *p;          /* pointer to a char */\n\nchar msg2[28]=\"Hello\";  /* msg2 = 'H' 'e' 'l' 'l' 'o' '\\0' */\n\n    p   = \"Bonjour\"; \n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"dir de msg: %p, dir de p: %p, dir de msg2: %p\\n\",msg,p,msg2);\n\n    p = msg2;\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"dir de msg: %p, dir de p: %p, dir de msg2: %p\\n\",msg,p,msg2);\n\n    p[0] = 'H', p[1] = 'i',p[2]='\\0';\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n    printf(\"msg len: %lu p len %lu msg2 len %lu\\n\", strlen(msg),strlen(p),strlen(msg2));\n    printf(\"msg size: %lu p size %lu msg2 size %lu\\n\", sizeof(msg),sizeof(p),sizeof(msg2));\n\n    msg[0] = 'B', msg[1] = 'y';\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n\n    msg = \"Goodbye\";\n    printf(\"msg: %s, p: %s, msg2: %s\\n\",msg,p,msg2);\n}  #include <stdio.h>\n#include <string.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. The code of fcuntion 'copy' does not work. Why?\n * 2. Use now 'copy2()'. Does the copy actually work?\n * 3. Suggest a valid implementation for a copy\n * 4. What does function \"mod\" do? \n * 5. Uncomment last line of code (call to mod()). Compile and execute. Why is there an error now?\n ************** */\n\nvoid copy2(char* org, char** dst) {\n    *dst = org;\n}\n\nvoid copy(char* org, char* dst) {\n    dst = org;\n}\n\nvoid mod(char* org, char* dst) {\n    int i;\n\n    for (i=0;i<strlen(org);i++)\n        dst[i] = org[i] - 32;\n\n}\n\nint main() {\n\n    char* cad1 = \"original\";          \n    char* cad2 = \"other\";\n    char cad3[32];\n\n    copy(cad1,cad2);\n    //copy2(cad1,&cad2);\n    printf(\"cad1 %s cad2 %s\\n\", cad1,cad2);\n\n    mod(cad1,cad3);\n    printf(\"cad1 %s cad3 %s\\n\", cad1,cad3);\n\n    //mod(cad1,cad1);\n}",
            "title": "Strings"
        },
        {
            "location": "/Subjects/IOTNA/ctutorial/#bitwaise-operations",
            "text": "#include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * Study the syntax of the different bit-level operators\n * and make sure you understand  the result of every operation\n ************** */\n\nint a,b,c;\n\nint main() {\n\n    a = 7;\n    b = 9;\n    c = a & b;\n    printf(\"%x AND %x = %x\\n\",a,b,c);\n\n    c= a | b;\n    printf(\"%x OR %x = %x\\n\",a,b,c);\n\n    c = a ^ b;\n    printf(\"%x XOR %x = %x\\n\",a,b,c);\n\n    c = ~a;\n    printf(\"NOT %x = %x\\n\",a,c);\n\n    c = a << 2;\n    printf(\" %x << 2 = %x\\n\",a,c);\n\n    c = a >> 1;\n    printf(\" %x >> 1 = %x\\n\",a,c);\n\n    c = a & 0xFB;\n    printf(\" %x bit 2 to 0 -> %x\\n\",a,c);\n\n    c = a | 0x40;\n    printf(\" %x bit 6 to 1 -> %x\\n\",a,c);\n\n    c = (a & 0x1C) >> 2;\n    printf(\"bits 4-3-2 of %x: %x\\n\",a,c);   \n}  #include <stdio.h>\n\n/**** QUESTIONS/TASKS ********\n * Compile and execute the code. \n * 1. Why the assignment using pointer 'p' does not overwrite completely 'a'?\n * 2. How is modified the address pointed by 'p' after the assignment p=p+1\n * 3. How would it be different if 'p' is declared as 'short *'\n *\n ************** */\nint a = 3;\nint b;\nchar * p;\nint c;\nint main() {\n\n    printf(\"a = %x Address of a: %p \\n\",a,&a);\n    p = (char*) &a;\n    p=p+1;\n    *p= 0x1f;\n    printf(\"a = %x. Address pointed by p:%p \\n\",a,p);\n\n    a = 3;\n    b = 0x00001f00;\n    a= a | b;\n\n    printf(\"a = %x. Address pointed by p:%p \\n\",a,p);\n}",
            "title": "Bitwaise operations"
        },
        {
            "location": "/Subjects/IOTNA/demo/",
            "text": "Introduction to ESP-IDF and Platform IO (demo)\n\n\nGoals\n\n\n\n\nMeet the IDE we will be using during the Master: native ESP-IDF and the tool PlatformIO\n\n\nLearn how to run  the virtual machine and install the environments\n\n\nLearn how to connect our ESP32 board to the computer and upload a binary\n\n\n\n\nUsing the Virtual Machine\n\n\nWe have provided a virtual machine with some of the tools we will be using already installed. Note that you can install everything natively in your system, and I will run faster. We provide the virtual machine just in case you prefer not to install new software in your own computer.\n\n\nYou can download the OVA file  from \nGoogle Drive\n or \nBaidu Netdisk\n (with code 7spz).  An OVA file  contains a OVF  (Open Virtualizaion Format) file so it can be opened in any virtualization framework.\n\n\nDuring the course, we will be using \nOracle VM Virtualbox\n which is a free and open-source hosted hypervisor for x86 virtualization. In order to run the virtual machine just follow the steps:\n\n\n\n\nDownload Virtual Box \nfrom this link\n.\n\n\nInstall Virtual Box in your machine.\n\n\nDownload the OVA file provided.\n\n\nImport\n the OVA file from Virtual Box (Use \"Import\" or \"Import Appliance\" from the File menu. Do not just drag the OVA file in the Virtual Box window)\n\n\n\n\nAfter importing the virtual machine is imported it should be listed in Virtual Box screen (the one named \nMIOT_VM_2022_CN\n)\n\n\n\n\nNow, you can run the virtual machine. We have installed a recent version of Ubuntu operating system (Ubuntu 20.04.1 LTS). There is a sinlge user (named Ubuntu) whose password is \nubuntu\n (small-caps). \n\n\n\n\nLaunching Visual Studio Code and PlatformIO\n\n\nDuring this online demo, I will show you how to use Visual Studio Code and the PlatformIO plugin to create a new project, compile it and upload it to our board.\n\n\nYou can install this environment in your own machine, which is recommended since virtualization introduces some overheads.  You can download \nVisual Studio Code from this link\n. Once installed, you can easily install the \nPlatformIO plugin\n from the \nExtensions: Marketplace\n in the same Visual Studio Code window:\n\n\n\n\nInstalling the native ESP-IDF environment\n\n\nThere is an alternative to PlatformIO: installing the native \nEspressif\n environment for ESP-IDF.  You have all the steps to install and setup their environment in \nthis link\n\n\nJust a summary of the information there provided (please check the website, because it could be updated),  we include here the most relevant steps for the environment installation in the Ubuntu terminal machine. \n\n\n\n\nOpen a Terminal and make sure your package system is up to date:\n\n\n\n\nsudo apt update\nsudo apt upgrade\n\n\n\n\n\n\nRun the following command to install the pre-requisites (note that you will be using \nsudo\n to run it with superuser privileges. The user \nUbuntu\n  has \nsudo\n privileges, so just use the same password as before when required: \nubuntu\n).\n\n\n\n\nsudo apt-get install git wget flex bison gperf python python3-pip python-setuptools cmake ninja-build ccache libffi-dev libssl-dev dfu-util\n\n\n\n\nIf you are installing the environment in your own Linux machine, make sure your user is also in the \ndilaout\n group. \n\n\n\n\nInstall Python 3 and make it the default distribution:\n\n\n\n\nsudo apt-get install python3 python3-pip python3-setuptools\nsudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10\n\n\n\n\n\n\nObtain ESP-IDF sources. We will install it under a folder called \nesp\n\n\n\n\nmkdir -p ~/esp\ncd ~/esp\ngit clone --recursive https://github.com/espressif/esp-idf.git\ncd esp-idf\ngit fetch\ngit pull\ngit submodule update --init --recursive\n\n\n\n\n\n\nNow you can proceed to install the environment by using the provided script in \nesp-idf\n folder. This should be done only once.\n\n\n\n\nsh install.sh\n\n\n\n\n\n\nEvery time you are to use the environment after opening a new Terminal, you should export some environment variables by running the \nexport\n script provided in the \nesp-idf\n folder:\n\n\n\n\n. ./export.sh\n\n\n\n\n\n\nYou are now ready to use the environment. \nidf.py\n is the front-end tool for everything: compiling, flashing , monitoring... You can now check the installed version by running:\n\n\n\n\n$ idf.py --version\nESP-IDF v4.xxxxx",
            "title": "Home"
        },
        {
            "location": "/Subjects/IOTNA/demo/#introduction-to-esp-idf-and-platform-io-demo",
            "text": "",
            "title": "Introduction to ESP-IDF and Platform IO (demo)"
        },
        {
            "location": "/Subjects/IOTNA/demo/#goals",
            "text": "Meet the IDE we will be using during the Master: native ESP-IDF and the tool PlatformIO  Learn how to run  the virtual machine and install the environments  Learn how to connect our ESP32 board to the computer and upload a binary",
            "title": "Goals"
        },
        {
            "location": "/Subjects/IOTNA/demo/#using-the-virtual-machine",
            "text": "We have provided a virtual machine with some of the tools we will be using already installed. Note that you can install everything natively in your system, and I will run faster. We provide the virtual machine just in case you prefer not to install new software in your own computer.  You can download the OVA file  from  Google Drive  or  Baidu Netdisk  (with code 7spz).  An OVA file  contains a OVF  (Open Virtualizaion Format) file so it can be opened in any virtualization framework.  During the course, we will be using  Oracle VM Virtualbox  which is a free and open-source hosted hypervisor for x86 virtualization. In order to run the virtual machine just follow the steps:   Download Virtual Box  from this link .  Install Virtual Box in your machine.  Download the OVA file provided.  Import  the OVA file from Virtual Box (Use \"Import\" or \"Import Appliance\" from the File menu. Do not just drag the OVA file in the Virtual Box window)   After importing the virtual machine is imported it should be listed in Virtual Box screen (the one named  MIOT_VM_2022_CN )   Now, you can run the virtual machine. We have installed a recent version of Ubuntu operating system (Ubuntu 20.04.1 LTS). There is a sinlge user (named Ubuntu) whose password is  ubuntu  (small-caps).",
            "title": "Using the Virtual Machine"
        },
        {
            "location": "/Subjects/IOTNA/demo/#launching-visual-studio-code-and-platformio",
            "text": "During this online demo, I will show you how to use Visual Studio Code and the PlatformIO plugin to create a new project, compile it and upload it to our board.  You can install this environment in your own machine, which is recommended since virtualization introduces some overheads.  You can download  Visual Studio Code from this link . Once installed, you can easily install the  PlatformIO plugin  from the  Extensions: Marketplace  in the same Visual Studio Code window:",
            "title": "Launching Visual Studio Code and PlatformIO"
        },
        {
            "location": "/Subjects/IOTNA/demo/#installing-the-native-esp-idf-environment",
            "text": "There is an alternative to PlatformIO: installing the native  Espressif  environment for ESP-IDF.  You have all the steps to install and setup their environment in  this link  Just a summary of the information there provided (please check the website, because it could be updated),  we include here the most relevant steps for the environment installation in the Ubuntu terminal machine.    Open a Terminal and make sure your package system is up to date:   sudo apt update\nsudo apt upgrade   Run the following command to install the pre-requisites (note that you will be using  sudo  to run it with superuser privileges. The user  Ubuntu   has  sudo  privileges, so just use the same password as before when required:  ubuntu ).   sudo apt-get install git wget flex bison gperf python python3-pip python-setuptools cmake ninja-build ccache libffi-dev libssl-dev dfu-util  If you are installing the environment in your own Linux machine, make sure your user is also in the  dilaout  group.    Install Python 3 and make it the default distribution:   sudo apt-get install python3 python3-pip python3-setuptools\nsudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10   Obtain ESP-IDF sources. We will install it under a folder called  esp   mkdir -p ~/esp\ncd ~/esp\ngit clone --recursive https://github.com/espressif/esp-idf.git\ncd esp-idf\ngit fetch\ngit pull\ngit submodule update --init --recursive   Now you can proceed to install the environment by using the provided script in  esp-idf  folder. This should be done only once.   sh install.sh   Every time you are to use the environment after opening a new Terminal, you should export some environment variables by running the  export  script provided in the  esp-idf  folder:   . ./export.sh   You are now ready to use the environment.  idf.py  is the front-end tool for everything: compiling, flashing , monitoring... You can now check the installed version by running:   $ idf.py --version\nESP-IDF v4.xxxxx",
            "title": "Installing the native ESP-IDF environment"
        },
        {
            "location": "/Subjects/MDM/",
            "text": "Massive Data Management\n\n\nAll the information and documentation about Massive Data Management (MDM) can be found in \nthis link",
            "title": "Home"
        },
        {
            "location": "/Subjects/MDM/#massive-data-management",
            "text": "All the information and documentation about Massive Data Management (MDM) can be found in  this link",
            "title": "Massive Data Management"
        },
        {
            "location": "/Subjects/NP1/FinalProject/",
            "text": "Networks and Protocols (NP1 + NP2) Final Programming Project\n\n\nAs a last exercise for the two subjects (NP1 and NP2) you will work in \nteams\nof 2 people\n on a project that shows what you have learned from these topics.\nYou will develop (program) a system to monitor the amount of people in a room,\nby detecting their smartphones, uploading the data to an external server for\nanalysis and visualization. In the following sections we describe what should be\ncovered for the two subjects.\n\n\nProject submission and deadline\n\n\nYou should submit:\n\n\n\n\n\n\nThe code of the program in the node\n\n\n\n\n\n\nData of your experiments\n\n\n\n\n\n\nA pdf report documenting your work in english.\n\n\n\n\n\n\nThe deadline for submission is April 17th. We will admit delayed\nsubmissions with penalization on the grade up to the 24th of April.\n\n\nRequirements for NP1\n\n\nYour system should manage a sensor network, formed by your ESP32 nodes. We assume\nthat you could have at least one node per room and that each room has a WiFi\naccess point reachable. In this context:\n\n\n\n\n\n\nYour nodes should be able to connect to the AP using WiFi, with WPA2-PSK\n  security.\n\n\n\n\n\n\nYour nodes should provide a provissioning option, so that you can configure\n  the wifi SSID to connect to. You can use a softAP or a BLE provisioning\n  method, that is up to you.\n\n\n\n\n\n\nYour nodes should use BLE to compute the number of other BLE devices in its\n  range (an estimation of the number of people in its range), using the RSSI to\n  compute the distance to the node (the student should research for methods to\n  compute the distance).\n\n\n\n\nAlternatively the student can opt for using a different technology of his\n  choice to estimate the number of people in the room.\n\n\n\n\n\n\n\n\nThe node should be configured through the menuconfig system, to establish its\n  parameters:\n\n\n\n\nSampling period.\n\n\nServer where the samples should be sent to (see requirements for NP2).\n\n\nRange of valid distances.\n\n\netc.\n\n\n\n\n\n\n\n\nOptional Parts for NP1\n\n\nOptionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):\n\n\n\n\n\n\nConsider an scenario with larger rooms, in which one node is not enough and\n  the wifi AP is not reachable on all points. In this scenario you can use the\n  ESP's wifi-mesh technology to build a mesh of nodes in the room.\n\n\n\n\n\n\nStudy the Over The Air (OTA) features of ESP and prepare your nodes to receive\n  OTA updates from an external server. Together with NP2 you can consider to\n  configure the nodes to trigger the OTA update through MQTT (or any other\n  application protocol you are using).\n\n\n\n\n\n\nAdd a GATT server that allows the node parameters to be configured with a BLE\n  client.\n\n\n\n\n\n\nRequirements for NP2\n\n\nThe developed system will periodically publish the calculated data for the \npopulation of BLE devices in the room, sending it to an external server for \nfurther storage and analysis. \n\n\nSpecifically, the minimum requirements related with NP2 include:\n\n\n\n\n\n\nYou will select an application-level protocol among those studied in NP2 \n  (or, alternatively, other similar protocols of your interest) and use it \n  for data publishing.\n\n\n\n\n\n\nServers/brokers to which data will be sent will be configured via \nmenuconfig\n, \n  together with the sending period and any other configurable parameter \n  considered useful.\n\n\n\n\n\n\nYou will select and use one of the two data representation methods studied in \n  the course (JSON or CBOR).\n\n\n\n\n\n\nData will be gathered by Node-RED and submitted to two different destinations:\n\n\n\n\nA dashboard of your election (e.g. Node-RED, Grafana, ...).\n\n\nA database (e.g. MongoDB), where it will be stored together with a timestamp.\n\n\n\n\n\n\n\n\nOptional Parts for NP2\n\n\nOptionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):\n\n\n\n\n\n\nUse encryption at all levels of the communication (e.g. MQTT).\n\n\n\n\n\n\nDevelop an alarm system that triggers under certain conditions (e.g. when the amount of \n  BLE devices is out of a pre-established range), and sends a notification to the user using\n  external services (e.g. SMS, e-mail, Telegram, ...).\n\n\n\n\n\n\nImplement bi-directional communication, with the possibility of externally modifying the \n  behavior of the ESP32 (e.g. modifying sampling or sending period).\n\n\n\n\n\n\nTeams for the project\n\n\n\n\n\n\n\n\nTeam\n\n\nMembers\n\n\n\n\n\n\n\n\n\n\n1\n\n\nLIU Jinhua, HU Hao\n\n\n\n\n\n\n2\n\n\nZhao Hu, Yan Zhao\n\n\n\n\n\n\n3\n\n\nHUANG Yujuan, DUAN Zhen\n\n\n\n\n\n\n4\n\n\nWEILIN ZHANG ,YONGTAO HE\n\n\n\n\n\n\n5\n\n\nQIUJI CHEN, XIAOLAN LI\n\n\n\n\n\n\n6\n\n\nJunyan Guo,Haozhijun\n\n\n\n\n\n\n7\n\n\njianchuang zhang,xionglan luo\n\n\n\n\n\n\n8\n\n\n\n\n\n\n\n\n9\n\n\nGonglu Zou\uff0cHongbiao Cao\n\n\n\n\n\n\n10\n\n\nJiali Gao\uff0cJiayun Pan\n\n\n\n\n\n\n11\n\n\nSuizhi Liu, Wei Ren\n\n\n\n\n\n\n12\n\n\nYang Chu, Wenyan Liao\n\n\n\n\n\n\n13\n\n\nFengfeng Gu, Bin Zhang\n\n\n\n\n\n\n14\n\n\nLi tianfeng, Yi Zhang\n\n\n\n\n\n\n15\n\n\nYouran Tian, Jun Shou\n\n\n\n\n\n\n16\n\n\nDongyang Xu\uff0cXueqing Zhao\n\n\n\n\n\n\n17\n\n\nYuanshuang Sha, Guanjie Xiao\n\n\n\n\n\n\n18\n\n\nLiao Yinghua, Qinghong Yu\n\n\n\n\n\n\n19\n\n\nShuishi Zhou",
            "title": "FinalProject"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#networks-and-protocols-np1-np2-final-programming-project",
            "text": "As a last exercise for the two subjects (NP1 and NP2) you will work in  teams\nof 2 people  on a project that shows what you have learned from these topics.\nYou will develop (program) a system to monitor the amount of people in a room,\nby detecting their smartphones, uploading the data to an external server for\nanalysis and visualization. In the following sections we describe what should be\ncovered for the two subjects.",
            "title": "Networks and Protocols (NP1 + NP2) Final Programming Project"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#project-submission-and-deadline",
            "text": "You should submit:    The code of the program in the node    Data of your experiments    A pdf report documenting your work in english.    The deadline for submission is April 17th. We will admit delayed\nsubmissions with penalization on the grade up to the 24th of April.",
            "title": "Project submission and deadline"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#requirements-for-np1",
            "text": "Your system should manage a sensor network, formed by your ESP32 nodes. We assume\nthat you could have at least one node per room and that each room has a WiFi\naccess point reachable. In this context:    Your nodes should be able to connect to the AP using WiFi, with WPA2-PSK\n  security.    Your nodes should provide a provissioning option, so that you can configure\n  the wifi SSID to connect to. You can use a softAP or a BLE provisioning\n  method, that is up to you.    Your nodes should use BLE to compute the number of other BLE devices in its\n  range (an estimation of the number of people in its range), using the RSSI to\n  compute the distance to the node (the student should research for methods to\n  compute the distance).   Alternatively the student can opt for using a different technology of his\n  choice to estimate the number of people in the room.     The node should be configured through the menuconfig system, to establish its\n  parameters:   Sampling period.  Server where the samples should be sent to (see requirements for NP2).  Range of valid distances.  etc.",
            "title": "Requirements for NP1"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#optional-parts-for-np1",
            "text": "Optionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):    Consider an scenario with larger rooms, in which one node is not enough and\n  the wifi AP is not reachable on all points. In this scenario you can use the\n  ESP's wifi-mesh technology to build a mesh of nodes in the room.    Study the Over The Air (OTA) features of ESP and prepare your nodes to receive\n  OTA updates from an external server. Together with NP2 you can consider to\n  configure the nodes to trigger the OTA update through MQTT (or any other\n  application protocol you are using).    Add a GATT server that allows the node parameters to be configured with a BLE\n  client.",
            "title": "Optional Parts for NP1"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#requirements-for-np2",
            "text": "The developed system will periodically publish the calculated data for the \npopulation of BLE devices in the room, sending it to an external server for \nfurther storage and analysis.   Specifically, the minimum requirements related with NP2 include:    You will select an application-level protocol among those studied in NP2 \n  (or, alternatively, other similar protocols of your interest) and use it \n  for data publishing.    Servers/brokers to which data will be sent will be configured via  menuconfig , \n  together with the sending period and any other configurable parameter \n  considered useful.    You will select and use one of the two data representation methods studied in \n  the course (JSON or CBOR).    Data will be gathered by Node-RED and submitted to two different destinations:   A dashboard of your election (e.g. Node-RED, Grafana, ...).  A database (e.g. MongoDB), where it will be stored together with a timestamp.",
            "title": "Requirements for NP2"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#optional-parts-for-np2",
            "text": "Optionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):    Use encryption at all levels of the communication (e.g. MQTT).    Develop an alarm system that triggers under certain conditions (e.g. when the amount of \n  BLE devices is out of a pre-established range), and sends a notification to the user using\n  external services (e.g. SMS, e-mail, Telegram, ...).    Implement bi-directional communication, with the possibility of externally modifying the \n  behavior of the ESP32 (e.g. modifying sampling or sending period).",
            "title": "Optional Parts for NP2"
        },
        {
            "location": "/Subjects/NP1/FinalProject/#teams-for-the-project",
            "text": "Team  Members      1  LIU Jinhua, HU Hao    2  Zhao Hu, Yan Zhao    3  HUANG Yujuan, DUAN Zhen    4  WEILIN ZHANG ,YONGTAO HE    5  QIUJI CHEN, XIAOLAN LI    6  Junyan Guo,Haozhijun    7  jianchuang zhang,xionglan luo    8     9  Gonglu Zou\uff0cHongbiao Cao    10  Jiali Gao\uff0cJiayun Pan    11  Suizhi Liu, Wei Ren    12  Yang Chu, Wenyan Liao    13  Fengfeng Gu, Bin Zhang    14  Li tianfeng, Yi Zhang    15  Youran Tian, Jun Shou    16  Dongyang Xu\uff0cXueqing Zhao    17  Yuanshuang Sha, Guanjie Xiao    18  Liao Yinghua, Qinghong Yu    19  Shuishi Zhou",
            "title": "Teams for the project"
        },
        {
            "location": "/Subjects/NP1/groups/",
            "text": "Groups for lecture assignments\n\n\nWe will be using the stable groups from NP1 to work during lectures (and after\nclass).\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\n\n\nGroup 2\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nLiu Jinhua\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nWeilin Zhang\n\n\n\n\n\n\nContributor\n\n\nDuan Zhen\n\n\n\n\n\n\nContributor\n\n\nYouran Tian\n\n\n\n\n\n\nContributor\n\n\nHuang Yujuan\n\n\n\n\n\n\nContributor\n\n\nJun Shou\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nYuanShuang Sha\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\nContributor\n\n\nLIAO  Yinghua\n\n\n\n\n\n\nContributor\n\n\nPAN Jiayun\n\n\n\n\n\n\nContributor\n\n\nZHANG  Yi\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nWEI REN\n\n\n\n\n\n\nContributor\n\n\nXIAZU HU\n\n\n\n\n\n\n\n\nGroup 5\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nShuishi Zhou\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nAuditor\n\n\nWENYAN LIAO\n\n\n\n\n\n\nContributor\n\n\nFENGFENG GU\n\n\n\n\n\n\nContributor\n\n\nBIN ZHANG\n\n\n\n\n\n\nContributor\n\n\nHONGBIAO CAO\n\n\n\n\n\n\nContributor\n\n\nGONGLU ZOU\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nXionglan Luo\n\n\n\n\n\n\nAuditor\n\n\nQiuji Chen\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang\n\n\n\n\n\n\nContributor\n\n\nYan Zhao\n\n\n\n\n\n\nContributor\n\n\nYongtao He\n\n\n\n\n\n\nContributor\n\n\nZhao Hu",
            "title": "Groups"
        },
        {
            "location": "/Subjects/NP1/groups/#groups-for-lecture-assignments",
            "text": "We will be using the stable groups from NP1 to work during lectures (and after\nclass).",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/NP1/groups/#group-1",
            "text": "Rol  Full name      Speaker  ZHOU Ping",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/NP1/groups/#group-2",
            "text": "Rol  Full name      Speaker  Liu Jinhua    Recorder  Hu Haho    Auditor  Weilin Zhang    Contributor  Duan Zhen    Contributor  Youran Tian    Contributor  Huang Yujuan    Contributor  Jun Shou",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/NP1/groups/#group-3",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  YuanShuang Sha    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao    Contributor  LIAO  Yinghua    Contributor  PAN Jiayun    Contributor  ZHANG  Yi",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/NP1/groups/#group-4",
            "text": "Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG YU    Auditor  SUIZHI LIU    Contributor  TIANFENG LI    Contributor  WEI REN    Contributor  XIAZU HU",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/NP1/groups/#group-5",
            "text": "Rol  Full name      Speaker  Shuishi Zhou    Contributor  Yang Chu    Auditor  WENYAN LIAO    Contributor  FENGFENG GU    Contributor  BIN ZHANG    Contributor  HONGBIAO CAO    Contributor  GONGLU ZOU",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/NP1/groups/#group-6",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Xionglan Luo    Auditor  Qiuji Chen    Contributor  Jianchuang Zhang    Contributor  Yan Zhao    Contributor  Yongtao He    Contributor  Zhao Hu",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/NP1/",
            "text": "Networks and Protocols 1\n\n\nGeneral information\n\n\nThis subject will cover the networking technologies used in IoT systems. Some\nspecific goals if this subject are:\n\n\n\n\n802.11 family\n\n\nBluetooth Low Energy\n\n\n802.15.4 and 6LoWPAN\n\n\nLPWAN, Lora\n\n\n\n\nThis subject is complemented by NP2, where the transport and application layer\nprotocolos for IoT in the Internet are covered\n\n\nSubject program and evaluation methodology\n\n\nProgram and evaluation\n\n\nProfessor\n\n\nChristian Tenllado (tenllado@ucm.es)\n\n\nPaper work assignment\n\n\nHere you can find  description about this assignment\n\n\nFinal programming project (teams of 2 people)\n\n\nOnce ready you will find \nhere\n the details on the final project for this\ncourse.\n\n\nWork groups (for regular lab assignments)\n\n\nHere you can find the current work groups\n\n\nQuizzes\n\n\nFor all quizzes will you are requested to use your e-mail address as name. All\nof them can be accessed directly from \nthis\nlink\n.\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay/Month\n\n\nTopic\n\n\nLab instructions\n\n\nDeliverable\n\n\n\n\n\n\n\n\n\n\n19/01\n\n\nBasic Concepts\n\n\n\n\n\n\n\n\n\n\n20/01\n\n\nBasic Concepts 2\n and \nWifi-1\n\n\n\n\nQuiz 1\n\n\n\n\n\n\n26/01\n\n\nWifi-1\n\n\n\n\nQuiz 2\n\n\n\n\n\n\n27/01\n\n\nWifi-2\n\n\n\n\nQuiz 3\n\n\n\n\n\n\n02/02\n\n\nWeek off (Chinese new year)\n\n\n\n\n\n\n\n\n\n\n03/02\n\n\nWeek off (Chinese new year)\n\n\n\n\n\n\n\n\n\n\n09/02\n\n\nLab 1. Introduction to ESP-IDF\n\n\nLab 1. instructions\n\n\nTasks 1.1-1.3\n\n\n\n\n\n\n10/02\n\n\nLab 1. Introduction to ESP-IDF\n\n\nLab 1. instructions\n\n\nTasks 1.4-1.6\n\n\n\n\n\n\n16/02\n\n\nLab 2. Wifi in ESP-IDF\n\n\nLab 2. instructions\n\n\nTasks 2.1-2.4\n\n\n\n\n\n\n17/02\n\n\nBLE-1\n\n\n\n\nQuiz\n\n\n\n\n\n\n23/02\n\n\nLab 3. Wifi mesh and provisioning\n\n\nLab 3. instructions\n\n\nTasks 3.1-3.2\n\n\n\n\n\n\n24/02\n\n\nLab 3. Wifi mesh and provisioning\n\n\nLab 3. instructions\n\n\nTasks 3.3-3.4\n\n\n\n\n\n\n02/03\n\n\nBLE-2\n and \nBLE-Mesh\n\n\n\n\nQuiz\n\n\n\n\n\n\n03/03\n\n\nLab 4. Bluetooth Low Energy\n\n\nLab 4. instructions\n\n\nTask 4.1\n\n\n\n\n\n\n09/03\n\n\nLab 4. Bluetooth Low Energy\n\n\nLab 4. instructions\n\n\nTask 4.2\n\n\n\n\n\n\n10/03\n\n\nLab 4. Bluetooth Low Energy\n\n\nLab 4. instructions\n\n\nExtra session\n\n\n\n\n\n\n16/03\n\n\n802.15.4\n, \n6LoWPAN\n\n\n\n\nQuiz\n\n\n\n\n\n\n17/03\n\n\nLab 5. Bluetooth Mesh\n\n\nLab 5. instructions\n\n\nTask 5.1 and 5.2\n\n\n\n\n\n\n23/03\n\n\nLab 6. 6LoWPAN, RPL\n\n\nLab 6. instructions\n\n\nTask 6.1\n\n\n\n\n\n\n24/03\n\n\nLPWAN\n\n\n\n\nQuiz\n\n\n\n\n\n\n30/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n31/03\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n06/04\n\n\nWork on Final Project\n\n\n\n\n\n\n\n\n\n\n07/04\n\n\nWork on Final Project",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/#networks-and-protocols-1",
            "text": "",
            "title": "Networks and Protocols 1"
        },
        {
            "location": "/Subjects/NP1/#general-information",
            "text": "This subject will cover the networking technologies used in IoT systems. Some\nspecific goals if this subject are:   802.11 family  Bluetooth Low Energy  802.15.4 and 6LoWPAN  LPWAN, Lora   This subject is complemented by NP2, where the transport and application layer\nprotocolos for IoT in the Internet are covered",
            "title": "General information"
        },
        {
            "location": "/Subjects/NP1/#subject-program-and-evaluation-methodology",
            "text": "Program and evaluation",
            "title": "Subject program and evaluation methodology"
        },
        {
            "location": "/Subjects/NP1/#professor",
            "text": "Christian Tenllado (tenllado@ucm.es)",
            "title": "Professor"
        },
        {
            "location": "/Subjects/NP1/#paper-work-assignment",
            "text": "Here you can find  description about this assignment",
            "title": "Paper work assignment"
        },
        {
            "location": "/Subjects/NP1/#final-programming-project-teams-of-2-people",
            "text": "Once ready you will find  here  the details on the final project for this\ncourse.",
            "title": "Final programming project (teams of 2 people)"
        },
        {
            "location": "/Subjects/NP1/#work-groups-for-regular-lab-assignments",
            "text": "Here you can find the current work groups",
            "title": "Work groups (for regular lab assignments)"
        },
        {
            "location": "/Subjects/NP1/#quizzes",
            "text": "For all quizzes will you are requested to use your e-mail address as name. All\nof them can be accessed directly from  this\nlink .",
            "title": "Quizzes"
        },
        {
            "location": "/Subjects/NP1/#schedule",
            "text": "Day/Month  Topic  Lab instructions  Deliverable      19/01  Basic Concepts      20/01  Basic Concepts 2  and  Wifi-1   Quiz 1    26/01  Wifi-1   Quiz 2    27/01  Wifi-2   Quiz 3    02/02  Week off (Chinese new year)      03/02  Week off (Chinese new year)      09/02  Lab 1. Introduction to ESP-IDF  Lab 1. instructions  Tasks 1.1-1.3    10/02  Lab 1. Introduction to ESP-IDF  Lab 1. instructions  Tasks 1.4-1.6    16/02  Lab 2. Wifi in ESP-IDF  Lab 2. instructions  Tasks 2.1-2.4    17/02  BLE-1   Quiz    23/02  Lab 3. Wifi mesh and provisioning  Lab 3. instructions  Tasks 3.1-3.2    24/02  Lab 3. Wifi mesh and provisioning  Lab 3. instructions  Tasks 3.3-3.4    02/03  BLE-2  and  BLE-Mesh   Quiz    03/03  Lab 4. Bluetooth Low Energy  Lab 4. instructions  Task 4.1    09/03  Lab 4. Bluetooth Low Energy  Lab 4. instructions  Task 4.2    10/03  Lab 4. Bluetooth Low Energy  Lab 4. instructions  Extra session    16/03  802.15.4 ,  6LoWPAN   Quiz    17/03  Lab 5. Bluetooth Mesh  Lab 5. instructions  Task 5.1 and 5.2    23/03  Lab 6. 6LoWPAN, RPL  Lab 6. instructions  Task 6.1    24/03  LPWAN   Quiz    30/03  Work on Final Project      31/03  Work on Final Project      06/04  Work on Final Project      07/04  Work on Final Project",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/NP1/paperProject/",
            "text": "Group paper work\n\n\nTogether with your lab group, you need to prepare a paper work, as explained in\nthe slides of the first class \nPresentation\n.\n\n\nIt is a documentation work in which you are requested to explore an document\nyourself on one of the networking technologies used for or focused on IoT\nsystems. The technologies proposed are listed bellow. You are requested to focus\nthe study on its use in your local area or China, however you can expand it to\nAsia or the whole world if you feel like doing it (not required).\n\n\nIn both cases you should study not only the technical aspects of the technology,\nyou should also include known use cases (in the case of choosing one of the\ntechnologies proposed below), expected growth of the technology, direct\ncompetitors and potential future market share.\n\n\nList of networking technologies you can consider\n\n\nThe networking technologies for the paper work shall not overlap between groups,\nyou should request one of the topics sending a mail to the professor\n(tenllado@ucm.es), who will confirm if you can choose the topic or if it has\nbeen already chosen by other group.\n\n\nThe topics are:\n\n\n\n\n5G\n\n\nNarrow Band IoT (NBIoT)\n\n\nLoRa\n\n\nSigFox\n\n\nZigbee\n\n\nThread and Open Thread\n\n\nDotDot and Thread\n\n\nPractical use case study of 6LoWPAN networks\n\n\nNetwork Technologies for Smart Buildings\n\n\nNetwork Technologies for Industry 4.0\n\n\nWifi Mesh technologies\n\n\nNetwork Technologies for Domotics (home automation)\n\n\nPractical use case of any of the studed technologies\n\n\n\n\nDeadline\n\n\nOriginally 8th April.\n\n\nDelivering the project\n\n\nOnce finished, please send me an email (to tenllado@ucm.es)",
            "title": "paperProject"
        },
        {
            "location": "/Subjects/NP1/paperProject/#group-paper-work",
            "text": "Together with your lab group, you need to prepare a paper work, as explained in\nthe slides of the first class  Presentation .  It is a documentation work in which you are requested to explore an document\nyourself on one of the networking technologies used for or focused on IoT\nsystems. The technologies proposed are listed bellow. You are requested to focus\nthe study on its use in your local area or China, however you can expand it to\nAsia or the whole world if you feel like doing it (not required).  In both cases you should study not only the technical aspects of the technology,\nyou should also include known use cases (in the case of choosing one of the\ntechnologies proposed below), expected growth of the technology, direct\ncompetitors and potential future market share.",
            "title": "Group paper work"
        },
        {
            "location": "/Subjects/NP1/paperProject/#list-of-networking-technologies-you-can-consider",
            "text": "The networking technologies for the paper work shall not overlap between groups,\nyou should request one of the topics sending a mail to the professor\n(tenllado@ucm.es), who will confirm if you can choose the topic or if it has\nbeen already chosen by other group.  The topics are:   5G  Narrow Band IoT (NBIoT)  LoRa  SigFox  Zigbee  Thread and Open Thread  DotDot and Thread  Practical use case study of 6LoWPAN networks  Network Technologies for Smart Buildings  Network Technologies for Industry 4.0  Wifi Mesh technologies  Network Technologies for Domotics (home automation)  Practical use case of any of the studed technologies",
            "title": "List of networking technologies you can consider"
        },
        {
            "location": "/Subjects/NP1/paperProject/#deadline",
            "text": "Originally 8th April.",
            "title": "Deadline"
        },
        {
            "location": "/Subjects/NP1/paperProject/#delivering-the-project",
            "text": "Once finished, please send me an email (to tenllado@ucm.es)",
            "title": "Delivering the project"
        },
        {
            "location": "/Subjects/NP1/P1/",
            "text": "Lab 1. Introduction to the ESP-IDF development environment\n\n\nESP-IDF (\nEspressif IoT Development Framework\n) is the official development\nenvironment from Espressif for ESP32 and ESP32-S SoCs. It allows to develop\n\nefficient\n firmwares for said boards using the WiFi and Bluetooth communication\ninterfaces, as well how to manage multiple characteristics of the SoCs that we\nwill be covering in future practices.\n\n\nESP-IDF uses \nFreeRTOS\n as RTOS for the construction of\nthe \nfirmware\n, although it adds a multitude of components to offer support for\nhigher level interaction with communication protocols, both low and high level,\nmost of them in the field of the Internet of Things.\n\n\nThis lab assignment is intended to be a basic introduction to setting up\nrunning the ESP-IDF development environment on a Linux operating system,\noffering two basic alternatives: command line and a specific plugin\nfor VSCode (PlatformIO). In addition, we will see in a superficial way the\nbasic structure of a simple program developed using ESP-IDF, as well as examples\nbasic for the start-up of the WiFi interface on an ESP32 board.\n\n\nWork flow. Commnad line toolset\n\n\nInstallation of prerequisites\n\n\nESP-IDF requires certain software packages installed on the system in order to\ndevelop the codes and download them onto the ESP32. Below we show the\nrequirements and installation process for Ubuntu/Debian based machines (like the\nvirtual machine used for this course), although the ESP-IDF documentation\nincludes instructions for other distributions and operating systems, including\nWindows and MacOS.\n\n\nIn your virtual machine, install the necessary packages using (like\nSuper user):\n\n\nsudo apt install git wget flex bison gperf python python3-pip python-setuptools cmake ninja-build ccache libffi-dev libssl-dev dfu-util\n\n\n\n\nIn addition, it is necessary for the user to belong to the \ndialout\n group (you\ncan edit the \n/etc/group\n file by adding your user to the line that indicates\nthe corresponding group, and starting again your session). Alternativelly you\ncan use the \nadduser\n command.\n\n\nCheck the version of python that your system is using:\n\n\npython --version\n\n\n\n\nIf it is not a version 3 but a version 2, you should install python3 on your\nsystem and make it the default python. In modern debian based distros python3 is\nalready de default and you can install the \npython-is-python3\n package to have a\nsymbolic link called python pointing to python3.\n\n\nsudo apt install python-is-python3\n\n\n\n\nObtaining ESP-IDF\n\n\nWe will use the versions of ESP-IDF obtained directly from the\nofficial Github repository. For it, run from your home directory:\n\n\nmkdir -p ~/esp\ncd ~/esp\ngit clone --recursive https://github.com/espressif/esp-idf.git\ncd esp-idf\ngit submodule update --init --recursive\n\n\n\n\nInstallation of additional tools\n\n\nFrom the \nesp-idf\n directory, run the \ninstall.sh\n script to install\nthe tools (\ntoolchain\n) specific to your version:\n\n\nsh install.sh\n\n\n\n\nEnvironment preparation\n\n\nAfter the start of each session, you will need to set correct values for certain\nenvironment variables. Fortunately a script is provided (\nexport.sh\n)\nwhich will allow you to set them automatically:\n\n\n. export.sh\n\n\n\n\nYou can add this line to any login file so you don't have I run the command\nevery time (for instance to your $HOME/.bashrc).\n\n\nIn any case, at this point you should have access to a program called\n\nidf.py\n, that will be used to manage the workflow. Check it out.\n\n\nProject preparation\n\n\nIn this first part, we will use a simple code example. The goal is not to\nanalyze in detail the the structure of that code (at least not for now), but to\nuse it to illustrate the typical workflow in an ESP-IDF project.\n\n\n\n\nRemember\n\n\nAfter executing the \nexport.sh\n script, you will have an environment\nvariable defined named \nIDF_PATH\n. Check its value and check that it points,\neffectively, to the IDF installation directory. We will use it at from now\non to refer to it.\n\n\n\n\nTo get started, take the \nhello_world\n example provided as part of the\ninstallation IDF basic, and copy it to any directory on the filesystem:\n\n\ncp -R $IDF_PATH/examples/get-started/hello_world $HOME/\ncd $HOME/hello_world\n\n\n\n\nBuild\n\n\nThe basic build process uses the \nidf.py\n script:\n\n\nidf.py build\n\n\n\n\nIf everything went well, the object files will have been generated and stored in\nthe \nbuild\n directory, and the binaries will be ready to be \nflashed\n on the\nESP32.\n\n\nFlash\n\n\nConnect the ESP32 using the microUSB cable, and if you are working in a virtual\nmachine, you have to make it visible to the hosted OS (for example, in\nVirtualBox, through the menu \nDevices->USB->Silicon Labs USB to UART Bridge\nController\n).\n\n\nIn any case, the output of the \ndmesg\n command after connecting the device \nwill provide you with information about the PORT that you should use in the\nflash process and subsequent monitoring.\n\n\nThe basic flash process uses the \nidf.py\n script:\n\n\nidf.py -p flash PORT\n\n\n\n\nMonitoring\n\n\nIf everything went well, the monitoring process will allow you to observe the\noutput of the program that is running on the board. For this we use again the\n\nidf.py\n script:\n\n\nidf.py -p PORT monitor\n\n\n\n\n\n\nNote\n\n\nCheck that, you can indeed carry out the compilation process, flash and\nmonitoring the program on the ESP32 board. Remember that the \nEN\n button,\nright next to the microUSB connector, will force a resetting it.\n\n\n\n\nWork flow. PlatformIO and vscode IDE\n\n\nThe above workflow can also be developed from other development environments.\nIn our case, the main steps are shown below for ESP-IDF integration with VSCode,\nusing \nPlatformIO\n. The virtual machines provided in the\ncourse already have the latest version of PlatformIO and ESP-IDF installed, so\nwe refer the reader to the official PlatformIO documentation to perform such\ninstallation on other operating systems.\n\n\nSetting up a project\n\n\nThe easiest way to create a new project is to press the button\n\nPlatformIO Home\n located at the bottom of the screen:\n\n\n\n\nNext, click on \nNew Project\n and select as development board\n\nESP DevkitC\n or \nEspressif ESP32 Dev Module\n. Select \nESP-IDF\n\nas a development \nframework\n for the project:\n\n\n\n\nAdding files to a project\n\n\nCreate a new \nmain.c\n file in the\nsrc\n directory of your project, or modify the\none that already exists using, for example, the following code:\n\n\n#include <string.h>\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_system.h\"\n#include \"esp_wifi.h\"\n#include \"esp_event.h\"\n#include \"esp_log.h\"\n#include \"nvs_flash.h\"\n\n#include \"lwip/err.h\"\n#include \"lwip/sys.h\"\n\n#define EXAMPLE_ESP_WIFI_SSID      \"mywifissid\"\n#define EXAMPLE_ESP_WIFI_PASS      \"mywifipass\"\n#define EXAMPLE_MAX_STA_CONN       (3)\n\nstatic const char *TAG = \"wifi softAP\";\n\nstatic void wifi_event_handler(void* arg, esp_event_base_t event_base,\n                                    int32_t event_id, void* event_data)\n{\n    if (event_id == WIFI_EVENT_AP_STACONNECTED) {\n        wifi_event_ap_staconnected_t* event = (wifi_event_ap_staconnected_t*) event_data;\n        ESP_LOGI(TAG, \"station \"MACSTR\" join, AID=%d\",\n                 MAC2STR(event->mac), event->aid);\n    } else if (event_id == WIFI_EVENT_AP_STADISCONNECTED) {\n        wifi_event_ap_stadisconnected_t* event = (wifi_event_ap_stadisconnected_t*) event_data;\n        ESP_LOGI(TAG, \"station \"MACSTR\" leave, AID=%d\",\n                 MAC2STR(event->mac), event->aid);\n    }\n}\n\nvoid wifi_init_softap()\n{\n    tcpip_adapter_init();\n    ESP_ERROR_CHECK(esp_event_loop_create_default());\n\n    wifi_init_config_t cfg = WIFI_INIT_CONFIG_DEFAULT();\n    ESP_ERROR_CHECK(esp_wifi_init(&cfg));\n\n    ESP_ERROR_CHECK(esp_event_handler_register(WIFI_EVENT, ESP_EVENT_ANY_ID, &wifi_event_handler, NULL));\n\n    wifi_config_t wifi_config = {\n        .ap = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .ssid_len = strlen(EXAMPLE_ESP_WIFI_SSID),\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .max_connection = EXAMPLE_MAX_STA_CONN,\n            .authmode = WIFI_AUTH_WPA_WPA2_PSK\n        },\n    };\n    if (strlen(EXAMPLE_ESP_WIFI_PASS) == 0) {\n        wifi_config.ap.authmode = WIFI_AUTH_OPEN;\n    }\n\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_AP));\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_AP, &wifi_config));\n    ESP_ERROR_CHECK(esp_wifi_start());\n\n    ESP_LOGI(TAG, \"wifi_init_softap finished. SSID:%s password:%s\",\n             EXAMPLE_ESP_WIFI_SSID, EXAMPLE_ESP_WIFI_PASS);\n}\n\nvoid app_main()\n{\n    //Initialize NVS\n    esp_err_t ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {\n      ESP_ERROR_CHECK(nvs_flash_erase());\n      ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK(ret);\n\n    ESP_LOGI(TAG, \"ESP_WIFI_MODE_AP\");\n    wifi_init_softap();\n}\n\n\n\n\nWe will not analyze for the moment the operation of the code (we will do that\nlater), it basically it establishes a wireless Access Point open to connections\nauthenticated via WPA2.\n\n\nProject Build\n\n\nTo build the project, display the Command Palette (menu \nView->Command Palette\n)\nand run the \nPlatformIO: Build\n command from it. You can also press the \nBuild\n\nbutton (in the form of \ncheck\n) in the bottom bar of PlatformIO:\n\n\n\n\nIf all went well, you should see a final message similar to the following in the\nsystem terminal:\n\n\n\n\nProject flashing\n\n\nTo upload the project to the board, we can use the command \nPlatformIO: Upload\n\nthrough the command palette, or press the corresponding button on the bottom bar\n(with a symbol left arrow):\n\n\n\n\nProject monitoring\n\n\nFinally, we can monitor the project using the command \nPlatformIO: Monitor\n\nfrom the command palette or through the bottom bar, using the button with\na plug as a symbol:\n\n\n\n\nAnalysis of a simple project (\nHello world\n) in ESP-IDF\n\n\n\n\nNote\n\n\nThe following tasks can be performed from the command line or by using\nPlatformIO. We nevertheless suggest you to use the lower level command line\ntoolset to become familiar with it.\n\n\n\n\nLook at the general structure of the \nhello_world\n directory that you compiled\npreviously. Specifically, we will be interested in inspecting the basic\nstructure of a main program for ESP-IDF, in this case \nhello_world_main.c\n.\n\n\n#include <stdio.h>\n#include \"sdkconfig.h\"\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_system.h\"\n#include \"esp_spi_flash.h\"\n\nvoid app_main(void)\n{\n    printf(\"Hello world!\\n\");\n\n    /* Print chip information */\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n    printf(\"This is %s chip with %d CPU cores, WiFi%s%s, \",\n            CONFIG_IDF_TARGET,\n            chip_info.cores,\n            (chip_info.features & CHIP_FEATURE_BT) ? \"/BT\" : \"\",\n            (chip_info.features & CHIP_FEATURE_BLE) ? \"/BLE\" : \"\");\n\n    printf(\"silicon revision %d, \", chip_info.revision);\n\n    printf(\"%dMB %s flash\\n\", spi_flash_get_chip_size() / (1024 * 1024),\n            (chip_info.features & CHIP_FEATURE_EMB_FLASH) ? \"embedded\" : \"external\");\n\n    printf(\"Minimum free heap size: %d bytes\\n\", esp_get_minimum_free_heap_size());\n\n    for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n    }\n    printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();\n}\n\n\n\n\nAt a high level, the \napp_main\n function is the entry point to every program\ndeveloped using ESP-IDF. More specifically, after the\n\nsystem load\n,\nthe so called \nmain task\n runs the code provided by the user and implemented in\nthe \napp_main\n function. Both the amount of its stack and its priority can be\nconfigured by the developer through the ESP-IDF configuration system (as we will\nsee later). Typically this function is used to carry out initial configuration\ntasks or to create and launch other tasks. Anyhow, as in this case, any\nfunctionality can be implemented inside the \napp_main\n function.\n\n\nIn this example, some generic information about the SoC that is running the\n\nfirmware\n is shown in first place:\n\n\n/* Print chip information */\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n    printf(\"This is %s chip with %d CPU cores, WiFi%s%s, \",\n            CONFIG_IDF_TARGET,\n            chip_info.cores,\n            (chip_info.features & CHIP_FEATURE_BT) ? \"/BT\" : \"\",\n            (chip_info.features & CHIP_FEATURE_BLE) ? \"/BLE\" : \"\");\n\n    printf(\"silicon revision %d, \", chip_info.revision);\n\n    printf(\"%dMB %s flash\\n\", spi_flash_get_chip_size() / (1024 * 1024),\n            (chip_info.features & CHIP_FEATURE_EMB_FLASH) ? \"embedded\" : \"external\");\n\n    printf(\"Minimum free heap size: %d bytes\\n\", esp_get_minimum_free_heap_size());\n\n\n\n\nThen, within a simple loop, the system displays a message and defers the\nexecution of the task for a specified period of time using the\n\nvTaskDelay\n function from FreeRTOS. This\nfunction receives the number of \nclock ticks\n you want to delay. The example\nuses the constant \nportTIC_PERIOD_MS\n to compute the number of ticks for 1000\nms:\n\n\n    for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n    }\n\n\n\n\nFinally, the task reboots the system after the completion of the main task:\n\n\n    printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();\n\n\n\n\n\n\nTask 1.1\n\n\nModify the suspension period of the task so that it is larger or smaller,\nand check that this effectively modifies the behavior of the\nloaded \nfirmware\n. Modify the program so that it is also showd on the\nscreen wether the SoC has WiFi capabilities and includes FLASH memory (you\ncan refer to\n\nthe following page\n).\n\n\n\n\nTask creation\n\n\nThe previous project can be redesigned to create an additiona task to execute\nthe logic of the program instead of having the main FreeRTOS task executing it.\nTo do this, we need to briefly introduce the basic FreeRTOS API for task\nmanagement.\n\n\nThe \nxTaskCreate\n function (included in\ntask.h\n) creates a new task:\n\n\n BaseType_t xTaskCreate( TaskFunction_t pvTaskCode,\n                         const char * const pcName,\n                         configSTACK_DEPTH_TYPE usStackDepth,\n                         void *pvParameters,\n                         UBaseType_t uxPriority,\n                         TaskHandle_t *pxCreatedTask\n                        );\n\n\n\n\nSpecifically, it creates a new task and adds it to the list of ready to run\ntasks, receiving as parameters:\n\n\n\n\npvTaskCode\n: a pointer to the input function for the task. Tasks are usually\n  implemented as an infinite loop, and should not return or end abruptly. A task\n  can be externally destroyed via its handler (last parameter in the creation),\n  or internally (from the task code itself), as as shown in the following\n  example taken directly from the FreeRTOS documentation:\n\n\n\n\n void vATaskFunction( void *pvParameters )\n    {\n        for( ;; )\n        {\n            -- Task application code here. --\n        }\n\n        /* Tasks must not attempt to return from their implementing\n        function or otherwise exit.  In newer FreeRTOS port\n        attempting to do so will result in an configASSERT() being\n        called if it is defined.  If it is necessary for a task to\n        exit then have the task call vTaskDelete( NULL ) to ensure\n        its exit is clean. */\n        vTaskDelete( NULL );\n    }\n\n\n\n\n\n\n\n\npcName\n: Descriptive name (in string form) of the task to be executed,\n    helpfull for debugging purposes.\n\n\n\n\n\n\nusStackDepth\n: size in words of the stack for the task.\n\n\n\n\n\n\npvParameters\n: parameters to the entry function of the task.\n\n\n\n\n\n\nuxPriority\n: priority assigned to the task.\n\n\n\n\n\n\npxCreatedTask\n: optional handle for the task.\n\n\n\n\n\n\nThus, the functionality of the \nHello, world\n program that we analyzed above\ncould be restructured using a single task:\n\n\nvoid hello_task(void *pvParameter)\n{\n    printf(\"Hello world!\\n\");\n    for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_RATE_MS);\n    }\n    printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();\n}\n\n\n\n\nAnd the task could be created from the main task:\n\n\nvoid app_main()\n{\n    nvs_flash_init();\n    xTaskCreate( &hello_task, \"hello_task\", 2048, NULL, 5, NULL );\n}\n\n\n\n\n\n\nTask 1.2\n\n\nImplement a modification of the \nhello_world\n program that uses two\nindependent tasks with different functionality (in this case it is\nenough to only show a different messaga on the screen) and different\nsuspension times. Check that, indeed, both tasks are run concurrently.\n\n\n\n\nProject customization\n\n\nESP-IDF uses the \nkconfiglib\n library to provide a system of Simple and\nextensible compile-time project setup. To illustrate its operation, we will\nuse the \nblink\n example, that can be found in the ESP-IDF distribution that you\ncloned earlier (copy the example to any point in your directory hierarchy before\nyou begin).\n\n\nTo configure the ESP-IDF project, simply use the following command:\n\n\nidf.py menuconfig\n\n\n\n\nExecuting the above command will allow you to browse a set of general options,\nwhich will allow you to configure the characteristics specific to the project\n(for example, selecting the components that you want to enable in its build).\n\n\n\n\nTask\n\n\nNavigate through the options that appear in the setup menus to\nfamiliarize yourself with them. You will use them in future practices.\n\n\n\n\nIn the \nblink\n project, notice that one of the menu options,\ncalled \nExample configuration\n, includes an option called \nBlink GPIO number\n.\nBeyond its functionality (it defines the number of GPIO pin to enable/disable),\nit is of interest to us that this configuration option will define at compile\ntime the value of a constant (a C preprocessor macro, in this case\n\nCONFIG_BLINK_GPIO\n) that can be used in any file of our project.\n\n\n\n\nNote\n\n\nObserve how the \nCONFIG_BLINK_GPIO\n constant is used in the code of the\n\nblink\n project.\n\n\n\n\nThis configuration option is not part of the default options of ESP-IDF, but has\nbeen added by the developers of the \nblink\n project.  Observe and study the\nformat and content of the file \nmain/Kconfig.projbuild\n, provided as part of the\nproject. It defines the characteristics (name, range, default value and\ndescription) of the new configuration option.\n\n\n\n\nTask 1.3\n\n\nModify the \nhello_world\n project so that it defines two configuration\noptions, that will allow to specify the wait time for each of the two tasks\nthat you have defined in your previous solution (Task 1.2). Make use of them\nin your code and verify that indeed its modification through the menu\nsystem allows a customization of the behavior of your codes.\n\n\n\n\nManagement of WiFi networks. Example 1. WiFi network scanning\n\n\nAs an example, and in preparation for the codes with which we will work in\nfuture lab assignments, we are going to analyze a concrete example of a\n\nfirmware\n that scans the available wireless networks within the reach of the\nESP32 node, and reports them through the serial port (we will seem them printed\non the screen if we monitor the node). It will report their main characteristics\nfor each of the networks detected.\n\n\n\n\nTask 1.4\n\n\nCopy the  example located in the directory \nexamples/wifi/scan\n to other\ndirectory from your \nhome\n folder. Before compiling it, change the maximum\nnumber of networks to scan through in the example setup menu to 20. Create a\nWiFi access point with your smartphone. Compile the code, flash it and\nmonitor the output, and verify that your network is correctly scanned.\n\n\n\n\nObserve its operation. Actually, the \nfirmware\n just scans a subset of the\navailable networks, reporting some of their characteristics (for example, SSID,\nAuthentication Mode, or Primary Channel).\n\n\n\n\nTask 1.5\n\n\nAnalyze the code for the \nwifi_scan\n function (main task). Specifically,\nfocus on the lines that enable and configure scanning of\nnetworks. Try to understand the general operation of the program, consulting\nand pointing out the role of each line, with special interest to those\nfunctions prefixed with \nesp_wifi_ *\n. Write down in a text file\nthe role of each of them, consulting the \nofficial documentation\n.\n\n\n\n\nManagement of WiFi networks. Example 2. Network event management\n\n\nIn this second example you will create a \nfirmware\n that connects the ESP32 as a\nstation to an existing access point. This example will allow you to observe,\nbroadly speaking, the event management system in FreeRTOS/ESP-IDF, that we use\nto respond to the network events such as obtaining an IP address or successfully\nconnect to an access point.\n\n\n\n\nTask\n\n\nCopy the \nstation\n example located in the directory\n\nexamples/wifi/getting_started\n to another folder in your \nhome\n directory.\nBefore compiling it, modify the SSID of the network to which it will try to\nconnect, as well as the chosen password through the system setup menus (you\ncan use the same access point you created before with your smartphone).\n\n\n\n\nObserve its operation. The \nfirmware\n just initializes the device in \nstation\n\nmode (as opposed to the \nAccess Point\n mode), making a connection to the\npreconfigured access point through the setup menu.\n\n\nAnalyze the code for the \nwifi_init_sta\n function. This function, which\nimplements the main task, is basically divided into two parts:\n\n\n\n\n\n\nEvent management\n. Observe the mechanism by which the reception of an event\n  is associated with the execution of a specific handler function previously\n  registered.\n\n\n\n\n\n\nConfiguration of the connection to an access point\n. The connection\n  configuration is made through the corresponding fields of a \nwifi_config_t\n\n  structure. Look at the basic fields you need, how the use of WPA2 is enforced\n  and how it collects connection data (SSID and password) through the\n  configuration system. Observe also how the wireless communication system is\n  initialized by the \nesp_wifi_start()\n call.\n\n\n\n\n\n\n\n\nTask 1.6\n\n\nModify the \nfirmware\n so that it can use a different \nhandler\n for the event\nof acquiring an IP address and the rest of the events of the WiFi system\nthat are already being handled. Check that, the output associated with said\nevent continues to be observed, even when both functions are different.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P1/#lab-1-introduction-to-the-esp-idf-development-environment",
            "text": "ESP-IDF ( Espressif IoT Development Framework ) is the official development\nenvironment from Espressif for ESP32 and ESP32-S SoCs. It allows to develop efficient  firmwares for said boards using the WiFi and Bluetooth communication\ninterfaces, as well how to manage multiple characteristics of the SoCs that we\nwill be covering in future practices.  ESP-IDF uses  FreeRTOS  as RTOS for the construction of\nthe  firmware , although it adds a multitude of components to offer support for\nhigher level interaction with communication protocols, both low and high level,\nmost of them in the field of the Internet of Things.  This lab assignment is intended to be a basic introduction to setting up\nrunning the ESP-IDF development environment on a Linux operating system,\noffering two basic alternatives: command line and a specific plugin\nfor VSCode (PlatformIO). In addition, we will see in a superficial way the\nbasic structure of a simple program developed using ESP-IDF, as well as examples\nbasic for the start-up of the WiFi interface on an ESP32 board.",
            "title": "Lab 1. Introduction to the ESP-IDF development environment"
        },
        {
            "location": "/Subjects/NP1/P1/#work-flow-commnad-line-toolset",
            "text": "",
            "title": "Work flow. Commnad line toolset"
        },
        {
            "location": "/Subjects/NP1/P1/#installation-of-prerequisites",
            "text": "ESP-IDF requires certain software packages installed on the system in order to\ndevelop the codes and download them onto the ESP32. Below we show the\nrequirements and installation process for Ubuntu/Debian based machines (like the\nvirtual machine used for this course), although the ESP-IDF documentation\nincludes instructions for other distributions and operating systems, including\nWindows and MacOS.  In your virtual machine, install the necessary packages using (like\nSuper user):  sudo apt install git wget flex bison gperf python python3-pip python-setuptools cmake ninja-build ccache libffi-dev libssl-dev dfu-util  In addition, it is necessary for the user to belong to the  dialout  group (you\ncan edit the  /etc/group  file by adding your user to the line that indicates\nthe corresponding group, and starting again your session). Alternativelly you\ncan use the  adduser  command.  Check the version of python that your system is using:  python --version  If it is not a version 3 but a version 2, you should install python3 on your\nsystem and make it the default python. In modern debian based distros python3 is\nalready de default and you can install the  python-is-python3  package to have a\nsymbolic link called python pointing to python3.  sudo apt install python-is-python3",
            "title": "Installation of prerequisites"
        },
        {
            "location": "/Subjects/NP1/P1/#obtaining-esp-idf",
            "text": "We will use the versions of ESP-IDF obtained directly from the\nofficial Github repository. For it, run from your home directory:  mkdir -p ~/esp\ncd ~/esp\ngit clone --recursive https://github.com/espressif/esp-idf.git\ncd esp-idf\ngit submodule update --init --recursive",
            "title": "Obtaining ESP-IDF"
        },
        {
            "location": "/Subjects/NP1/P1/#installation-of-additional-tools",
            "text": "From the  esp-idf  directory, run the  install.sh  script to install\nthe tools ( toolchain ) specific to your version:  sh install.sh",
            "title": "Installation of additional tools"
        },
        {
            "location": "/Subjects/NP1/P1/#environment-preparation",
            "text": "After the start of each session, you will need to set correct values for certain\nenvironment variables. Fortunately a script is provided ( export.sh )\nwhich will allow you to set them automatically:  . export.sh  You can add this line to any login file so you don't have I run the command\nevery time (for instance to your $HOME/.bashrc).  In any case, at this point you should have access to a program called idf.py , that will be used to manage the workflow. Check it out.",
            "title": "Environment preparation"
        },
        {
            "location": "/Subjects/NP1/P1/#project-preparation",
            "text": "In this first part, we will use a simple code example. The goal is not to\nanalyze in detail the the structure of that code (at least not for now), but to\nuse it to illustrate the typical workflow in an ESP-IDF project.   Remember  After executing the  export.sh  script, you will have an environment\nvariable defined named  IDF_PATH . Check its value and check that it points,\neffectively, to the IDF installation directory. We will use it at from now\non to refer to it.   To get started, take the  hello_world  example provided as part of the\ninstallation IDF basic, and copy it to any directory on the filesystem:  cp -R $IDF_PATH/examples/get-started/hello_world $HOME/\ncd $HOME/hello_world",
            "title": "Project preparation"
        },
        {
            "location": "/Subjects/NP1/P1/#build",
            "text": "The basic build process uses the  idf.py  script:  idf.py build  If everything went well, the object files will have been generated and stored in\nthe  build  directory, and the binaries will be ready to be  flashed  on the\nESP32.",
            "title": "Build"
        },
        {
            "location": "/Subjects/NP1/P1/#flash",
            "text": "Connect the ESP32 using the microUSB cable, and if you are working in a virtual\nmachine, you have to make it visible to the hosted OS (for example, in\nVirtualBox, through the menu  Devices->USB->Silicon Labs USB to UART Bridge\nController ).  In any case, the output of the  dmesg  command after connecting the device \nwill provide you with information about the PORT that you should use in the\nflash process and subsequent monitoring.  The basic flash process uses the  idf.py  script:  idf.py -p flash PORT",
            "title": "Flash"
        },
        {
            "location": "/Subjects/NP1/P1/#monitoring",
            "text": "If everything went well, the monitoring process will allow you to observe the\noutput of the program that is running on the board. For this we use again the idf.py  script:  idf.py -p PORT monitor   Note  Check that, you can indeed carry out the compilation process, flash and\nmonitoring the program on the ESP32 board. Remember that the  EN  button,\nright next to the microUSB connector, will force a resetting it.",
            "title": "Monitoring"
        },
        {
            "location": "/Subjects/NP1/P1/#work-flow-platformio-and-vscode-ide",
            "text": "The above workflow can also be developed from other development environments.\nIn our case, the main steps are shown below for ESP-IDF integration with VSCode,\nusing  PlatformIO . The virtual machines provided in the\ncourse already have the latest version of PlatformIO and ESP-IDF installed, so\nwe refer the reader to the official PlatformIO documentation to perform such\ninstallation on other operating systems.",
            "title": "Work flow. PlatformIO and vscode IDE"
        },
        {
            "location": "/Subjects/NP1/P1/#setting-up-a-project",
            "text": "The easiest way to create a new project is to press the button PlatformIO Home  located at the bottom of the screen:   Next, click on  New Project  and select as development board ESP DevkitC  or  Espressif ESP32 Dev Module . Select  ESP-IDF \nas a development  framework  for the project:",
            "title": "Setting up a project"
        },
        {
            "location": "/Subjects/NP1/P1/#adding-files-to-a-project",
            "text": "Create a new  main.c  file in the src  directory of your project, or modify the\none that already exists using, for example, the following code:  #include <string.h>\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_system.h\"\n#include \"esp_wifi.h\"\n#include \"esp_event.h\"\n#include \"esp_log.h\"\n#include \"nvs_flash.h\"\n\n#include \"lwip/err.h\"\n#include \"lwip/sys.h\"\n\n#define EXAMPLE_ESP_WIFI_SSID      \"mywifissid\"\n#define EXAMPLE_ESP_WIFI_PASS      \"mywifipass\"\n#define EXAMPLE_MAX_STA_CONN       (3)\n\nstatic const char *TAG = \"wifi softAP\";\n\nstatic void wifi_event_handler(void* arg, esp_event_base_t event_base,\n                                    int32_t event_id, void* event_data)\n{\n    if (event_id == WIFI_EVENT_AP_STACONNECTED) {\n        wifi_event_ap_staconnected_t* event = (wifi_event_ap_staconnected_t*) event_data;\n        ESP_LOGI(TAG, \"station \"MACSTR\" join, AID=%d\",\n                 MAC2STR(event->mac), event->aid);\n    } else if (event_id == WIFI_EVENT_AP_STADISCONNECTED) {\n        wifi_event_ap_stadisconnected_t* event = (wifi_event_ap_stadisconnected_t*) event_data;\n        ESP_LOGI(TAG, \"station \"MACSTR\" leave, AID=%d\",\n                 MAC2STR(event->mac), event->aid);\n    }\n}\n\nvoid wifi_init_softap()\n{\n    tcpip_adapter_init();\n    ESP_ERROR_CHECK(esp_event_loop_create_default());\n\n    wifi_init_config_t cfg = WIFI_INIT_CONFIG_DEFAULT();\n    ESP_ERROR_CHECK(esp_wifi_init(&cfg));\n\n    ESP_ERROR_CHECK(esp_event_handler_register(WIFI_EVENT, ESP_EVENT_ANY_ID, &wifi_event_handler, NULL));\n\n    wifi_config_t wifi_config = {\n        .ap = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .ssid_len = strlen(EXAMPLE_ESP_WIFI_SSID),\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .max_connection = EXAMPLE_MAX_STA_CONN,\n            .authmode = WIFI_AUTH_WPA_WPA2_PSK\n        },\n    };\n    if (strlen(EXAMPLE_ESP_WIFI_PASS) == 0) {\n        wifi_config.ap.authmode = WIFI_AUTH_OPEN;\n    }\n\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_AP));\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_AP, &wifi_config));\n    ESP_ERROR_CHECK(esp_wifi_start());\n\n    ESP_LOGI(TAG, \"wifi_init_softap finished. SSID:%s password:%s\",\n             EXAMPLE_ESP_WIFI_SSID, EXAMPLE_ESP_WIFI_PASS);\n}\n\nvoid app_main()\n{\n    //Initialize NVS\n    esp_err_t ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {\n      ESP_ERROR_CHECK(nvs_flash_erase());\n      ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK(ret);\n\n    ESP_LOGI(TAG, \"ESP_WIFI_MODE_AP\");\n    wifi_init_softap();\n}  We will not analyze for the moment the operation of the code (we will do that\nlater), it basically it establishes a wireless Access Point open to connections\nauthenticated via WPA2.",
            "title": "Adding files to a project"
        },
        {
            "location": "/Subjects/NP1/P1/#project-build",
            "text": "To build the project, display the Command Palette (menu  View->Command Palette )\nand run the  PlatformIO: Build  command from it. You can also press the  Build \nbutton (in the form of  check ) in the bottom bar of PlatformIO:   If all went well, you should see a final message similar to the following in the\nsystem terminal:",
            "title": "Project Build"
        },
        {
            "location": "/Subjects/NP1/P1/#project-flashing",
            "text": "To upload the project to the board, we can use the command  PlatformIO: Upload \nthrough the command palette, or press the corresponding button on the bottom bar\n(with a symbol left arrow):",
            "title": "Project flashing"
        },
        {
            "location": "/Subjects/NP1/P1/#project-monitoring",
            "text": "Finally, we can monitor the project using the command  PlatformIO: Monitor \nfrom the command palette or through the bottom bar, using the button with\na plug as a symbol:",
            "title": "Project monitoring"
        },
        {
            "location": "/Subjects/NP1/P1/#analysis-of-a-simple-project-hello-world-in-esp-idf",
            "text": "Note  The following tasks can be performed from the command line or by using\nPlatformIO. We nevertheless suggest you to use the lower level command line\ntoolset to become familiar with it.   Look at the general structure of the  hello_world  directory that you compiled\npreviously. Specifically, we will be interested in inspecting the basic\nstructure of a main program for ESP-IDF, in this case  hello_world_main.c .  #include <stdio.h>\n#include \"sdkconfig.h\"\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"esp_system.h\"\n#include \"esp_spi_flash.h\"\n\nvoid app_main(void)\n{\n    printf(\"Hello world!\\n\");\n\n    /* Print chip information */\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n    printf(\"This is %s chip with %d CPU cores, WiFi%s%s, \",\n            CONFIG_IDF_TARGET,\n            chip_info.cores,\n            (chip_info.features & CHIP_FEATURE_BT) ? \"/BT\" : \"\",\n            (chip_info.features & CHIP_FEATURE_BLE) ? \"/BLE\" : \"\");\n\n    printf(\"silicon revision %d, \", chip_info.revision);\n\n    printf(\"%dMB %s flash\\n\", spi_flash_get_chip_size() / (1024 * 1024),\n            (chip_info.features & CHIP_FEATURE_EMB_FLASH) ? \"embedded\" : \"external\");\n\n    printf(\"Minimum free heap size: %d bytes\\n\", esp_get_minimum_free_heap_size());\n\n    for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n    }\n    printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();\n}  At a high level, the  app_main  function is the entry point to every program\ndeveloped using ESP-IDF. More specifically, after the system load ,\nthe so called  main task  runs the code provided by the user and implemented in\nthe  app_main  function. Both the amount of its stack and its priority can be\nconfigured by the developer through the ESP-IDF configuration system (as we will\nsee later). Typically this function is used to carry out initial configuration\ntasks or to create and launch other tasks. Anyhow, as in this case, any\nfunctionality can be implemented inside the  app_main  function.  In this example, some generic information about the SoC that is running the firmware  is shown in first place:  /* Print chip information */\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n    printf(\"This is %s chip with %d CPU cores, WiFi%s%s, \",\n            CONFIG_IDF_TARGET,\n            chip_info.cores,\n            (chip_info.features & CHIP_FEATURE_BT) ? \"/BT\" : \"\",\n            (chip_info.features & CHIP_FEATURE_BLE) ? \"/BLE\" : \"\");\n\n    printf(\"silicon revision %d, \", chip_info.revision);\n\n    printf(\"%dMB %s flash\\n\", spi_flash_get_chip_size() / (1024 * 1024),\n            (chip_info.features & CHIP_FEATURE_EMB_FLASH) ? \"embedded\" : \"external\");\n\n    printf(\"Minimum free heap size: %d bytes\\n\", esp_get_minimum_free_heap_size());  Then, within a simple loop, the system displays a message and defers the\nexecution of the task for a specified period of time using the vTaskDelay  function from FreeRTOS. This\nfunction receives the number of  clock ticks  you want to delay. The example\nuses the constant  portTIC_PERIOD_MS  to compute the number of ticks for 1000\nms:      for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\n    }  Finally, the task reboots the system after the completion of the main task:      printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();   Task 1.1  Modify the suspension period of the task so that it is larger or smaller,\nand check that this effectively modifies the behavior of the\nloaded  firmware . Modify the program so that it is also showd on the\nscreen wether the SoC has WiFi capabilities and includes FLASH memory (you\ncan refer to the following page ).",
            "title": "Analysis of a simple project (Hello world) in ESP-IDF"
        },
        {
            "location": "/Subjects/NP1/P1/#task-creation",
            "text": "The previous project can be redesigned to create an additiona task to execute\nthe logic of the program instead of having the main FreeRTOS task executing it.\nTo do this, we need to briefly introduce the basic FreeRTOS API for task\nmanagement.  The  xTaskCreate  function (included in task.h ) creates a new task:   BaseType_t xTaskCreate( TaskFunction_t pvTaskCode,\n                         const char * const pcName,\n                         configSTACK_DEPTH_TYPE usStackDepth,\n                         void *pvParameters,\n                         UBaseType_t uxPriority,\n                         TaskHandle_t *pxCreatedTask\n                        );  Specifically, it creates a new task and adds it to the list of ready to run\ntasks, receiving as parameters:   pvTaskCode : a pointer to the input function for the task. Tasks are usually\n  implemented as an infinite loop, and should not return or end abruptly. A task\n  can be externally destroyed via its handler (last parameter in the creation),\n  or internally (from the task code itself), as as shown in the following\n  example taken directly from the FreeRTOS documentation:    void vATaskFunction( void *pvParameters )\n    {\n        for( ;; )\n        {\n            -- Task application code here. --\n        }\n\n        /* Tasks must not attempt to return from their implementing\n        function or otherwise exit.  In newer FreeRTOS port\n        attempting to do so will result in an configASSERT() being\n        called if it is defined.  If it is necessary for a task to\n        exit then have the task call vTaskDelete( NULL ) to ensure\n        its exit is clean. */\n        vTaskDelete( NULL );\n    }    pcName : Descriptive name (in string form) of the task to be executed,\n    helpfull for debugging purposes.    usStackDepth : size in words of the stack for the task.    pvParameters : parameters to the entry function of the task.    uxPriority : priority assigned to the task.    pxCreatedTask : optional handle for the task.    Thus, the functionality of the  Hello, world  program that we analyzed above\ncould be restructured using a single task:  void hello_task(void *pvParameter)\n{\n    printf(\"Hello world!\\n\");\n    for (int i = 10; i >= 0; i--) {\n        printf(\"Restarting in %d seconds...\\n\", i);\n        vTaskDelay(1000 / portTICK_RATE_MS);\n    }\n    printf(\"Restarting now.\\n\");\n    fflush(stdout);\n    esp_restart();\n}  And the task could be created from the main task:  void app_main()\n{\n    nvs_flash_init();\n    xTaskCreate( &hello_task, \"hello_task\", 2048, NULL, 5, NULL );\n}   Task 1.2  Implement a modification of the  hello_world  program that uses two\nindependent tasks with different functionality (in this case it is\nenough to only show a different messaga on the screen) and different\nsuspension times. Check that, indeed, both tasks are run concurrently.",
            "title": "Task creation"
        },
        {
            "location": "/Subjects/NP1/P1/#project-customization",
            "text": "ESP-IDF uses the  kconfiglib  library to provide a system of Simple and\nextensible compile-time project setup. To illustrate its operation, we will\nuse the  blink  example, that can be found in the ESP-IDF distribution that you\ncloned earlier (copy the example to any point in your directory hierarchy before\nyou begin).  To configure the ESP-IDF project, simply use the following command:  idf.py menuconfig  Executing the above command will allow you to browse a set of general options,\nwhich will allow you to configure the characteristics specific to the project\n(for example, selecting the components that you want to enable in its build).   Task  Navigate through the options that appear in the setup menus to\nfamiliarize yourself with them. You will use them in future practices.   In the  blink  project, notice that one of the menu options,\ncalled  Example configuration , includes an option called  Blink GPIO number .\nBeyond its functionality (it defines the number of GPIO pin to enable/disable),\nit is of interest to us that this configuration option will define at compile\ntime the value of a constant (a C preprocessor macro, in this case CONFIG_BLINK_GPIO ) that can be used in any file of our project.   Note  Observe how the  CONFIG_BLINK_GPIO  constant is used in the code of the blink  project.   This configuration option is not part of the default options of ESP-IDF, but has\nbeen added by the developers of the  blink  project.  Observe and study the\nformat and content of the file  main/Kconfig.projbuild , provided as part of the\nproject. It defines the characteristics (name, range, default value and\ndescription) of the new configuration option.   Task 1.3  Modify the  hello_world  project so that it defines two configuration\noptions, that will allow to specify the wait time for each of the two tasks\nthat you have defined in your previous solution (Task 1.2). Make use of them\nin your code and verify that indeed its modification through the menu\nsystem allows a customization of the behavior of your codes.",
            "title": "Project customization"
        },
        {
            "location": "/Subjects/NP1/P1/#management-of-wifi-networks-example-1-wifi-network-scanning",
            "text": "As an example, and in preparation for the codes with which we will work in\nfuture lab assignments, we are going to analyze a concrete example of a firmware  that scans the available wireless networks within the reach of the\nESP32 node, and reports them through the serial port (we will seem them printed\non the screen if we monitor the node). It will report their main characteristics\nfor each of the networks detected.   Task 1.4  Copy the  example located in the directory  examples/wifi/scan  to other\ndirectory from your  home  folder. Before compiling it, change the maximum\nnumber of networks to scan through in the example setup menu to 20. Create a\nWiFi access point with your smartphone. Compile the code, flash it and\nmonitor the output, and verify that your network is correctly scanned.   Observe its operation. Actually, the  firmware  just scans a subset of the\navailable networks, reporting some of their characteristics (for example, SSID,\nAuthentication Mode, or Primary Channel).   Task 1.5  Analyze the code for the  wifi_scan  function (main task). Specifically,\nfocus on the lines that enable and configure scanning of\nnetworks. Try to understand the general operation of the program, consulting\nand pointing out the role of each line, with special interest to those\nfunctions prefixed with  esp_wifi_ * . Write down in a text file\nthe role of each of them, consulting the  official documentation .",
            "title": "Management of WiFi networks. Example 1. WiFi network scanning"
        },
        {
            "location": "/Subjects/NP1/P1/#management-of-wifi-networks-example-2-network-event-management",
            "text": "In this second example you will create a  firmware  that connects the ESP32 as a\nstation to an existing access point. This example will allow you to observe,\nbroadly speaking, the event management system in FreeRTOS/ESP-IDF, that we use\nto respond to the network events such as obtaining an IP address or successfully\nconnect to an access point.   Task  Copy the  station  example located in the directory examples/wifi/getting_started  to another folder in your  home  directory.\nBefore compiling it, modify the SSID of the network to which it will try to\nconnect, as well as the chosen password through the system setup menus (you\ncan use the same access point you created before with your smartphone).   Observe its operation. The  firmware  just initializes the device in  station \nmode (as opposed to the  Access Point  mode), making a connection to the\npreconfigured access point through the setup menu.  Analyze the code for the  wifi_init_sta  function. This function, which\nimplements the main task, is basically divided into two parts:    Event management . Observe the mechanism by which the reception of an event\n  is associated with the execution of a specific handler function previously\n  registered.    Configuration of the connection to an access point . The connection\n  configuration is made through the corresponding fields of a  wifi_config_t \n  structure. Look at the basic fields you need, how the use of WPA2 is enforced\n  and how it collects connection data (SSID and password) through the\n  configuration system. Observe also how the wireless communication system is\n  initialized by the  esp_wifi_start()  call.     Task 1.6  Modify the  firmware  so that it can use a different  handler  for the event\nof acquiring an IP address and the rest of the events of the WiFi system\nthat are already being handled. Check that, the output associated with said\nevent continues to be observed, even when both functions are different.",
            "title": "Management of WiFi networks. Example 2. Network event management"
        },
        {
            "location": "/Subjects/NP1/P2/",
            "text": "Lab 2. WiFi in ESP32\n\n\nGoals\n\n\n\n\nFamiliarize yourself with the workflow of the WiFi driver in ESP-IDF.\n\n\nUnderstand the difference between \nstation\n and \nAP\n modes.\n\n\nDevelop \nfirmware\n that can work as AP for others and as \nstation\n to connect\n  to another AP.\n\n\nUnderstand the network scanning mechanisms in ESP-IDF.\n\n\n\n\nIntroduction\n\n\nThe ESP-IDF WiFi libraries and components provide support to configure and\nmonitor 802.11 connections on ESP32 boards. This includes settings for:\n\n\n\n\n\n\nStation\n mode (WiFi client mode, or \nSTA\n).\n  In this case, the ESP32 connects to a preconfigured access point.\n\n\n\n\n\n\nAP\n mode (also called \nsoftAP\n or \nAccess Point\n mode). In this case, other\n  stations can connect to the ESP32.\n\n\n\n\n\n\nAP-STA combined mode, where ESP32 is concurrently acting as an access point\n  and a station connected to another access point.\n\n\n\n\n\n\nVarious security modes in both client mode and AP mode (WPA, WPA2, WEP, etc.)\n\n\n\n\n\n\nAccess point scanning (active and passive).\n\n\n\n\n\n\nKey provisioning and WPS mode.\n\n\n\n\n\n\nPromiscuous mode for IEEE 802.11 packet monitoring.\n\n\n\n\n\n\nIn the present lab we will study through basic examples the main features\nsupported by the WiFi driver. All these characteristics can be used later for\nthe development of codes and more complex projects with minimal modifications.\n\n\nESP32 Wi-Fi Programming Model\n\n\nThe ESP32 Wi-Fi programming model can be described with the following figure:\n\n\n\n\nThe Wi-Fi driver can be considered a black box that knows nothing about\nhigh-layer code, such as the TCP/IP stack, application task, event task, etc.\nThe application task (code) generally calls Wi-Fi driver APIs to initialize\nWi-Fi and handles Wi-Fi events when necessary. Wi-Fi driver receives API calls,\nhandles them, and post events to the application.\n\n\nWi-Fi event handling is based on the \nesp_event\nlibrary\n.\nEvents are sent by the Wi-Fi driver to the \ndefault event\nloop\n.\nApplication may handle these events in \ncallbacks\n registered using\n\nesp_event_handler_register()\n. Wi-Fi events are also handled by esp_netif\ncomponent to provide a set of default behaviors. For example, when Wi-Fi station\nconnects to an AP, esp_netif will automatically start the DHCP client by default\n(even though this Default behavior can be customized to, for example, assign an\nIP address statically).\n\n\n\n\nNote\n\n\nAll the API mentioned below is described in depth in\nthis \nlink\n. It is advisable to have this information during the process\nas well as in this lab document.\n\n\n\n\nWiFi events\n\n\nThe following list shows the description of the wifi events that are handled in\nthe example codes we work through in this lab assignment.\n\n\n\n\n\n\nWIFI_EVENT_SCAN_DONE\n\n\nThe scan-done event is triggered by \nesp_wifi_scan_start()\n and will arise\nin the following scenarios:\n- The scan is completed, e.g., the target AP is found successfully, or all\n  channels have been scanned.\n- The scan is stopped by \nesp_wifi_scan_stop()\n.\n- The \nesp_wifi_scan_start()\n is called before the scan is completed. A new\n  scan will override the current scan and a scan-done event will be\n  generated.\n\n\nThe scan-done event will not arise in the following scenarios:\n- It is a blocked scan.\n- The scan is caused by \nesp_wifi_connect()\n.\n\n\nUpon receiving this event, the event task does nothing. The application\nevent callback needs to call \nesp_wifi_scan_get_ap_num()\n and\n\nesp_wifi_scan_get_ap_records()\n to fetch the scanned AP list and trigger\nthe Wi-Fi driver to free the internal memory which is allocated during the\nscan (do not forget to do this!). Refer to ESP32 Wi-Fi Scan for a more\ndetailed description.\n\n\n\n\n\n\nWIFI_EVENT_STA_START\n\n\nIf \nesp_wifi_start()\n returns ESP_OK and the current Wi-Fi mode is station\nor station/AP, then this event will arise. Upon receiving this event, the\nevent task will initialize the LwIP network interface (netif). Generally,\nthe application event callback needs to call \nesp_wifi_connect()\n to connect\nto the configured AP.\n\n\n\n\n\n\nWIFI_EVENT_STA_STOP\n\n\nIf \nesp_wifi_stop()\n returns ESP_OK and the current Wi-Fi mode is station or\nstation/AP, then this event will arise. Upon receiving this event, the event\ntask will release the station\u2019s IP address, stop the DHCP client, remove\nTCP/UDP-related connections and clear the LwIP station netif, etc. The\napplication event callback generally does not need to do anything.\n\n\n\n\n\n\nWIFI_EVENT_STA_CONNECTED\n\n\nIf \nesp_wifi_connect()\n returns ESP_OK and the station successfully connects\nto the target AP, the connection event will arise. Upon receiving this\nevent, the event task starts the DHCP client and begins the DHCP process of\ngetting the IP address. Then, the Wi-Fi driver is ready for sending and\nreceiving data.\n\n\nThis moment is good for beginning the application work, provided that the\napplication does not depend on LwIP, namely the IP address. However, if the\napplication is LwIP-based, then you need to wait until the got ip event\n\nWIFI_EVENT_STA_GOT_IP\n comes in.\n\n\n\n\n\n\nWIFI_EVENT_STA_DISCONNECTED\n\n\nThis event can be generated in the following scenarios:\n\n\n\n\n\n\nWhen \nesp_wifi_disconnect()\n, or \nesp_wifi_stop()\n is called and the\n  station is already connected to the AP.\n\n\n\n\n\n\nWhen \nesp_wifi_connect()\n is called, but the Wi-Fi driver fails to set up\n  a connection with the AP due to certain reasons, e.g. the scan fails to\n  find the target AP, authentication times out, etc. If there are more\n  than one AP with the same SSID, the disconnected event is raised after\n  the station fails to connect all of the found APs.\n\n\n\n\n\n\nWhen the Wi-Fi connection is disrupted because of specific reasons,\n  e.g., the station continuously loses N beacons, the AP kicks off the\n  station, the AP\u2019s authentication mode is changed, etc.\n\n\n\n\n\n\nUpon receiving this event, the default behavior of the event task is to:\n- Shut down the station\u2019s LwIP netif.\n\n\n\n\nNotify the LwIP task to clear the UDP/TCP connections which cause the\n  wrong status to all sockets. For socket-based applications, the\n  application callback can choose to close all sockets and re-create them,\n  if necessary, upon receiving this event.\n\n\n\n\nThe most common event handle code for this event in application is to call\n\nesp_wifi_connect()\n to reconnect the Wi-Fi. However, if the event is raised\nbecause \nesp_wifi_disconnect()\n is called, the application should not call\nesp_wifi_connect() to reconnect. It\u2019s application\u2019s responsibility to\ndistinguish whether the event is caused by \nesp_wifi_disconnect()\n or other\nreasons.\n\n\n\n\n\n\nIP_EVENT_STA_GOT_IP\n (was \nWIFI_EVENT_STA_GOT_IP\n)\n\n\nThis event arises when the DHCP client successfully gets the IPV4 address\nfrom the DHCP server, or when the IPV4 address is changed. The event means\nthat everything is ready and the application can begin its tasks (e.g.,\ncreating sockets).\n\n\nThe IPV4 may be changed because of the following reasons:\n- The DHCP client fails to renew/rebind the IPV4 address, and the station\u2019s\n  IPV4 is reset to 0.\n- The DHCP client rebinds to a different address.\n- The static-configured IPV4 address is changed.\n\n\nWhether the IPV4 address is changed or NOT is indicated by field ip_change\nof ip_event_got_ip_t.\n\n\nThe socket is based on the IPV4 address, which means that, if the IPV4\nchanges, all sockets relating to this IPV4 will become abnormal. Upon\nreceiving this event, the application needs to close all sockets and\nrecreate the application when the IPV4 changes to a valid one.\n\n\n\n\n\n\nIP_STA_LOST_IP\n (was \nWIFI_EVENT_STA_LOST_IP\n)\n\n\nThis event arises when the IPV4 address become invalid.\n\n\nIP_STA_LOST_IP doesn\u2019t arise immediately after the Wi-Fi disconnects,\ninstead it starts an IPV4 address lost timer, if the IPV4 address is got\nbefore ip lost timer expires, IP_EVENT_STA_LOST_IP doesn\u2019t happen.\nOtherwise, the event arises when IPV4 address lost timer expires.\n\n\nGenerally the application don\u2019t need to care about this event, it is just a\ndebug event to let the application know that the IPV4 address is lost.\n\n\n\n\n\n\nWIFI_EVENT_STA_START\n\n\nIf \nesp_wifi_start()\n returns ESP_OK and the current Wi-Fi mode is station or\nstation/AP, then this event will arise. Upon receiving this event, the event\ntask will initialize the LwIP network interface (netif). Generally, the\napplication event callback needs to call esp_wifi_connect() to connect to\nthe configured AP.\n\n\n\n\n\n\nWIFI_EVENT_AP_START\n\n\nSimilar to \nWIFI_EVENT_STA_START\n\n\n\n\n\n\nWIFI_EVENT_AP_STACONNECTED\n\n\nEvery time a station is connected to ESP32 AP, the\n\nWIFI_EVENT_AP_STACONNECTED\n will arise. Upon receiving this event, the\nevent task will do nothing, and the application callback can also ignore it.\nHowever, you may want to do something, for example, to get the info of the\nconnected STA, etc.\n\n\n\n\n\n\nWIFI_EVENT_AP_STADISCONNECTED\n\n\nThis event can happen in the following scenarios:\n- The application calls \nesp_wifi_disconnect()\n, or \nesp_wifi_deauth_sta()\n,\n  to manually disconnect the station.\n- The Wi-Fi driver kicks off the station, e.g. because the AP has not\n  received any packets in the past five minutes, etc. The time can be\n  modified by \nesp_wifi_set_inactive_time()\n.\n- The station kicks off the AP.\n\n\nWhen this event happens, the event task will do nothing, but the application\nevent callback needs to do something, e.g., close the socket which is\nrelated to this station, etc.\n\n\n\n\n\n\nStation Mode\n\n\nThe figure describes some usual scenarios in station mode:\n\n\n\n\nThe main phases in this mode are analyzed below (not all of them have to be\npresent necessarily in all settings).\n\n\n1. WiFi/LwIP Init Phase\n\n\nThe following 1-5 steps are the recommended sequence to initialize a\nWi-Fi-/LwIP-based application:\n\n\n\n\nThe main task calls \nesp_netif_init()\n to create an LwIP core task and\n   initialize LwIP-related work.\n\n\nThe main task calls \nesp_event_loop_create()\n to create a system Event\n   task and initialize an application event\u2019s callback function. In the\n   scenario above, the application event\u2019s callback function does nothing\n   but relaying the event to the application task.\n\n\nThe main task calls \nesp_netif_create_default_wifi_ap()\n or\n   \nesp_netif_create_default_wifi_sta()\n to create default network interface\n   instance binding station or AP with TCP/IP stack.\n\n\nThe main task calls \nesp_wifi_init()\n to create the Wi-Fi driver task and\n   initialize the Wi-Fi driver.\n\n\nThe main task calls OS API to create the application task.\n\n\n\n\nHowever, it is NOT a must-follow sequence, which means that you can create\nthe application task in step 1 and put all other initializations in the\napplication task. Moreover, you may not want to create the application task\nin the initialization phase if the application task depends on the sockets.\nRather, you can defer the task creation until the IP is obtained.\n\n\n2. WiFi Configuraci\u00f3n Phase\n\n\nOnce the Wi-Fi driver is initialized, you can start configuring the Wi-Fi\ndriver. In this scenario, the mode is station, so you may need to call\n\nesp_wifi_set_mode()\n (\nWIFI_MODE_STA\n) to configure the Wi-Fi mode as station.\nYou can call other \nesp_wifi_set_xxx\n APIs to configure more settings, such as\nthe protocol mode, country code, bandwidth, etc. Refer to \nESP32 Wi-Fi\nConfiguration\n\nfor more information on the operation modes.\n\n\nGenerally, we configure the Wi-Fi driver before setting up the Wi-Fi connection,\nbut this is NOT mandatory, which means that you can configure the Wi-Fi\nconnection anytime, provided that the Wi-Fi driver is initialized successfully.\nHowever, if the configuration does not need to change after the Wi-Fi connection\nis set up, you should configure the Wi-Fi driver at this stage, because the\nconfiguration APIs (such as \nesp_wifi_set_protocol()\n) will cause the Wi-Fi to\nreconnect, which may not be desirable.\n\n\nThe routine \nesp_wifi_set_config ()\n allows you to configure the basic aspects\nof the WiFi connection. For example, the following code performs a basic WiFi\nsetup by providing SSID, password, and authentication mode before configuring\nthe connection:\n\n\n    wifi_config_t wifi_config = {\n        .sta = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .threshold.authmode = WIFI_AUTH_WPA2_PSK,\n\n            .pmf_cfg = {\n                .capable = true,\n                .required = false\n            },\n        },\n    };\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_STA) );\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_STA, &wifi_config) );\n\n\n\n\n3. WiFi Start Phase\n\n\n\n\nCall \nesp_wifi_start()\n to start the Wi-Fi driver.\n\n\nThe Wi-Fi driver posts \nWIFI_EVENT_STA_START\n to the event task; then,\n   the event task will do some common things and will call the application\n   event callback function.\n\n\nThe application event callback function relays the \nWIFI_EVENT_STA_START\n\n   to the application task. We recommend that you call \nesp_wifi_connect()\n.\n   However, you can also call \nesp_wifi_connect()\n in other phrases after\n   the \nWIFI_EVENT_STA_START\n arises.\n\n\n\n\n4. WiFi Connect Phase\n\n\n\n\nOnce \nesp_wifi_connect()\n is called, the Wi-Fi driver will start the\n   internal scan/connection process.\n\n\nIf the internal scan/connection process is successful, the\n   \nWIFI_EVENT_STA_CONNECTED\n will be generated. In the event task, it\n   starts the DHCP client, which will finally trigger the DHCP process.\n\n\nIn the above-mentioned scenario, the application event callback will\n   relay the event to the application task. Generally, the application needs\n   to do nothing, and you can do whatever you want, e.g., print a log, etc.\n\n\n\n\nIn step 2, the Wi-Fi connection may fail because, for example, the password is\nwrong, the AP is not found, etc. In a case like this,\n\nWIFI_EVENT_STA_DISCONNECTED\n will arise and the reason for such a failure will\nbe provided. For handling events that disrupt Wi-Fi connection, please refer to\nphase 6.\n\n\n5. Wi-Fi \nGot IP\n Phase\n\n\n\n\nOnce the DHCP client is initialized in step 4.2, the got IP phase will\n   begin.\n\n\nIf the IP address is successfully received from the DHCP server, then\n   \nIP_EVENT_STA_GOT_IP\n will arise and the event task will perform common\n   handling.\n\n\nIn the application event callback, \nIP_EVENT_STA_GOT_IP\n is relayed to\n   the application task. For LwIP-based applications, this event is very\n   special and means that everything is ready for the application to begin\n   its tasks, e.g. creating the TCP/UDP socket, etc. A very common mistake\n   is to initialize the socket before \nIP_EVENT_STA_GOT_IP\n is received. DO\n   NOT start the socket-related work before the IP is received.\n\n\n\n\n6. WiFi Disconnect Phase\n\n\n\n\nWhen the Wi-Fi connection is disrupted, e.g. because the AP is powered\n   off, the RSSI is poor, etc., \nWIFI_EVENT_STA_DISCONNECTED\n will arise.\n\n\nIn the scenario described above, the application event callback function\n   relays \nWIFI_EVENT_STA_DISCONNECTED\n to the application task. We\n   recommend that \nesp_wifi_connect()\n be called to reconnect the Wi-Fi,\n   close all sockets and re-create them if necessary.\n\n\n\n\n7. WiFi IP Change Phase\n\n\n\n\n\n\nIf the IP address is changed, the \nIP_EVENT_STA_GOT_IP\n will arise with\n   \nip_change\n field set to true in the \nip_event_got_ip_t\n structure passed\n   to the event handler.\n\n\n\n\n\n\nThis event is important to the application. When it occurs, the timing is\n   good for closing all created sockets and recreating them.\n\n\n\n\n\n\n8. WiFi Deinit Phase\n\n\n\n\nCall \nesp_wifi_disconnect()\n to disconnect the Wi-Fi connectivity.\n\n\nCall \nesp_wifi_stop()\n to stop the Wi-Fi driver.\n\n\nCall \nesp_wifi_deinit()\n to unload the Wi-Fi driver.\n\n\n\n\nAnalysis of an example (\nwifi/getting_started/station\n)\n\n\n\n\nTask 2.1\n\n\nAnalyze the \nstation\n example, compile it and flash it. Study the treatment\nof events that it carries out, and how these are emitted for real cases. To\ndo this, try the following things:\n- connect your ESP32 with an existing access point\n- connect your ESP32 with a non-existent access point\n- turn off the access point while the IP is granted\nDo it while you monitor the ESP32 to see the screen messages of the events\nhandlers. If there is no message for one of them modify the code to handle\nit. Deliver the code and a brief report commenting your observations (pdf\nformat).\n\n\n\n\nAccess Point Mode\n\n\nThe following figure roughly describes some of the main scenarios\nthat can occur in \nAP (access point)\n mode:\n\n\n\n\nThe workflow is very similar to that of \nstation\n mode, with the difference\nbasic type of WiFi configuration to perform (\nWIFI_MODE_AP\n) and obviously\nconfiguration parameters. Take a look at the following configuration example:\n\n\n    wifi_config_t wifi_config = {\n        .ap = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .ssid_len = strlen(EXAMPLE_ESP_WIFI_SSID),\n            .channel = EXAMPLE_ESP_WIFI_CHANNEL,\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .max_connection = EXAMPLE_MAX_STA_CONN,\n            .authmode = WIFI_AUTH_WPA_WPA2_PSK\n        },\n    };\n    if (strlen(EXAMPLE_ESP_WIFI_PASS) == 0) {\n        wifi_config.ap.authmode = WIFI_AUTH_OPEN;\n    }\n\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_AP));\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_AP, &wifi_config));\n\n\n\n\nFor more information on the configuration parameters of an Access Point, check\n\nAP Basic Configuration\n.\n\n\nAnalysis of an example (\nwifi/getting_started/softAP\n)\n\n\n\n\nTask 2.2\n\n\nAnalyze the \nsoftAP\n example, compile it and flash it. Study the treatment\nof events that it carries out, and how these are emitted for real cases. To\ndo it, connect different clients (\nstations\n), either ESP32 or any another\ndevice, and analyze the generated events and their response. If there is no\nmessage printed for any of them, add the corresponding handling code.\nDeliver the code and a small report documenting your observations (pdf\nformat).\n\n\n\n\nCombined STA and AP Mode\n\n\nESP-IDF supports a mixed mode of connection, in which the ESP32 is both\nan access point (AP) and a station (\nstation\n). This mode is configured\nusing the \nESP_MODE_APSTA\n parameter in the invocation of the routine\n\nesp_wifi_set_mode()\n.\n\n\nObviously, the code will require two independent \nwifi_config_t\n structures, one\nwith the data associated with the point access (field \n.ap\n) mode and another\nwith the fields associated with the \nstation\n mode (\n.sta\n field). In addition,\nit will be necessary to invoke the configuration routine (\nesp_wifi_set_config\n)\nwith each of these structures. And finally, you also need to invoke the\ninitialization of \nnetif\n both in \nstation\n mode\n(\nesp_netif_create_default_wifi_sta()\n) an in \nAP\n mode\n(\nesp_netif_create_default_wifi_ap()\n).\n\n\nExercise: develop a \nstation/AP\n mixed node\n\n\n\n\nTask 2.3\n\n\nModify the \nstation\n example so that the ESP32 behaves at the same time\nas a station and as an access point. Add the necessary configuration options\nto be able to set all the parameters via \nmenuconfig\n. Check that the ESP32\nactually connects to the point access and that at the same time it is\npossible to connect another device to it as a station (for example, your\nmobile phone). Deliver the developed code.\n\n\n\n\nScanning WiFi networks\n\n\nWiFi Scanning Modes\n\n\nThe WiFi network scanning mode (i.e. invoking the routine\n\nesp_wifi_scan_start()\n) is only supported currently in \nstation\n or\n\nstation/AP\n modes. The different types of network scanning modes are:\n\n\n\n\n\n\n\n\nMode\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nActive Scan\n\n\nScan by sending a probe request. The default scan is an active scan.\n\n\n\n\n\n\nPassive Scan\n\n\nNo probe request is sent out. Just switch to the specific channel and wait for a beacon. Application can enable it via the scan_type field of wifi_scan_config_t.\n\n\n\n\n\n\nForeground Scan\n\n\nThis scan is applicable when there is no Wi-Fi connection in station mode. Foreground or background scanning is controlled by the Wi-Fi driver and cannot be configured by the application.\n\n\n\n\n\n\nBackground Scan\n\n\nThis scan is applicable when there is a Wi-Fi connection in station mode or in station/AP mode. Whether it is a foreground scan or background scan depends on the Wi-Fi driver and cannot be configured by the application.\n\n\n\n\n\n\nAll-Channel Scan\n\n\nIt scans all of the channels. If the channel field of wifi_scan_config_t is set to 0, it is an all-channel scan.\n\n\n\n\n\n\nSpecific Channel Scan\n\n\nIt scans specific channels only. If the channel field of wifi_scan_config_t set to 1-14, it is a specific-channel scan.\n\n\n\n\n\n\n\n\nThe scan modes in above table can be combined arbitrarily, so we totally have 8\ndifferent scans:\n\n\n\n\nAll-Channel Background Active Scan\n\n\nAll-Channel Background Passive Scan\n\n\nAll-Channel Foreground Active Scan\n\n\nAll-Channel Foreground Passive Scan\n\n\nSpecific-Channel Background Active Scan\n\n\nSpecific-Channel Background Passive Scan\n\n\nSpecific-Channel Foreground Active Scan\n\n\nSpecific-Channel Foreground Passive Scan\n\n\n\n\nScan Configuration\n\n\nThe scan type and other per-scan attributes are configured by\n\nesp_wifi_scan_start()\n. The table below provides a detailed description of\n\nwifi_scan_config_t\n.\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nssid\n\n\nIf the SSID is not NULL it is only the AP with the same SSID that can be scanned.\n\n\n\n\n\n\nbssid\n\n\nIf the BSSID is not NULL it is only the AP with the same BSSID that can be scanned.\n\n\n\n\n\n\nchannel\n\n\nIf \nchannel\n is 0 there will be an all-channel scan; otherwise there will be a specific-channel scan.\n\n\n\n\n\n\nshow_hidden\n\n\nIf \nshow_hidden\n is 0 the scan ignores the AP with a hidden SSID; otherwise the scan considers the hidden AP a normal one.\n\n\n\n\n\n\nscan_type\n\n\nIf \nscan_type\n is \nWIFI_SCAN_TYPE_ACTIVE\n the scan is \nactive\n; otherwise it is a \npassive\n one.\n\n\n\n\n\n\nscan_time\n\n\nThis field is used to control how long the scan dwells on each channel. See \nScan Configuration\n for more details\n\n\n\n\n\n\n\n\nScan All APs on All Channels (Foreground)\n\n\nThe following figure describes a basic scan over all channels in foreground\n(remember that it can only occur in \nstation\n mode when it is not yet connected\nto an AP).\n\n\n\n\n1. Scan Configuration Phase\n\n\n\n\nCall esp_wifi_set_country() to set the country info if the default\n   country info is not what you want, refer to Wi-Fi Country Code.\n\n\nCall esp_wifi_scan_start() to configure the scan. To do so, you can refer to\n   Scan Configuration. Since this is an all-channel scan, just set the\n   SSID/BSSID/channel to 0.\n\n\n\n\n2. WiFi Driver's Internal Scan Phase\n\n\n\n\nThe Wi-Fi driver switches to channel 1, in case the scan type is\n   \nWIFI_SCAN_TYPE_ACTIVE\n, and broadcasts a probe request. Otherwise, the Wi-Fi\n   will wait for a beacon from the APs. The Wi-Fi driver will stay in channel 1\n   for some time. The dwell time is configured in min/max time, with default\n   value being 120 ms.\n\n\nThe Wi-Fi driver switches to channel 2 and performs the same operation as in\n   step 2.1.\n\n\nThe Wi-Fi driver scans the last channel N, where N is determined by the\n   country code which is configured in step 1.1.\n\n\n\n\n3. Scan-Done Event Handling Phase\n\n\n\n\nWhen all channels are scanned, WIFI_EVENT_SCAN_DONE will arise.\n\n\nThe application\u2019s event callback function notifies the application task that\n   \nWIFI_EVENT_SCAN_DONE\n is received. \nesp_wifi_scan_get_ap_num()\n is called to\n   get the number of APs that have been found in this scan. Then, it allocates\n   enough entries and calls \nesp_wifi_scan_get_ap_records()\n to get the AP\n   records. Please note that the AP records in the Wi-Fi driver will be freed,\n   once \nesp_wifi_scan_get_ap_records()\n is called. Do not call\n   \nesp_wifi_scan_get_ap_records()\n twice for a single scan-done event. If\n   \nesp_wifi_scan_get_ap_records()\n is not called when the scan-done event\n   occurs, the AP records allocated by the Wi-Fi driver will not be freed. So,\n   make sure you call \nesp_wifi_scan_get_ap_records()\n, yet only once.\n\n\n\n\nAnalysis of an example (\nwifi/scan\n)\n\n\nAnalyze the scan example, and try to observe the flow detailed above.\n\n\n\n\nTask 2.4\n\n\nCompile, flash and run the scan sample. See if the results are what you\nexpected in your home environment. Study and modify the waiting times in the\nscan and see the effect on the scan time. Deliver a brief report with your\nobservations (pdf format).",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P2/#lab-2-wifi-in-esp32",
            "text": "",
            "title": "Lab 2. WiFi in ESP32"
        },
        {
            "location": "/Subjects/NP1/P2/#goals",
            "text": "Familiarize yourself with the workflow of the WiFi driver in ESP-IDF.  Understand the difference between  station  and  AP  modes.  Develop  firmware  that can work as AP for others and as  station  to connect\n  to another AP.  Understand the network scanning mechanisms in ESP-IDF.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP1/P2/#introduction",
            "text": "The ESP-IDF WiFi libraries and components provide support to configure and\nmonitor 802.11 connections on ESP32 boards. This includes settings for:    Station  mode (WiFi client mode, or  STA ).\n  In this case, the ESP32 connects to a preconfigured access point.    AP  mode (also called  softAP  or  Access Point  mode). In this case, other\n  stations can connect to the ESP32.    AP-STA combined mode, where ESP32 is concurrently acting as an access point\n  and a station connected to another access point.    Various security modes in both client mode and AP mode (WPA, WPA2, WEP, etc.)    Access point scanning (active and passive).    Key provisioning and WPS mode.    Promiscuous mode for IEEE 802.11 packet monitoring.    In the present lab we will study through basic examples the main features\nsupported by the WiFi driver. All these characteristics can be used later for\nthe development of codes and more complex projects with minimal modifications.",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/NP1/P2/#esp32-wi-fi-programming-model",
            "text": "The ESP32 Wi-Fi programming model can be described with the following figure:   The Wi-Fi driver can be considered a black box that knows nothing about\nhigh-layer code, such as the TCP/IP stack, application task, event task, etc.\nThe application task (code) generally calls Wi-Fi driver APIs to initialize\nWi-Fi and handles Wi-Fi events when necessary. Wi-Fi driver receives API calls,\nhandles them, and post events to the application.  Wi-Fi event handling is based on the  esp_event\nlibrary .\nEvents are sent by the Wi-Fi driver to the  default event\nloop .\nApplication may handle these events in  callbacks  registered using esp_event_handler_register() . Wi-Fi events are also handled by esp_netif\ncomponent to provide a set of default behaviors. For example, when Wi-Fi station\nconnects to an AP, esp_netif will automatically start the DHCP client by default\n(even though this Default behavior can be customized to, for example, assign an\nIP address statically).   Note  All the API mentioned below is described in depth in\nthis  link . It is advisable to have this information during the process\nas well as in this lab document.",
            "title": "ESP32 Wi-Fi Programming Model"
        },
        {
            "location": "/Subjects/NP1/P2/#wifi-events",
            "text": "The following list shows the description of the wifi events that are handled in\nthe example codes we work through in this lab assignment.    WIFI_EVENT_SCAN_DONE  The scan-done event is triggered by  esp_wifi_scan_start()  and will arise\nin the following scenarios:\n- The scan is completed, e.g., the target AP is found successfully, or all\n  channels have been scanned.\n- The scan is stopped by  esp_wifi_scan_stop() .\n- The  esp_wifi_scan_start()  is called before the scan is completed. A new\n  scan will override the current scan and a scan-done event will be\n  generated.  The scan-done event will not arise in the following scenarios:\n- It is a blocked scan.\n- The scan is caused by  esp_wifi_connect() .  Upon receiving this event, the event task does nothing. The application\nevent callback needs to call  esp_wifi_scan_get_ap_num()  and esp_wifi_scan_get_ap_records()  to fetch the scanned AP list and trigger\nthe Wi-Fi driver to free the internal memory which is allocated during the\nscan (do not forget to do this!). Refer to ESP32 Wi-Fi Scan for a more\ndetailed description.    WIFI_EVENT_STA_START  If  esp_wifi_start()  returns ESP_OK and the current Wi-Fi mode is station\nor station/AP, then this event will arise. Upon receiving this event, the\nevent task will initialize the LwIP network interface (netif). Generally,\nthe application event callback needs to call  esp_wifi_connect()  to connect\nto the configured AP.    WIFI_EVENT_STA_STOP  If  esp_wifi_stop()  returns ESP_OK and the current Wi-Fi mode is station or\nstation/AP, then this event will arise. Upon receiving this event, the event\ntask will release the station\u2019s IP address, stop the DHCP client, remove\nTCP/UDP-related connections and clear the LwIP station netif, etc. The\napplication event callback generally does not need to do anything.    WIFI_EVENT_STA_CONNECTED  If  esp_wifi_connect()  returns ESP_OK and the station successfully connects\nto the target AP, the connection event will arise. Upon receiving this\nevent, the event task starts the DHCP client and begins the DHCP process of\ngetting the IP address. Then, the Wi-Fi driver is ready for sending and\nreceiving data.  This moment is good for beginning the application work, provided that the\napplication does not depend on LwIP, namely the IP address. However, if the\napplication is LwIP-based, then you need to wait until the got ip event WIFI_EVENT_STA_GOT_IP  comes in.    WIFI_EVENT_STA_DISCONNECTED  This event can be generated in the following scenarios:    When  esp_wifi_disconnect() , or  esp_wifi_stop()  is called and the\n  station is already connected to the AP.    When  esp_wifi_connect()  is called, but the Wi-Fi driver fails to set up\n  a connection with the AP due to certain reasons, e.g. the scan fails to\n  find the target AP, authentication times out, etc. If there are more\n  than one AP with the same SSID, the disconnected event is raised after\n  the station fails to connect all of the found APs.    When the Wi-Fi connection is disrupted because of specific reasons,\n  e.g., the station continuously loses N beacons, the AP kicks off the\n  station, the AP\u2019s authentication mode is changed, etc.    Upon receiving this event, the default behavior of the event task is to:\n- Shut down the station\u2019s LwIP netif.   Notify the LwIP task to clear the UDP/TCP connections which cause the\n  wrong status to all sockets. For socket-based applications, the\n  application callback can choose to close all sockets and re-create them,\n  if necessary, upon receiving this event.   The most common event handle code for this event in application is to call esp_wifi_connect()  to reconnect the Wi-Fi. However, if the event is raised\nbecause  esp_wifi_disconnect()  is called, the application should not call\nesp_wifi_connect() to reconnect. It\u2019s application\u2019s responsibility to\ndistinguish whether the event is caused by  esp_wifi_disconnect()  or other\nreasons.    IP_EVENT_STA_GOT_IP  (was  WIFI_EVENT_STA_GOT_IP )  This event arises when the DHCP client successfully gets the IPV4 address\nfrom the DHCP server, or when the IPV4 address is changed. The event means\nthat everything is ready and the application can begin its tasks (e.g.,\ncreating sockets).  The IPV4 may be changed because of the following reasons:\n- The DHCP client fails to renew/rebind the IPV4 address, and the station\u2019s\n  IPV4 is reset to 0.\n- The DHCP client rebinds to a different address.\n- The static-configured IPV4 address is changed.  Whether the IPV4 address is changed or NOT is indicated by field ip_change\nof ip_event_got_ip_t.  The socket is based on the IPV4 address, which means that, if the IPV4\nchanges, all sockets relating to this IPV4 will become abnormal. Upon\nreceiving this event, the application needs to close all sockets and\nrecreate the application when the IPV4 changes to a valid one.    IP_STA_LOST_IP  (was  WIFI_EVENT_STA_LOST_IP )  This event arises when the IPV4 address become invalid.  IP_STA_LOST_IP doesn\u2019t arise immediately after the Wi-Fi disconnects,\ninstead it starts an IPV4 address lost timer, if the IPV4 address is got\nbefore ip lost timer expires, IP_EVENT_STA_LOST_IP doesn\u2019t happen.\nOtherwise, the event arises when IPV4 address lost timer expires.  Generally the application don\u2019t need to care about this event, it is just a\ndebug event to let the application know that the IPV4 address is lost.    WIFI_EVENT_STA_START  If  esp_wifi_start()  returns ESP_OK and the current Wi-Fi mode is station or\nstation/AP, then this event will arise. Upon receiving this event, the event\ntask will initialize the LwIP network interface (netif). Generally, the\napplication event callback needs to call esp_wifi_connect() to connect to\nthe configured AP.    WIFI_EVENT_AP_START  Similar to  WIFI_EVENT_STA_START    WIFI_EVENT_AP_STACONNECTED  Every time a station is connected to ESP32 AP, the WIFI_EVENT_AP_STACONNECTED  will arise. Upon receiving this event, the\nevent task will do nothing, and the application callback can also ignore it.\nHowever, you may want to do something, for example, to get the info of the\nconnected STA, etc.    WIFI_EVENT_AP_STADISCONNECTED  This event can happen in the following scenarios:\n- The application calls  esp_wifi_disconnect() , or  esp_wifi_deauth_sta() ,\n  to manually disconnect the station.\n- The Wi-Fi driver kicks off the station, e.g. because the AP has not\n  received any packets in the past five minutes, etc. The time can be\n  modified by  esp_wifi_set_inactive_time() .\n- The station kicks off the AP.  When this event happens, the event task will do nothing, but the application\nevent callback needs to do something, e.g., close the socket which is\nrelated to this station, etc.",
            "title": "WiFi events"
        },
        {
            "location": "/Subjects/NP1/P2/#station-mode",
            "text": "The figure describes some usual scenarios in station mode:   The main phases in this mode are analyzed below (not all of them have to be\npresent necessarily in all settings).  1. WiFi/LwIP Init Phase  The following 1-5 steps are the recommended sequence to initialize a\nWi-Fi-/LwIP-based application:   The main task calls  esp_netif_init()  to create an LwIP core task and\n   initialize LwIP-related work.  The main task calls  esp_event_loop_create()  to create a system Event\n   task and initialize an application event\u2019s callback function. In the\n   scenario above, the application event\u2019s callback function does nothing\n   but relaying the event to the application task.  The main task calls  esp_netif_create_default_wifi_ap()  or\n    esp_netif_create_default_wifi_sta()  to create default network interface\n   instance binding station or AP with TCP/IP stack.  The main task calls  esp_wifi_init()  to create the Wi-Fi driver task and\n   initialize the Wi-Fi driver.  The main task calls OS API to create the application task.   However, it is NOT a must-follow sequence, which means that you can create\nthe application task in step 1 and put all other initializations in the\napplication task. Moreover, you may not want to create the application task\nin the initialization phase if the application task depends on the sockets.\nRather, you can defer the task creation until the IP is obtained.  2. WiFi Configuraci\u00f3n Phase  Once the Wi-Fi driver is initialized, you can start configuring the Wi-Fi\ndriver. In this scenario, the mode is station, so you may need to call esp_wifi_set_mode()  ( WIFI_MODE_STA ) to configure the Wi-Fi mode as station.\nYou can call other  esp_wifi_set_xxx  APIs to configure more settings, such as\nthe protocol mode, country code, bandwidth, etc. Refer to  ESP32 Wi-Fi\nConfiguration \nfor more information on the operation modes.  Generally, we configure the Wi-Fi driver before setting up the Wi-Fi connection,\nbut this is NOT mandatory, which means that you can configure the Wi-Fi\nconnection anytime, provided that the Wi-Fi driver is initialized successfully.\nHowever, if the configuration does not need to change after the Wi-Fi connection\nis set up, you should configure the Wi-Fi driver at this stage, because the\nconfiguration APIs (such as  esp_wifi_set_protocol() ) will cause the Wi-Fi to\nreconnect, which may not be desirable.  The routine  esp_wifi_set_config ()  allows you to configure the basic aspects\nof the WiFi connection. For example, the following code performs a basic WiFi\nsetup by providing SSID, password, and authentication mode before configuring\nthe connection:      wifi_config_t wifi_config = {\n        .sta = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .threshold.authmode = WIFI_AUTH_WPA2_PSK,\n\n            .pmf_cfg = {\n                .capable = true,\n                .required = false\n            },\n        },\n    };\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_STA) );\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_STA, &wifi_config) );  3. WiFi Start Phase   Call  esp_wifi_start()  to start the Wi-Fi driver.  The Wi-Fi driver posts  WIFI_EVENT_STA_START  to the event task; then,\n   the event task will do some common things and will call the application\n   event callback function.  The application event callback function relays the  WIFI_EVENT_STA_START \n   to the application task. We recommend that you call  esp_wifi_connect() .\n   However, you can also call  esp_wifi_connect()  in other phrases after\n   the  WIFI_EVENT_STA_START  arises.   4. WiFi Connect Phase   Once  esp_wifi_connect()  is called, the Wi-Fi driver will start the\n   internal scan/connection process.  If the internal scan/connection process is successful, the\n    WIFI_EVENT_STA_CONNECTED  will be generated. In the event task, it\n   starts the DHCP client, which will finally trigger the DHCP process.  In the above-mentioned scenario, the application event callback will\n   relay the event to the application task. Generally, the application needs\n   to do nothing, and you can do whatever you want, e.g., print a log, etc.   In step 2, the Wi-Fi connection may fail because, for example, the password is\nwrong, the AP is not found, etc. In a case like this, WIFI_EVENT_STA_DISCONNECTED  will arise and the reason for such a failure will\nbe provided. For handling events that disrupt Wi-Fi connection, please refer to\nphase 6.  5. Wi-Fi  Got IP  Phase   Once the DHCP client is initialized in step 4.2, the got IP phase will\n   begin.  If the IP address is successfully received from the DHCP server, then\n    IP_EVENT_STA_GOT_IP  will arise and the event task will perform common\n   handling.  In the application event callback,  IP_EVENT_STA_GOT_IP  is relayed to\n   the application task. For LwIP-based applications, this event is very\n   special and means that everything is ready for the application to begin\n   its tasks, e.g. creating the TCP/UDP socket, etc. A very common mistake\n   is to initialize the socket before  IP_EVENT_STA_GOT_IP  is received. DO\n   NOT start the socket-related work before the IP is received.   6. WiFi Disconnect Phase   When the Wi-Fi connection is disrupted, e.g. because the AP is powered\n   off, the RSSI is poor, etc.,  WIFI_EVENT_STA_DISCONNECTED  will arise.  In the scenario described above, the application event callback function\n   relays  WIFI_EVENT_STA_DISCONNECTED  to the application task. We\n   recommend that  esp_wifi_connect()  be called to reconnect the Wi-Fi,\n   close all sockets and re-create them if necessary.   7. WiFi IP Change Phase    If the IP address is changed, the  IP_EVENT_STA_GOT_IP  will arise with\n    ip_change  field set to true in the  ip_event_got_ip_t  structure passed\n   to the event handler.    This event is important to the application. When it occurs, the timing is\n   good for closing all created sockets and recreating them.    8. WiFi Deinit Phase   Call  esp_wifi_disconnect()  to disconnect the Wi-Fi connectivity.  Call  esp_wifi_stop()  to stop the Wi-Fi driver.  Call  esp_wifi_deinit()  to unload the Wi-Fi driver.",
            "title": "Station Mode"
        },
        {
            "location": "/Subjects/NP1/P2/#analysis-of-an-example-wifigetting_startedstation",
            "text": "Task 2.1  Analyze the  station  example, compile it and flash it. Study the treatment\nof events that it carries out, and how these are emitted for real cases. To\ndo this, try the following things:\n- connect your ESP32 with an existing access point\n- connect your ESP32 with a non-existent access point\n- turn off the access point while the IP is granted\nDo it while you monitor the ESP32 to see the screen messages of the events\nhandlers. If there is no message for one of them modify the code to handle\nit. Deliver the code and a brief report commenting your observations (pdf\nformat).",
            "title": "Analysis of an example (wifi/getting_started/station)"
        },
        {
            "location": "/Subjects/NP1/P2/#access-point-mode",
            "text": "The following figure roughly describes some of the main scenarios\nthat can occur in  AP (access point)  mode:   The workflow is very similar to that of  station  mode, with the difference\nbasic type of WiFi configuration to perform ( WIFI_MODE_AP ) and obviously\nconfiguration parameters. Take a look at the following configuration example:      wifi_config_t wifi_config = {\n        .ap = {\n            .ssid = EXAMPLE_ESP_WIFI_SSID,\n            .ssid_len = strlen(EXAMPLE_ESP_WIFI_SSID),\n            .channel = EXAMPLE_ESP_WIFI_CHANNEL,\n            .password = EXAMPLE_ESP_WIFI_PASS,\n            .max_connection = EXAMPLE_MAX_STA_CONN,\n            .authmode = WIFI_AUTH_WPA_WPA2_PSK\n        },\n    };\n    if (strlen(EXAMPLE_ESP_WIFI_PASS) == 0) {\n        wifi_config.ap.authmode = WIFI_AUTH_OPEN;\n    }\n\n    ESP_ERROR_CHECK(esp_wifi_set_mode(WIFI_MODE_AP));\n    ESP_ERROR_CHECK(esp_wifi_set_config(ESP_IF_WIFI_AP, &wifi_config));  For more information on the configuration parameters of an Access Point, check AP Basic Configuration .",
            "title": "Access Point Mode"
        },
        {
            "location": "/Subjects/NP1/P2/#analysis-of-an-example-wifigetting_startedsoftap",
            "text": "Task 2.2  Analyze the  softAP  example, compile it and flash it. Study the treatment\nof events that it carries out, and how these are emitted for real cases. To\ndo it, connect different clients ( stations ), either ESP32 or any another\ndevice, and analyze the generated events and their response. If there is no\nmessage printed for any of them, add the corresponding handling code.\nDeliver the code and a small report documenting your observations (pdf\nformat).",
            "title": "Analysis of an example (wifi/getting_started/softAP)"
        },
        {
            "location": "/Subjects/NP1/P2/#combined-sta-and-ap-mode",
            "text": "ESP-IDF supports a mixed mode of connection, in which the ESP32 is both\nan access point (AP) and a station ( station ). This mode is configured\nusing the  ESP_MODE_APSTA  parameter in the invocation of the routine esp_wifi_set_mode() .  Obviously, the code will require two independent  wifi_config_t  structures, one\nwith the data associated with the point access (field  .ap ) mode and another\nwith the fields associated with the  station  mode ( .sta  field). In addition,\nit will be necessary to invoke the configuration routine ( esp_wifi_set_config )\nwith each of these structures. And finally, you also need to invoke the\ninitialization of  netif  both in  station  mode\n( esp_netif_create_default_wifi_sta() ) an in  AP  mode\n( esp_netif_create_default_wifi_ap() ).",
            "title": "Combined STA and AP Mode"
        },
        {
            "location": "/Subjects/NP1/P2/#exercise-develop-a-stationap-mixed-node",
            "text": "Task 2.3  Modify the  station  example so that the ESP32 behaves at the same time\nas a station and as an access point. Add the necessary configuration options\nto be able to set all the parameters via  menuconfig . Check that the ESP32\nactually connects to the point access and that at the same time it is\npossible to connect another device to it as a station (for example, your\nmobile phone). Deliver the developed code.",
            "title": "Exercise: develop a station/AP mixed node"
        },
        {
            "location": "/Subjects/NP1/P2/#scanning-wifi-networks",
            "text": "",
            "title": "Scanning WiFi networks"
        },
        {
            "location": "/Subjects/NP1/P2/#wifi-scanning-modes",
            "text": "The WiFi network scanning mode (i.e. invoking the routine esp_wifi_scan_start() ) is only supported currently in  station  or station/AP  modes. The different types of network scanning modes are:     Mode  Description      Active Scan  Scan by sending a probe request. The default scan is an active scan.    Passive Scan  No probe request is sent out. Just switch to the specific channel and wait for a beacon. Application can enable it via the scan_type field of wifi_scan_config_t.    Foreground Scan  This scan is applicable when there is no Wi-Fi connection in station mode. Foreground or background scanning is controlled by the Wi-Fi driver and cannot be configured by the application.    Background Scan  This scan is applicable when there is a Wi-Fi connection in station mode or in station/AP mode. Whether it is a foreground scan or background scan depends on the Wi-Fi driver and cannot be configured by the application.    All-Channel Scan  It scans all of the channels. If the channel field of wifi_scan_config_t is set to 0, it is an all-channel scan.    Specific Channel Scan  It scans specific channels only. If the channel field of wifi_scan_config_t set to 1-14, it is a specific-channel scan.     The scan modes in above table can be combined arbitrarily, so we totally have 8\ndifferent scans:   All-Channel Background Active Scan  All-Channel Background Passive Scan  All-Channel Foreground Active Scan  All-Channel Foreground Passive Scan  Specific-Channel Background Active Scan  Specific-Channel Background Passive Scan  Specific-Channel Foreground Active Scan  Specific-Channel Foreground Passive Scan",
            "title": "WiFi Scanning Modes"
        },
        {
            "location": "/Subjects/NP1/P2/#scan-configuration",
            "text": "The scan type and other per-scan attributes are configured by esp_wifi_scan_start() . The table below provides a detailed description of wifi_scan_config_t .     Field  Description      ssid  If the SSID is not NULL it is only the AP with the same SSID that can be scanned.    bssid  If the BSSID is not NULL it is only the AP with the same BSSID that can be scanned.    channel  If  channel  is 0 there will be an all-channel scan; otherwise there will be a specific-channel scan.    show_hidden  If  show_hidden  is 0 the scan ignores the AP with a hidden SSID; otherwise the scan considers the hidden AP a normal one.    scan_type  If  scan_type  is  WIFI_SCAN_TYPE_ACTIVE  the scan is  active ; otherwise it is a  passive  one.    scan_time  This field is used to control how long the scan dwells on each channel. See  Scan Configuration  for more details",
            "title": "Scan Configuration"
        },
        {
            "location": "/Subjects/NP1/P2/#scan-all-aps-on-all-channels-foreground",
            "text": "The following figure describes a basic scan over all channels in foreground\n(remember that it can only occur in  station  mode when it is not yet connected\nto an AP).   1. Scan Configuration Phase   Call esp_wifi_set_country() to set the country info if the default\n   country info is not what you want, refer to Wi-Fi Country Code.  Call esp_wifi_scan_start() to configure the scan. To do so, you can refer to\n   Scan Configuration. Since this is an all-channel scan, just set the\n   SSID/BSSID/channel to 0.   2. WiFi Driver's Internal Scan Phase   The Wi-Fi driver switches to channel 1, in case the scan type is\n    WIFI_SCAN_TYPE_ACTIVE , and broadcasts a probe request. Otherwise, the Wi-Fi\n   will wait for a beacon from the APs. The Wi-Fi driver will stay in channel 1\n   for some time. The dwell time is configured in min/max time, with default\n   value being 120 ms.  The Wi-Fi driver switches to channel 2 and performs the same operation as in\n   step 2.1.  The Wi-Fi driver scans the last channel N, where N is determined by the\n   country code which is configured in step 1.1.   3. Scan-Done Event Handling Phase   When all channels are scanned, WIFI_EVENT_SCAN_DONE will arise.  The application\u2019s event callback function notifies the application task that\n    WIFI_EVENT_SCAN_DONE  is received.  esp_wifi_scan_get_ap_num()  is called to\n   get the number of APs that have been found in this scan. Then, it allocates\n   enough entries and calls  esp_wifi_scan_get_ap_records()  to get the AP\n   records. Please note that the AP records in the Wi-Fi driver will be freed,\n   once  esp_wifi_scan_get_ap_records()  is called. Do not call\n    esp_wifi_scan_get_ap_records()  twice for a single scan-done event. If\n    esp_wifi_scan_get_ap_records()  is not called when the scan-done event\n   occurs, the AP records allocated by the Wi-Fi driver will not be freed. So,\n   make sure you call  esp_wifi_scan_get_ap_records() , yet only once.",
            "title": "Scan All APs on All Channels (Foreground)"
        },
        {
            "location": "/Subjects/NP1/P2/#analysis-of-an-example-wifiscan",
            "text": "Analyze the scan example, and try to observe the flow detailed above.   Task 2.4  Compile, flash and run the scan sample. See if the results are what you\nexpected in your home environment. Study and modify the waiting times in the\nscan and see the effect on the scan time. Deliver a brief report with your\nobservations (pdf format).",
            "title": "Analysis of an example (wifi/scan)"
        },
        {
            "location": "/Subjects/NP1/P3/",
            "text": "Lab 3. WiFi. Advanced Concepts (WiFi Mesh, provisioning and low power mode)\n\n\nGoals\n\n\nThis lab assignment is divided into three main parts, that address\nthree advanced topics related to WiFi. The goals for each of these parts are the\nfollowing:\n\n\n\n\n\n\nWiFi MESH\n\n\n\n\nReview the basic concepts for building a self-managed WiFi Mesh network.\n\n\nPresent the basic API for creating applications based on the\n  ESP-MESH stack.\n\n\nObserve an ESP-MESH network in operation, as well as its autoconfiguration\n  capabilities.\n\n\n\n\n\n\n\n\nProvisioning\n\n\n\n\nUnderstand and experiment with different modes of provisioning of WiFi\n  credentials, via \nBLE\n and via\nsoftAP\n.\n\n\nCheck the clear exchange of keys by making provisions from the command\n  line, as well as observe the utility (and the necessity) of exanging\n  encrypted credentials.\n\n\n\n\n\n\n\n\nEnergy saving\n\n\n\n\nUnderstand the three power operating modes for the WiFi radio of the ESP32.\n\n\nObserve the influence of these operating modes in the latency of the\n  connection.\n\n\n\n\n\n\n\n\nPart 1. WiFi Mesh (ESP MESH)\n\n\nThe ESP-MESH stack is built on top of the WiFi driver (that is, it obviously\nmakes use of the WiFi services), and in some cases also makes use of IP stack\nservices (\nlwIP\n), as for example in the root node, which is the only node that\nhas IP communication with an edge router . The following diagram shows the Mesh\nstack situation in ESP-IDF:\n\n\n\n\nLike any other ESP-IDF component, ESP-MESH communicates with applications\nthrough its own events:\n\n\n\n\nThe type \nmesh_event_id_t\n defines all the possible events that may arise in the\ndifferent phases of the life cycle of a network (for example, for a given node,\nconnection or disconnection from its parent node, or from one of its child\nnodes). Event handlers for the ESP-MESH events are registered with the\n\nesp_event_handler_register()\n. Some typical events are for example, the\nconnection of a parent node (\nMESH_EVENT_PARENT_CONNECTED\n) or of a child\n(\nMESH_EVENT_CHILD_CONNECTED\n), indicating, respectively, that a node can start\nemitting upward in the graph, or downward. Similarly, in a root node, the\nreception of the events \nIP_EVENT_STA_GOT_IP\n and\nIP_EVENT_STA_LOST_IP\n\nindicate that said root node may or may not send data to the external IP\nnetwork.\n\n\nEvents\n\n\n\n\nMESH_EVENT_STARTED\n: mesh is started\n\n\nMESH_EVENT_STOPPED\n: mesh is stopped\n\n\nMESH_EVENT_CHANNEL_SWITCH\n: channel switch\n\n\nMESH_EVENT_CHILD_CONNECTED\n: a child is connected on softAP interface\n\n\nMESH_EVENT_CHILD_DISCONNECTED\n: a child is disconnected on softAP interface\n\n\nMESH_EVENT_ROUTING_TABLE_ADD\n: routing table is changed by adding newly joined children\n\n\nMESH_EVENT_ROUTING_TABLE_REMOVE\n: routing table is changed by removing leave children\n\n\nMESH_EVENT_PARENT_CONNECTED\n: parent is connected on station interface\n\n\nMESH_EVENT_PARENT_DISCONNECTED\n: parent is disconnected on station interface\n\n\nMESH_EVENT_NO_PARENT_FOUND\n: no parent found\n\n\nMESH_EVENT_LAYER_CHANGE\n: layer changes over the mesh network\n\n\nMESH_EVENT_TODS_STATE\n: state represents whether the root is able to access external IP network\n\n\nMESH_EVENT_VOTE_STARTED\n: the process of voting a new root is started either by children or by the root\n\n\nMESH_EVENT_VOTE_STOPPED\n: the process of voting a new root is stopped\n\n\nMESH_EVENT_ROOT_ADDRESS\n: the root address is obtained. It is posted by mesh stack automatically.\n\n\nMESH_EVENT_ROOT_SWITCH_REQ\n: root switch request sent from a new voted root candidate\n\n\nMESH_EVENT_ROOT_SWITCH_ACK\n: root switch acknowledgment responds the above request sent from current root\n\n\nMESH_EVENT_ROOT_ASKED_YIELD\n: the root is asked yield by a more powerful existing root. If self organized is disabled and this device is specified to be a root by users, users should set a new parent for this device. if self organized is enabled, this device will find a new parent by itself, users could ignore this event.\n\n\nMESH_EVENT_ROOT_FIXED\n: when devices join a network, if the setting of Fixed Root for one device is different from that of its parent, the device will update the setting the same as its parent\u2019s. Fixed Root Setting of each device is variable as that setting changes of the root.\n\n\nMESH_EVENT_SCAN_DONE\n: if self-organized networking is disabled, user can call esp_wifi_scan_start() to trigger this event, and add the corresponding scan done handler in this event.\n\n\nMESH_EVENT_NETWORK_STATE\n: network state, such as whether current mesh network has a root.\n\n\nMESH_EVENT_STOP_RECONNECTION\n: the root stops reconnecting to the router and non-root devices stop reconnecting to their parents.\n\n\nMESH_EVENT_FIND_NETWORK\n: when the channel field in mesh configuration is set to zero, mesh stack will perform a full channel scan to find a mesh network that can join, and return the channel value after finding it.\n\n\nMESH_EVENT_ROUTER_SWITCH\n: if users specify BSSID of the router in mesh configuration, when the root connects to another router with the same SSID, this event will be posted and the new router information is attached.\n\n\nMESH_EVENT_PS_PARENT_DUTY\n: parent duty\n\n\nMESH_EVENT_PS_CHILD_DUTY\n: child duty\n\n\nMESH_EVENT_PS_DEVICE_DUTY\n: device duty\n\n\n\n\nLwIP and ESP-WIFI-MESH\n\n\nThe application can access the ESP-WIFI-MESH stack directly without having to go\nthrough the LwIP stack. The LwIP stack is only required by the root node to\ntransmit/receive data to/from an external IP network. However, since every node\ncan potentially become the root node (due to automatic root node selection),\neach node must still initialize the LwIP stack.\n\n\nEach node is required to initialize LwIP by calling \ntcpip_adapter_init()\n. In\norder to prevent non-root node access to LwIP, the application should stop the\nfollowing services after LwIP initialization:\n\n\n\n\nDHCP server service on the softAP interface.\n\n\nDHCP client service on the station interface.\n\n\n\n\nThe following code snippet demonstrates how to initialize LwIP for ESP-WIFI-MESH\napplications.\n\n\n/*  tcpip initialization */\ntcpip_adapter_init();\n/*\n * for mesh\n * stop DHCP server on softAP interface by default\n * stop DHCP client on station interface by default\n */\nESP_ERROR_CHECK(tcpip_adapter_dhcps_stop(TCPIP_ADAPTER_IF_AP));\nESP_ERROR_CHECK(tcpip_adapter_dhcpc_stop(TCPIP_ADAPTER_IF_STA));\n\n\n\n\nESP-WIFI-MESH requires a root node to be connected with a router. Therefore, in\nthe event that a node becomes the root, the corresponding handler must start the\nDHCP client service and immediately obtain an IP address. Doing so will allow\nother nodes to begin transmitting/receiving packets to/from the external IP\nnetwork. However, this step is unnecessary if static IP settings are used.\n\n\nWriting an ESP-WIFI-MESH Application\n\n\nThe prerequisites for starting ESP-WIFI-MESH is to initialize LwIP and Wi-Fi,\nThe following code snippet demonstrates the necessary prerequisite steps before\nESP-WIFI-MESH itself can be initialized.\n\n\ntcpip_adapter_init();\n/*\n * for mesh\n * stop DHCP server on softAP interface by default\n * stop DHCP client on station interface by default\n */\nESP_ERROR_CHECK(tcpip_adapter_dhcps_stop(TCPIP_ADAPTER_IF_AP));\nESP_ERROR_CHECK(tcpip_adapter_dhcpc_stop(TCPIP_ADAPTER_IF_STA));\n\n/*  event initialization */\nESP_ERROR_CHECK(esp_event_loop_create_default());\n\n/*  Wi-Fi initialization */\nwifi_init_config_t config = WIFI_INIT_CONFIG_DEFAULT();\nESP_ERROR_CHECK(esp_wifi_init(&config));\n/*  register IP events handler */\nESP_ERROR_CHECK(esp_event_handler_register(IP_EVENT, IP_EVENT_STA_GOT_IP, &ip_event_handler, NULL));\nESP_ERROR_CHECK(esp_wifi_set_storage(WIFI_STORAGE_FLASH));\nESP_ERROR_CHECK(esp_wifi_start());\n\n\n\n\nAfter initializing LwIP and Wi-Fi, the process of getting an ESP-WIFI-MESH\nnetwork up and running can be summarized into the following three steps:\n\n\n\n\nInitialize Mesh\n\n\nConfiguring an ESP-WIFI-MESH Network\n\n\nStart Mesh\n\n\n\n\n1. Initialize Mesh\n\n\nThe following code snippet demonstrates how to initialize ESP-WIFI-MESH:\n\n\n/*  mesh initialization */\nESP_ERROR_CHECK(esp_mesh_init());\n/*  register mesh events handler */\nESP_ERROR_CHECK(esp_event_handler_register(MESH_EVENT, ESP_EVENT_ANY_ID, &mesh_event_handler, NULL));\n\n\n\n\n2. Configuring an ESP-WIFI-MESH Network\n\n\nESP-WIFI-MESH is configured via \nesp_mesh_set_config()\n which receives its\narguments using the \nmesh_cfg_t\n structure. The structure contains the following\nparameters used to configure ESP-WIFI-MESH:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nChannel\n\n\nRange from 1 to 14\n\n\n\n\n\n\nMesh ID\n\n\nID of ESP-WIFI-MESH Network, see mesh_addr_t\n\n\n\n\n\n\nRouter\n\n\nRouter Configuration, see mesh_router_t\n\n\n\n\n\n\nMesh AP\n\n\nMesh AP Configuration, see mesh_ap_cfg_t\n\n\n\n\n\n\nCrypto Functions\n\n\nCrypto Functions for Mesh IE, see mesh_crypto_funcs_t\n\n\n\n\n\n\n\n\nThe following code snippet shows an example of how to configure ESP-WIFI-MESH:\n\n\n/* Mesh ID */\nstatic const uint8_t MESH_ID = { 0x77, 0x77, 0x77, 0x77, 0x77, 0x77 };\n/* Enable the Mesh IE encryption by default */\nmesh_cfg_t cfg = MESH_INIT_CONFIG_DEFAULT();\n/* mesh ID */\nmemcpy((uint8_t *) &cfg.mesh_id, MESH_ID, 6);\n/* channel (must match the router's channel) */\ncfg.channel = CONFIG_MESH_CHANNEL;\n/* router */\ncfg.router.ssid_len = strlen(CONFIG_MESH_ROUTER_SSID);\nmemcpy((uint8_t *) &cfg.router.ssid, CONFIG_MESH_ROUTER_SSID, cfg.router.ssid_len);\nmemcpy((uint8_t *) &cfg.router.password, CONFIG_MESH_ROUTER_PASSWD,\n       strlen(CONFIG_MESH_ROUTER_PASSWD));\n/* mesh softAP */\ncfg.mesh_ap.max_connection = CONFIG_MESH_AP_CONNECTIONS;\nmemcpy((uint8_t *) &cfg.mesh_ap.password, CONFIG_MESH_AP_PASSWD,\n       strlen(CONFIG_MESH_AP_PASSWD));\nESP_ERROR_CHECK(esp_mesh_set_config(&cfg));\n\n\n\n\n3. Start Mesh\n\n\nThe following code snippet demonstrates how to start ESP-WIFI-MESH:\n\n\n/* mesh start */\nESP_ERROR_CHECK(esp_mesh_start());\n\n\n\n\nAfter starting ESP-WIFI-MESH, the application should check for ESP-WIFI-MESH\nevents to determine when it has connected to the network. After connecting, the\napplication can start transmitting and receiving packets over the ESP-WIFI-MESH\nnetwork using \nesp_mesh_send()\n and \nesp_mesh_recv()\n.\n\n\n\n\nTask 3.1\n\n\nThe most convenient way to observe the behavior of a WiFi network Mesh is to\ndeploy an infrastructure with a sufficient number of nodes belonging to to\nthe same network. Unfortunately, this requires would require to have a large\namount of nodes in the same closed space, and given the conditions of this\ncurse it wont be possible.\n\n\nIn this lab experience, each of you will deploy a WiFi Mesh network with\nonly two nodes, using the two ESP32 nodes that each student has. You will\nstart by copying the example \nexamples/mesh/internal_communication\n to\nanother directory in your home folder. Then you can configure the project\nto:\n\n\n\n\nConnect to an access point generated with your own smartphone or the\n   wifi router at your place (\nRouter SSID and Router password\n).\n\n\nConfigure the ESP-MESH network to use WPA2_PSK and select as password\n   \npassword\n.\n\n\n\n\nAt this time, you will not make any changes to the code in the example.\nCompile your code. Flash the two ESP nodes you have and monitor the output\nof both nodes in two different terminals (use the command line toolset here\nfor convenience).  If you have the possibility, try to physically arrange\nthe nodes in a way that one has better connection with your\nsmartphone/router than the other (play with distance or obstacles). Monitor\nthe output of each node and annotate the following information:\n\n\n\n\nMAC addresses of the \nSTA\n and\nSoftAP\n interfaces (you will see then in\n   the first outgoing messages).\n\n\nLayer of the topology in which your node is located (you will observe it\n   in \n[L: XX]\n format for sending and receiving data).\n\n\nIf the root node has been chosen, also note this circumstance and the IP\n   assigned by the \nrouter\n (see the response to the corresponding event).\n\n\n\n\nAlso, take note of the ID of the Mesh network that was used. Before\ncollecting this information make sure that the topology has converged. Draw\na graph of your small wifi mesh network.\n\n\nNext, turn off the root node and wait for the network to converge again.\nVerify that the other node became the new root node.\n\n\nNow reconnect the node you disconnected previously, and see how it\nreconnects to the mesh. Is it again the root node? Annotate it and discuss\nwhy you think it is or is not the root node again and if that is what you\nexpected.\n\n\nDeliver a report in pdf format in which you explain your observations in\nenglish.\n\n\n\n\nPart 2. WiFi Provisioning\n\n\nESP-IDF provides a specific component that offers a WiFi provisioning service.\nThis component provides APIs that control Wi-Fi provisioning service for\nreceiving and configuring Wi-Fi credentials over SoftAP or BLE transport via\nsecure Protocol Communication (protocomm) sessions. The set of \nwifi_prov_mgr_\n\nAPIs help in quickly implementing a provisioning service having necessary\nfeatures with minimal amount of code and sufficient flexibility.\n\n\nTo complete this part of the lab assignment you will have to work with the\nexample \nexamples/provisioning/wifi-prov-mgr\n.\n\n\nInitialization of the provisioning service\n\n\nThe \nwifi_prov_mgr_init()\n function must be called to configure and initialize\nthe provisioning manager before any other \nwifi_prov_mgr_\n API functions. Note\nthat the manager relies on other components of IDF, namely NVS, TCP/IP, Event\nLoop and Wi-Fi (and optionally mDNS), hence these must be initialized\nbeforehand. The manager can be de-initialized at any moment by making a call to\n\nwifi_prov_mgr_deinit()\n.\n\n\nAn initialization example could be:\n\n\nwifi_prov_mgr_config_t config = {\n  .scheme = wifi_prov_scheme_ble,\n  .scheme_event_handler = WIFI_PROV_SCHEME_BLE_EVENT_HANDLER_FREE_BTDM\n};\n\nESP_ERR_CHECK( wifi_prov_mgr_init(config) );\n\n\n\n\nThe configuration structure \nwifi_prov_mgr_config_t\n has a few fields to specify\nthe behavior desired of the manager. The \nscheme\n field is used to specify the\nprovisioning scheme. Each scheme corresponds to one of the modes of transport\nsupported by protocomm:\n\n\n\n\nwifi_prov_scheme_ble\n: BLE transport and GATT Server for handling\n  provisioning commands\n\n\nwifi_prov_scheme_softap\n: Wi-Fi SoftAP transport and HTTP Server for handling\n  provisioning commands\n\n\nwifi_prov_scheme_console\n: Serial transport and console for handling\n  provisioning commands\n\n\n\n\nWe refer you to \nWiFi Provisioning\nInitialization\n \nfor additional information on the fields of the \nwifi_prov_mgr_config_t\n\nstructure.\n\n\nCheck Provisioning State\n\n\nWhether the device is provisioned or not can be checked at runtime by calling\n\nwifi_prov_mgr_is_provisioned()\n. This internally checks if the Wi-Fi\ncredentials are stored in NVS.\n\n\nAlthough there are different methods to delete the provisioning information\nstored in NVS, we will use the mechanism provided by \nidf.py\n to\ndelete its content. To do this, we will execute:\n\n\nidf.py erase_flash\n\n\n\n\nStart Provisioning Service\n\n\nAt the time of starting provisioning we need to specify a service name and the\ncorresponding key. These translate to:\n\n\n\n\nWi-Fi SoftAP SSID and passphrase, respectively, when scheme is\n  \nwifi_prov_scheme_softap\n\n\nBLE Device name (service key is ignored) when scheme is \nwifi_prov_scheme_ble\n\n\n\n\nAlso, since internally the manager uses \nprotocomm\n, we have the option of\nchoosing one of the security features provided by it :\n\n\n\n\nSecurity 1 is secure communication which consists of an initial handshake\n  involving X25519 key exchange along with an authentication using a proof of\n  possession (pop), followed by the encryption/decryption of subsequent\n  messages with AES-CTR.\n\n\nSecurity 0 is simply a plain text communication. In this case the pop is simply\n  ignored\n\n\n\n\nSee \nProvisioning\n\nfor details about the security features.\n\n\nThe following code snippet shows an example of Provisioning Service\ninitialization:\n\n\nconst char *service_name = \"my_device\";\nconst char *service_key  = \"password\";\n\nwifi_prov_security_t security = WIFI_PROV_SECURITY_1;\nconst char *pop = \"abcd1234\";\n\nESP_ERR_CHECK( wifi_prov_mgr_start_provisioning(security, pop, service_name, service_key) );\n\n\n\n\nThe provisioning service will automatically finish only if it receives valid\nWi-Fi AP credentials followed by a successful connection to the AP (IP\nobtained). Nevertheless, the provisioning service can be stopped at any moment\nby making a call to \nwifi_prov_mgr_stop_provisioning()\n.\n\n\nWaiting For Completion\n\n\nTypically, the main application will wait for the provisioning to finish, then\nde-initialize the manager to free up resources and finally start executing its\nown logic.\n\n\nThere are two ways for making this possible: \n\n\n\n\nThe simpler way is to use a \nblocking\n call to \nwifi_prov_mgr_wait()\n.\n\n\n\n\n// Start provisioning service\nESP_ERROR_CHECK( wifi_prov_mgr_start_provisioning(security, pop, service_name, service_key) );\n\n// Wait for service to complete\nwifi_prov_mgr_wait();\n\n// Finally de-initialize the manager\nwifi_prov_mgr_deinit();\n\n// From here, the usual application logic would starts\n// ...\n\n\n\n\n\n\nThe second mechanism is based on events (i.e., is asynchronous/non blocking).\n  The default event loop handler to catch \nWIFI_PROV_EVENT\n and call\n  \nwifi_prov_mgr_deinit()\n when event ID is \nWIFI_PROV_END\n:\n\n\n\n\nstatic void event_handler(void* arg, esp_event_base_t event_base,\n                          int event_id, void* event_data)\n{\n    if (event_base == WIFI_PROV_EVENT && event_id == WIFI_PROV_END) {\n        /* De-initialize manager once provisioning is finished */\n        wifi_prov_mgr_deinit();\n    }\n}\n\n\n\n\nProvisioning tools for mobile devices\n\n\nThere are applications prepared by Espressif to carry out the process\nprovisioning over ESP32. These applications are available both for Android\nand IOS devices, for BLE and/or SoftAP transports:\n\n\n\n\n\n\nAndroid:\n\n\n\n\nBLE Transport\n.\n\n\nSoftAP Transport\n.\n\n\n\n\n\n\n\n\nIOS:\n\n\n\n\nBLE Transport\n.\n\n\nSoftAP Transport\n.\n\n\n\n\n\n\n\n\n\n\nTask 3.2\n\n\nProvision your ESP32 devices using the credentials that correspond to your\nWiFi network (home wifi or smartphone) using the applications corresponding\nto your mobile device, for both BLE and SoftAP transports.  Write down a\nsmall report in english (in pdf format) describing the process, including\nthe screenshots corresponding to the ESP32 output that show that the\nprovisioning was successful.  Remember, before each repetition of the\nexperiment, use the command \nidf.py erase_flash\n to remove provisioning\ninformation from previous sessions. Check the operation of the different\nsecurity levels.\n\n\n\n\nThese applications work by means of a very simple communication with the\nunprovisioned ESP32, whose mechanisms depend on the transport being used.  In\nthe case of BLE, a GATT table is created with different characteristics used to\nwrite (send) data to the device. We will see what a GATT table is in next lab\nassignment. In the case of the \nsoftAP\n transport, a series of \nendpoints\n are\ncreated (HTTP URIs) that allow, in a simple way, to read and write the data that\nwe want to communicate to the other end of the communication.\n\n\nThe following table summarizes the \nendpoints\n created by the standard versions\nof the provisioning protocol (they can be adapted to include additional\ninformation to exchange):\n\n\n\n\n\n\n\n\n\n\nEndpoint (BLE + GATT Server)\n\n\nURI (SoftAP + HTTP)\n\n\n\n\n\n\n\n\n\n\nSession establishment\n\n\nprov-session\n\n\nhttp://IP:80/prov-session\n\n\n\n\n\n\nNetwork scanning available\n\n\nprov-scan\n\n\nhttp://IP:80/prov-scan\n\n\n\n\n\n\nProvisioning configuration\n\n\nprov-config\n\n\nhttp://IP:80/prov-config\n\n\n\n\n\n\nProtocol version\n\n\nproto-ver\n\n\nhttp://IP:80/proto-ver\n\n\n\n\n\n\n\n\nThe details of this type of provisioning protocol remain as additional exercise\nto the student, and go beyond the goals of the assignment. However, it would be\nadvisable to have a mechanism that allows them to be observed, and determine,\nfor example in the case of SoftAP, if the exchange of credentials is done as\nplain text (plaintext) or encrypted, which could pose serious security problems\nfor the user of a device mobile, since the credentials of connection to the WiFi\nnetwork would be exposed.\n\n\nTo analyze this security issue, we will use our laptop/pc as provisioning device.\nWe have to connect the laptop/pc to the provisioning SSID of the ESP32 node and\nuse a command line tool provided with the ESP-IDF toolset, called \nesp_prov.py\n,\nwhich can be found in the directory \ntools/esp_prov\n.\n\n\n\n\nNote\n\n\nBefore using the program, you must install the respective dependencies\nusing the commands (from the \ntools/esp_prov\n directory):\n\n\npip install -r requirements.txt\npip install -r requirements_linux_extra.txt\n\n\n\n\nIts use is simple, and can be consulted by running \npython esp_prov.py -h\n.\nBasically a provisioning session using \nsoftAP\n on a device with IP\n\n192.168.4.1\n, without layer security (encryption) and providing the SSID and\nkey SSID_EXAMPLE/KEY_EXAMPLE would result in:\n\n\npython esp_prov.py --transport softap --service_name \"192.168.4.1:80\" --sec_ver 0 --ssid SSID_EXAMPLE --passphrase KEY_EXAMPLE\n\n\n\n\n\n\nTask 3.3\n\n\nPerform the provisioning process from the command line using the above\nindications. Use the wireshark program to analyze the provisioning traffic\nand find evidences of the clear delivery of the network credentials between\nthe provisioner and the device (text mode, without encryption) and the use\nof the \nendpoints/URIs\n previously mentioned. Create a small report in\nenglish (in pdf format) describing the process and showing the evidences you\nfound.  Next, try with safe mode (option \n--sec_ver 1\n) and see how the keys\nexchanged are now encrypted. Add the corresponding comments to your report.\n\n\n\n\nPart 3. WiFi Power States\n\n\nStation mode\n\n\nCurrently, ESP32 Wi-Fi supports the Modem-sleep mode which refers to the legacy\npower-saving mode in the IEEE 802.11 protocol. Modem-sleep mode works in\nstation-only mode and the station must connect to the AP first. If the\nModem-sleep mode is enabled, the station node will switch between active and\nsleep state periodically. In sleep state, RF, PHY and BB are turned off in order\nto reduce power consumption. The connection with the AP is nevertheless kept\nalive.\n\n\nModem-sleep\n mode includes minimum and maximum power save modes. In minimum\npower save mode, the station wakes up for every beacon with DTIM (Delivery\nTraffic Indication Message) so that it can receive all the broadcast data.\nHowever, it cannot save much more power if the DTIM interval is short, and this\ninterval is established by the AP.\n\n\nIn maximum power save mode, station wakes up every \nlisten\n interval to receive\nthe AP beacon. The \nlisten\n interval can be set longer than the AP DTIM\ninterval, leading extra power savings at the risk of loosing some broadcast\ndata, because station may be in sleep state during a DTIM beacon transmission.\nThe \nlisten\n interval is configured with the \nesp_wifi_set_config()\n function,\nwhich should be invoked before connecting to AP.\n\n\nAP mode\n\n\nCurrently ESP32 AP doesn\u2019t support all of the power saving features defined in\nthe Wi-Fi specification. To be specific, in AP mode it only caches unicast data\nfor the stations connect to it, but does not cache the multicast data. If\nstations connected to the ESP32 AP have enabled the power save mode, they may\nexperience multicast packet loss.\n\n\nIn the future, all power save features will be supported on ESP32 AP.\n\n\nExample\n\n\nThe example \nexamples/wifi/power_save\n uses a simple code to illustrate\nthe configuration of a station in the \nModem-sleep\n mode, and you can select\nbetween the minimum and maximum submodes. These submodes can be configured\nthrough the configuration menu. In addition, an option is offered to modify the\nlistening time in the case of the \nmaximum\n submode.\n\n\n\n\nTask 3.4\n\n\nCompile, flash, and run the sample code using all the three configurations\navailable: no savings, minimum savings and maximum savings. In the case of\nmaximum savings, vary the listening time so that it takes different values.\nIn all cases, connect your ESP32 to an access point and, from a laptop\nconnected to the same AP, execute a series of \nping\n commands towards the\nstation. Analyze the relation between the mode, DTIM, listen times and the\nping response time, showing graphical represntations when possible. Deliver\na small report in english (in pdf format).",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P3/#lab-3-wifi-advanced-concepts-wifi-mesh-provisioning-and-low-power-mode",
            "text": "",
            "title": "Lab 3. WiFi. Advanced Concepts (WiFi Mesh, provisioning and low power mode)"
        },
        {
            "location": "/Subjects/NP1/P3/#goals",
            "text": "This lab assignment is divided into three main parts, that address\nthree advanced topics related to WiFi. The goals for each of these parts are the\nfollowing:    WiFi MESH   Review the basic concepts for building a self-managed WiFi Mesh network.  Present the basic API for creating applications based on the\n  ESP-MESH stack.  Observe an ESP-MESH network in operation, as well as its autoconfiguration\n  capabilities.     Provisioning   Understand and experiment with different modes of provisioning of WiFi\n  credentials, via  BLE  and via softAP .  Check the clear exchange of keys by making provisions from the command\n  line, as well as observe the utility (and the necessity) of exanging\n  encrypted credentials.     Energy saving   Understand the three power operating modes for the WiFi radio of the ESP32.  Observe the influence of these operating modes in the latency of the\n  connection.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP1/P3/#part-1-wifi-mesh-esp-mesh",
            "text": "The ESP-MESH stack is built on top of the WiFi driver (that is, it obviously\nmakes use of the WiFi services), and in some cases also makes use of IP stack\nservices ( lwIP ), as for example in the root node, which is the only node that\nhas IP communication with an edge router . The following diagram shows the Mesh\nstack situation in ESP-IDF:   Like any other ESP-IDF component, ESP-MESH communicates with applications\nthrough its own events:   The type  mesh_event_id_t  defines all the possible events that may arise in the\ndifferent phases of the life cycle of a network (for example, for a given node,\nconnection or disconnection from its parent node, or from one of its child\nnodes). Event handlers for the ESP-MESH events are registered with the esp_event_handler_register() . Some typical events are for example, the\nconnection of a parent node ( MESH_EVENT_PARENT_CONNECTED ) or of a child\n( MESH_EVENT_CHILD_CONNECTED ), indicating, respectively, that a node can start\nemitting upward in the graph, or downward. Similarly, in a root node, the\nreception of the events  IP_EVENT_STA_GOT_IP  and IP_EVENT_STA_LOST_IP \nindicate that said root node may or may not send data to the external IP\nnetwork.",
            "title": "Part 1. WiFi Mesh (ESP MESH)"
        },
        {
            "location": "/Subjects/NP1/P3/#events",
            "text": "MESH_EVENT_STARTED : mesh is started  MESH_EVENT_STOPPED : mesh is stopped  MESH_EVENT_CHANNEL_SWITCH : channel switch  MESH_EVENT_CHILD_CONNECTED : a child is connected on softAP interface  MESH_EVENT_CHILD_DISCONNECTED : a child is disconnected on softAP interface  MESH_EVENT_ROUTING_TABLE_ADD : routing table is changed by adding newly joined children  MESH_EVENT_ROUTING_TABLE_REMOVE : routing table is changed by removing leave children  MESH_EVENT_PARENT_CONNECTED : parent is connected on station interface  MESH_EVENT_PARENT_DISCONNECTED : parent is disconnected on station interface  MESH_EVENT_NO_PARENT_FOUND : no parent found  MESH_EVENT_LAYER_CHANGE : layer changes over the mesh network  MESH_EVENT_TODS_STATE : state represents whether the root is able to access external IP network  MESH_EVENT_VOTE_STARTED : the process of voting a new root is started either by children or by the root  MESH_EVENT_VOTE_STOPPED : the process of voting a new root is stopped  MESH_EVENT_ROOT_ADDRESS : the root address is obtained. It is posted by mesh stack automatically.  MESH_EVENT_ROOT_SWITCH_REQ : root switch request sent from a new voted root candidate  MESH_EVENT_ROOT_SWITCH_ACK : root switch acknowledgment responds the above request sent from current root  MESH_EVENT_ROOT_ASKED_YIELD : the root is asked yield by a more powerful existing root. If self organized is disabled and this device is specified to be a root by users, users should set a new parent for this device. if self organized is enabled, this device will find a new parent by itself, users could ignore this event.  MESH_EVENT_ROOT_FIXED : when devices join a network, if the setting of Fixed Root for one device is different from that of its parent, the device will update the setting the same as its parent\u2019s. Fixed Root Setting of each device is variable as that setting changes of the root.  MESH_EVENT_SCAN_DONE : if self-organized networking is disabled, user can call esp_wifi_scan_start() to trigger this event, and add the corresponding scan done handler in this event.  MESH_EVENT_NETWORK_STATE : network state, such as whether current mesh network has a root.  MESH_EVENT_STOP_RECONNECTION : the root stops reconnecting to the router and non-root devices stop reconnecting to their parents.  MESH_EVENT_FIND_NETWORK : when the channel field in mesh configuration is set to zero, mesh stack will perform a full channel scan to find a mesh network that can join, and return the channel value after finding it.  MESH_EVENT_ROUTER_SWITCH : if users specify BSSID of the router in mesh configuration, when the root connects to another router with the same SSID, this event will be posted and the new router information is attached.  MESH_EVENT_PS_PARENT_DUTY : parent duty  MESH_EVENT_PS_CHILD_DUTY : child duty  MESH_EVENT_PS_DEVICE_DUTY : device duty",
            "title": "Events"
        },
        {
            "location": "/Subjects/NP1/P3/#lwip-and-esp-wifi-mesh",
            "text": "The application can access the ESP-WIFI-MESH stack directly without having to go\nthrough the LwIP stack. The LwIP stack is only required by the root node to\ntransmit/receive data to/from an external IP network. However, since every node\ncan potentially become the root node (due to automatic root node selection),\neach node must still initialize the LwIP stack.  Each node is required to initialize LwIP by calling  tcpip_adapter_init() . In\norder to prevent non-root node access to LwIP, the application should stop the\nfollowing services after LwIP initialization:   DHCP server service on the softAP interface.  DHCP client service on the station interface.   The following code snippet demonstrates how to initialize LwIP for ESP-WIFI-MESH\napplications.  /*  tcpip initialization */\ntcpip_adapter_init();\n/*\n * for mesh\n * stop DHCP server on softAP interface by default\n * stop DHCP client on station interface by default\n */\nESP_ERROR_CHECK(tcpip_adapter_dhcps_stop(TCPIP_ADAPTER_IF_AP));\nESP_ERROR_CHECK(tcpip_adapter_dhcpc_stop(TCPIP_ADAPTER_IF_STA));  ESP-WIFI-MESH requires a root node to be connected with a router. Therefore, in\nthe event that a node becomes the root, the corresponding handler must start the\nDHCP client service and immediately obtain an IP address. Doing so will allow\nother nodes to begin transmitting/receiving packets to/from the external IP\nnetwork. However, this step is unnecessary if static IP settings are used.",
            "title": "LwIP and ESP-WIFI-MESH"
        },
        {
            "location": "/Subjects/NP1/P3/#writing-an-esp-wifi-mesh-application",
            "text": "The prerequisites for starting ESP-WIFI-MESH is to initialize LwIP and Wi-Fi,\nThe following code snippet demonstrates the necessary prerequisite steps before\nESP-WIFI-MESH itself can be initialized.  tcpip_adapter_init();\n/*\n * for mesh\n * stop DHCP server on softAP interface by default\n * stop DHCP client on station interface by default\n */\nESP_ERROR_CHECK(tcpip_adapter_dhcps_stop(TCPIP_ADAPTER_IF_AP));\nESP_ERROR_CHECK(tcpip_adapter_dhcpc_stop(TCPIP_ADAPTER_IF_STA));\n\n/*  event initialization */\nESP_ERROR_CHECK(esp_event_loop_create_default());\n\n/*  Wi-Fi initialization */\nwifi_init_config_t config = WIFI_INIT_CONFIG_DEFAULT();\nESP_ERROR_CHECK(esp_wifi_init(&config));\n/*  register IP events handler */\nESP_ERROR_CHECK(esp_event_handler_register(IP_EVENT, IP_EVENT_STA_GOT_IP, &ip_event_handler, NULL));\nESP_ERROR_CHECK(esp_wifi_set_storage(WIFI_STORAGE_FLASH));\nESP_ERROR_CHECK(esp_wifi_start());  After initializing LwIP and Wi-Fi, the process of getting an ESP-WIFI-MESH\nnetwork up and running can be summarized into the following three steps:   Initialize Mesh  Configuring an ESP-WIFI-MESH Network  Start Mesh",
            "title": "Writing an ESP-WIFI-MESH Application"
        },
        {
            "location": "/Subjects/NP1/P3/#1-initialize-mesh",
            "text": "The following code snippet demonstrates how to initialize ESP-WIFI-MESH:  /*  mesh initialization */\nESP_ERROR_CHECK(esp_mesh_init());\n/*  register mesh events handler */\nESP_ERROR_CHECK(esp_event_handler_register(MESH_EVENT, ESP_EVENT_ANY_ID, &mesh_event_handler, NULL));",
            "title": "1. Initialize Mesh"
        },
        {
            "location": "/Subjects/NP1/P3/#2-configuring-an-esp-wifi-mesh-network",
            "text": "ESP-WIFI-MESH is configured via  esp_mesh_set_config()  which receives its\narguments using the  mesh_cfg_t  structure. The structure contains the following\nparameters used to configure ESP-WIFI-MESH:     Parameter  Description      Channel  Range from 1 to 14    Mesh ID  ID of ESP-WIFI-MESH Network, see mesh_addr_t    Router  Router Configuration, see mesh_router_t    Mesh AP  Mesh AP Configuration, see mesh_ap_cfg_t    Crypto Functions  Crypto Functions for Mesh IE, see mesh_crypto_funcs_t     The following code snippet shows an example of how to configure ESP-WIFI-MESH:  /* Mesh ID */\nstatic const uint8_t MESH_ID = { 0x77, 0x77, 0x77, 0x77, 0x77, 0x77 };\n/* Enable the Mesh IE encryption by default */\nmesh_cfg_t cfg = MESH_INIT_CONFIG_DEFAULT();\n/* mesh ID */\nmemcpy((uint8_t *) &cfg.mesh_id, MESH_ID, 6);\n/* channel (must match the router's channel) */\ncfg.channel = CONFIG_MESH_CHANNEL;\n/* router */\ncfg.router.ssid_len = strlen(CONFIG_MESH_ROUTER_SSID);\nmemcpy((uint8_t *) &cfg.router.ssid, CONFIG_MESH_ROUTER_SSID, cfg.router.ssid_len);\nmemcpy((uint8_t *) &cfg.router.password, CONFIG_MESH_ROUTER_PASSWD,\n       strlen(CONFIG_MESH_ROUTER_PASSWD));\n/* mesh softAP */\ncfg.mesh_ap.max_connection = CONFIG_MESH_AP_CONNECTIONS;\nmemcpy((uint8_t *) &cfg.mesh_ap.password, CONFIG_MESH_AP_PASSWD,\n       strlen(CONFIG_MESH_AP_PASSWD));\nESP_ERROR_CHECK(esp_mesh_set_config(&cfg));",
            "title": "2. Configuring an ESP-WIFI-MESH Network"
        },
        {
            "location": "/Subjects/NP1/P3/#3-start-mesh",
            "text": "The following code snippet demonstrates how to start ESP-WIFI-MESH:  /* mesh start */\nESP_ERROR_CHECK(esp_mesh_start());  After starting ESP-WIFI-MESH, the application should check for ESP-WIFI-MESH\nevents to determine when it has connected to the network. After connecting, the\napplication can start transmitting and receiving packets over the ESP-WIFI-MESH\nnetwork using  esp_mesh_send()  and  esp_mesh_recv() .   Task 3.1  The most convenient way to observe the behavior of a WiFi network Mesh is to\ndeploy an infrastructure with a sufficient number of nodes belonging to to\nthe same network. Unfortunately, this requires would require to have a large\namount of nodes in the same closed space, and given the conditions of this\ncurse it wont be possible.  In this lab experience, each of you will deploy a WiFi Mesh network with\nonly two nodes, using the two ESP32 nodes that each student has. You will\nstart by copying the example  examples/mesh/internal_communication  to\nanother directory in your home folder. Then you can configure the project\nto:   Connect to an access point generated with your own smartphone or the\n   wifi router at your place ( Router SSID and Router password ).  Configure the ESP-MESH network to use WPA2_PSK and select as password\n    password .   At this time, you will not make any changes to the code in the example.\nCompile your code. Flash the two ESP nodes you have and monitor the output\nof both nodes in two different terminals (use the command line toolset here\nfor convenience).  If you have the possibility, try to physically arrange\nthe nodes in a way that one has better connection with your\nsmartphone/router than the other (play with distance or obstacles). Monitor\nthe output of each node and annotate the following information:   MAC addresses of the  STA  and SoftAP  interfaces (you will see then in\n   the first outgoing messages).  Layer of the topology in which your node is located (you will observe it\n   in  [L: XX]  format for sending and receiving data).  If the root node has been chosen, also note this circumstance and the IP\n   assigned by the  router  (see the response to the corresponding event).   Also, take note of the ID of the Mesh network that was used. Before\ncollecting this information make sure that the topology has converged. Draw\na graph of your small wifi mesh network.  Next, turn off the root node and wait for the network to converge again.\nVerify that the other node became the new root node.  Now reconnect the node you disconnected previously, and see how it\nreconnects to the mesh. Is it again the root node? Annotate it and discuss\nwhy you think it is or is not the root node again and if that is what you\nexpected.  Deliver a report in pdf format in which you explain your observations in\nenglish.",
            "title": "3. Start Mesh"
        },
        {
            "location": "/Subjects/NP1/P3/#part-2-wifi-provisioning",
            "text": "ESP-IDF provides a specific component that offers a WiFi provisioning service.\nThis component provides APIs that control Wi-Fi provisioning service for\nreceiving and configuring Wi-Fi credentials over SoftAP or BLE transport via\nsecure Protocol Communication (protocomm) sessions. The set of  wifi_prov_mgr_ \nAPIs help in quickly implementing a provisioning service having necessary\nfeatures with minimal amount of code and sufficient flexibility.  To complete this part of the lab assignment you will have to work with the\nexample  examples/provisioning/wifi-prov-mgr .",
            "title": "Part 2. WiFi Provisioning"
        },
        {
            "location": "/Subjects/NP1/P3/#initialization-of-the-provisioning-service",
            "text": "The  wifi_prov_mgr_init()  function must be called to configure and initialize\nthe provisioning manager before any other  wifi_prov_mgr_  API functions. Note\nthat the manager relies on other components of IDF, namely NVS, TCP/IP, Event\nLoop and Wi-Fi (and optionally mDNS), hence these must be initialized\nbeforehand. The manager can be de-initialized at any moment by making a call to wifi_prov_mgr_deinit() .  An initialization example could be:  wifi_prov_mgr_config_t config = {\n  .scheme = wifi_prov_scheme_ble,\n  .scheme_event_handler = WIFI_PROV_SCHEME_BLE_EVENT_HANDLER_FREE_BTDM\n};\n\nESP_ERR_CHECK( wifi_prov_mgr_init(config) );  The configuration structure  wifi_prov_mgr_config_t  has a few fields to specify\nthe behavior desired of the manager. The  scheme  field is used to specify the\nprovisioning scheme. Each scheme corresponds to one of the modes of transport\nsupported by protocomm:   wifi_prov_scheme_ble : BLE transport and GATT Server for handling\n  provisioning commands  wifi_prov_scheme_softap : Wi-Fi SoftAP transport and HTTP Server for handling\n  provisioning commands  wifi_prov_scheme_console : Serial transport and console for handling\n  provisioning commands   We refer you to  WiFi Provisioning\nInitialization  \nfor additional information on the fields of the  wifi_prov_mgr_config_t \nstructure.",
            "title": "Initialization of the provisioning service"
        },
        {
            "location": "/Subjects/NP1/P3/#check-provisioning-state",
            "text": "Whether the device is provisioned or not can be checked at runtime by calling wifi_prov_mgr_is_provisioned() . This internally checks if the Wi-Fi\ncredentials are stored in NVS.  Although there are different methods to delete the provisioning information\nstored in NVS, we will use the mechanism provided by  idf.py  to\ndelete its content. To do this, we will execute:  idf.py erase_flash",
            "title": "Check Provisioning State"
        },
        {
            "location": "/Subjects/NP1/P3/#start-provisioning-service",
            "text": "At the time of starting provisioning we need to specify a service name and the\ncorresponding key. These translate to:   Wi-Fi SoftAP SSID and passphrase, respectively, when scheme is\n   wifi_prov_scheme_softap  BLE Device name (service key is ignored) when scheme is  wifi_prov_scheme_ble   Also, since internally the manager uses  protocomm , we have the option of\nchoosing one of the security features provided by it :   Security 1 is secure communication which consists of an initial handshake\n  involving X25519 key exchange along with an authentication using a proof of\n  possession (pop), followed by the encryption/decryption of subsequent\n  messages with AES-CTR.  Security 0 is simply a plain text communication. In this case the pop is simply\n  ignored   See  Provisioning \nfor details about the security features.  The following code snippet shows an example of Provisioning Service\ninitialization:  const char *service_name = \"my_device\";\nconst char *service_key  = \"password\";\n\nwifi_prov_security_t security = WIFI_PROV_SECURITY_1;\nconst char *pop = \"abcd1234\";\n\nESP_ERR_CHECK( wifi_prov_mgr_start_provisioning(security, pop, service_name, service_key) );  The provisioning service will automatically finish only if it receives valid\nWi-Fi AP credentials followed by a successful connection to the AP (IP\nobtained). Nevertheless, the provisioning service can be stopped at any moment\nby making a call to  wifi_prov_mgr_stop_provisioning() .",
            "title": "Start Provisioning Service"
        },
        {
            "location": "/Subjects/NP1/P3/#waiting-for-completion",
            "text": "Typically, the main application will wait for the provisioning to finish, then\nde-initialize the manager to free up resources and finally start executing its\nown logic.  There are two ways for making this possible:    The simpler way is to use a  blocking  call to  wifi_prov_mgr_wait() .   // Start provisioning service\nESP_ERROR_CHECK( wifi_prov_mgr_start_provisioning(security, pop, service_name, service_key) );\n\n// Wait for service to complete\nwifi_prov_mgr_wait();\n\n// Finally de-initialize the manager\nwifi_prov_mgr_deinit();\n\n// From here, the usual application logic would starts\n// ...   The second mechanism is based on events (i.e., is asynchronous/non blocking).\n  The default event loop handler to catch  WIFI_PROV_EVENT  and call\n   wifi_prov_mgr_deinit()  when event ID is  WIFI_PROV_END :   static void event_handler(void* arg, esp_event_base_t event_base,\n                          int event_id, void* event_data)\n{\n    if (event_base == WIFI_PROV_EVENT && event_id == WIFI_PROV_END) {\n        /* De-initialize manager once provisioning is finished */\n        wifi_prov_mgr_deinit();\n    }\n}",
            "title": "Waiting For Completion"
        },
        {
            "location": "/Subjects/NP1/P3/#provisioning-tools-for-mobile-devices",
            "text": "There are applications prepared by Espressif to carry out the process\nprovisioning over ESP32. These applications are available both for Android\nand IOS devices, for BLE and/or SoftAP transports:    Android:   BLE Transport .  SoftAP Transport .     IOS:   BLE Transport .  SoftAP Transport .      Task 3.2  Provision your ESP32 devices using the credentials that correspond to your\nWiFi network (home wifi or smartphone) using the applications corresponding\nto your mobile device, for both BLE and SoftAP transports.  Write down a\nsmall report in english (in pdf format) describing the process, including\nthe screenshots corresponding to the ESP32 output that show that the\nprovisioning was successful.  Remember, before each repetition of the\nexperiment, use the command  idf.py erase_flash  to remove provisioning\ninformation from previous sessions. Check the operation of the different\nsecurity levels.   These applications work by means of a very simple communication with the\nunprovisioned ESP32, whose mechanisms depend on the transport being used.  In\nthe case of BLE, a GATT table is created with different characteristics used to\nwrite (send) data to the device. We will see what a GATT table is in next lab\nassignment. In the case of the  softAP  transport, a series of  endpoints  are\ncreated (HTTP URIs) that allow, in a simple way, to read and write the data that\nwe want to communicate to the other end of the communication.  The following table summarizes the  endpoints  created by the standard versions\nof the provisioning protocol (they can be adapted to include additional\ninformation to exchange):      Endpoint (BLE + GATT Server)  URI (SoftAP + HTTP)      Session establishment  prov-session  http://IP:80/prov-session    Network scanning available  prov-scan  http://IP:80/prov-scan    Provisioning configuration  prov-config  http://IP:80/prov-config    Protocol version  proto-ver  http://IP:80/proto-ver     The details of this type of provisioning protocol remain as additional exercise\nto the student, and go beyond the goals of the assignment. However, it would be\nadvisable to have a mechanism that allows them to be observed, and determine,\nfor example in the case of SoftAP, if the exchange of credentials is done as\nplain text (plaintext) or encrypted, which could pose serious security problems\nfor the user of a device mobile, since the credentials of connection to the WiFi\nnetwork would be exposed.  To analyze this security issue, we will use our laptop/pc as provisioning device.\nWe have to connect the laptop/pc to the provisioning SSID of the ESP32 node and\nuse a command line tool provided with the ESP-IDF toolset, called  esp_prov.py ,\nwhich can be found in the directory  tools/esp_prov .   Note  Before using the program, you must install the respective dependencies\nusing the commands (from the  tools/esp_prov  directory):  pip install -r requirements.txt\npip install -r requirements_linux_extra.txt   Its use is simple, and can be consulted by running  python esp_prov.py -h .\nBasically a provisioning session using  softAP  on a device with IP 192.168.4.1 , without layer security (encryption) and providing the SSID and\nkey SSID_EXAMPLE/KEY_EXAMPLE would result in:  python esp_prov.py --transport softap --service_name \"192.168.4.1:80\" --sec_ver 0 --ssid SSID_EXAMPLE --passphrase KEY_EXAMPLE   Task 3.3  Perform the provisioning process from the command line using the above\nindications. Use the wireshark program to analyze the provisioning traffic\nand find evidences of the clear delivery of the network credentials between\nthe provisioner and the device (text mode, without encryption) and the use\nof the  endpoints/URIs  previously mentioned. Create a small report in\nenglish (in pdf format) describing the process and showing the evidences you\nfound.  Next, try with safe mode (option  --sec_ver 1 ) and see how the keys\nexchanged are now encrypted. Add the corresponding comments to your report.",
            "title": "Provisioning tools for mobile devices"
        },
        {
            "location": "/Subjects/NP1/P3/#part-3-wifi-power-states",
            "text": "",
            "title": "Part 3. WiFi Power States"
        },
        {
            "location": "/Subjects/NP1/P3/#station-mode",
            "text": "Currently, ESP32 Wi-Fi supports the Modem-sleep mode which refers to the legacy\npower-saving mode in the IEEE 802.11 protocol. Modem-sleep mode works in\nstation-only mode and the station must connect to the AP first. If the\nModem-sleep mode is enabled, the station node will switch between active and\nsleep state periodically. In sleep state, RF, PHY and BB are turned off in order\nto reduce power consumption. The connection with the AP is nevertheless kept\nalive.  Modem-sleep  mode includes minimum and maximum power save modes. In minimum\npower save mode, the station wakes up for every beacon with DTIM (Delivery\nTraffic Indication Message) so that it can receive all the broadcast data.\nHowever, it cannot save much more power if the DTIM interval is short, and this\ninterval is established by the AP.  In maximum power save mode, station wakes up every  listen  interval to receive\nthe AP beacon. The  listen  interval can be set longer than the AP DTIM\ninterval, leading extra power savings at the risk of loosing some broadcast\ndata, because station may be in sleep state during a DTIM beacon transmission.\nThe  listen  interval is configured with the  esp_wifi_set_config()  function,\nwhich should be invoked before connecting to AP.",
            "title": "Station mode"
        },
        {
            "location": "/Subjects/NP1/P3/#ap-mode",
            "text": "Currently ESP32 AP doesn\u2019t support all of the power saving features defined in\nthe Wi-Fi specification. To be specific, in AP mode it only caches unicast data\nfor the stations connect to it, but does not cache the multicast data. If\nstations connected to the ESP32 AP have enabled the power save mode, they may\nexperience multicast packet loss.  In the future, all power save features will be supported on ESP32 AP.",
            "title": "AP mode"
        },
        {
            "location": "/Subjects/NP1/P3/#example",
            "text": "The example  examples/wifi/power_save  uses a simple code to illustrate\nthe configuration of a station in the  Modem-sleep  mode, and you can select\nbetween the minimum and maximum submodes. These submodes can be configured\nthrough the configuration menu. In addition, an option is offered to modify the\nlistening time in the case of the  maximum  submode.   Task 3.4  Compile, flash, and run the sample code using all the three configurations\navailable: no savings, minimum savings and maximum savings. In the case of\nmaximum savings, vary the listening time so that it takes different values.\nIn all cases, connect your ESP32 to an access point and, from a laptop\nconnected to the same AP, execute a series of  ping  commands towards the\nstation. Analyze the relation between the mode, DTIM, listen times and the\nping response time, showing graphical represntations when possible. Deliver\na small report in english (in pdf format).",
            "title": "Example"
        },
        {
            "location": "/Subjects/NP1/P4/",
            "text": "Lab 4. Bluetooth Low Energy (BLE)\n\n\nGoals\n\n\n\n\nDissect in detail a GATT table construction \nfirmware\n (GATT server) using the\n  ESP-IDF API.\n\n\nLearn to use \ngatttool\n to interact with the GATT server.\n\n\nModify the GATT server to accept notification requests from the client,\n  and to publish updated values for a certain characteristic on demand.\n\n\n\n\nGATT Sever Implementation\n\n\nIntroduction\n\n\nIn this lab assignmet, we will deploy a GATT server using the ESP-IDF API. This\nAPI exposes the functionalities of Bluedroid, the Bluetooth stack (including\nBLE) that provides ESP-IDF for the development of Bluetooth applications.\n\n\nWe will use the example from \nexamples/bluetooth/bluedroid/ble/gatt_server_service_table\n,\nwhich example implements a Bluetooth Low Energy (BLE) Generic\nAttribute (GATT) Server using a table-like data structure to define the server\nservices and characteristics such as the one shown in the figure below\nTherefore, it demonstrates a practical way to define the server functionality in\none place instead of adding services and characteristics one by one.\n\n\nThis example implements the \nHeart Rate Profile\n as defined by the \nTraditional\nProfile Specifications\n.\n\n\n \n\n\n\nWe will therefore display three characteristics. Of them, the most important for\nus will be the heart rate measurement value, with its value (\nHeart Rate\nMeasurement Value\n) and its notification settings (\nHeart Rate Measurement\nNotification Configuration\n).\n\n\nDue to the complexity of the code (at least in its initial part), this document\nfollows the program workflow and breaks down the code in order to make sense of\nevery section and reasoning behind the implementation.\n\n\nIncludes\n\n\nLet\u2019s start by taking a look at the included headers:\n\n\n#include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"freertos/event_groups.h\"\n#include \"esp_system.h\"\n#include \"esp_log.h\"\n#include \"nvs_flash.h\"\n#include \"esp_bt.h\"\n#include \"esp_gap_ble_api.h\"\n#include \"esp_gatts_api.h\"\n#include \"esp_bt_main.h\"\n#include \"gatts_table_creat_demo.h\"\n#include \"esp_gatt_common_api.h\"\n\n\n\n\nThese includes are required for the \nFreeRTOS\n and underlaying system components\nto run, including logging functionality and a library to store data in\nnon-volatile flash memory. We are interested in \nbt.h\n, \nesp_bt_main.h\n,\n\nesp_gap_ble_api.h\n and \nesp_gatts_api.h\n which expose the BLE APIs required\nto implement this example.\n\n\n\n\nesp_bt.h\n: implements BT controller and VHCI configuration procedures from the host side.\n\n\nesp_bt_main.h\n: implements initialization and enabling of the Bluedroid stack.\n\n\nesp_gap_ble_api.h\n: implements GAP configuration such as advertising and connection parameters.\n\n\nesp_gatts_api.h\n: implements GATT Server configuration such as creating services and characteristics.\n\n\n\n\nService Table\n\n\nThe header file \ngatts_table_creat_demo.h\n is where an enumeration of the\nservices and characteristics is created:\n\n\nenum\n{\n    IDX_SVC,\n    IDX_CHAR_A,\n    IDX_CHAR_VAL_A,\n    IDX_CHAR_CFG_A,\n\n    IDX_CHAR_B,\n    IDX_CHAR_VAL_B,\n\n    IDX_CHAR_C,\n    IDX_CHAR_VAL_C,\n\n    HRS_IDX_NB,\n};\n\n\n\n\nThe enumeration elements are set up in the same order as the Heart Rate Profile\nattributes, starting with the service followed by the characteristics of that\nservice. In addition, the Heart Rate Measurement characteristic has a Client\nCharacteristic Configuration (CCC) descriptor which is an additional attribute\nthat describes if the characteristic has notifications enabled. The enumeration\nindex can be used to identify each element later when creating the actual\nattributes table. In summary, the elements are described as follows:\n\n\n\n\nIDX_SVC\n: Heart Rate Service index\n\n\nIDX_CHAR_A\n: Heart Rate Measurement characteristic index\n\n\nIDX_CHAR_VAL_A\n: Heart Rate Measurement characteristic value index\n\n\nIDX_CHAR_CFG_A\n: Heart Rate Measurement notifications configuration (CCC) index\n\n\nIDX_CHAR_B\n: Heart Rate Body Sensor Location characteristic index\n\n\nIDX_CHAR_VAL_B\n: Heart Rate Body Sensor Location characteristic value index\n\n\nIDX_CHAR_C\n: Heart Rate Control Point characteristic index\n\n\nIDX_CHAR_VAL_C\n: Heart Rate Control Point characteristic value index\n\n\nIDX_NB\n: Number of table elements.\n\n\n\n\nMain Entry Point\n\n\nThe entry point to this example is the \napp_main()\n function:\n\n\nvoid app_main(void)\n{\n    esp_err_t ret;\n\n    /* Initialize NVS. */\n    ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {\n        ESP_ERROR_CHECK(nvs_flash_erase());\n        ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK( ret );\n\n    ESP_ERROR_CHECK(esp_bt_controller_mem_release(ESP_BT_MODE_CLASSIC_BT));\n\n    esp_bt_controller_config_t bt_cfg = BT_CONTROLLER_INIT_CONFIG_DEFAULT();\n    ret = esp_bt_controller_init(&bt_cfg);\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable controller failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bt_controller_enable(ESP_BT_MODE_BLE);\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable controller failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bluedroid_init();\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s init bluetooth failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bluedroid_enable();\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable bluetooth failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_ble_gatts_register_callback(gatts_event_handler);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gatts register error, error code = %x\", ret);\n        return;\n    }\n\n    ret = esp_ble_gap_register_callback(gap_event_handler);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gap register error, error code = %x\", ret);\n        return;\n    }\n\n    ret = esp_ble_gatts_app_register(ESP_APP_ID);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gatts app register error, error code = %x\", ret);\n        return;\n    }\n\n    esp_err_t local_mtu_ret = esp_ble_gatt_set_local_mtu(500);\n    if (local_mtu_ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"set local  MTU failed, error code = %x\", local_mtu_ret);\n    }\n}\n\n\n\n\nThe main function starts by initializing the non-volatile storage library in\norder to be able to save parameters in flash memory.\n\n\nret = nvs_flash_init();\n\n\n\n\nBT Controller and Stack Initialization\n\n\nThe main function also initializes the BT controller by first creating a BT\ncontroller configuration structure named \nesp_bt_controller_config_t\n with\ndefault settings generated by the \nBT_CONTROLLER_INIT_CONFIG_DEFAULT()\n macro.\n\n\nThe BT controller implements the Host Controller Interface (HCI) on the\ncontroller side, the Link Layer (LL) and the Physical Layer (PHY). The BT\nController is invisible to the user applications and deals with the lower layers\nof the BLE stack. The controller configuration includes setting the BT\ncontroller stack size, priority and HCI baud rate. With the settings created,\nthe BT controller is initialized and enabled with the \nesp_bt_controller_init()\n\nfunction:\n\n\nesp_bt_controller_config_t bt_cfg = BT_CONTROLLER_INIT_CONFIG_DEFAULT();\nret = esp_bt_controller_init(&bt_cfg);\n\n\n\n\nNext, the controller is enabled in BLE Mode.\n\n\nret = esp_bt_controller_enable(ESP_BT_MODE_BLE);\n\n\n\n\nThere are four Bluetooth modes supported:\n\n\n\n\nESP_BT_MODE_IDLE\n: Bluetooth not running\n\n\nESP_BT_MODE_BLE\n: BLE mode\n\n\nESP_BT_MODE_CLASSIC_BT\n: BT Classic mode\n\n\nESP_BT_MODE_BTDM\n: Dual mode (BLE + BT Classic)\n\n\n\n\nAfter the initialization of the BT controller, the Bluedroid stack, which\nincludes the common definitions and APIs for both BT Classic and BLE, is\ninitialized and enabled by using:\n\n\nret = esp_bluedroid_init();\nret = esp_bluedroid_enable();\n\n\n\n\nThe Bluetooth stack is up and running at this point in the program flow, however\nthe functionality of the application has not been defined yet. The functionality\nis defined by reacting to events such as what happens when another device tries\nto read or write parameters and establish a connection.\n\n\nThe two main managers of events are the GAP and GATT event handlers. The\napplication needs to register a callback function for each event handler in\norder to let the application know which functions are going to handle the GAP\nand GATT events:\n\n\nesp_ble_gatts_register_callback(gatts_event_handler);\nesp_ble_gap_register_callback(gap_event_handler);\n\n\n\n\nThe functions \ngatts_event_handler()\n and \ngap_event_handler()\n handle all the\nevents that are pushed to the application from the BLE stack.\n\n\nApplication Profiles\n\n\nThis example implements one Application Profile for the Heart Rate Service. An\nApplication Profile is a way to group functionality which is designed to be used\nby one client application, for example one smartphone mobile app. In this way,\ndifferent types of profiles can be accommodated in one server.\n\n\nThe Application Profile ID, which is an user-assigned number to identify each\nprofile, is used to register the profile in the stack, in this example the ID is\n0x55.\n\n\n#define PROFILE_NUM                 1\n#define PROFILE_APP_IDX             0\n#define ESP_APP_ID                  0x55\n\n\n\n\nThe profiles are stored in the \nheart_rate_profile_tab\n array. Since there is\nonly one profile in this example, one element is stored in the array with index\nzero as defined by the \nPROFILE_APP_IDX\n. Additionally, the profile event\nhandler callback function is initialized. Each application on the GATT server\nuses a different interface, represented by the \ngatts_if\n parameter. For\ninitialization, this parameter is set to \nESP_GATT_IF_NONE\n, later when the\napplication is registered, the \ngatts_if\n parameter is updated with the\ncorresponding interface generated by the stack.\n\n\n/* One gatt-based profile one app_id and one gatts_if, this array will store the gatts_if returned by ESP_GATTS_REG_EVT */\nstatic struct gatts_profile_inst heart_rate_profile_tab[PROFILE_NUM] = {\n    [PROFILE_APP_IDX] = {\n        .gatts_cb = gatts_profile_event_handler,\n        .gatts_if = ESP_GATT_IF_NONE,       /* Not get the gatt_if, so initial is ESP_GATT_IF_NONE */\n    },\n};\n\n\n\n\nThe application registration takes place inside \napp_main()\n using the\n\nesp_ble_gatts_app_register()\n function:\n\n\nesp_ble_gatts_app_register(ESP_HEART_RATE_APP_ID);\n\n\n\n\nSetting GAP Parameters\n\n\nThe register application event is the first one that is triggered during the lifetime of the program. This example uses this event to configure advertising parameters upon registration in the profile event handler. The functions used to achieve this are:\n\n\n\n\nesp_ble_gap_set_device_name()\n: used to set the advertised device name.\n\n\nesp_ble_gap_config_adv_data()\n: used to configure standard advertising data.\n\n\n\n\nThe function used to configure standard Bluetooth Specification advertisement parameters is \nesp_ble_gap_config_adv_data()\n which takes a pointer to an \nesp_ble_adv_data_t\n structure. The \nesp_ble_adv_data_t\n data structure for advertising data has the following definition:\n\n\ntypedef struct {\n    bool set_scan_rsp;    /*!< Set this advertising data as scan response or not*/\n    bool include_name;    /*!< Advertising data include device name or not */\n    bool include_txpower; /*!< Advertising data include TX power */\n    int min_interval;     /*!< Advertising data show slave preferred connection min interval */\n    int max_interval;     /*!< Advertising data show slave preferred connection max interval */\n    int appearance;       /*!< External appearance of device */\n    uint16_t manufacturer_len; /*!< Manufacturer data length */\n    uint8_t *p_manufacturer_data; /*!< Manufacturer data point */\n    uint16_t service_data_len;    /*!< Service data length */\n    uint8_t *p_service_data;      /*!< Service data point */\n    uint16_t service_uuid_len;    /*!< Service uuid length */\n    uint8_t *p_service_uuid;      /*!< Service uuid array point */\n    uint8_t flag;         /*!< Advertising flag of discovery mode, see BLE_ADV_DATA_FLAG detail */\n} esp_ble_adv_data_t;\n\n\n\n\nIn this example, the structure is initialized as follows:\n\n\nstatic esp_ble_adv_data_t heart_rate_adv_config = {\n    .set_scan_rsp = false,\n    .include_name = true,\n    .include_txpower = true,\n    .min_interval = 0x0006,\n    .max_interval = 0x0010,\n    .appearance = 0x00,\n    .manufacturer_len = 0, //TEST_MANUFACTURER_DATA_LEN,\n    .p_manufacturer_data =  NULL, //&test_manufacturer[0],\n    .service_data_len = 0,\n    .p_service_data = NULL,\n    .service_uuid_len = sizeof(heart_rate_service_uuid),\n    .p_service_uuid = heart_rate_service_uuid,\n    .flag = (ESP_BLE_ADV_FLAG_GEN_DISC | ESP_BLE_ADV_FLAG_BREDR_NOT_SPT),\n};\n\n\n\n\nThe minimum and maximum slave preferred connection intervals are set in units of\n1.25 ms. In this example, the minimum slave preferred connection interval is\ndefined as 0x0006 * 1.25 ms = 7.5 ms and the maximum slave preferred connection\ninterval is initialized as 0x0010 * 1.25 ms = 20 ms.\n\n\nAn advertising payload can be up to 31 bytes of data. It is possible that some\nof the parameters surpass the 31-byte advertisement packet limit which causes\nthe stack to cut the message and leave some of the parameters out. To solve\nthis, usually the longer parameters are stored in the scan response, which can\nbe configured using the same \nesp_ble_gap_config_adv_data()\n function and an\nadditional esp_ble_adv_data_t type structure with the .set_scan_rsp parameter is\nset to true. Finally, to set the device name the\n\nesp_ble_gap_set_device_name()\n function is used. The registering event\nhandler is shown as follows:\n\n\nstatic void gatts_profile_event_handler(esp_gatts_cb_event_t event,\nesp_gatt_if_t gatts_if, esp_ble_gatts_cb_param_t *param)\n{\n    ESP_LOGE(GATTS_TABLE_TAG, \"event = %x\\n\",event);\n    switch (event) {\n        case ESP_GATTS_REG_EVT:\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n            esp_ble_gap_set_device_name(SAMPLE_DEVICE_NAME);\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n            esp_ble_gap_config_adv_data(&heart_rate_adv_config);\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n...\n\n\n\n\nGAP Event Handler\n\n\nOnce the advertising data have been set, the\n\nESP_GAP_BLE_ADV_DATA_SET_COMPLETE_EVT\n is triggered and managed by the GAP\nevent handler. Moreover, an \nESP_GAP_BLE_SCAN_RSP_DATA_SET_COMPLETE_EVT\n is\ntriggered as well if the scan response is also set. Once the configuration of\nthe advertising and scan response data has been set, the handler can use any of\nthese events to start advertising, which is done using the\n\nesp_ble_gap_start_advertising()\n function:\n\n\nstatic void gap_event_handler(esp_gap_ble_cb_event_t event, esp_ble_gap_cb_param_t *param)\n{\n    ESP_LOGE(GATTS_TABLE_TAG, \"GAP_EVT, event %d\\n\", event);\n\n    switch (event) {\n    case ESP_GAP_BLE_ADV_DATA_SET_COMPLETE_EVT:\n        esp_ble_gap_start_advertising(&heart_rate_adv_params);\n        break;\n    case ESP_GAP_BLE_ADV_START_COMPLETE_EVT:\n        //advertising start complete event to indicate advertising start successfully or failed\n        if (param->adv_start_cmpl.status != ESP_BT_STATUS_SUCCESS) {\n            ESP_LOGE(GATTS_TABLE_TAG, \"Advertising start failed\\n\");\n        }\n        break;\n    default:\n        break;\n    }\n}\n\n\n\n\nThe function to start advertising takes a structure of type\n\nesp_ble_adv_params_t\n with the advertising parameters required.\n\n\n/// Advertising parameters\ntypedef struct {\n    uint16_t adv_int_min; /*!< Minimum advertising interval for undirected and low duty cycle directed advertising.\n    Range: 0x0020 to 0x4000\n    Default: N = 0x0800 (1.28 second)\n    Time = N * 0.625 msec\n    Time Range: 20 ms to 10.24 sec */\n    uint16_t adv_int_max; /*!< Maximum advertising interval for undirected and low duty cycle directed advertising.\n    Range: 0x0020 to 0x4000\n    Default: N = 0x0800 (1.28 second)\n    Time = N * 0.625 msec\n    Time Range: 20 ms to 10.24 sec */\n    esp_ble_adv_type_t adv_type;            /*!< Advertising type */\n    esp_ble_addr_type_t own_addr_type;      /*!< Owner bluetooth device address type */\n    esp_bd_addr_t peer_addr;                /*!< Peer device bluetooth device address */\n    esp_ble_addr_type_t peer_addr_type;     /*!< Peer device bluetooth device address type */\n    esp_ble_adv_channel_t channel_map;      /*!< Advertising channel map */\n    esp_ble_adv_filter_t adv_filter_policy; /*!< Advertising filter policy */\n} esp_ble_adv_params_t;\n\n\n\n\nNote that \nesp_ble_gap_config_adv_data()\n configures the data that is\nadvertised to the client and takes an \nesp_ble_adv_data_t structure\n, while\n\nesp_ble_gap_start_advertising()\n makes the server to actually start\nadvertising and takes an \nesp_ble_adv_params_t\n structure. The advertising\ndata is the information that is shown to the client, while the advertising\nparameters are the configuration required by the BLE stack to execute.\n\n\nFor this example, the advertisement parameters are initialized as follows:\n\n\nstatic esp_ble_adv_params_t heart_rate_adv_params = {\n    .adv_int_min        = 0x20,\n    .adv_int_max        = 0x40,\n    .adv_type           = ADV_TYPE_IND,\n    .own_addr_type      = BLE_ADDR_TYPE_PUBLIC,\n    //.peer_addr            =\n    //.peer_addr_type       =\n    .channel_map        = ADV_CHNL_ALL,\n    .adv_filter_policy = ADV_FILTER_ALLOW_SCAN_ANY_CON_ANY,\n};\n\n\n\n\nThese parameters configure the advertising interval between 20 ms to 40 ms. The\nadvertisement is of type ADV_IND, which is generic, not directed to a particular\ncentral device and advertises the server as connectable. The address type is\npublic, uses all channels and allows both scan and connection requests from any\ncentral.\n\n\nIf the advertising started successfully, an\n\nESP_GAP_BLE_ADV_START_COMPLETE_EVT\n event is generated which in this example\nis used to check if the advertising status is indeed advertising or otherwise\nprint an error message.\n\n\n...\n    case ESP_GAP_BLE_ADV_START_COMPLETE_EVT:\n        //advertising start complete event to indicate advertising start successfully or failed\n        if (param->adv_start_cmpl.status != ESP_BT_STATUS_SUCCESS) {\n            ESP_LOGE(GATTS_TABLE_TAG, \"Advertising start failed\\n\");\n        }\n        break;\n...\n\n\n\n\nGATT Event Handlers\n\n\nWhen an Application Profile is registered, an \nESP_GATTS_REG_EVT\n event is\ntriggered. The parameters of the \nESP_GATTS_REG_EVT\n are:\n\n\nesp_gatt_status_t status;    /*!< Operation status */\nuint16_t app_id;             /*!< Application id which input in register API */\n\n\n\n\nIn addition to the previous parameters, the event also contains the GATT\ninterface assigned by the BLE stack. The event is captured by the\n\ngatts_event_handler()\n which stores the generated interface in the profile\ntable and then forwards it to the corresponding profile event handler.\n\n\nstatic void gatts_event_handler(esp_gatts_cb_event_t event, esp_gatt_if_t gatts_if, esp_ble_gatts_cb_param_t *param)\n{\n    ESP_LOGI(GATTS_TABLE_TAG, \"EVT %d, gatts if %d\\n\", event, gatts_if);\n\n    /* If event is register event, store the gatts_if for each profile */\n    if (event == ESP_GATTS_REG_EVT) {\n        if (param->reg.status == ESP_GATT_OK) {\n            heart_rate_profile_tab[HEART_PROFILE_APP_IDX].gatts_if = gatts_if;\n        } else {\n            ESP_LOGI(GATTS_TABLE_TAG, \"Reg app failed, app_id %04x, status %d\\n\",\n                    param->reg.app_id,\n                    param->reg.status);\n            return;\n        }\n    }\n\n    do {\n        int idx;\n        for (idx = 0; idx < HEART_PROFILE_NUM; idx++) {\n            if (gatts_if == ESP_GATT_IF_NONE || /* ESP_GATT_IF_NONE, not specify a certain gatt_if, need to call every profile cb function */\n            gatts_if == heart_rate_profile_tab[idx].gatts_if) {\n                if (heart_rate_profile_tab[idx].gatts_cb) {\n                    heart_rate_profile_tab[idx].gatts_cb(event, gatts_if, param);\n                }\n            }\n        }\n    } while (0);\n}\n\n\n\n\nCreating Services and Characteristics with the Attribute Table\n\n\nThe register event is used to create a table of profile attributes by employing\nthe \nesp_ble_gatts_create_attr_tab()\n function. This function takes an\nargument of type \nesp_gatts_attr_db_t\n which corresponds to a look up table\nkeyed by the enumeration values defined in the header file.\n\n\nThe \nesp_gatts_attr_db_t\n structure has two members:\n\n\nesp_attr_control_t    attr_control;       /*!< The attribute control type*/\nesp_attr_desc_t       att_desc;           /*!< The attribute type*/\n\n\n\n\nThe attr_control is the auto-respond parameter which can be set as\n\nESP_GATT_AUTO_RSP\n to allow the BLE stack to take care of responding messages\nwhen read or write events arrive. The other option is \nESP_GATT_RSP_BY_APP\n\nwhich allows to manually respond to messages using the\n\nesp_ble_gatts_send_response()\n function.\n\n\nThe \natt_desc\n is the attribute description which is made of:\n\n\nuint16_t uuid_length;      /*!< UUID length */\nuint8_t  *uuid_p;          /*!< UUID value */\nuint16_t perm;             /*!< Attribute permission */\nuint16_t max_length;       /*!< Maximum length of the element*/\nuint16_t length;           /*!< Current length of the element*/\nuint8_t  *value;           /*!< Element value array*/\n\n\n\n\nFor example, the first element of the table in this example is the service\nattribute:\n\n\n[HRS_IDX_SVC]                       =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&primary_service_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint16_t), sizeof(heart_rate_svc), (uint8_t *)&heart_rate_svc}},\n\n\n\n\nThe initialization values are:\n\n\n\n\n[HRS_IDX_SVC]\n: Named or designated initializer in the enum table.\n\n\nESP_GATT_AUTO_RSP\n: Auto respond configuration, set to respond automatically by the stack.\n\n\nESP_UUID_LEN_16\n: UUID length set to 16 bits.\n\n\n(uint8_t *)&primary_service_uuid\n: UUID to identify the service as a primary one (0x2800).\n\n\nESP_GATT_PERM_READ\n: Read Permission for the service.\n\n\nsizeof(uint16_t)\n: Maximum length of the service UUID (16 bits).\n\n\nsizeof(heart_rate_svc)\n: Current service length set to the size of the variable \nheart_rate_svc\n, which is 16 bits.\n\n\n(uint8_t *)&heart_rate_svc\n: Service attribute value set to the variable \nheart_rate_svc\n which contains the Heart Rate Service UUID (0x180D).\n\n\n\n\nThe rest of the attributes is initialized in the same way. Some attributes also\nhave the \nNOTIFY\n property which is set by \n&char_prop_notify\n. The complete\ntable structure is initialized as follows:\n\n\n/// Full HRS Database Description - Used to add attributes into the database\nstatic const esp_gatts_attr_db_t heart_rate_gatt_db[HRS_IDX_NB] =\n{\n    // Heart Rate Service Declaration\n    [HRS_IDX_SVC]                       =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&primary_service_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint16_t), sizeof(heart_rate_svc), (uint8_t *)&heart_rate_svc}},\n\n    // Heart Rate Measurement Characteristic Declaration\n    [HRS_IDX_HR_MEAS_CHAR]            =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_notify}},\n\n    // Heart Rate Measurement Characteristic Value\n    [HRS_IDX_HR_MEAS_VAL]               =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&heart_rate_meas_uuid, ESP_GATT_PERM_READ,\n      HRPS_HT_MEAS_MAX_LEN,0, NULL}},\n\n    // Heart Rate Measurement Characteristic - Client Characteristic Configuration Descriptor\n    [HRS_IDX_HR_MEAS_NTF_CFG]           =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_client_config_uuid, ESP_GATT_PERM_READ|ESP_GATT_PERM_WRITE,\n      sizeof(uint16_t),sizeof(heart_measurement_ccc), (uint8_t *)heart_measurement_ccc}},\n\n    // Body Sensor Location Characteristic Declaration\n    [HRS_IDX_BOBY_SENSOR_LOC_CHAR]  =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_read}},\n\n    // Body Sensor Location Characteristic Value\n    [HRS_IDX_BOBY_SENSOR_LOC_VAL]   =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&body_sensor_location_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint8_t), sizeof(body_sensor_loc_val), (uint8_t *)body_sensor_loc_val}},\n\n    // Heart Rate Control Point Characteristic Declaration\n    [HRS_IDX_HR_CTNL_PT_CHAR]          =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_read_write}},\n\n    // Heart Rate Control Point Characteristic Value\n    [HRS_IDX_HR_CTNL_PT_VAL]             =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&heart_rate_ctrl_point, ESP_GATT_PERM_WRITE|ESP_GATT_PERM_READ,\n      sizeof(uint8_t), sizeof(heart_ctrl_point), (uint8_t *)heart_ctrl_point}},\n};\n\n\n\n\nStarting the Service\n\n\nWhen the attribute table is created, an \nESP_GATTS_CREAT_ATTR_TAB_EVT\n event is triggered. This event has the following parameters:\n\n\nesp_gatt_status_t status;    /*!< Operation status */\nesp_bt_uuid_t svc_uuid;      /*!< Service uuid type */\nuint16_t num_handle;         /*!< The number of the attribute handle to be added to the gatts database */\nuint16_t *handles;           /*!< The number to the handles */\n\n\n\n\nThis example uses this event to print information and to check that the size of the created table equals the number of elements in the enumeration HRS_IDX_NB. If the table is correctly created, the attribute handles are copied into the handle table heart_rate_handle_table and the service is started using the \nesp_ble_gatts_start_service()\n function:\n\n\ncase ESP_GATTS_CREAT_ATTR_TAB_EVT:{\n        ESP_LOGI(GATTS_TABLE_TAG, \"The number handle =%x\\n\",param->add_attr_tab.num_handle);\n        if (param->add_attr_tab.status != ESP_GATT_OK){\n            ESP_LOGE(GATTS_TABLE_TAG, \"Create attribute table failed, error code=0x%x\", param->add_attr_tab.status);\n        }\n        else if (param->add_attr_tab.num_handle != HRS_IDX_NB){\n            ESP_LOGE(GATTS_TABLE_TAG, \"Create attribute table abnormally, num_handle (%d) \\\n                    doesn't equal to HRS_IDX_NB(%d)\", param->add_attr_tab.num_handle, HRS_IDX_NB);\n        }\n        else {\n            memcpy(heart_rate_handle_table, param->add_attr_tab.handles, sizeof(heart_rate_handle_table));\n            esp_ble_gatts_start_service(heart_rate_handle_table[HRS_IDX_SVC]);\n        }\n        break;\n\n\n\n\nThe handles stored in the handles pointer of the event parameters are numbers\nthat identify each attribute. The handles can be used to know which\ncharacteristic is being read or written to, therefore they can be passed around\nand to upper layers of the application to handle different actions.\n\n\nFinally, the heart_rate_handle_table contains the Application Profile in the\nform of a structure with information about the attribute parameters as well as\nGATT interface, connection ID, permissions and application ID. The profile\nstructure is shown as follows, note that not all members are used in this\nexample:\n\n\nstruct gatts_profile_inst {\n    esp_gatts_cb_t gatts_cb;\n    uint16_t gatts_if;\n    uint16_t app_id;\n    uint16_t conn_id;\n    uint16_t service_handle;\n    esp_gatt_srvc_id_t service_id;\n    uint16_t char_handle;\n    esp_bt_uuid_t char_uuid;\n    esp_gatt_perm_t perm;\n    esp_gatt_char_prop_t property;\n    uint16_t descr_handle;\n    esp_bt_uuid_t descr_uuid;\n};\n\n\n\n\nInteraction with the GATT Server\n\n\nThere are many tools that allow you to manage the connection to the GATT server.\nOn Linux, we will use \nhcitool\n and\ngatttool\n. In Windows, you can use a tool\ncalled \nBluetooth LE Explorer\n, that implements, albeit graphically, the same\nfunctionality.\n\n\nFor this part of the lab assignment, you have to make visible the bluetooth\ncontroller of your host machine (laptop/pc) to the virtual machine used for the\ncourse.\n\n\nUsing \nhcitool\n and \ngatttool\n in client mode\n\n\nScanning available devices: \nhcitool\n\n\nhcitool\n is a command line tool that allows you to manage the Bluetooth\ninterface of the computer on which it is running. In our case, We will need to\ndetermine the Bluetooth MAC address of our server.  To do this, first of all, we\nwill perform a scan of the devices BLE available in the environment using the\ncommand:\n\n\nsudo hcitool lescan\n\n\n\n\n\n\nNote\n\n\nThis command will not work if you did not make the bluetooth controller\navailable to the virtual machine.\n\n\n\n\nIf all went well, one line per available BLE device in the announcement phase\nwill be displayed. Among them, we must find our device, and annotate its MAC\naddress.\n\n\n\n\nTask\n\n\nEdit the file \nmain/gatts_table_creat_demo.c\n and modify the name of your\ndevice, which will be announced in each emmited advertisment packet in the\n\nadvertising\n phase. You can achieve this by modifying the corresponding\nfield of the structure \nraw_adv_data\n. Next, compile and flash the example,\nand start a session of scanning of BLE devices using the command:\n\n\nsudo hcitool lescan\n\n\nYou should see your device on one of the output lines. Write down or\nremember its MAC address.\n\n\n\n\nInteracting with the GATT server: \ngatttool\n.\n\n\n\n\nTask 4.1\n\n\nWrite a small pdf report documenting all the steps and Tasks in this\nsection.\n\n\n\n\nOnce the Bluetooth MAC address of the device is obtained, we must proceed in two\nphases. The first one is to pair it to the ESP device. The second, the\ninteraction with the GATT table. In both cases, you will use the \ngatttool\n tool\nfrom the command line.\n\n\nTo start a \ngatttool\n session, we'll invoke the tool in interactive mode, using\nthe command:\n\n\ngatttool -b MAC -I\n\n\n\n\nThis will open an interactive console, waiting for the corresponding commands.\n\n\nTo perform the pairing, and considering that the Bluetooth MAC is already known,\nwe will use the \nconnect\n command. If everything went well, we should observe a\nchange in the color of the prompt, and the \nConnection successful\n message. At\nthis point, see how the debugging output of ESP32 shows the messages\ncorresponding to the pairing process.\n\n\nFrom the \ngatttool\n terminal, you can run the command \nhelp\n to get help (in the\nform of a list of available commands):\n\n\ngatttool -b 24:6F:28:36:60:B2 -I\n[24:6F:28:36:60:B2][LE]> connect\nAttempting to connect to 24:6F:28:36:60:B2\nConnection successful\n[24:6F:28:36:60:B2][LE]> help\nhelp                                           Show this help\nexit                                           Exit interactive mode\nquit                                           Exit interactive mode\nconnect         [address [address type]]       Connect to a remote device\ndisconnect                                     Disconnect from a remote device\nprimary         [UUID]                         Primary Service Discovery\nincluded        [start hnd [end hnd]]          Find Included Services\ncharacteristics [start hnd [end hnd [UUID]]]   Characteristics Discovery\nchar-desc       [start hnd] [end hnd]          Characteristics Descriptor Discovery\nchar-read-hnd   <handle>                       Characteristics Value/Descriptor Read by handle\nchar-read-uuid  <UUID> [start hnd] [end hnd]   Characteristics Value/Descriptor Read by UUID\nchar-write-req  <handle> <new value>           Characteristic Value Write (Write Request)\nchar-write-cmd  <handle> <new value>           Characteristic Value Write (No response)\nsec-level       [low | medium | high]          Set security level. Default: low\nmtu             <value>                        Exchange MTU for GATT/ATT\n\n\n\n\nWe'll start by looking at the list of GATT server features.\n\n\n\n\nTask\n\n\nUsing the corresponding command (\ncharacteristics\n), consult and write down\nthe features available on your GATT server.\n\n\n\n\nOne of these characteristics will be of crucial interest, since it will allow us\naccess, through its UUID, the instant heart rate measurement value, as well as\nas well as the notification settings on that value. To determine which of the\nlines is the one that interests us, look at the returned UUID value for each of\nthem, and determine, based on the macro \nGATTS_CHAR_UUID_TEST_A\n which one is\nit.\n\n\nTo interact with this feature, we will need to know its handler, to use it as a\nparameter in the \ngatttool\n commands. This handler is shown, for each line,\nafter the string \nchar value handle\n.\n\n\n\n\nTask\n\n\nThe handler that allows reading the \nHeart Rate Value\n has associated a\nhandler of type character. Write its value down.\n\n\n\n\nTo read the value of the characteristic we can use the read command, using the\nannotated handler as argument (\nchar-read-hnd handler\n).\n\n\n\n\nTask\n\n\nRead the heart rate monitoring value characteristic. What do you obtain? You\nshould observe a four-byte return value with value 0x00. These values\ncorrespond to those of the \nchar_value\n variable in your code. Modify them,\nrebuild the project and \nflash\n it on the ESP32. Repeat the read. Did you\nread the new value?\n\n\n\n\n\n\nTask\n\n\nNow try to write to the characteristic. Use the command \nchar-write-cmd\nhandler value\n, where value is, for example, \n11223344\n. It's possible?\nWhy?\n\n\n\n\nWe will now write to its client configuration characteristic descriptor. Its hancler\nis the handler of the characteristic's value plus one. For instance, if the\nhandle for the value is \n0x0001\n, its cliente configuration characteristic\nwould have the handle \n0x0002\n.\n\n\n\n\nTask\n\n\nTry now to write to the client configuration characteristic. Use the command\n\nchar-write-cmd handler value\n, where value is, for example, \n0100\n. It's\npossible? Why?\n\n\n\n\nTask 4.2\n\n\nAs you may have noticed, it is possible to read from the monitoring value,\nand write to config value. We will use this last feature to configure\nnotifications about the monitoring value. This way, each time the value\nchanges, the clients that have activated the notifications will receive the\nnew value.\n\n\nTo achieve this we need to modify some parts of our code. Specifically, we\nwill need:\n\n\n\n\nCreate a new task that periodically modifies the heart rate value (in our\n   case generating a new random value). This task will consist of an\n   infinite loop that, generates a new value for the characteristic and\n   correctly updates the gatt table. Then, if notifications have been\n   activated, it sends the new value to the clients:\n\n\n\n\nstatic void publish_data_task(void *pvParameters)\n{\n    while (1) {\n        ESP_LOGI(\"APP\", \"Sending data...\");\n\n        // Step 1: Update characteristic value ...\n\n        // Step 2: If indications are active send the indication...\n\n        // Step 3: Sleep for one second...\n        vTaskDelay( 1000. / portTICK_PERIOD_MS);\n    }\n}\n\n\n\n\nThis routine should be created in response to the connection event by a\nclient, using, for example, the invocation to:\n\n\nxTaskCreate(&publish_data_task, \"publish_data_task\", 4096, NULL, 5, NULL);\n\n\n\n\n\n\n\n\nThe update of the value, carried out periodically and randomly, will modify\nbyte 1 of the heart rate value, taking a random value between 0 and 255 (as an\nadditional note, current heart rate monitors support values higher for heart\nrate, although the configuration of this functionality is outside the scope of\npractice), and then update the internal gatt table using the\n\nesp_ble_gatts_set_attr_value\n\nfunction.\n\n\n\n\n\n\nThe verification of the activation or not of the notification is done by\nconsulting the two bytes of the corresponding client configuration\ncharacteristic. If these values are \n0x01\n and\n0x00\n (positions 0 and 1,\nrespectively), the notifications are active, and therefore, the notification\nshall be sent. You will need to use the function\n\nesp_ble_gatts_get_attr_value\n\nto read this descriptor.\n\n\n\n\n\n\nTo send the notification, we will use the following function:\n\n\n\n\n\n\nesp_ble_gatts_send_indicate(heart_rate_profile_tab[0].gatts_if,\n                                      heart_rate_profile_tab[0].conn_id,\n                                      heart_rate_handle_table[IDX_CHAR_VAL_A],\n                                      sizeof(char_value), char_value, false);\n\n\n\n\nThe activation of notifications from \ngatttool\n will be done by writing the\nvalue \n0x0100\n in the client configuration characteristic, this is:\n\n\nchar-write-cmd HANDLER 0100\n\n\n\n\nIf you also modify the UUIDs by those provided in the specification of Bluetooth\nfor the \nHeart Rate Service\n, and everything has been configured correctly, your\nESP32 should be able to interface with any heart rate monitor to, for example,\nAndroid. To do this, use the following UUIDs:\n\n\n\n\nstatic const uint16_t GATTS_SERVICE_UUID_TEST      = 0x180D; //0x00FF;\n\n\nstatic const uint16_t GATTS_CHAR_UUID_TEST_A       = 0x2A37; //0xFF01;\n\n\nstatic const uint16_t GATTS_CHAR_UUID_TEST_B       = 0x2A38; //0xFF02;\n\n\nstatic const uint16_t GATTS_CHAR_UUID_TEST_C       = 0x2A39; //0xFF03;\n\n\n\n\nDeliver the modified code with a small pdf report showing how you activate the\nnotifications with gatttool, and how the node then sends a new value every\nsecond.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P4/#lab-4-bluetooth-low-energy-ble",
            "text": "",
            "title": "Lab 4. Bluetooth Low Energy (BLE)"
        },
        {
            "location": "/Subjects/NP1/P4/#goals",
            "text": "Dissect in detail a GATT table construction  firmware  (GATT server) using the\n  ESP-IDF API.  Learn to use  gatttool  to interact with the GATT server.  Modify the GATT server to accept notification requests from the client,\n  and to publish updated values for a certain characteristic on demand.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP1/P4/#gatt-sever-implementation",
            "text": "",
            "title": "GATT Sever Implementation"
        },
        {
            "location": "/Subjects/NP1/P4/#introduction",
            "text": "In this lab assignmet, we will deploy a GATT server using the ESP-IDF API. This\nAPI exposes the functionalities of Bluedroid, the Bluetooth stack (including\nBLE) that provides ESP-IDF for the development of Bluetooth applications.  We will use the example from  examples/bluetooth/bluedroid/ble/gatt_server_service_table ,\nwhich example implements a Bluetooth Low Energy (BLE) Generic\nAttribute (GATT) Server using a table-like data structure to define the server\nservices and characteristics such as the one shown in the figure below\nTherefore, it demonstrates a practical way to define the server functionality in\none place instead of adding services and characteristics one by one.  This example implements the  Heart Rate Profile  as defined by the  Traditional\nProfile Specifications .     We will therefore display three characteristics. Of them, the most important for\nus will be the heart rate measurement value, with its value ( Heart Rate\nMeasurement Value ) and its notification settings ( Heart Rate Measurement\nNotification Configuration ).  Due to the complexity of the code (at least in its initial part), this document\nfollows the program workflow and breaks down the code in order to make sense of\nevery section and reasoning behind the implementation.",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/NP1/P4/#includes",
            "text": "Let\u2019s start by taking a look at the included headers:  #include \"freertos/FreeRTOS.h\"\n#include \"freertos/task.h\"\n#include \"freertos/event_groups.h\"\n#include \"esp_system.h\"\n#include \"esp_log.h\"\n#include \"nvs_flash.h\"\n#include \"esp_bt.h\"\n#include \"esp_gap_ble_api.h\"\n#include \"esp_gatts_api.h\"\n#include \"esp_bt_main.h\"\n#include \"gatts_table_creat_demo.h\"\n#include \"esp_gatt_common_api.h\"  These includes are required for the  FreeRTOS  and underlaying system components\nto run, including logging functionality and a library to store data in\nnon-volatile flash memory. We are interested in  bt.h ,  esp_bt_main.h , esp_gap_ble_api.h  and  esp_gatts_api.h  which expose the BLE APIs required\nto implement this example.   esp_bt.h : implements BT controller and VHCI configuration procedures from the host side.  esp_bt_main.h : implements initialization and enabling of the Bluedroid stack.  esp_gap_ble_api.h : implements GAP configuration such as advertising and connection parameters.  esp_gatts_api.h : implements GATT Server configuration such as creating services and characteristics.",
            "title": "Includes"
        },
        {
            "location": "/Subjects/NP1/P4/#service-table",
            "text": "The header file  gatts_table_creat_demo.h  is where an enumeration of the\nservices and characteristics is created:  enum\n{\n    IDX_SVC,\n    IDX_CHAR_A,\n    IDX_CHAR_VAL_A,\n    IDX_CHAR_CFG_A,\n\n    IDX_CHAR_B,\n    IDX_CHAR_VAL_B,\n\n    IDX_CHAR_C,\n    IDX_CHAR_VAL_C,\n\n    HRS_IDX_NB,\n};  The enumeration elements are set up in the same order as the Heart Rate Profile\nattributes, starting with the service followed by the characteristics of that\nservice. In addition, the Heart Rate Measurement characteristic has a Client\nCharacteristic Configuration (CCC) descriptor which is an additional attribute\nthat describes if the characteristic has notifications enabled. The enumeration\nindex can be used to identify each element later when creating the actual\nattributes table. In summary, the elements are described as follows:   IDX_SVC : Heart Rate Service index  IDX_CHAR_A : Heart Rate Measurement characteristic index  IDX_CHAR_VAL_A : Heart Rate Measurement characteristic value index  IDX_CHAR_CFG_A : Heart Rate Measurement notifications configuration (CCC) index  IDX_CHAR_B : Heart Rate Body Sensor Location characteristic index  IDX_CHAR_VAL_B : Heart Rate Body Sensor Location characteristic value index  IDX_CHAR_C : Heart Rate Control Point characteristic index  IDX_CHAR_VAL_C : Heart Rate Control Point characteristic value index  IDX_NB : Number of table elements.",
            "title": "Service Table"
        },
        {
            "location": "/Subjects/NP1/P4/#main-entry-point",
            "text": "The entry point to this example is the  app_main()  function:  void app_main(void)\n{\n    esp_err_t ret;\n\n    /* Initialize NVS. */\n    ret = nvs_flash_init();\n    if (ret == ESP_ERR_NVS_NO_FREE_PAGES || ret == ESP_ERR_NVS_NEW_VERSION_FOUND) {\n        ESP_ERROR_CHECK(nvs_flash_erase());\n        ret = nvs_flash_init();\n    }\n    ESP_ERROR_CHECK( ret );\n\n    ESP_ERROR_CHECK(esp_bt_controller_mem_release(ESP_BT_MODE_CLASSIC_BT));\n\n    esp_bt_controller_config_t bt_cfg = BT_CONTROLLER_INIT_CONFIG_DEFAULT();\n    ret = esp_bt_controller_init(&bt_cfg);\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable controller failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bt_controller_enable(ESP_BT_MODE_BLE);\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable controller failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bluedroid_init();\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s init bluetooth failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_bluedroid_enable();\n    if (ret) {\n        ESP_LOGE(GATTS_TABLE_TAG, \"%s enable bluetooth failed: %s\", __func__, esp_err_to_name(ret));\n        return;\n    }\n\n    ret = esp_ble_gatts_register_callback(gatts_event_handler);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gatts register error, error code = %x\", ret);\n        return;\n    }\n\n    ret = esp_ble_gap_register_callback(gap_event_handler);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gap register error, error code = %x\", ret);\n        return;\n    }\n\n    ret = esp_ble_gatts_app_register(ESP_APP_ID);\n    if (ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"gatts app register error, error code = %x\", ret);\n        return;\n    }\n\n    esp_err_t local_mtu_ret = esp_ble_gatt_set_local_mtu(500);\n    if (local_mtu_ret){\n        ESP_LOGE(GATTS_TABLE_TAG, \"set local  MTU failed, error code = %x\", local_mtu_ret);\n    }\n}  The main function starts by initializing the non-volatile storage library in\norder to be able to save parameters in flash memory.  ret = nvs_flash_init();",
            "title": "Main Entry Point"
        },
        {
            "location": "/Subjects/NP1/P4/#bt-controller-and-stack-initialization",
            "text": "The main function also initializes the BT controller by first creating a BT\ncontroller configuration structure named  esp_bt_controller_config_t  with\ndefault settings generated by the  BT_CONTROLLER_INIT_CONFIG_DEFAULT()  macro.  The BT controller implements the Host Controller Interface (HCI) on the\ncontroller side, the Link Layer (LL) and the Physical Layer (PHY). The BT\nController is invisible to the user applications and deals with the lower layers\nof the BLE stack. The controller configuration includes setting the BT\ncontroller stack size, priority and HCI baud rate. With the settings created,\nthe BT controller is initialized and enabled with the  esp_bt_controller_init() \nfunction:  esp_bt_controller_config_t bt_cfg = BT_CONTROLLER_INIT_CONFIG_DEFAULT();\nret = esp_bt_controller_init(&bt_cfg);  Next, the controller is enabled in BLE Mode.  ret = esp_bt_controller_enable(ESP_BT_MODE_BLE);  There are four Bluetooth modes supported:   ESP_BT_MODE_IDLE : Bluetooth not running  ESP_BT_MODE_BLE : BLE mode  ESP_BT_MODE_CLASSIC_BT : BT Classic mode  ESP_BT_MODE_BTDM : Dual mode (BLE + BT Classic)   After the initialization of the BT controller, the Bluedroid stack, which\nincludes the common definitions and APIs for both BT Classic and BLE, is\ninitialized and enabled by using:  ret = esp_bluedroid_init();\nret = esp_bluedroid_enable();  The Bluetooth stack is up and running at this point in the program flow, however\nthe functionality of the application has not been defined yet. The functionality\nis defined by reacting to events such as what happens when another device tries\nto read or write parameters and establish a connection.  The two main managers of events are the GAP and GATT event handlers. The\napplication needs to register a callback function for each event handler in\norder to let the application know which functions are going to handle the GAP\nand GATT events:  esp_ble_gatts_register_callback(gatts_event_handler);\nesp_ble_gap_register_callback(gap_event_handler);  The functions  gatts_event_handler()  and  gap_event_handler()  handle all the\nevents that are pushed to the application from the BLE stack.",
            "title": "BT Controller and Stack Initialization"
        },
        {
            "location": "/Subjects/NP1/P4/#application-profiles",
            "text": "This example implements one Application Profile for the Heart Rate Service. An\nApplication Profile is a way to group functionality which is designed to be used\nby one client application, for example one smartphone mobile app. In this way,\ndifferent types of profiles can be accommodated in one server.  The Application Profile ID, which is an user-assigned number to identify each\nprofile, is used to register the profile in the stack, in this example the ID is\n0x55.  #define PROFILE_NUM                 1\n#define PROFILE_APP_IDX             0\n#define ESP_APP_ID                  0x55  The profiles are stored in the  heart_rate_profile_tab  array. Since there is\nonly one profile in this example, one element is stored in the array with index\nzero as defined by the  PROFILE_APP_IDX . Additionally, the profile event\nhandler callback function is initialized. Each application on the GATT server\nuses a different interface, represented by the  gatts_if  parameter. For\ninitialization, this parameter is set to  ESP_GATT_IF_NONE , later when the\napplication is registered, the  gatts_if  parameter is updated with the\ncorresponding interface generated by the stack.  /* One gatt-based profile one app_id and one gatts_if, this array will store the gatts_if returned by ESP_GATTS_REG_EVT */\nstatic struct gatts_profile_inst heart_rate_profile_tab[PROFILE_NUM] = {\n    [PROFILE_APP_IDX] = {\n        .gatts_cb = gatts_profile_event_handler,\n        .gatts_if = ESP_GATT_IF_NONE,       /* Not get the gatt_if, so initial is ESP_GATT_IF_NONE */\n    },\n};  The application registration takes place inside  app_main()  using the esp_ble_gatts_app_register()  function:  esp_ble_gatts_app_register(ESP_HEART_RATE_APP_ID);",
            "title": "Application Profiles"
        },
        {
            "location": "/Subjects/NP1/P4/#setting-gap-parameters",
            "text": "The register application event is the first one that is triggered during the lifetime of the program. This example uses this event to configure advertising parameters upon registration in the profile event handler. The functions used to achieve this are:   esp_ble_gap_set_device_name() : used to set the advertised device name.  esp_ble_gap_config_adv_data() : used to configure standard advertising data.   The function used to configure standard Bluetooth Specification advertisement parameters is  esp_ble_gap_config_adv_data()  which takes a pointer to an  esp_ble_adv_data_t  structure. The  esp_ble_adv_data_t  data structure for advertising data has the following definition:  typedef struct {\n    bool set_scan_rsp;    /*!< Set this advertising data as scan response or not*/\n    bool include_name;    /*!< Advertising data include device name or not */\n    bool include_txpower; /*!< Advertising data include TX power */\n    int min_interval;     /*!< Advertising data show slave preferred connection min interval */\n    int max_interval;     /*!< Advertising data show slave preferred connection max interval */\n    int appearance;       /*!< External appearance of device */\n    uint16_t manufacturer_len; /*!< Manufacturer data length */\n    uint8_t *p_manufacturer_data; /*!< Manufacturer data point */\n    uint16_t service_data_len;    /*!< Service data length */\n    uint8_t *p_service_data;      /*!< Service data point */\n    uint16_t service_uuid_len;    /*!< Service uuid length */\n    uint8_t *p_service_uuid;      /*!< Service uuid array point */\n    uint8_t flag;         /*!< Advertising flag of discovery mode, see BLE_ADV_DATA_FLAG detail */\n} esp_ble_adv_data_t;  In this example, the structure is initialized as follows:  static esp_ble_adv_data_t heart_rate_adv_config = {\n    .set_scan_rsp = false,\n    .include_name = true,\n    .include_txpower = true,\n    .min_interval = 0x0006,\n    .max_interval = 0x0010,\n    .appearance = 0x00,\n    .manufacturer_len = 0, //TEST_MANUFACTURER_DATA_LEN,\n    .p_manufacturer_data =  NULL, //&test_manufacturer[0],\n    .service_data_len = 0,\n    .p_service_data = NULL,\n    .service_uuid_len = sizeof(heart_rate_service_uuid),\n    .p_service_uuid = heart_rate_service_uuid,\n    .flag = (ESP_BLE_ADV_FLAG_GEN_DISC | ESP_BLE_ADV_FLAG_BREDR_NOT_SPT),\n};  The minimum and maximum slave preferred connection intervals are set in units of\n1.25 ms. In this example, the minimum slave preferred connection interval is\ndefined as 0x0006 * 1.25 ms = 7.5 ms and the maximum slave preferred connection\ninterval is initialized as 0x0010 * 1.25 ms = 20 ms.  An advertising payload can be up to 31 bytes of data. It is possible that some\nof the parameters surpass the 31-byte advertisement packet limit which causes\nthe stack to cut the message and leave some of the parameters out. To solve\nthis, usually the longer parameters are stored in the scan response, which can\nbe configured using the same  esp_ble_gap_config_adv_data()  function and an\nadditional esp_ble_adv_data_t type structure with the .set_scan_rsp parameter is\nset to true. Finally, to set the device name the esp_ble_gap_set_device_name()  function is used. The registering event\nhandler is shown as follows:  static void gatts_profile_event_handler(esp_gatts_cb_event_t event,\nesp_gatt_if_t gatts_if, esp_ble_gatts_cb_param_t *param)\n{\n    ESP_LOGE(GATTS_TABLE_TAG, \"event = %x\\n\",event);\n    switch (event) {\n        case ESP_GATTS_REG_EVT:\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n            esp_ble_gap_set_device_name(SAMPLE_DEVICE_NAME);\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n            esp_ble_gap_config_adv_data(&heart_rate_adv_config);\n            ESP_LOGI(GATTS_TABLE_TAG, \"%s %d\\n\", __func__, __LINE__);\n...",
            "title": "Setting GAP Parameters"
        },
        {
            "location": "/Subjects/NP1/P4/#gap-event-handler",
            "text": "Once the advertising data have been set, the ESP_GAP_BLE_ADV_DATA_SET_COMPLETE_EVT  is triggered and managed by the GAP\nevent handler. Moreover, an  ESP_GAP_BLE_SCAN_RSP_DATA_SET_COMPLETE_EVT  is\ntriggered as well if the scan response is also set. Once the configuration of\nthe advertising and scan response data has been set, the handler can use any of\nthese events to start advertising, which is done using the esp_ble_gap_start_advertising()  function:  static void gap_event_handler(esp_gap_ble_cb_event_t event, esp_ble_gap_cb_param_t *param)\n{\n    ESP_LOGE(GATTS_TABLE_TAG, \"GAP_EVT, event %d\\n\", event);\n\n    switch (event) {\n    case ESP_GAP_BLE_ADV_DATA_SET_COMPLETE_EVT:\n        esp_ble_gap_start_advertising(&heart_rate_adv_params);\n        break;\n    case ESP_GAP_BLE_ADV_START_COMPLETE_EVT:\n        //advertising start complete event to indicate advertising start successfully or failed\n        if (param->adv_start_cmpl.status != ESP_BT_STATUS_SUCCESS) {\n            ESP_LOGE(GATTS_TABLE_TAG, \"Advertising start failed\\n\");\n        }\n        break;\n    default:\n        break;\n    }\n}  The function to start advertising takes a structure of type esp_ble_adv_params_t  with the advertising parameters required.  /// Advertising parameters\ntypedef struct {\n    uint16_t adv_int_min; /*!< Minimum advertising interval for undirected and low duty cycle directed advertising.\n    Range: 0x0020 to 0x4000\n    Default: N = 0x0800 (1.28 second)\n    Time = N * 0.625 msec\n    Time Range: 20 ms to 10.24 sec */\n    uint16_t adv_int_max; /*!< Maximum advertising interval for undirected and low duty cycle directed advertising.\n    Range: 0x0020 to 0x4000\n    Default: N = 0x0800 (1.28 second)\n    Time = N * 0.625 msec\n    Time Range: 20 ms to 10.24 sec */\n    esp_ble_adv_type_t adv_type;            /*!< Advertising type */\n    esp_ble_addr_type_t own_addr_type;      /*!< Owner bluetooth device address type */\n    esp_bd_addr_t peer_addr;                /*!< Peer device bluetooth device address */\n    esp_ble_addr_type_t peer_addr_type;     /*!< Peer device bluetooth device address type */\n    esp_ble_adv_channel_t channel_map;      /*!< Advertising channel map */\n    esp_ble_adv_filter_t adv_filter_policy; /*!< Advertising filter policy */\n} esp_ble_adv_params_t;  Note that  esp_ble_gap_config_adv_data()  configures the data that is\nadvertised to the client and takes an  esp_ble_adv_data_t structure , while esp_ble_gap_start_advertising()  makes the server to actually start\nadvertising and takes an  esp_ble_adv_params_t  structure. The advertising\ndata is the information that is shown to the client, while the advertising\nparameters are the configuration required by the BLE stack to execute.  For this example, the advertisement parameters are initialized as follows:  static esp_ble_adv_params_t heart_rate_adv_params = {\n    .adv_int_min        = 0x20,\n    .adv_int_max        = 0x40,\n    .adv_type           = ADV_TYPE_IND,\n    .own_addr_type      = BLE_ADDR_TYPE_PUBLIC,\n    //.peer_addr            =\n    //.peer_addr_type       =\n    .channel_map        = ADV_CHNL_ALL,\n    .adv_filter_policy = ADV_FILTER_ALLOW_SCAN_ANY_CON_ANY,\n};  These parameters configure the advertising interval between 20 ms to 40 ms. The\nadvertisement is of type ADV_IND, which is generic, not directed to a particular\ncentral device and advertises the server as connectable. The address type is\npublic, uses all channels and allows both scan and connection requests from any\ncentral.  If the advertising started successfully, an ESP_GAP_BLE_ADV_START_COMPLETE_EVT  event is generated which in this example\nis used to check if the advertising status is indeed advertising or otherwise\nprint an error message.  ...\n    case ESP_GAP_BLE_ADV_START_COMPLETE_EVT:\n        //advertising start complete event to indicate advertising start successfully or failed\n        if (param->adv_start_cmpl.status != ESP_BT_STATUS_SUCCESS) {\n            ESP_LOGE(GATTS_TABLE_TAG, \"Advertising start failed\\n\");\n        }\n        break;\n...",
            "title": "GAP Event Handler"
        },
        {
            "location": "/Subjects/NP1/P4/#gatt-event-handlers",
            "text": "When an Application Profile is registered, an  ESP_GATTS_REG_EVT  event is\ntriggered. The parameters of the  ESP_GATTS_REG_EVT  are:  esp_gatt_status_t status;    /*!< Operation status */\nuint16_t app_id;             /*!< Application id which input in register API */  In addition to the previous parameters, the event also contains the GATT\ninterface assigned by the BLE stack. The event is captured by the gatts_event_handler()  which stores the generated interface in the profile\ntable and then forwards it to the corresponding profile event handler.  static void gatts_event_handler(esp_gatts_cb_event_t event, esp_gatt_if_t gatts_if, esp_ble_gatts_cb_param_t *param)\n{\n    ESP_LOGI(GATTS_TABLE_TAG, \"EVT %d, gatts if %d\\n\", event, gatts_if);\n\n    /* If event is register event, store the gatts_if for each profile */\n    if (event == ESP_GATTS_REG_EVT) {\n        if (param->reg.status == ESP_GATT_OK) {\n            heart_rate_profile_tab[HEART_PROFILE_APP_IDX].gatts_if = gatts_if;\n        } else {\n            ESP_LOGI(GATTS_TABLE_TAG, \"Reg app failed, app_id %04x, status %d\\n\",\n                    param->reg.app_id,\n                    param->reg.status);\n            return;\n        }\n    }\n\n    do {\n        int idx;\n        for (idx = 0; idx < HEART_PROFILE_NUM; idx++) {\n            if (gatts_if == ESP_GATT_IF_NONE || /* ESP_GATT_IF_NONE, not specify a certain gatt_if, need to call every profile cb function */\n            gatts_if == heart_rate_profile_tab[idx].gatts_if) {\n                if (heart_rate_profile_tab[idx].gatts_cb) {\n                    heart_rate_profile_tab[idx].gatts_cb(event, gatts_if, param);\n                }\n            }\n        }\n    } while (0);\n}",
            "title": "GATT Event Handlers"
        },
        {
            "location": "/Subjects/NP1/P4/#creating-services-and-characteristics-with-the-attribute-table",
            "text": "The register event is used to create a table of profile attributes by employing\nthe  esp_ble_gatts_create_attr_tab()  function. This function takes an\nargument of type  esp_gatts_attr_db_t  which corresponds to a look up table\nkeyed by the enumeration values defined in the header file.  The  esp_gatts_attr_db_t  structure has two members:  esp_attr_control_t    attr_control;       /*!< The attribute control type*/\nesp_attr_desc_t       att_desc;           /*!< The attribute type*/  The attr_control is the auto-respond parameter which can be set as ESP_GATT_AUTO_RSP  to allow the BLE stack to take care of responding messages\nwhen read or write events arrive. The other option is  ESP_GATT_RSP_BY_APP \nwhich allows to manually respond to messages using the esp_ble_gatts_send_response()  function.  The  att_desc  is the attribute description which is made of:  uint16_t uuid_length;      /*!< UUID length */\nuint8_t  *uuid_p;          /*!< UUID value */\nuint16_t perm;             /*!< Attribute permission */\nuint16_t max_length;       /*!< Maximum length of the element*/\nuint16_t length;           /*!< Current length of the element*/\nuint8_t  *value;           /*!< Element value array*/  For example, the first element of the table in this example is the service\nattribute:  [HRS_IDX_SVC]                       =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&primary_service_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint16_t), sizeof(heart_rate_svc), (uint8_t *)&heart_rate_svc}},  The initialization values are:   [HRS_IDX_SVC] : Named or designated initializer in the enum table.  ESP_GATT_AUTO_RSP : Auto respond configuration, set to respond automatically by the stack.  ESP_UUID_LEN_16 : UUID length set to 16 bits.  (uint8_t *)&primary_service_uuid : UUID to identify the service as a primary one (0x2800).  ESP_GATT_PERM_READ : Read Permission for the service.  sizeof(uint16_t) : Maximum length of the service UUID (16 bits).  sizeof(heart_rate_svc) : Current service length set to the size of the variable  heart_rate_svc , which is 16 bits.  (uint8_t *)&heart_rate_svc : Service attribute value set to the variable  heart_rate_svc  which contains the Heart Rate Service UUID (0x180D).   The rest of the attributes is initialized in the same way. Some attributes also\nhave the  NOTIFY  property which is set by  &char_prop_notify . The complete\ntable structure is initialized as follows:  /// Full HRS Database Description - Used to add attributes into the database\nstatic const esp_gatts_attr_db_t heart_rate_gatt_db[HRS_IDX_NB] =\n{\n    // Heart Rate Service Declaration\n    [HRS_IDX_SVC]                       =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&primary_service_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint16_t), sizeof(heart_rate_svc), (uint8_t *)&heart_rate_svc}},\n\n    // Heart Rate Measurement Characteristic Declaration\n    [HRS_IDX_HR_MEAS_CHAR]            =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_notify}},\n\n    // Heart Rate Measurement Characteristic Value\n    [HRS_IDX_HR_MEAS_VAL]               =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&heart_rate_meas_uuid, ESP_GATT_PERM_READ,\n      HRPS_HT_MEAS_MAX_LEN,0, NULL}},\n\n    // Heart Rate Measurement Characteristic - Client Characteristic Configuration Descriptor\n    [HRS_IDX_HR_MEAS_NTF_CFG]           =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_client_config_uuid, ESP_GATT_PERM_READ|ESP_GATT_PERM_WRITE,\n      sizeof(uint16_t),sizeof(heart_measurement_ccc), (uint8_t *)heart_measurement_ccc}},\n\n    // Body Sensor Location Characteristic Declaration\n    [HRS_IDX_BOBY_SENSOR_LOC_CHAR]  =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_read}},\n\n    // Body Sensor Location Characteristic Value\n    [HRS_IDX_BOBY_SENSOR_LOC_VAL]   =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&body_sensor_location_uuid, ESP_GATT_PERM_READ,\n      sizeof(uint8_t), sizeof(body_sensor_loc_val), (uint8_t *)body_sensor_loc_val}},\n\n    // Heart Rate Control Point Characteristic Declaration\n    [HRS_IDX_HR_CTNL_PT_CHAR]          =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&character_declaration_uuid, ESP_GATT_PERM_READ,\n      CHAR_DECLARATION_SIZE,CHAR_DECLARATION_SIZE, (uint8_t *)&char_prop_read_write}},\n\n    // Heart Rate Control Point Characteristic Value\n    [HRS_IDX_HR_CTNL_PT_VAL]             =\n    {{ESP_GATT_AUTO_RSP}, {ESP_UUID_LEN_16, (uint8_t *)&heart_rate_ctrl_point, ESP_GATT_PERM_WRITE|ESP_GATT_PERM_READ,\n      sizeof(uint8_t), sizeof(heart_ctrl_point), (uint8_t *)heart_ctrl_point}},\n};",
            "title": "Creating Services and Characteristics with the Attribute Table"
        },
        {
            "location": "/Subjects/NP1/P4/#starting-the-service",
            "text": "When the attribute table is created, an  ESP_GATTS_CREAT_ATTR_TAB_EVT  event is triggered. This event has the following parameters:  esp_gatt_status_t status;    /*!< Operation status */\nesp_bt_uuid_t svc_uuid;      /*!< Service uuid type */\nuint16_t num_handle;         /*!< The number of the attribute handle to be added to the gatts database */\nuint16_t *handles;           /*!< The number to the handles */  This example uses this event to print information and to check that the size of the created table equals the number of elements in the enumeration HRS_IDX_NB. If the table is correctly created, the attribute handles are copied into the handle table heart_rate_handle_table and the service is started using the  esp_ble_gatts_start_service()  function:  case ESP_GATTS_CREAT_ATTR_TAB_EVT:{\n        ESP_LOGI(GATTS_TABLE_TAG, \"The number handle =%x\\n\",param->add_attr_tab.num_handle);\n        if (param->add_attr_tab.status != ESP_GATT_OK){\n            ESP_LOGE(GATTS_TABLE_TAG, \"Create attribute table failed, error code=0x%x\", param->add_attr_tab.status);\n        }\n        else if (param->add_attr_tab.num_handle != HRS_IDX_NB){\n            ESP_LOGE(GATTS_TABLE_TAG, \"Create attribute table abnormally, num_handle (%d) \\\n                    doesn't equal to HRS_IDX_NB(%d)\", param->add_attr_tab.num_handle, HRS_IDX_NB);\n        }\n        else {\n            memcpy(heart_rate_handle_table, param->add_attr_tab.handles, sizeof(heart_rate_handle_table));\n            esp_ble_gatts_start_service(heart_rate_handle_table[HRS_IDX_SVC]);\n        }\n        break;  The handles stored in the handles pointer of the event parameters are numbers\nthat identify each attribute. The handles can be used to know which\ncharacteristic is being read or written to, therefore they can be passed around\nand to upper layers of the application to handle different actions.  Finally, the heart_rate_handle_table contains the Application Profile in the\nform of a structure with information about the attribute parameters as well as\nGATT interface, connection ID, permissions and application ID. The profile\nstructure is shown as follows, note that not all members are used in this\nexample:  struct gatts_profile_inst {\n    esp_gatts_cb_t gatts_cb;\n    uint16_t gatts_if;\n    uint16_t app_id;\n    uint16_t conn_id;\n    uint16_t service_handle;\n    esp_gatt_srvc_id_t service_id;\n    uint16_t char_handle;\n    esp_bt_uuid_t char_uuid;\n    esp_gatt_perm_t perm;\n    esp_gatt_char_prop_t property;\n    uint16_t descr_handle;\n    esp_bt_uuid_t descr_uuid;\n};",
            "title": "Starting the Service"
        },
        {
            "location": "/Subjects/NP1/P4/#interaction-with-the-gatt-server",
            "text": "There are many tools that allow you to manage the connection to the GATT server.\nOn Linux, we will use  hcitool  and gatttool . In Windows, you can use a tool\ncalled  Bluetooth LE Explorer , that implements, albeit graphically, the same\nfunctionality.  For this part of the lab assignment, you have to make visible the bluetooth\ncontroller of your host machine (laptop/pc) to the virtual machine used for the\ncourse.",
            "title": "Interaction with the GATT Server"
        },
        {
            "location": "/Subjects/NP1/P4/#using-hcitool-and-gatttool-in-client-mode",
            "text": "",
            "title": "Using hcitool and gatttool in client mode"
        },
        {
            "location": "/Subjects/NP1/P4/#scanning-available-devices-hcitool",
            "text": "hcitool  is a command line tool that allows you to manage the Bluetooth\ninterface of the computer on which it is running. In our case, We will need to\ndetermine the Bluetooth MAC address of our server.  To do this, first of all, we\nwill perform a scan of the devices BLE available in the environment using the\ncommand:  sudo hcitool lescan   Note  This command will not work if you did not make the bluetooth controller\navailable to the virtual machine.   If all went well, one line per available BLE device in the announcement phase\nwill be displayed. Among them, we must find our device, and annotate its MAC\naddress.   Task  Edit the file  main/gatts_table_creat_demo.c  and modify the name of your\ndevice, which will be announced in each emmited advertisment packet in the advertising  phase. You can achieve this by modifying the corresponding\nfield of the structure  raw_adv_data . Next, compile and flash the example,\nand start a session of scanning of BLE devices using the command:  sudo hcitool lescan  You should see your device on one of the output lines. Write down or\nremember its MAC address.",
            "title": "Scanning available devices: hcitool"
        },
        {
            "location": "/Subjects/NP1/P4/#interacting-with-the-gatt-server-gatttool",
            "text": "Task 4.1  Write a small pdf report documenting all the steps and Tasks in this\nsection.   Once the Bluetooth MAC address of the device is obtained, we must proceed in two\nphases. The first one is to pair it to the ESP device. The second, the\ninteraction with the GATT table. In both cases, you will use the  gatttool  tool\nfrom the command line.  To start a  gatttool  session, we'll invoke the tool in interactive mode, using\nthe command:  gatttool -b MAC -I  This will open an interactive console, waiting for the corresponding commands.  To perform the pairing, and considering that the Bluetooth MAC is already known,\nwe will use the  connect  command. If everything went well, we should observe a\nchange in the color of the prompt, and the  Connection successful  message. At\nthis point, see how the debugging output of ESP32 shows the messages\ncorresponding to the pairing process.  From the  gatttool  terminal, you can run the command  help  to get help (in the\nform of a list of available commands):  gatttool -b 24:6F:28:36:60:B2 -I\n[24:6F:28:36:60:B2][LE]> connect\nAttempting to connect to 24:6F:28:36:60:B2\nConnection successful\n[24:6F:28:36:60:B2][LE]> help\nhelp                                           Show this help\nexit                                           Exit interactive mode\nquit                                           Exit interactive mode\nconnect         [address [address type]]       Connect to a remote device\ndisconnect                                     Disconnect from a remote device\nprimary         [UUID]                         Primary Service Discovery\nincluded        [start hnd [end hnd]]          Find Included Services\ncharacteristics [start hnd [end hnd [UUID]]]   Characteristics Discovery\nchar-desc       [start hnd] [end hnd]          Characteristics Descriptor Discovery\nchar-read-hnd   <handle>                       Characteristics Value/Descriptor Read by handle\nchar-read-uuid  <UUID> [start hnd] [end hnd]   Characteristics Value/Descriptor Read by UUID\nchar-write-req  <handle> <new value>           Characteristic Value Write (Write Request)\nchar-write-cmd  <handle> <new value>           Characteristic Value Write (No response)\nsec-level       [low | medium | high]          Set security level. Default: low\nmtu             <value>                        Exchange MTU for GATT/ATT  We'll start by looking at the list of GATT server features.   Task  Using the corresponding command ( characteristics ), consult and write down\nthe features available on your GATT server.   One of these characteristics will be of crucial interest, since it will allow us\naccess, through its UUID, the instant heart rate measurement value, as well as\nas well as the notification settings on that value. To determine which of the\nlines is the one that interests us, look at the returned UUID value for each of\nthem, and determine, based on the macro  GATTS_CHAR_UUID_TEST_A  which one is\nit.  To interact with this feature, we will need to know its handler, to use it as a\nparameter in the  gatttool  commands. This handler is shown, for each line,\nafter the string  char value handle .   Task  The handler that allows reading the  Heart Rate Value  has associated a\nhandler of type character. Write its value down.   To read the value of the characteristic we can use the read command, using the\nannotated handler as argument ( char-read-hnd handler ).   Task  Read the heart rate monitoring value characteristic. What do you obtain? You\nshould observe a four-byte return value with value 0x00. These values\ncorrespond to those of the  char_value  variable in your code. Modify them,\nrebuild the project and  flash  it on the ESP32. Repeat the read. Did you\nread the new value?    Task  Now try to write to the characteristic. Use the command  char-write-cmd\nhandler value , where value is, for example,  11223344 . It's possible?\nWhy?   We will now write to its client configuration characteristic descriptor. Its hancler\nis the handler of the characteristic's value plus one. For instance, if the\nhandle for the value is  0x0001 , its cliente configuration characteristic\nwould have the handle  0x0002 .   Task  Try now to write to the client configuration characteristic. Use the command char-write-cmd handler value , where value is, for example,  0100 . It's\npossible? Why?",
            "title": "Interacting with the GATT server: gatttool."
        },
        {
            "location": "/Subjects/NP1/P4/#task-42",
            "text": "As you may have noticed, it is possible to read from the monitoring value,\nand write to config value. We will use this last feature to configure\nnotifications about the monitoring value. This way, each time the value\nchanges, the clients that have activated the notifications will receive the\nnew value.  To achieve this we need to modify some parts of our code. Specifically, we\nwill need:   Create a new task that periodically modifies the heart rate value (in our\n   case generating a new random value). This task will consist of an\n   infinite loop that, generates a new value for the characteristic and\n   correctly updates the gatt table. Then, if notifications have been\n   activated, it sends the new value to the clients:   static void publish_data_task(void *pvParameters)\n{\n    while (1) {\n        ESP_LOGI(\"APP\", \"Sending data...\");\n\n        // Step 1: Update characteristic value ...\n\n        // Step 2: If indications are active send the indication...\n\n        // Step 3: Sleep for one second...\n        vTaskDelay( 1000. / portTICK_PERIOD_MS);\n    }\n}  This routine should be created in response to the connection event by a\nclient, using, for example, the invocation to:  xTaskCreate(&publish_data_task, \"publish_data_task\", 4096, NULL, 5, NULL);    The update of the value, carried out periodically and randomly, will modify\nbyte 1 of the heart rate value, taking a random value between 0 and 255 (as an\nadditional note, current heart rate monitors support values higher for heart\nrate, although the configuration of this functionality is outside the scope of\npractice), and then update the internal gatt table using the esp_ble_gatts_set_attr_value \nfunction.    The verification of the activation or not of the notification is done by\nconsulting the two bytes of the corresponding client configuration\ncharacteristic. If these values are  0x01  and 0x00  (positions 0 and 1,\nrespectively), the notifications are active, and therefore, the notification\nshall be sent. You will need to use the function esp_ble_gatts_get_attr_value \nto read this descriptor.    To send the notification, we will use the following function:    esp_ble_gatts_send_indicate(heart_rate_profile_tab[0].gatts_if,\n                                      heart_rate_profile_tab[0].conn_id,\n                                      heart_rate_handle_table[IDX_CHAR_VAL_A],\n                                      sizeof(char_value), char_value, false);  The activation of notifications from  gatttool  will be done by writing the\nvalue  0x0100  in the client configuration characteristic, this is:  char-write-cmd HANDLER 0100  If you also modify the UUIDs by those provided in the specification of Bluetooth\nfor the  Heart Rate Service , and everything has been configured correctly, your\nESP32 should be able to interface with any heart rate monitor to, for example,\nAndroid. To do this, use the following UUIDs:   static const uint16_t GATTS_SERVICE_UUID_TEST      = 0x180D; //0x00FF;  static const uint16_t GATTS_CHAR_UUID_TEST_A       = 0x2A37; //0xFF01;  static const uint16_t GATTS_CHAR_UUID_TEST_B       = 0x2A38; //0xFF02;  static const uint16_t GATTS_CHAR_UUID_TEST_C       = 0x2A39; //0xFF03;   Deliver the modified code with a small pdf report showing how you activate the\nnotifications with gatttool, and how the node then sends a new value every\nsecond.",
            "title": "Task 4.2"
        },
        {
            "location": "/Subjects/NP1/P5/",
            "text": "Lab 5. Bluetooth Mesh (BLE MESH)\n\n\nGoals\n\n\n\n\n\n\nPut into practice the concepts studied in theory in relation to BLE MESH,\n  specifically the provisioning and client/server models.\n\n\n\n\n\n\nDeploy a provisioning infrastructure for an ONOFF GENERIC model SERVER with\n  provisioning from mobile application for remote control of on/off LEDs.\n\n\n\n\n\n\nDeploy a provisioning infrastructure of a GENERIC SENSOR model provisioned\n  from ESP32.\n\n\n\n\n\n\nExample for the ON-OFF MODEL\n\n\nThe codes that we will study in this lab assignment are in\n\nexamples/bluetooth/esp_ble_mesh/ble_mesh_node\n in the system case \nOnOff\n\n(first part of the assignment) and \nble_mesh_sensor_model\n for the\nsensor model (second part).\n\n\nIn addition, download and install on your smartphone the application \nnRF Mesh\n\n(available both for Android and IOS). You will use this application to provision\nthe devices and interact with the mesh.\n\n\nThe ON-OFF server\n\n\nThis server implements only one element with two models:\n\n\n\n\n\n\nConfiguration Server model\n: The role of this model is mainly to configure\n  Provisioner device\u2019s AppKey and set up its relay function, TTL size,\n  subscription, etc.\n\n\n\n\n\n\nGeneric OnOff Server model\n: This model implements the most basic function\n  of turning the lights on and off.\n\n\n\n\n\n\nThe code in \nble_mesh_demo_main.c\n contains the following main application\ncodes, that we can summarize as:\n\n Initialize Bluetooth Controller stack and Host stack (bluedroid)\n\n Initialize BLE Mesh stack\n\n Register the callback function of BLE Mesh provision and BLE Mesh model\n\n Implement and initialize BLE Mesh element\n\n Implement and initialize BLE Mesh Configuration Server model and Generic OnOff\n  Server model\n\n Function as BLE Mesh Configuration Server Model Get Opcode and BLE Mesh\n  Configuration Server Model Set Opcode\n* Declare and define the RGB LED structure.\n\n\nFor better understanding of the code, the following sections provide a detailed\nanalysis the file \nble_mesh_demo_main.c\n.\n\n\n1. Initializing and Enabling BLE Mesh\n\n\nWhen ESP32 system initialization is completed, \napp_main\n is called. The\ncode block below demonstrates the implementation of the functions in\n\napp_main\n.\n\n\nvoid app_main(void)\n{\n    int err;\n\n    ESP_LOGI(TAG, \"Initializing...\");\n\n    board_init();\n\n    err = bluetooth_init();\n\n    if (err) {\n        ESP_LOGE(TAG, \"esp32_bluetooth_init failed (err %d)\", err);\n        return;\n    }\n\n    /* Initializes the Bluetooth Mesh Subsystem */\n    err = ble_mesh_init();\n    if (err) {\n        ESP_LOGE(TAG, \"Bluetooth mesh init failed (err %d)\", err);\n    }\n}\n\n\n\n\nIn particular, the code includes:\n- \nerr = bluetooth_init()\n: initialization related to the Bluetooth protocol\n  stack (including Controller and Host)\n- \nerr = ble_mesh_init()\n: initialization related to BLE Mesh\n\n\nFurther, the code for initialization of the BLE Mesh protocol stack is\nintroduced, together with the description of the required actions to\ninitialize BLE Mesh.\n\n\nstatic esp_err_t ble_mesh_init(void)\n{\n    int err = 0;\n\n    memcpy(dev_uuid + 2, esp_bt_dev_get_address(), BLE_MESH_ADDR_LEN);\n\n    // See comment 1\n     esp_ble_mesh_register_prov_callback(esp_ble_mesh_prov_cb);\n    esp_ble_mesh_register_custom_model_callback(esp_ble_mesh_model_cb);\n\n    err = esp_ble_mesh_init(&provision, &composition);\n    if (err) {\n        ESP_LOGE(TAG, \"Initializing mesh failed (err %d)\", err);\n        return err;\n    }\n\n    esp_ble_mesh_node_prov_enable(ESP_BLE_MESH_PROV_ADV | ESP_BLE_MESH_PROV_GATT);\n\n    ESP_LOGI(TAG, \"BLE Mesh Node initialized\");\n\n    board_led_operation(LED_G, LED_ON);\n\n    return err;\n}\n\n\n\n\nObservet that the code includes the following funtionality:\n\n\n\n\n\n\nesp_ble_mesh_register_prov_callback(esp_ble_mesh_prov_cb)\n: registers the\n  provisioning callback function in the BLE Mesh stack. This callback function\n  gets executed during the BLE Mesh network configuration process. It allows the\n  BLE Mesh stack to generate events and notify the application layer about\n  important network configuration processes. This callback function mainly\n  implements the following events:\n\n\n\n\n\n\nESP_BLE_MESH_PROVISION_REG_EVT\n: Generated when the BLE Mesh initialization\n    process is completed after calling the API function \nesp_ble_mesh_init\n. It\n    returns the initialization status of the BLE Mesh application.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_LINK_OPEN_EVT\n: Generated when a Provisioner and an\n    unprovisioned device establish a link.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_LINK_CLOSE_EVT\n: Generated to notify the application\n    layer that a link has been broken after BLE Mesh bottom-layer protocol sends\n    or receives the message \nThe Link Broken\n.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_OUTPUT_NUMBER_EVT\n: Received by the application\n    layer if during the configuration process \noutput_actions\n is set as\n    \nESP_BLE_MESH_DISPLAY_NUMBER\n, and the target peer \ninput_actions\n is set as\n    \nESP_BLE_MESH_ENTER_NUMBER\n.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_OUTPUT_STRING_EVT\n: Received by the application\n    layer if during the configuration process \noutput_actions\n is set as\n    \nESP_BLE_MESH_DISPLAY_STRING\n, and the target peer \ninput_actions\n is set as\n    \nESP_BLE_MESH_ENTER_STRING\n.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_INPUT_EVT\n: Received by the application layer if\n    during the configuration process \ninput_actions\n is set as anything but\n    \nESP_BLE_MESH_NO_INPUT\n.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_COMPLETE_EVT\n: Received by the application layer\n    when the provisioning is completed.\n\n\n\n\n\n\nESP_BLE_MESH_NODE_PROV_RESET_EVT\n: Received by the application layer when\n    the network reset is completed.\n\n\n\n\n\n\nesp_ble_mesh_register_custom_model_callback(esp_ble_mesh_model_cb)\n:\n  registers the model operation callback function. This callback function is\n  used when the target peer operates the model state of the source peer after\n  BLE Mesh has completed network configuration. This callback function mainly\n  implements the following events:\n\n\n\n\n\n\nESP_BLE_MESH_MODEL_OPERATION_EVT\n: Can be triggered by the two scenarios\n  below:\n\n\n\n\nServer model receives \nGet Status\n or \nSet Status\n from Client model.\n\n\nClient model receives \nStatus state\n from Server model.\n\n\n\n\n\n\n\n\nESP_BLE_MESH_MODEL_SEND_COMP_EVT\n: Generated after the Server model sends\n  \nStatus state\n by calling the API function\n  \nesp_ble_mesh_server_model_send_msg\n.\n\n\n\n\n\n\nESP_BLE_MESH_MODEL_PUBLISH_COMP_EVT\n: Generated after the application has\n  completed calling the API \nesp_ble_mesh_model_publish_msg\n to publish\n  messages\n\n\n\n\n\n\nESP_BLE_MESH_CLIENT_MODEL_SEND_TIMEOUT_EVT\n: Generated when the Client\n  model calls the API function \nesp_ble_mesh_client_model_send_msg\n, but\n  fails to receive ACK from the target peer due to timeout\n\n\n\n\n\n\nESP_BLE_MESH_MODEL_PUBLISH_UPDATE_EVT\n: Generated after the application\n  sets up the publish function to regularly send messages to the target\n  peer.\n\n\n\n\n\n\n\n\n\n\nesp_ble_mesh_node_prov_enable(ESP_BLE_MESH_PROV_ADV |\n  ESP_BLE_MESH_PROV_GATT)\n: enables the Advertising and Scan functions when the\n  BLE Mesh initialization is completed. It makes the devices visible to\n  Provisioners for network provisioning.\n\n\n\n\n\n\nboard_led_operation(LED_G, LED_ON)\n: initializes the RGB LED.\n\n\n\n\n\n\nAt this point, initialization and enabling of BLE Mesh as a node port is\ncompleted, which means a Provisioner can identify devices for network\nprovisioning and data transmission.\n\n\n2 Implementation of BLE Mesh Element Structure\n\n\nIn this section we shows:\n- Things that have to be done before the initialization of the previous section\n- How to add an element and a model to ESP BLE Mesh stack\n- How to choose a different encryption approach\n- How to declare the features of Proxy, Relay, Low Power and Friend\n\n\nFirst of all, before calling the API \nesp_ble_mesh_init\n to initialize BLE Mesh,\nan element and a model need to be declared and defined. The code block below\nshows the declaration of an element structure.\n\n\n/*!< Abstraction that describes a BLE Mesh Element.\n    This structure is associated with bt_mesh_elem in mesh_access.h */\ntypedef struct {\n    /* Element Address, it is assigned during provisioning. */\n    uint16_t element_addr;\n\n    /* Location Descriptor (GATT Bluetooth Namespace Descriptors) */\n    const uint16_t location;\n\n    /* Model count */\n    const uint8_t sig_model_count;\n    const uint8_t vnd_model_count;\n\n    /* Models */\n    esp_ble_mesh_model_t *sig_models;\n    esp_ble_mesh_model_t *vnd_models;\n} esp_ble_mesh_elem_t;\n\n\n\n\nThe next code block shows the definition of an element structure, build from the\n\nESP_BLE_MESH_ELEMENT\n macro.\n\n\nstatic esp_ble_mesh_elem_t elements[] = {\n    ESP_BLE_MESH_ELEMENT(0, root_models, ESP_BLE_MESH_MODEL_NONE),\n};\n\n\n\n\nAnother code block provides the codes needed to implement the macro\n\nESP_BLE_MESH_ELEMENT\n.\n\n\n#define ESP_BLE_MESH_ELEMENT(_loc, _mods, _vnd_mods)    \\\n{                                                       \\\n    .location         = (_loc),                         \\\n    .sig_model_count  = ARRAY_SIZE(_mods),              \\\n    .sig_models       = (_mods),                        \\\n    .vnd_model_count  = ARRAY_SIZE(_vnd_mods),          \\\n    .vnd_models       = (_vnd_mods),                    \\\n}\n\n\n\n\nThe variables of the element structure are as follows:\n\n\n\n\naddr\n: stores the element primary address, used by Mesh Stack during the\n  configuration process. It can be ignored for the higher level applications.\n\n\nloc\n: location descriptor defined by SIG. For this demo, set its value to\n  \n0\n.\n\n\nmodel_count\n: number of SIG models supported in this element.\n\n\nvnd_model_count\n: number of the Vendor model supported in this element.\n\n\nmodels\n: pointer to the SIG Models that have already been defined.\n\n\nvnd_models\n: pointer to the Vendor Model that has already been defined.\n\n\n\n\n3 Implementation of BLE Mesh Model Structure\n\n\nThe preceding section has introduced the specific ways to implement and define\nan element by passing specific model pointers to it. This section explains how\nto implement and define a Model structure, which is shown in the code blocks\nbelow.\n\n\n/** Abstraction that describes a Mesh Model instance.\n *  This structure is associated with bt_mesh_model in mesh_access.h\n */\nstruct esp_ble_mesh_model {\n    /* Model ID */\n    union {\n        const uint16_t model_id;\n        struct {\n            uint16_t company_id;\n            uint16_t model_id;\n        } vnd;\n    };\n\n    /* The Element to which this Model belongs */\n    esp_ble_mesh_elem_t *element;\n\n    /* Model Publication */\n    esp_ble_mesh_model_pub_t *const pub;\n\n    /* AppKey List */\n    uint16_t keys[CONFIG_BLE_MESH_MODEL_KEY_COUNT];\n\n    /* Subscription List (group or virtual addresses) */\n    uint16_t groups[CONFIG_BLE_MESH_MODEL_GROUP_COUNT];\n\n    /* Model operation context */\n    esp_ble_mesh_model_op_t *op;\n\n    /* Model-specific user data */\n    void *user_data;\n};\n\n\n\n\nThe block above shows a specific implementation of the model structure. Although\nthis structure has many variables, only the following four ones are used for\napplications:\n\n\n\n\n\n\nid\n and \nvnd\n: union variables, defining the SIG Model and the Vendor Model\n  respectively.\n\n\n\n\n\n\nop\n: structure with a set of variables for the Model Operation, declaring the\n  opcode that corresponds to Get, Set, or Status State, as well as the minimum\n  value lengths that are supported in this module.\n\n\n\n\n\n\npub\n: structure that needs to be defined if the Model structure supports the\n  Publish function.\n\n\n\n\n\n\nuser_data\n: optional variable for storing the application layer data.\n\n\n\n\n\n\nThe other structures and variables (keys, group, element) get their values\nthrough the BLE Mesh stack during the initialization or configuration stages.\nYou are not required to initialize them.\n\n\nThe next code block presents the definition of the model structure, and the\n\nroot_models[]\n array. This array is used for indicating the number of the\nexisting model structures. A model is implemented by using a macro.\n\n\nstatic esp_ble_mesh_model_t root_models[] = {\n    ESP_BLE_MESH_MODEL_CFG_SRV(&config_server),\n    ESP_BLE_MESH_SIG_MODEL(ESP_BLE_MESH_MODEL_ID_GEN_ONOFF_SRV, onoff_op,\n    &onoff_pub, &led_state[0]),\n};\n\n\n\n\nDifferent models require different macros. The existing types of models and\ntheir respective macros needed for implementation are given in the table below\n(as we are implementing a Generic OnOff Server model, we use the\n\nESP_BLE_MESH_MODEL_ID_GEN_ONOFF_SRV\n macro).\n\n\n\n\n\n\n\n\nModel Name\n\n\nMacro Required for its Definition\n\n\n\n\n\n\n\n\n\n\nConfiguration Server Model\n\n\nESP_BLE_MESH_MODEL_CFG_SRV\n\n\n\n\n\n\nConfiguration Client Model\n\n\nESP_BLE_MESH_MODEL_CFG_CLI\n\n\n\n\n\n\nGeneric OnOff Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_ONOFF_CLI\n\n\n\n\n\n\nGeneric Level Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_LEVEL_CLI\n\n\n\n\n\n\nGeneric Default Transition Time Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_DEF_TRANS_TIME_CLI\n\n\n\n\n\n\nGeneric Power OnOff Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_POWER_ONOFF_CLI\n\n\n\n\n\n\nGeneric Power Level Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_POWER_LEVEL_CLI\n\n\n\n\n\n\nGeneric Battery Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_BATTERY_CLI\n\n\n\n\n\n\nGeneric Location Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_LOCATION_CLI\n\n\n\n\n\n\nGeneric Property Client Model\n\n\nESP_BLE_MESH_MODEL_GEN_PROPERTY_CLI\n\n\n\n\n\n\nLight Lightness Client Model\n\n\nESP_BLE_MESH_MODEL_LIGHT_LIGHTNESS_CLI\n\n\n\n\n\n\nLight CTL Client Model\n\n\nESP_BLE_MESH_MODEL_LIGHT_CTL_CLI\n\n\n\n\n\n\nLight HSL Client Model\n\n\nESP_BLE_MESH_MODEL_LIGHT_HSL_CLI\n\n\n\n\n\n\nSensor Client Model\n\n\nESP_BLE_MESH_MODEL_SENSOR_CLI\n\n\n\n\n\n\nScene Client Model\n\n\nESP_BLE_MESH_MODEL_SCENE_CLI\n\n\n\n\n\n\n\n\nAnother important structure in a model is the \nesp_ble_mesh_model_op_t *op\n\npointer. This structure points to the operation structure that defines the\nModel state. Generally, there are two types of models in BLE Mesh:\n\n\n\n\nServer Model\n:\n\n\nConsists of one or multiple states that can exist across different elements\n\n\nDefines the messages sent/received by the model, along with the element's\n  behavior.\n\n\nExample\uff1aOn/Off switch --- Indicates the On/Off status.\n\n\n\n\n\n\n\n\n\n\nClient Model\n:\n\n\nDefines the messages used by the client to request, change or use the\n  relevant state of the server.\n\n\nExample\uff1aOn/Off switch --- Indicates the On or Off message sent by the\n  Client.\n\n\n\n\n\n\n\n\n\n\n\n\nThe following code block shows the declaration of the Model operation structure.\n\n\n/*!< Model operation context.\n    This structure is associated with bt_mesh_model_op in mesh_access.h */\ntypedef struct {\n    const uint32_t    opcode;   /* Opcode encoded with the ESP_BLE_MESH_MODEL_OP_* macro */\n    const size_t      min_len;  /* Minimum required message length */\n    esp_ble_mesh_cb_t param_cb; /* The callback is only used for the BLE Mesh stack, not for the app layer. */\n} esp_ble_mesh_model_op_t;\n\n\n\n\nThere are three variables in the declaration of the operation structure:\n\n\n\n\nopcode\n: opcode corresponding to a state. As specified in BLE Mesh, the SIG\n  Model opcode should be 1~2 bytes, and the Vendor Model opcode should be 3\n  bytes.\n\n\nmin_len\n: min length of the messages received by the state. For example,\n  OnOff Get state is 0 bytes, and OnOff Set State is 2 bytes.\n\n\nparam_cb\n: used for the BLE Mesh protocol only. Applications need to set its\n  value to \n0\n.\n\n\n\n\nThe definition for our OnOff Server code is:\n\n\nstatic esp_ble_mesh_model_op_t onoff_op[] = {\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_GET, 0, 0},\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET, 2, 0},\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET_UNACK, 2, 0},\n    /* Each model operation struct array must use this terminator\n     * as the end tag of the operation uint. */\n    ESP_BLE_MESH_MODEL_OP_END,\n};\n\n\n\n\nThe OnOff Client\n\n\nThe design of the client is much easier. In a generic way, it just defines an\nON/OFF Client model and waits to be provisioned. Once the provisioning process\nis completed, every time one of the buttons on the board (RESET) is pressed, it\nsends a request for a change in the status of the lights to all the nodes in its\nmesh network. This behaviour is coded in the following functions defined in the\n\nboard.c\n file:\n\n\nstatic void button_tap_cb(void* arg)\n{\n    ESP_LOGI(TAG, \"tap cb (%s)\", (char *)arg);\n\n    example_ble_mesh_send_gen_onoff_set();\n}\n\nstatic void board_button_init(void)\n{\n    button_handle_t btn_handle = iot_button_create(BUTTON_IO_NUM, BUTTON_ACTIVE_LEVEL);\n    if (btn_handle) {\n        iot_button_set_evt_cb(btn_handle, BUTTON_CB_RELEASE, button_tap_cb, \"RELEASE\");\n    }\n}\n\nvoid board_init(void)\n{\n    board_led_init();\n    board_button_init();\n}\n\n\n\n\nThe invoked function, \nexample_ble_mesh_send_gen_onoff_set\n, sends a \nSET\n\noperation to all network members:\n\n\nvoid example_ble_mesh_send_gen_onoff_set(void)\n{\n    esp_ble_mesh_generic_client_set_state_t set = {0};\n    esp_ble_mesh_client_common_param_t common = {0};\n    esp_err_t err = ESP_OK;\n\n    common.opcode = ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET_UNACK;\n    common.model = onoff_client.model;\n    common.ctx.net_idx = store.net_idx;\n    common.ctx.app_idx = store.app_idx;\n    common.ctx.addr = 0xFFFF;   /* to all nodes */\n    common.ctx.send_ttl = 3;\n    common.ctx.send_rel = false;\n    common.msg_timeout = 0;     /* 0 indicates that timeout value from menuconfig will be used */\n    common.msg_role = ROLE_NODE;\n\n    set.onoff_set.op_en = false;\n    set.onoff_set.onoff = store.onoff;\n    set.onoff_set.tid = store.tid++;\n\n    err = esp_ble_mesh_generic_client_set_state(&common, &set);\n    if (err) {\n        ESP_LOGE(TAG, \"Send Generic OnOff Set Unack failed\");\n        return;\n    }\n\n    store.onoff = !store.onoff;\n    mesh_example_info_store(); /* Store proper mesh example info */\n}\n\n\n\n\nObserve that the destination address is for all nodes in the network\n(\ncommon.ctx.addr = 0xFFFF;\n).\n\n\nProvisioning and control from a mobile application\n\n\nYou will use the two ESP nodes you have, one programmed as an OnOff Server and\nthe other programmed as an OnOff Client. If you have three LEDs available, you\ncan place the server node on a breadboard and connect the anodes of the LEDs to\nthe pins where the server node expects the lights to be connected (you can find\nthose in the \nboard.h\n file, mainly the pins 25, 26 and 27). It is convenient\nthat you also place in series a current limmitng resistor, a 220 ohm resistor\nshould be fine.\n\n\nYou can run the two nodes and monitor its output (use the idf.py command). Once\nboth are up and running you will use the \nnRF Mesh\n app on your smartphone to\ncomplete the provisioning of both nodes, creating a ble mesh for thme. To\ncomplete the provisioning you have to proceed as follows:\n\n\n\n\nSTEP 1\n: the initial screen will show you the nodes that are already\n  provisioned (initially none).\n\n\n\n\n\n\n\n\nSTEP 2\n: you will click on \nADD NODE\n and provision (one by one) your two\n  nodes:\n\n\n\n\n\n\n\n\nSTEP 3\n: you have to generate the network information for the new node\n  (\nidentify\n it), pressing \nIDENTIFY\n:\n\n\n\n\n\n\n\n\nSTEP 4\n: once the network information has been generated, you can provision\n  the node (pressing \nPROVISION\n):\n\n\n\n\n\n\n\n\nSTEP 5\n: if everything went well, a success message like the following one\n  will be shown:\n\n\n\n\n\n\n\n\nSTEP 6\n: after repeating this step with the two nodes in our group, you will\n  see a screen like the following. Observe and write down the unicast addresses\n  of each node. The node with one item is the OnOff Client; the node with three\n  elements is the OnOff Server.\n\n\n\n\n\n\nNext, you will generate a group of nodes. This will allow you to subscribe the\n  models to it, and publish messages that will be broadcasted to all models in\n  the group.\n\n\n\n\nSTEP 7\n: Create a new group by pressing the \n+\n button. Give it the name and\n  address you want, for example, \nLiving Room\n, \n0xC000\n. If everything went\n  well, you will see a single valid group with no nodes associated/subscribed to it.\n\n\n\n\n\n\n\n\nSTEP 8\n: Next, you will subscribe each \nGeneric On Off Server\n and \nGeneric\n  On Off Client\n models to the group you just created. You have to do it node by\n  node, first by clicking on the concrete model:\n\n\n\n\n\n\nAnd then associate an application key (\nBIND KEY\n) and subscribe (\nSUBSCRIBE\n)\n  to the desired group:\n\n\n\n\n\n\n\n\nNow, if all went well, if you go to the group description tab, you will see an\nicon with a picture for the lights, and another icon for the client (a swithc).\n\n\n\n\nAt this point, if you are monitoring the output of all ESP32s, you will see that\nthe state of the LED changes at the request of the application (pressing the\nlight icon). In addition, you will see that it also changes if you press the\ncorresponding button of the switch (\nRESET\n) on the board. If you did connect\nthe LEDs to the server board as mentioned above, you will see how they change\ntheir on/off state when you press the light icon in the smartphone or the button\nin the client board.\n\n\n\n\nTask 5.1\n\n\nThe client sends, after pressing the button, the message of type \nSET\n to\nall the nodes of the network. Modify it so that it is only sent to the nodes\nthat belong to its group. Try to subscribe/unsubscribe a model from the\ngroup, and you will see how it no longer receives the status change request\nmessages. Deliver the modified code.\n\n\n\n\nExample for the SENSOR MODEL\n\n\nIn this part of the assignment, we implement a sensor model client that is also\na provisioner, and a configurable sensor model server. We will work with the\ncode in \nexamples/bluetooth/esp_ble_mesh/ble_mesh_sensor_model\n.\n\n\nThe \nSensor Server\n model is a model that allows exposing series of\nsensorization data.\n\n\nThe \nSensor Client\n model is used to consume sensorization values (\nSensor states\n)\nexposed by the server.\n\n\nThese models are made up of the following parts:\n\n\n\n\nStatus \nSensor Descriptor\n. It describes the sensor data, and is immutable\n  throughout its life.\n\n\nStatus \nSensor Setting\n. Controls the sensor parameters. For example, it could\n  indicate its sensitivity, that could be remotely adjusted to prevent a motion\n  sensor from tripping on small movements.\n\n\nStatus \nSensor Cadence\n. Controls the cadence of sensing.\n\n\nStatus \nSensor Data\n. It contains the sensed values. It is actually\n  represented by one or more \nProperty ID\n - \nValue\n pairs.\n\n\nStatus \nSensor Series Column\n. Only used if each of the values is considered\n  as belonging to a data series.\n\n\n\n\nIn the \nclient\n example, the device is both a provisioner and a client. Once the\nserver device is provisioned and configured, users can press the button on the\nboard to send requests to the server that, successively, will return the next\nstatus of the sensor in order (\nDescriptor\n, \nSetting\n, \nCadence\n, ...).\n\n\nIn the \nserver\n example, the non-provisioned device implements a \nSensor Server\n\nmodel. The server supports two state instances: the first (\nProperty ID 0x0056\n)\nwould represent \nIndoor\n temperature; the second (\nProperty ID 0x005B\n) would\nrepresent the \nOutdoor\n temperature. All data, in these examples, is\npre-initialized.\n\n\nRunning the example\n\n\nFirst, start the client/provider node and monitor its output. Then stat the\nserver node, you will see that it is provisioned by your client, granting it a\nunicast address. Write it down.\n\n\nThe general operation of the system is:\n\n\n\n\nDevice A runs the \nclient\n example, and device B runs the \nserver\n example.\n\n\nA acts as a provider. After receiving a request from B, he provisions it and\n   stores his address. You will see the MAC BLE (UUID) of B in the provisioning\n   process from A.\n\n\nIn A, each press of the button will make a request to node B.\n\n\nSuccessively, these requests will be, in order and for each press:\n\n\nSensor Descriptor\n.\n\n\nSensor Cadence\n.\n\n\nSensor Settings\n.\n\n\nSensor Data\n.\n\n\nSensor Series\n.\n\n\n\n\n\n\n\n\n\n\nTask\n\n\nStudy the client and server code, and see to which node is the client\nsending the requests, what operations are requested on each button press,\nand what data the returns the server in each case.\n\n\n\n\n\n\nTask 5.2\n\n\nModify the client and/or server code so that insted of requesting\niteratively \nall\n the values from the \nlast\n provided node, it request\nonly the sensor data (\nSensor Data State\n) of \nall\n the provisioned nodes.\nSo if there are three provisioned nodes, each press would return the\nsensorization value of one of them, in the provisioning order.  You will\nfind the \nesp_ble_mesh_provisioner_get_node_table_entry\n function usefull\nto get a list/table of all connected nodes.\n\n\nAs an additional functionality, modify the code so that only those\nauthorized nodes will be automatically provisioned (those that belong to\nyour room, for example).\n\n\nA final \noptional\n modification would be to periodically change randombly\nthe sensed data on the server, with a predetermined cadence (remote\nmodification of the cadence remains an advanced exercise).\n\n\nDeliver the resulting code.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P5/#lab-5-bluetooth-mesh-ble-mesh",
            "text": "",
            "title": "Lab 5. Bluetooth Mesh (BLE MESH)"
        },
        {
            "location": "/Subjects/NP1/P5/#goals",
            "text": "Put into practice the concepts studied in theory in relation to BLE MESH,\n  specifically the provisioning and client/server models.    Deploy a provisioning infrastructure for an ONOFF GENERIC model SERVER with\n  provisioning from mobile application for remote control of on/off LEDs.    Deploy a provisioning infrastructure of a GENERIC SENSOR model provisioned\n  from ESP32.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP1/P5/#example-for-the-on-off-model",
            "text": "The codes that we will study in this lab assignment are in examples/bluetooth/esp_ble_mesh/ble_mesh_node  in the system case  OnOff \n(first part of the assignment) and  ble_mesh_sensor_model  for the\nsensor model (second part).  In addition, download and install on your smartphone the application  nRF Mesh \n(available both for Android and IOS). You will use this application to provision\nthe devices and interact with the mesh.",
            "title": "Example for the ON-OFF MODEL"
        },
        {
            "location": "/Subjects/NP1/P5/#the-on-off-server",
            "text": "This server implements only one element with two models:    Configuration Server model : The role of this model is mainly to configure\n  Provisioner device\u2019s AppKey and set up its relay function, TTL size,\n  subscription, etc.    Generic OnOff Server model : This model implements the most basic function\n  of turning the lights on and off.    The code in  ble_mesh_demo_main.c  contains the following main application\ncodes, that we can summarize as:  Initialize Bluetooth Controller stack and Host stack (bluedroid)  Initialize BLE Mesh stack  Register the callback function of BLE Mesh provision and BLE Mesh model  Implement and initialize BLE Mesh element  Implement and initialize BLE Mesh Configuration Server model and Generic OnOff\n  Server model  Function as BLE Mesh Configuration Server Model Get Opcode and BLE Mesh\n  Configuration Server Model Set Opcode\n* Declare and define the RGB LED structure.  For better understanding of the code, the following sections provide a detailed\nanalysis the file  ble_mesh_demo_main.c .",
            "title": "The ON-OFF server"
        },
        {
            "location": "/Subjects/NP1/P5/#1-initializing-and-enabling-ble-mesh",
            "text": "When ESP32 system initialization is completed,  app_main  is called. The\ncode block below demonstrates the implementation of the functions in app_main .  void app_main(void)\n{\n    int err;\n\n    ESP_LOGI(TAG, \"Initializing...\");\n\n    board_init();\n\n    err = bluetooth_init();\n\n    if (err) {\n        ESP_LOGE(TAG, \"esp32_bluetooth_init failed (err %d)\", err);\n        return;\n    }\n\n    /* Initializes the Bluetooth Mesh Subsystem */\n    err = ble_mesh_init();\n    if (err) {\n        ESP_LOGE(TAG, \"Bluetooth mesh init failed (err %d)\", err);\n    }\n}  In particular, the code includes:\n-  err = bluetooth_init() : initialization related to the Bluetooth protocol\n  stack (including Controller and Host)\n-  err = ble_mesh_init() : initialization related to BLE Mesh  Further, the code for initialization of the BLE Mesh protocol stack is\nintroduced, together with the description of the required actions to\ninitialize BLE Mesh.  static esp_err_t ble_mesh_init(void)\n{\n    int err = 0;\n\n    memcpy(dev_uuid + 2, esp_bt_dev_get_address(), BLE_MESH_ADDR_LEN);\n\n    // See comment 1\n     esp_ble_mesh_register_prov_callback(esp_ble_mesh_prov_cb);\n    esp_ble_mesh_register_custom_model_callback(esp_ble_mesh_model_cb);\n\n    err = esp_ble_mesh_init(&provision, &composition);\n    if (err) {\n        ESP_LOGE(TAG, \"Initializing mesh failed (err %d)\", err);\n        return err;\n    }\n\n    esp_ble_mesh_node_prov_enable(ESP_BLE_MESH_PROV_ADV | ESP_BLE_MESH_PROV_GATT);\n\n    ESP_LOGI(TAG, \"BLE Mesh Node initialized\");\n\n    board_led_operation(LED_G, LED_ON);\n\n    return err;\n}  Observet that the code includes the following funtionality:    esp_ble_mesh_register_prov_callback(esp_ble_mesh_prov_cb) : registers the\n  provisioning callback function in the BLE Mesh stack. This callback function\n  gets executed during the BLE Mesh network configuration process. It allows the\n  BLE Mesh stack to generate events and notify the application layer about\n  important network configuration processes. This callback function mainly\n  implements the following events:    ESP_BLE_MESH_PROVISION_REG_EVT : Generated when the BLE Mesh initialization\n    process is completed after calling the API function  esp_ble_mesh_init . It\n    returns the initialization status of the BLE Mesh application.    ESP_BLE_MESH_NODE_PROV_LINK_OPEN_EVT : Generated when a Provisioner and an\n    unprovisioned device establish a link.    ESP_BLE_MESH_NODE_PROV_LINK_CLOSE_EVT : Generated to notify the application\n    layer that a link has been broken after BLE Mesh bottom-layer protocol sends\n    or receives the message  The Link Broken .    ESP_BLE_MESH_NODE_PROV_OUTPUT_NUMBER_EVT : Received by the application\n    layer if during the configuration process  output_actions  is set as\n     ESP_BLE_MESH_DISPLAY_NUMBER , and the target peer  input_actions  is set as\n     ESP_BLE_MESH_ENTER_NUMBER .    ESP_BLE_MESH_NODE_PROV_OUTPUT_STRING_EVT : Received by the application\n    layer if during the configuration process  output_actions  is set as\n     ESP_BLE_MESH_DISPLAY_STRING , and the target peer  input_actions  is set as\n     ESP_BLE_MESH_ENTER_STRING .    ESP_BLE_MESH_NODE_PROV_INPUT_EVT : Received by the application layer if\n    during the configuration process  input_actions  is set as anything but\n     ESP_BLE_MESH_NO_INPUT .    ESP_BLE_MESH_NODE_PROV_COMPLETE_EVT : Received by the application layer\n    when the provisioning is completed.    ESP_BLE_MESH_NODE_PROV_RESET_EVT : Received by the application layer when\n    the network reset is completed.    esp_ble_mesh_register_custom_model_callback(esp_ble_mesh_model_cb) :\n  registers the model operation callback function. This callback function is\n  used when the target peer operates the model state of the source peer after\n  BLE Mesh has completed network configuration. This callback function mainly\n  implements the following events:    ESP_BLE_MESH_MODEL_OPERATION_EVT : Can be triggered by the two scenarios\n  below:   Server model receives  Get Status  or  Set Status  from Client model.  Client model receives  Status state  from Server model.     ESP_BLE_MESH_MODEL_SEND_COMP_EVT : Generated after the Server model sends\n   Status state  by calling the API function\n   esp_ble_mesh_server_model_send_msg .    ESP_BLE_MESH_MODEL_PUBLISH_COMP_EVT : Generated after the application has\n  completed calling the API  esp_ble_mesh_model_publish_msg  to publish\n  messages    ESP_BLE_MESH_CLIENT_MODEL_SEND_TIMEOUT_EVT : Generated when the Client\n  model calls the API function  esp_ble_mesh_client_model_send_msg , but\n  fails to receive ACK from the target peer due to timeout    ESP_BLE_MESH_MODEL_PUBLISH_UPDATE_EVT : Generated after the application\n  sets up the publish function to regularly send messages to the target\n  peer.      esp_ble_mesh_node_prov_enable(ESP_BLE_MESH_PROV_ADV |\n  ESP_BLE_MESH_PROV_GATT) : enables the Advertising and Scan functions when the\n  BLE Mesh initialization is completed. It makes the devices visible to\n  Provisioners for network provisioning.    board_led_operation(LED_G, LED_ON) : initializes the RGB LED.    At this point, initialization and enabling of BLE Mesh as a node port is\ncompleted, which means a Provisioner can identify devices for network\nprovisioning and data transmission.",
            "title": "1. Initializing and Enabling BLE Mesh"
        },
        {
            "location": "/Subjects/NP1/P5/#2-implementation-of-ble-mesh-element-structure",
            "text": "In this section we shows:\n- Things that have to be done before the initialization of the previous section\n- How to add an element and a model to ESP BLE Mesh stack\n- How to choose a different encryption approach\n- How to declare the features of Proxy, Relay, Low Power and Friend  First of all, before calling the API  esp_ble_mesh_init  to initialize BLE Mesh,\nan element and a model need to be declared and defined. The code block below\nshows the declaration of an element structure.  /*!< Abstraction that describes a BLE Mesh Element.\n    This structure is associated with bt_mesh_elem in mesh_access.h */\ntypedef struct {\n    /* Element Address, it is assigned during provisioning. */\n    uint16_t element_addr;\n\n    /* Location Descriptor (GATT Bluetooth Namespace Descriptors) */\n    const uint16_t location;\n\n    /* Model count */\n    const uint8_t sig_model_count;\n    const uint8_t vnd_model_count;\n\n    /* Models */\n    esp_ble_mesh_model_t *sig_models;\n    esp_ble_mesh_model_t *vnd_models;\n} esp_ble_mesh_elem_t;  The next code block shows the definition of an element structure, build from the ESP_BLE_MESH_ELEMENT  macro.  static esp_ble_mesh_elem_t elements[] = {\n    ESP_BLE_MESH_ELEMENT(0, root_models, ESP_BLE_MESH_MODEL_NONE),\n};  Another code block provides the codes needed to implement the macro ESP_BLE_MESH_ELEMENT .  #define ESP_BLE_MESH_ELEMENT(_loc, _mods, _vnd_mods)    \\\n{                                                       \\\n    .location         = (_loc),                         \\\n    .sig_model_count  = ARRAY_SIZE(_mods),              \\\n    .sig_models       = (_mods),                        \\\n    .vnd_model_count  = ARRAY_SIZE(_vnd_mods),          \\\n    .vnd_models       = (_vnd_mods),                    \\\n}  The variables of the element structure are as follows:   addr : stores the element primary address, used by Mesh Stack during the\n  configuration process. It can be ignored for the higher level applications.  loc : location descriptor defined by SIG. For this demo, set its value to\n   0 .  model_count : number of SIG models supported in this element.  vnd_model_count : number of the Vendor model supported in this element.  models : pointer to the SIG Models that have already been defined.  vnd_models : pointer to the Vendor Model that has already been defined.",
            "title": "2 Implementation of BLE Mesh Element Structure"
        },
        {
            "location": "/Subjects/NP1/P5/#3-implementation-of-ble-mesh-model-structure",
            "text": "The preceding section has introduced the specific ways to implement and define\nan element by passing specific model pointers to it. This section explains how\nto implement and define a Model structure, which is shown in the code blocks\nbelow.  /** Abstraction that describes a Mesh Model instance.\n *  This structure is associated with bt_mesh_model in mesh_access.h\n */\nstruct esp_ble_mesh_model {\n    /* Model ID */\n    union {\n        const uint16_t model_id;\n        struct {\n            uint16_t company_id;\n            uint16_t model_id;\n        } vnd;\n    };\n\n    /* The Element to which this Model belongs */\n    esp_ble_mesh_elem_t *element;\n\n    /* Model Publication */\n    esp_ble_mesh_model_pub_t *const pub;\n\n    /* AppKey List */\n    uint16_t keys[CONFIG_BLE_MESH_MODEL_KEY_COUNT];\n\n    /* Subscription List (group or virtual addresses) */\n    uint16_t groups[CONFIG_BLE_MESH_MODEL_GROUP_COUNT];\n\n    /* Model operation context */\n    esp_ble_mesh_model_op_t *op;\n\n    /* Model-specific user data */\n    void *user_data;\n};  The block above shows a specific implementation of the model structure. Although\nthis structure has many variables, only the following four ones are used for\napplications:    id  and  vnd : union variables, defining the SIG Model and the Vendor Model\n  respectively.    op : structure with a set of variables for the Model Operation, declaring the\n  opcode that corresponds to Get, Set, or Status State, as well as the minimum\n  value lengths that are supported in this module.    pub : structure that needs to be defined if the Model structure supports the\n  Publish function.    user_data : optional variable for storing the application layer data.    The other structures and variables (keys, group, element) get their values\nthrough the BLE Mesh stack during the initialization or configuration stages.\nYou are not required to initialize them.  The next code block presents the definition of the model structure, and the root_models[]  array. This array is used for indicating the number of the\nexisting model structures. A model is implemented by using a macro.  static esp_ble_mesh_model_t root_models[] = {\n    ESP_BLE_MESH_MODEL_CFG_SRV(&config_server),\n    ESP_BLE_MESH_SIG_MODEL(ESP_BLE_MESH_MODEL_ID_GEN_ONOFF_SRV, onoff_op,\n    &onoff_pub, &led_state[0]),\n};  Different models require different macros. The existing types of models and\ntheir respective macros needed for implementation are given in the table below\n(as we are implementing a Generic OnOff Server model, we use the ESP_BLE_MESH_MODEL_ID_GEN_ONOFF_SRV  macro).     Model Name  Macro Required for its Definition      Configuration Server Model  ESP_BLE_MESH_MODEL_CFG_SRV    Configuration Client Model  ESP_BLE_MESH_MODEL_CFG_CLI    Generic OnOff Client Model  ESP_BLE_MESH_MODEL_GEN_ONOFF_CLI    Generic Level Client Model  ESP_BLE_MESH_MODEL_GEN_LEVEL_CLI    Generic Default Transition Time Client Model  ESP_BLE_MESH_MODEL_GEN_DEF_TRANS_TIME_CLI    Generic Power OnOff Client Model  ESP_BLE_MESH_MODEL_GEN_POWER_ONOFF_CLI    Generic Power Level Client Model  ESP_BLE_MESH_MODEL_GEN_POWER_LEVEL_CLI    Generic Battery Client Model  ESP_BLE_MESH_MODEL_GEN_BATTERY_CLI    Generic Location Client Model  ESP_BLE_MESH_MODEL_GEN_LOCATION_CLI    Generic Property Client Model  ESP_BLE_MESH_MODEL_GEN_PROPERTY_CLI    Light Lightness Client Model  ESP_BLE_MESH_MODEL_LIGHT_LIGHTNESS_CLI    Light CTL Client Model  ESP_BLE_MESH_MODEL_LIGHT_CTL_CLI    Light HSL Client Model  ESP_BLE_MESH_MODEL_LIGHT_HSL_CLI    Sensor Client Model  ESP_BLE_MESH_MODEL_SENSOR_CLI    Scene Client Model  ESP_BLE_MESH_MODEL_SCENE_CLI     Another important structure in a model is the  esp_ble_mesh_model_op_t *op \npointer. This structure points to the operation structure that defines the\nModel state. Generally, there are two types of models in BLE Mesh:   Server Model :  Consists of one or multiple states that can exist across different elements  Defines the messages sent/received by the model, along with the element's\n  behavior.  Example\uff1aOn/Off switch --- Indicates the On/Off status.      Client Model :  Defines the messages used by the client to request, change or use the\n  relevant state of the server.  Example\uff1aOn/Off switch --- Indicates the On or Off message sent by the\n  Client.       The following code block shows the declaration of the Model operation structure.  /*!< Model operation context.\n    This structure is associated with bt_mesh_model_op in mesh_access.h */\ntypedef struct {\n    const uint32_t    opcode;   /* Opcode encoded with the ESP_BLE_MESH_MODEL_OP_* macro */\n    const size_t      min_len;  /* Minimum required message length */\n    esp_ble_mesh_cb_t param_cb; /* The callback is only used for the BLE Mesh stack, not for the app layer. */\n} esp_ble_mesh_model_op_t;  There are three variables in the declaration of the operation structure:   opcode : opcode corresponding to a state. As specified in BLE Mesh, the SIG\n  Model opcode should be 1~2 bytes, and the Vendor Model opcode should be 3\n  bytes.  min_len : min length of the messages received by the state. For example,\n  OnOff Get state is 0 bytes, and OnOff Set State is 2 bytes.  param_cb : used for the BLE Mesh protocol only. Applications need to set its\n  value to  0 .   The definition for our OnOff Server code is:  static esp_ble_mesh_model_op_t onoff_op[] = {\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_GET, 0, 0},\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET, 2, 0},\n    { ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET_UNACK, 2, 0},\n    /* Each model operation struct array must use this terminator\n     * as the end tag of the operation uint. */\n    ESP_BLE_MESH_MODEL_OP_END,\n};",
            "title": "3 Implementation of BLE Mesh Model Structure"
        },
        {
            "location": "/Subjects/NP1/P5/#the-onoff-client",
            "text": "The design of the client is much easier. In a generic way, it just defines an\nON/OFF Client model and waits to be provisioned. Once the provisioning process\nis completed, every time one of the buttons on the board (RESET) is pressed, it\nsends a request for a change in the status of the lights to all the nodes in its\nmesh network. This behaviour is coded in the following functions defined in the board.c  file:  static void button_tap_cb(void* arg)\n{\n    ESP_LOGI(TAG, \"tap cb (%s)\", (char *)arg);\n\n    example_ble_mesh_send_gen_onoff_set();\n}\n\nstatic void board_button_init(void)\n{\n    button_handle_t btn_handle = iot_button_create(BUTTON_IO_NUM, BUTTON_ACTIVE_LEVEL);\n    if (btn_handle) {\n        iot_button_set_evt_cb(btn_handle, BUTTON_CB_RELEASE, button_tap_cb, \"RELEASE\");\n    }\n}\n\nvoid board_init(void)\n{\n    board_led_init();\n    board_button_init();\n}  The invoked function,  example_ble_mesh_send_gen_onoff_set , sends a  SET \noperation to all network members:  void example_ble_mesh_send_gen_onoff_set(void)\n{\n    esp_ble_mesh_generic_client_set_state_t set = {0};\n    esp_ble_mesh_client_common_param_t common = {0};\n    esp_err_t err = ESP_OK;\n\n    common.opcode = ESP_BLE_MESH_MODEL_OP_GEN_ONOFF_SET_UNACK;\n    common.model = onoff_client.model;\n    common.ctx.net_idx = store.net_idx;\n    common.ctx.app_idx = store.app_idx;\n    common.ctx.addr = 0xFFFF;   /* to all nodes */\n    common.ctx.send_ttl = 3;\n    common.ctx.send_rel = false;\n    common.msg_timeout = 0;     /* 0 indicates that timeout value from menuconfig will be used */\n    common.msg_role = ROLE_NODE;\n\n    set.onoff_set.op_en = false;\n    set.onoff_set.onoff = store.onoff;\n    set.onoff_set.tid = store.tid++;\n\n    err = esp_ble_mesh_generic_client_set_state(&common, &set);\n    if (err) {\n        ESP_LOGE(TAG, \"Send Generic OnOff Set Unack failed\");\n        return;\n    }\n\n    store.onoff = !store.onoff;\n    mesh_example_info_store(); /* Store proper mesh example info */\n}  Observe that the destination address is for all nodes in the network\n( common.ctx.addr = 0xFFFF; ).",
            "title": "The OnOff Client"
        },
        {
            "location": "/Subjects/NP1/P5/#provisioning-and-control-from-a-mobile-application",
            "text": "You will use the two ESP nodes you have, one programmed as an OnOff Server and\nthe other programmed as an OnOff Client. If you have three LEDs available, you\ncan place the server node on a breadboard and connect the anodes of the LEDs to\nthe pins where the server node expects the lights to be connected (you can find\nthose in the  board.h  file, mainly the pins 25, 26 and 27). It is convenient\nthat you also place in series a current limmitng resistor, a 220 ohm resistor\nshould be fine.  You can run the two nodes and monitor its output (use the idf.py command). Once\nboth are up and running you will use the  nRF Mesh  app on your smartphone to\ncomplete the provisioning of both nodes, creating a ble mesh for thme. To\ncomplete the provisioning you have to proceed as follows:   STEP 1 : the initial screen will show you the nodes that are already\n  provisioned (initially none).     STEP 2 : you will click on  ADD NODE  and provision (one by one) your two\n  nodes:     STEP 3 : you have to generate the network information for the new node\n  ( identify  it), pressing  IDENTIFY :     STEP 4 : once the network information has been generated, you can provision\n  the node (pressing  PROVISION ):     STEP 5 : if everything went well, a success message like the following one\n  will be shown:     STEP 6 : after repeating this step with the two nodes in our group, you will\n  see a screen like the following. Observe and write down the unicast addresses\n  of each node. The node with one item is the OnOff Client; the node with three\n  elements is the OnOff Server.    Next, you will generate a group of nodes. This will allow you to subscribe the\n  models to it, and publish messages that will be broadcasted to all models in\n  the group.   STEP 7 : Create a new group by pressing the  +  button. Give it the name and\n  address you want, for example,  Living Room ,  0xC000 . If everything went\n  well, you will see a single valid group with no nodes associated/subscribed to it.     STEP 8 : Next, you will subscribe each  Generic On Off Server  and  Generic\n  On Off Client  models to the group you just created. You have to do it node by\n  node, first by clicking on the concrete model:    And then associate an application key ( BIND KEY ) and subscribe ( SUBSCRIBE )\n  to the desired group:     Now, if all went well, if you go to the group description tab, you will see an\nicon with a picture for the lights, and another icon for the client (a swithc).   At this point, if you are monitoring the output of all ESP32s, you will see that\nthe state of the LED changes at the request of the application (pressing the\nlight icon). In addition, you will see that it also changes if you press the\ncorresponding button of the switch ( RESET ) on the board. If you did connect\nthe LEDs to the server board as mentioned above, you will see how they change\ntheir on/off state when you press the light icon in the smartphone or the button\nin the client board.   Task 5.1  The client sends, after pressing the button, the message of type  SET  to\nall the nodes of the network. Modify it so that it is only sent to the nodes\nthat belong to its group. Try to subscribe/unsubscribe a model from the\ngroup, and you will see how it no longer receives the status change request\nmessages. Deliver the modified code.",
            "title": "Provisioning and control from a mobile application"
        },
        {
            "location": "/Subjects/NP1/P5/#example-for-the-sensor-model",
            "text": "In this part of the assignment, we implement a sensor model client that is also\na provisioner, and a configurable sensor model server. We will work with the\ncode in  examples/bluetooth/esp_ble_mesh/ble_mesh_sensor_model .  The  Sensor Server  model is a model that allows exposing series of\nsensorization data.  The  Sensor Client  model is used to consume sensorization values ( Sensor states )\nexposed by the server.  These models are made up of the following parts:   Status  Sensor Descriptor . It describes the sensor data, and is immutable\n  throughout its life.  Status  Sensor Setting . Controls the sensor parameters. For example, it could\n  indicate its sensitivity, that could be remotely adjusted to prevent a motion\n  sensor from tripping on small movements.  Status  Sensor Cadence . Controls the cadence of sensing.  Status  Sensor Data . It contains the sensed values. It is actually\n  represented by one or more  Property ID  -  Value  pairs.  Status  Sensor Series Column . Only used if each of the values is considered\n  as belonging to a data series.   In the  client  example, the device is both a provisioner and a client. Once the\nserver device is provisioned and configured, users can press the button on the\nboard to send requests to the server that, successively, will return the next\nstatus of the sensor in order ( Descriptor ,  Setting ,  Cadence , ...).  In the  server  example, the non-provisioned device implements a  Sensor Server \nmodel. The server supports two state instances: the first ( Property ID 0x0056 )\nwould represent  Indoor  temperature; the second ( Property ID 0x005B ) would\nrepresent the  Outdoor  temperature. All data, in these examples, is\npre-initialized.",
            "title": "Example for the SENSOR MODEL"
        },
        {
            "location": "/Subjects/NP1/P5/#running-the-example",
            "text": "First, start the client/provider node and monitor its output. Then stat the\nserver node, you will see that it is provisioned by your client, granting it a\nunicast address. Write it down.  The general operation of the system is:   Device A runs the  client  example, and device B runs the  server  example.  A acts as a provider. After receiving a request from B, he provisions it and\n   stores his address. You will see the MAC BLE (UUID) of B in the provisioning\n   process from A.  In A, each press of the button will make a request to node B.  Successively, these requests will be, in order and for each press:  Sensor Descriptor .  Sensor Cadence .  Sensor Settings .  Sensor Data .  Sensor Series .      Task  Study the client and server code, and see to which node is the client\nsending the requests, what operations are requested on each button press,\nand what data the returns the server in each case.    Task 5.2  Modify the client and/or server code so that insted of requesting\niteratively  all  the values from the  last  provided node, it request\nonly the sensor data ( Sensor Data State ) of  all  the provisioned nodes.\nSo if there are three provisioned nodes, each press would return the\nsensorization value of one of them, in the provisioning order.  You will\nfind the  esp_ble_mesh_provisioner_get_node_table_entry  function usefull\nto get a list/table of all connected nodes.  As an additional functionality, modify the code so that only those\nauthorized nodes will be automatically provisioned (those that belong to\nyour room, for example).  A final  optional  modification would be to periodically change randombly\nthe sensed data on the server, with a predetermined cadence (remote\nmodification of the cadence remains an advanced exercise).  Deliver the resulting code.",
            "title": "Running the example"
        },
        {
            "location": "/Subjects/NP1/P6/",
            "text": "Lab 6. 6LowPAN and RPL\n\n\nIntroduction and goals\n\n\nEdge routers are routers that can be found on the edge of a network, routing the\ntraffic of that network to a second external network. Its function, in short, is\nto connect one network to another.\n\n\nIn this lab, we will see how to build a simulation using an edge router in\nContiki. More specifically, we will see how a Contiki edge router can be used to\nroute traffic between an RPL network (a Contiki sensor network with routing\nprotocol RPL over IPv6) and an external IPv4 network, following the diagram\nbelow:\n\n\n\n\nThe goal of the lab is to provide an overview of how to deploy both an RPL\nnetwork with Contiki in the Cooja simulator, as well as making it interact with\na second real external network using the tool \ntunslip\n.\n\n\nInstallation of software requirements\n\n\nThe basic installation of Contiki (in its version 2.7) is in the\n\n/home/ubuntu/contiki\n directory of your virtual machine.\n\n\nBefore you begin, you will need to install some support software:\n\n\nsudo apt install -y openjdk-8-jdk openjdk-8-jre\n\n\n\n\nNext, be sure to select Java version 8 for a correct functioning of the Cooja\ncompilation process, run the following command and make sure that the option\n\n/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n is selected:\n\n\nubuntu@ubuntu2004:~/contiki/tools/cooja$ sudo update-alternatives --config java\n\n\n\n\nFinally, you will need to install the compiler that will allow you to generate\nthe images for the simulated nodes:\n\n\nsudo apt install gcc-msp430 gdb-msp430\n\n\n\n\nContiki Code\n\n\nIn the development of the lab assignment, we will use the following files, all\nlocated in the \nexamples/ipv6/rpl-border-router\n subdirectory of the Contiki\ninstallation path:\n\n\n\n\nborder_router.c\n: code that we will use for the edge router.\n\n\nudp-client.c\n or\nudp_server.c\n (in the \nexamples/ipv6/rpl-udp\n directory):\n  that will we will use for the nodes in our RPL network (its functionality is\n  not relevant for the moment).\n\n\nslip-bridge.c\n: contains the \ncallback\n functions to process a SLIP\n  connection request.\n\n\nhttpd-simple.c\n: it contains a simple web server that will allow us check the\n  routing tables of the edge router.\n\n\n\n\nNodes that implement the \nudp-client.c\n or \nborder_router.c\n code will form a\nDAG, with the edge router configured as root. The edge router will receive the\nnetwork prefix via an SLIP connection (\nSerial Line Interface Protocol\n) and\nwill communicate it to the rest of the nodes of the RPL network so that they can\nbuild their corresponding global IPv6 addresses.\n\n\nThe following code snippets, taken from the edge router, show the point where it\nwaits for the network prefix. Once received, the edge router is configured as\nthe root of the DAG and sends the prefix to all other nodes of the network:\n\n\n/* Request prefix until it has been received */ \n while(!prefix_set) { \n   etimer_set(&et, CLOCK_SECOND); \n   request_prefix(); \n   PROCESS_WAIT_EVENT_UNTIL(etimer_expired(&et)); \n } \n\n\n dag = rpl_set_root(RPL_DEFAULT_INSTANCE,(uip_ip6addr_t *)dag_id); \n if(dag != NULL) { \n   rpl_set_prefix(dag, &prefix, 64); \n   PRINTF(\"created a new RPL dag\\n\"); \n }\n\n\n\n\nBy default, the edge router hosts a simple web page that will allows us to check\nthe status of its routing table. This page will be displayed by introducing in a\nweb browser of the virtual machine the IPv6 address of the edge router. The use\nor not of this page is controlled with the macro \nWEBSERVER\n in the\n\nhttp-simple.c\n file:\n\n\nPROCESS(border_router_process, \"Border router process\");\n#if WEBSERVER==0\n/* No webserver */\nAUTOSTART_PROCESSES(&border_router_process);\n#elif WEBSERVER>1\n/* Use an external webserver application */\n#include \"webserver-nogui.h\"\nAUTOSTART_PROCESSES(&border_router_process,&webserver_nogui_process); \n\n\n\n\nCode compilation\n\n\nThe code for the edge router can be found in the path\n\nexamples/ipv6/rpl-border-router\n. In a terminal, use the following command to\nperform the compilation:\n\n\ncd examples/ipv6/rpl-border-router\nmake TARGET=z1\n\n\n\n\nOnce executed, a file called \nborder-router.z1\n will be created, which will be\nused to program the mote (simulated device) for the edge router in the cooja\nsimulator.\n\n\nTo demonstrate the functionality of the edge router, we will create a network of\nnodes with the edge router as root. For the rest of the nodes, we will use\nUDP client code, implemented in the file \nudp-client.c\n. Prepare images for\nthese motes as follows:\n\n\ncd examples/ipv6/rpl-udp\nmake TARGET=z1\n\n\n\n\nAs before, you will obtain a file named \nudp-client.z1\n, that will that shall be\nused to program the rest of the motes of the DAG.\n\n\nSimulation with Cooja\n\n\nAfter compiling the images, it is time to configure the complete simulation in\nCooja. Start the simulator using the following command:\n\n\ncd tools/cooja\nant run\n\n\n\n\nOnce cooja starts follow these steps to create a new simulation:\n\n\n\n\nSelect the \nFile->New Simulation\n option. Then the \nUDGM\n option and enter\n   the name of the simulation. Press \nCreate\n.\n\n\nIn the \nMotes\n menu, select\nAdd New Motes->Create new motes\n and select\n   \nZ1\n as the type of mote.\n\n\nFind the location of the image for the border router\n   (\nexamples/ipv6/rpl-border-router\n) and select the file\n   \nrpl-border-router.z1\n. Click on \nCreate\n and add \none\n mote of this type.\n\n\nRepeat steps 2 and 3, but this time with the UDP client image that you\n   created earlier. Add \nfour\n or \nfive\n motes of this type (selecting four\n   instead one in step 3) and manually distribute them throughout the\n   simulation, so that not all of them can be directly reached from the edge\n   router.\n\n\n\n\n\n\nSelect the \nView\n menu options as shown in the figure. This will allow you to\neasily create your topology (you can temporarily add the IP address as\nwell, although it might overload the figure with too much information):\n\n\n\n\nNext, create a bridge between the simulated RPL network in Cooja and\nthe local machine by  This can be done by selecting \nTools\n and \nSerial Socket\n(SERVER)\n on the edge router mote (identify it with its numeric value). If every\nthing went well you will get a message like the one in the figure below (note\nthat the message indicates \nListening on port 60001\n):\n\n\n\n\nThen \nstart the simulation\n (\nStart\n button).\n\n\nThe tunslip tool\n\n\nAs we have said, an edge router acts as a link to connect a network to another\nnetwork. In this example, the edge router is used to route data between the RPL\nnetwork and an external network. So far, we have only created the RPL network,\nso we need to simulate a scenario where this RPL network connects to an external\nnetwork. To do this, we use the tunslip utility provided with Contiki. It will\ncreate a bridge between the RPL network and the local machine.\n\n\nThe code \ntunslip6.c\n is located in the\ntools\n directory of the contiki\ninstallation path, and it can be compiled with the following command:\n\n\nmake tunslip6\n\n\n\n\nThen we can establish a connection between the RPL network and the local\nmachine by running the following command:\n\n\nsudo ./tunslip6 -a 127.0.0.1 aaaa::1/64\n\n\n\n\nIf the execution was correct, you will see an output in the terminal similar to\nthis one:\n\n\nubuntu@ubuntu2004:~/contiki/tools$ sudo ./tunslip6 -a 127.0.0.1 aaaa::1/64\nslip connected to ``127.0.0.1:60001''\nopened tun device ``/dev/tun0''\nifconfig tun0 inet `hostname` mtu 1500 up\nifconfig tun0 add aaaa::1/64\nifconfig tun0 add fe80::0:0:0:1/64\nifconfig tun0\n\ntun0: flags=4305<UP,POINTOPOINT,RUNNING,NOARP,MULTICAST>  mtu 1500\n        inet 127.0.1.1  netmask 255.255.255.255  destination 127.0.1.1\n        inet6 aaaa::1  prefixlen 64  scopeid 0x0<global>\n        inet6 fe80::1  prefixlen 64  scopeid 0x20<link>\n        inet6 fe80::ace4:dadf:8e12:be05  prefixlen 64  scopeid 0x20<link>\n        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 500  (UNSPEC)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n*** Address:aaaa::1 => aaaa:0000:0000:0000\nGot configuration message of type P\nSetting prefix aaaa::\nServer IPv6 addresses:\n aaaa::c30c:0:0:1\n fe80::c30c:0:0:1\n\n\n\n\nThe program has created a bridge interface \ntun0\n with IPv4 127.0.1.1, and has\nsent, via serial, a configuration message to the edge router indicating the\ndesired IPv6 prefix for the RPL network nodes (\naaaa\n). The last two lines are\npart of the output of the edge router, and indicate their IPv6 addresses after\nthe reception of the prefix.\n\n\nNote that in the Cooja window a message with the text \nClient connected:\n/127.0.0.1\n has appeared.\n\n\nSimulation analysis\n\n\nIt is possible to verify the address of the edge router through a command\nping from your virtual machine:\n\n\nubuntu@ubuntu2004:~/contiki/tools$ ping aaaa::c30c:0:0:1\nPING aaaa::c30c:0:0:1(aaaa::c30c:0:0:1) 56 data bytes\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=1 ttl=64 time=21.5 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=2 ttl=64 time=7.44 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=3 ttl=64 time=8.57 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=4 ttl=64 time=62.7 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=5 ttl=64 time=15.2 ms\n--- aaaa::c30c:0:0:1 ping statistics ---\n5 packets transmitted, 5 received, 0% packet loss, time 4015ms\nrtt min/avg/max/mdev = 7.442/23.066/62.661/20.427 ms\n\n\n\n\nSo as with any other node in the RPL network, for instance with node 4:\n\n\nubuntu@ubuntu2004:~/contiki/tools$ ping aaaa::c30c:0:0:4\nPING aaaa::c30c:0:0:4(aaaa::c30c:0:0:4) 56 data bytes\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=1 ttl=62 time=116 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=2 ttl=62 time=106 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=3 ttl=62 time=108 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=4 ttl=62 time=111 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=5 ttl=62 time=79.0 ms\n^C\n--- aaaa::c30c:0:0:4 ping statistics ---\n5 packets transmitted, 5 received, 0% packet loss, time 4016ms\nrtt min/avg/max/mdev = 79.002/104.028/115.794/12.937 ms\n\n\n\n\nThe address of each node can be obtained by filtering the log screen\nbased on the destination node (mote) ID.\n\n\nIn addition you can open a web browser on the virtual machine and browse the IP\naddress of the edge router to observe its routing table:\n\n\n\n\n\n\nTask 6.1\n\n\nFollow the steps detailed above to create an RPL network with a reduced\nnumber of nodes (between 5 and 10), connecting it to your local network.\nMake sure that not all nodes fall in range of the edge router, and begin\nyour simulation. Study the RPL traffic generated while the DAG is being\nconstructed, and check connectivity with all of the nodes via \nping6\n.  Move\none mote that is in the reach of the edge router out of its reach. With\n\nping6\n active on that mote, observe how the mote converges to the DODAG\nagain (selecting a new upstrem node). You can also move other motes or\ncreate new ones, and study, through the web interface of the edge router,\nthe time to establish new routes.\n\n\nFinally, you can anaylaze the RPL trafic with wireshark by exporting a PCAP\nfile. You have to enable them opening the radio messages tool from the Tools\nmenu and selecting Analyzer->6LoWPAN Analyzer with PCAP. Then you can export\nthe PCAP file with the radio mesagges tool and import it in whireshark,\nwhere you can filter the mesagges by protocol or address as usual. A\nconvenient step here is to eliminate duplicated packages from the PCAP file\nbefore opening it in whireshark. That can be done with the editcap command:\n\n\neditcap -d original_capture_file.cap output_capture_file.cap\n\n\nYou can then easily trace the routes followed by the messages sent from each\nnode and generate a figure that represent the topology of the network.\n\n\nThe student should prepare a small pdf report documenting all these analysis\nand observations, showing all the experiments conducted on the network.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP1/P6/#lab-6-6lowpan-and-rpl",
            "text": "",
            "title": "Lab 6. 6LowPAN and RPL"
        },
        {
            "location": "/Subjects/NP1/P6/#introduction-and-goals",
            "text": "Edge routers are routers that can be found on the edge of a network, routing the\ntraffic of that network to a second external network. Its function, in short, is\nto connect one network to another.  In this lab, we will see how to build a simulation using an edge router in\nContiki. More specifically, we will see how a Contiki edge router can be used to\nroute traffic between an RPL network (a Contiki sensor network with routing\nprotocol RPL over IPv6) and an external IPv4 network, following the diagram\nbelow:   The goal of the lab is to provide an overview of how to deploy both an RPL\nnetwork with Contiki in the Cooja simulator, as well as making it interact with\na second real external network using the tool  tunslip .",
            "title": "Introduction and goals"
        },
        {
            "location": "/Subjects/NP1/P6/#installation-of-software-requirements",
            "text": "The basic installation of Contiki (in its version 2.7) is in the /home/ubuntu/contiki  directory of your virtual machine.  Before you begin, you will need to install some support software:  sudo apt install -y openjdk-8-jdk openjdk-8-jre  Next, be sure to select Java version 8 for a correct functioning of the Cooja\ncompilation process, run the following command and make sure that the option /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java  is selected:  ubuntu@ubuntu2004:~/contiki/tools/cooja$ sudo update-alternatives --config java  Finally, you will need to install the compiler that will allow you to generate\nthe images for the simulated nodes:  sudo apt install gcc-msp430 gdb-msp430",
            "title": "Installation of software requirements"
        },
        {
            "location": "/Subjects/NP1/P6/#contiki-code",
            "text": "In the development of the lab assignment, we will use the following files, all\nlocated in the  examples/ipv6/rpl-border-router  subdirectory of the Contiki\ninstallation path:   border_router.c : code that we will use for the edge router.  udp-client.c  or udp_server.c  (in the  examples/ipv6/rpl-udp  directory):\n  that will we will use for the nodes in our RPL network (its functionality is\n  not relevant for the moment).  slip-bridge.c : contains the  callback  functions to process a SLIP\n  connection request.  httpd-simple.c : it contains a simple web server that will allow us check the\n  routing tables of the edge router.   Nodes that implement the  udp-client.c  or  border_router.c  code will form a\nDAG, with the edge router configured as root. The edge router will receive the\nnetwork prefix via an SLIP connection ( Serial Line Interface Protocol ) and\nwill communicate it to the rest of the nodes of the RPL network so that they can\nbuild their corresponding global IPv6 addresses.  The following code snippets, taken from the edge router, show the point where it\nwaits for the network prefix. Once received, the edge router is configured as\nthe root of the DAG and sends the prefix to all other nodes of the network:  /* Request prefix until it has been received */ \n while(!prefix_set) { \n   etimer_set(&et, CLOCK_SECOND); \n   request_prefix(); \n   PROCESS_WAIT_EVENT_UNTIL(etimer_expired(&et)); \n } \n\n\n dag = rpl_set_root(RPL_DEFAULT_INSTANCE,(uip_ip6addr_t *)dag_id); \n if(dag != NULL) { \n   rpl_set_prefix(dag, &prefix, 64); \n   PRINTF(\"created a new RPL dag\\n\"); \n }  By default, the edge router hosts a simple web page that will allows us to check\nthe status of its routing table. This page will be displayed by introducing in a\nweb browser of the virtual machine the IPv6 address of the edge router. The use\nor not of this page is controlled with the macro  WEBSERVER  in the http-simple.c  file:  PROCESS(border_router_process, \"Border router process\");\n#if WEBSERVER==0\n/* No webserver */\nAUTOSTART_PROCESSES(&border_router_process);\n#elif WEBSERVER>1\n/* Use an external webserver application */\n#include \"webserver-nogui.h\"\nAUTOSTART_PROCESSES(&border_router_process,&webserver_nogui_process);",
            "title": "Contiki Code"
        },
        {
            "location": "/Subjects/NP1/P6/#code-compilation",
            "text": "The code for the edge router can be found in the path examples/ipv6/rpl-border-router . In a terminal, use the following command to\nperform the compilation:  cd examples/ipv6/rpl-border-router\nmake TARGET=z1  Once executed, a file called  border-router.z1  will be created, which will be\nused to program the mote (simulated device) for the edge router in the cooja\nsimulator.  To demonstrate the functionality of the edge router, we will create a network of\nnodes with the edge router as root. For the rest of the nodes, we will use\nUDP client code, implemented in the file  udp-client.c . Prepare images for\nthese motes as follows:  cd examples/ipv6/rpl-udp\nmake TARGET=z1  As before, you will obtain a file named  udp-client.z1 , that will that shall be\nused to program the rest of the motes of the DAG.",
            "title": "Code compilation"
        },
        {
            "location": "/Subjects/NP1/P6/#simulation-with-cooja",
            "text": "After compiling the images, it is time to configure the complete simulation in\nCooja. Start the simulator using the following command:  cd tools/cooja\nant run  Once cooja starts follow these steps to create a new simulation:   Select the  File->New Simulation  option. Then the  UDGM  option and enter\n   the name of the simulation. Press  Create .  In the  Motes  menu, select Add New Motes->Create new motes  and select\n    Z1  as the type of mote.  Find the location of the image for the border router\n   ( examples/ipv6/rpl-border-router ) and select the file\n    rpl-border-router.z1 . Click on  Create  and add  one  mote of this type.  Repeat steps 2 and 3, but this time with the UDP client image that you\n   created earlier. Add  four  or  five  motes of this type (selecting four\n   instead one in step 3) and manually distribute them throughout the\n   simulation, so that not all of them can be directly reached from the edge\n   router.    Select the  View  menu options as shown in the figure. This will allow you to\neasily create your topology (you can temporarily add the IP address as\nwell, although it might overload the figure with too much information):   Next, create a bridge between the simulated RPL network in Cooja and\nthe local machine by  This can be done by selecting  Tools  and  Serial Socket\n(SERVER)  on the edge router mote (identify it with its numeric value). If every\nthing went well you will get a message like the one in the figure below (note\nthat the message indicates  Listening on port 60001 ):   Then  start the simulation  ( Start  button).",
            "title": "Simulation with Cooja"
        },
        {
            "location": "/Subjects/NP1/P6/#the-tunslip-tool",
            "text": "As we have said, an edge router acts as a link to connect a network to another\nnetwork. In this example, the edge router is used to route data between the RPL\nnetwork and an external network. So far, we have only created the RPL network,\nso we need to simulate a scenario where this RPL network connects to an external\nnetwork. To do this, we use the tunslip utility provided with Contiki. It will\ncreate a bridge between the RPL network and the local machine.  The code  tunslip6.c  is located in the tools  directory of the contiki\ninstallation path, and it can be compiled with the following command:  make tunslip6  Then we can establish a connection between the RPL network and the local\nmachine by running the following command:  sudo ./tunslip6 -a 127.0.0.1 aaaa::1/64  If the execution was correct, you will see an output in the terminal similar to\nthis one:  ubuntu@ubuntu2004:~/contiki/tools$ sudo ./tunslip6 -a 127.0.0.1 aaaa::1/64\nslip connected to ``127.0.0.1:60001''\nopened tun device ``/dev/tun0''\nifconfig tun0 inet `hostname` mtu 1500 up\nifconfig tun0 add aaaa::1/64\nifconfig tun0 add fe80::0:0:0:1/64\nifconfig tun0\n\ntun0: flags=4305<UP,POINTOPOINT,RUNNING,NOARP,MULTICAST>  mtu 1500\n        inet 127.0.1.1  netmask 255.255.255.255  destination 127.0.1.1\n        inet6 aaaa::1  prefixlen 64  scopeid 0x0<global>\n        inet6 fe80::1  prefixlen 64  scopeid 0x20<link>\n        inet6 fe80::ace4:dadf:8e12:be05  prefixlen 64  scopeid 0x20<link>\n        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 500  (UNSPEC)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n*** Address:aaaa::1 => aaaa:0000:0000:0000\nGot configuration message of type P\nSetting prefix aaaa::\nServer IPv6 addresses:\n aaaa::c30c:0:0:1\n fe80::c30c:0:0:1  The program has created a bridge interface  tun0  with IPv4 127.0.1.1, and has\nsent, via serial, a configuration message to the edge router indicating the\ndesired IPv6 prefix for the RPL network nodes ( aaaa ). The last two lines are\npart of the output of the edge router, and indicate their IPv6 addresses after\nthe reception of the prefix.  Note that in the Cooja window a message with the text  Client connected:\n/127.0.0.1  has appeared.",
            "title": "The tunslip tool"
        },
        {
            "location": "/Subjects/NP1/P6/#simulation-analysis",
            "text": "It is possible to verify the address of the edge router through a command\nping from your virtual machine:  ubuntu@ubuntu2004:~/contiki/tools$ ping aaaa::c30c:0:0:1\nPING aaaa::c30c:0:0:1(aaaa::c30c:0:0:1) 56 data bytes\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=1 ttl=64 time=21.5 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=2 ttl=64 time=7.44 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=3 ttl=64 time=8.57 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=4 ttl=64 time=62.7 ms\n64 bytes from aaaa::c30c:0:0:1: icmp_seq=5 ttl=64 time=15.2 ms\n--- aaaa::c30c:0:0:1 ping statistics ---\n5 packets transmitted, 5 received, 0% packet loss, time 4015ms\nrtt min/avg/max/mdev = 7.442/23.066/62.661/20.427 ms  So as with any other node in the RPL network, for instance with node 4:  ubuntu@ubuntu2004:~/contiki/tools$ ping aaaa::c30c:0:0:4\nPING aaaa::c30c:0:0:4(aaaa::c30c:0:0:4) 56 data bytes\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=1 ttl=62 time=116 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=2 ttl=62 time=106 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=3 ttl=62 time=108 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=4 ttl=62 time=111 ms\n64 bytes from aaaa::c30c:0:0:4: icmp_seq=5 ttl=62 time=79.0 ms\n^C\n--- aaaa::c30c:0:0:4 ping statistics ---\n5 packets transmitted, 5 received, 0% packet loss, time 4016ms\nrtt min/avg/max/mdev = 79.002/104.028/115.794/12.937 ms  The address of each node can be obtained by filtering the log screen\nbased on the destination node (mote) ID.  In addition you can open a web browser on the virtual machine and browse the IP\naddress of the edge router to observe its routing table:    Task 6.1  Follow the steps detailed above to create an RPL network with a reduced\nnumber of nodes (between 5 and 10), connecting it to your local network.\nMake sure that not all nodes fall in range of the edge router, and begin\nyour simulation. Study the RPL traffic generated while the DAG is being\nconstructed, and check connectivity with all of the nodes via  ping6 .  Move\none mote that is in the reach of the edge router out of its reach. With ping6  active on that mote, observe how the mote converges to the DODAG\nagain (selecting a new upstrem node). You can also move other motes or\ncreate new ones, and study, through the web interface of the edge router,\nthe time to establish new routes.  Finally, you can anaylaze the RPL trafic with wireshark by exporting a PCAP\nfile. You have to enable them opening the radio messages tool from the Tools\nmenu and selecting Analyzer->6LoWPAN Analyzer with PCAP. Then you can export\nthe PCAP file with the radio mesagges tool and import it in whireshark,\nwhere you can filter the mesagges by protocol or address as usual. A\nconvenient step here is to eliminate duplicated packages from the PCAP file\nbefore opening it in whireshark. That can be done with the editcap command:  editcap -d original_capture_file.cap output_capture_file.cap  You can then easily trace the routes followed by the messages sent from each\nnode and generate a figure that represent the topology of the network.  The student should prepare a small pdf report documenting all these analysis\nand observations, showing all the experiments conducted on the network.",
            "title": "Simulation analysis"
        },
        {
            "location": "/Subjects/NP2/FinalProject/",
            "text": "Networks and Protocols (NP1 + NP2) Final Programming Project\n\n\nAs a last exercise for the two subjects (NP1 and NP2) you will work in \nteams\nof 2 people\n on a project that shows what you have learned from these topics.\nYou will develop (program) a system to monitor the amount of people in a room,\nby detecting their smartphones, uploading the data to an external server for\nanalysis and visualization. In the following sections we describe what should be\ncovered for the two subjects.\n\n\nRequirements for NP1\n\n\nYour system should manage a sensor network, formed by your ESP32 nodes. We assume\nthat you could have at least one node per room and that each room has a WiFi\naccess point reachable. In this context:\n\n\n\n\n\n\nYour nodes should be able to connect to the AP using WiFi, with WPA2-PSK\n  security.\n\n\n\n\n\n\nYour nodes should provide a provissioning option, so that you can configure\n  the wifi SSID to connect to. You can use a softAP or a BLE provisioning\n  method, that is up to you.\n\n\n\n\n\n\nYour nodes should use BLE to compute the number of other BLE devices in its\n  range (an estimation of the number of people in its range), using the RSSI to\n  compute the distance to the node (the student should research for methods to\n  compute the distance).\n\n\n\n\nAlternatively the student can opt for using a different technology of his\n  choice to estimate the number of people in the room.\n\n\n\n\n\n\n\n\nThe node should be configured through the menuconfig system, to establish its\n  parameters:\n\n\n\n\nSampling period.\n\n\nServer where the samples should be sent to (see requirements for NP2).\n\n\nRange of valid distances.\n\n\netc.\n\n\n\n\n\n\n\n\nOptional Parts for NP1\n\n\nOptionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):\n\n\n\n\n\n\nConsider an scenario with larger rooms, in which one node is not enough and\n  the wifi AP is not reachable on all points. In this scenario you can use the\n  ESP's wifi-mesh technology to build a mesh of nodes in the room.\n\n\n\n\n\n\nStudy the Over The Air (OTA) features of ESP and prepare your nodes to receive\n  OTA updates from an external server. Together with NP2 you can consider to\n  configure the nodes to trigger the OTA update through MQTT (or any other\n  application protocol you are using).\n\n\n\n\n\n\nAdd a GATT server that allows the node parameters to be configured with a BLE\n  client.\n\n\n\n\n\n\nRequirements for NP2\n\n\nThe developed system will periodically publish the calculated data for the \npopulation of BLE devices in the room, sending it to an external server for \nfurther storage and analysis. \n\n\nSpecifically, the minimum requirements related with NP2 include:\n\n\n\n\n\n\nYou will select an application-level protocol among those studied in NP2 \n  (or, alternatively, other similar protocols of your interest) and use it \n  for data publishing.\n\n\n\n\n\n\nServers/brokers to which data will be sent will be configured via \nmenuconfig\n, \n  together with the sending period and any other configurable parameter \n  considered useful.\n\n\n\n\n\n\nYou will select and use one of the two data representation methods studied in \n  the course (JSON or CBOR).\n\n\n\n\n\n\nData will be gathered by Node-RED and submitted to two different destinations:\n\n\n\n\nA dashboard of your election (e.g. Node-RED, Grafana, ...).\n\n\nA database (e.g. MongoDB), where it will be stored together with a timestamp.\n\n\n\n\n\n\n\n\nOptional Parts for NP2\n\n\nOptionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):\n\n\n\n\n\n\nUse encryption at all levels of the communication (e.g. MQTT).\n\n\n\n\n\n\nDevelop an alarm system that triggers under certain conditions (e.g. when the amount of \n  BLE devices is out of a pre-established range), and sends a notification to the user using\n  external services (e.g. SMS, e-mail, Telegram, ...).\n\n\n\n\n\n\nImplement bi-directional communication, with the possibility of externally modifying the \n  behavior of the ESP32 (e.g. modifying sampling or sending period).",
            "title": "FinalProject"
        },
        {
            "location": "/Subjects/NP2/FinalProject/#networks-and-protocols-np1-np2-final-programming-project",
            "text": "As a last exercise for the two subjects (NP1 and NP2) you will work in  teams\nof 2 people  on a project that shows what you have learned from these topics.\nYou will develop (program) a system to monitor the amount of people in a room,\nby detecting their smartphones, uploading the data to an external server for\nanalysis and visualization. In the following sections we describe what should be\ncovered for the two subjects.",
            "title": "Networks and Protocols (NP1 + NP2) Final Programming Project"
        },
        {
            "location": "/Subjects/NP2/FinalProject/#requirements-for-np1",
            "text": "Your system should manage a sensor network, formed by your ESP32 nodes. We assume\nthat you could have at least one node per room and that each room has a WiFi\naccess point reachable. In this context:    Your nodes should be able to connect to the AP using WiFi, with WPA2-PSK\n  security.    Your nodes should provide a provissioning option, so that you can configure\n  the wifi SSID to connect to. You can use a softAP or a BLE provisioning\n  method, that is up to you.    Your nodes should use BLE to compute the number of other BLE devices in its\n  range (an estimation of the number of people in its range), using the RSSI to\n  compute the distance to the node (the student should research for methods to\n  compute the distance).   Alternatively the student can opt for using a different technology of his\n  choice to estimate the number of people in the room.     The node should be configured through the menuconfig system, to establish its\n  parameters:   Sampling period.  Server where the samples should be sent to (see requirements for NP2).  Range of valid distances.  etc.",
            "title": "Requirements for NP1"
        },
        {
            "location": "/Subjects/NP2/FinalProject/#optional-parts-for-np1",
            "text": "Optionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):    Consider an scenario with larger rooms, in which one node is not enough and\n  the wifi AP is not reachable on all points. In this scenario you can use the\n  ESP's wifi-mesh technology to build a mesh of nodes in the room.    Study the Over The Air (OTA) features of ESP and prepare your nodes to receive\n  OTA updates from an external server. Together with NP2 you can consider to\n  configure the nodes to trigger the OTA update through MQTT (or any other\n  application protocol you are using).    Add a GATT server that allows the node parameters to be configured with a BLE\n  client.",
            "title": "Optional Parts for NP1"
        },
        {
            "location": "/Subjects/NP2/FinalProject/#requirements-for-np2",
            "text": "The developed system will periodically publish the calculated data for the \npopulation of BLE devices in the room, sending it to an external server for \nfurther storage and analysis.   Specifically, the minimum requirements related with NP2 include:    You will select an application-level protocol among those studied in NP2 \n  (or, alternatively, other similar protocols of your interest) and use it \n  for data publishing.    Servers/brokers to which data will be sent will be configured via  menuconfig , \n  together with the sending period and any other configurable parameter \n  considered useful.    You will select and use one of the two data representation methods studied in \n  the course (JSON or CBOR).    Data will be gathered by Node-RED and submitted to two different destinations:   A dashboard of your election (e.g. Node-RED, Grafana, ...).  A database (e.g. MongoDB), where it will be stored together with a timestamp.",
            "title": "Requirements for NP2"
        },
        {
            "location": "/Subjects/NP2/FinalProject/#optional-parts-for-np2",
            "text": "Optionally you can extend the project incorporating some extra features like the\nfollowing (these are only ideas, you can also propose some others):    Use encryption at all levels of the communication (e.g. MQTT).    Develop an alarm system that triggers under certain conditions (e.g. when the amount of \n  BLE devices is out of a pre-established range), and sends a notification to the user using\n  external services (e.g. SMS, e-mail, Telegram, ...).    Implement bi-directional communication, with the possibility of externally modifying the \n  behavior of the ESP32 (e.g. modifying sampling or sending period).",
            "title": "Optional Parts for NP2"
        },
        {
            "location": "/Subjects/NP2/groups/",
            "text": "Groups for lecture assignments\n\n\nWe will be using the stable groups from NP1 to work during lectures (and after\nclass).\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\n\n\nGroup 2\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nLiu Jinhua\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nWeilin Zhang\n\n\n\n\n\n\nContributor\n\n\nDuan Zhen\n\n\n\n\n\n\nContributor\n\n\nYouran Tian\n\n\n\n\n\n\nContributor\n\n\nHuang Yujuan\n\n\n\n\n\n\nContributor\n\n\nJun Shou\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nYuanShuang Sha\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\nContributor\n\n\nLIAO  Yinghua\n\n\n\n\n\n\nContributor\n\n\nPAN Jiayun\n\n\n\n\n\n\nContributor\n\n\nZHANG  Yi\n\n\n\n\n\n\nContributor\n\n\nWEI REN\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nXIAZU HU\n\n\n\n\n\n\n\n\nGroup 5\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nShuishi Zhou\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nAuditor\n\n\nWENYAN LIAO\n\n\n\n\n\n\nContributor\n\n\nFENGFENG GU\n\n\n\n\n\n\nContributor\n\n\nBIN ZHANG\n\n\n\n\n\n\nContributor\n\n\nHONGBIAO CAO\n\n\n\n\n\n\nContributor\n\n\nGONGLU ZOU\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nXionglan Luo\n\n\n\n\n\n\nAuditor\n\n\nQiuji Chen\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang\n\n\n\n\n\n\nContributor\n\n\nYan Zhao\n\n\n\n\n\n\nContributor\n\n\nYongtao He\n\n\n\n\n\n\nContributor\n\n\nZhao Hu",
            "title": "Groups"
        },
        {
            "location": "/Subjects/NP2/groups/#groups-for-lecture-assignments",
            "text": "We will be using the stable groups from NP1 to work during lectures (and after\nclass).",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/NP2/groups/#group-1",
            "text": "Rol  Full name      Speaker  ZHOU Ping",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/NP2/groups/#group-2",
            "text": "Rol  Full name      Speaker  Liu Jinhua    Recorder  Hu Haho    Auditor  Weilin Zhang    Contributor  Duan Zhen    Contributor  Youran Tian    Contributor  Huang Yujuan    Contributor  Jun Shou",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/NP2/groups/#group-3",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  YuanShuang Sha    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao    Contributor  LIAO  Yinghua    Contributor  PAN Jiayun    Contributor  ZHANG  Yi    Contributor  WEI REN",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/NP2/groups/#group-4",
            "text": "Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG YU    Auditor  SUIZHI LIU    Contributor  TIANFENG LI    Contributor  XIAZU HU",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/NP2/groups/#group-5",
            "text": "Rol  Full name      Speaker  Shuishi Zhou    Contributor  Yang Chu    Auditor  WENYAN LIAO    Contributor  FENGFENG GU    Contributor  BIN ZHANG    Contributor  HONGBIAO CAO    Contributor  GONGLU ZOU",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/NP2/groups/#group-6",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Xionglan Luo    Auditor  Qiuji Chen    Contributor  Jianchuang Zhang    Contributor  Yan Zhao    Contributor  Yongtao He    Contributor  Zhao Hu",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/NP2/",
            "text": "Networks and Protocols 2\n\n\nGeneral information\n\n\nThis subject will cover different topics about application-level\ncommunication APIs, standard and interfaces, with special emphasis\non Internet of Things inter-communication. Specifically, we will\ncover both Linux and \n\nESP-IDF\n \nprogramming on the ESP32, to fulfill the following specific goals:\n\n\n\n\nGet a global overview of the necessities and particularities of\nIoT from the application communication perspective.\n\n\nAdvocate for open standards for IoT communication.\n\n\nIntroduce the concept of Smart Object, and study how it can be\nported to different APIs and languages.\n\n\nIntroduce different techniques for information representation.\n\n\nStudy a number of IoT frameworks and stream processing platforms.\n\n\n\n\nSubject program and evaluation methodology\n\n\nProgram and evaluation\n\n\nProfessor\n\n\nFrancisco Igual (figual@ucm.es)\n\n\nPaper work assignment\n\n\nHere you can find description about this individual assignment\n\n\nFinal programming project (teams of 2 people), shared with NP1\n\n\nOnce ready you will find \nhere\n the details on the final project for this\ncourse.\n\n\nWork groups (for regular lab assignments)\n\n\nHere you can find the current work groups\n\n\nQuizzes\n\n\nAll quizzes will be done in \nthis link\n. The name of the room is UCMIOTNP2.\nYou MUST enter your email to answer the quizzes (the email address where you received mails from me).\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay/Month\n\n\nTopic\n\n\nLab instructions\n\n\nDeliverable\n\n\n\n\n\n\n\n\n\n\n18/01\n\n\nBasic Concepts (I)\n\n\n\n\n\n\n\n\n\n\n20/01\n\n\nBasic Concepts (II)\n\n\n\n\nAssignment 1\n\n\n\n\n\n\n25/01\n\n\nSmart Objects\n, Lab 1. TCP/UDP sockets (Linux)\n\n\nLab 1. instructions\n\n\n\n\n\n\n\n\n27/01\n\n\nLab 1. TCP/UDP sockets (Linux)\n\n\nLab 1. instructions\n\n\n\n\n\n\n\n\n01/02\n\n\nWeek off (Chinese new year)\n\n\n\n\n\n\n\n\n\n\n03/02\n\n\nWeek off (Chinese new year)\n\n\n\n\n\n\n\n\n\n\n08/02\n\n\nTransport layer\n,\n\n\nLab 1. instructions\n\n\n\n\n\n\n\n\n10/02\n\n\nLab 1. TCP/UDP sockets (Linux)\n\n\nLab 1. instructions\n\n\n\n\n\n\n\n\n15/02\n\n\nLab 2. TCP/UDP sockets (ESP32)\n\n\nLab 2. instructions\n\n\nAll tasks from Lab1.\n\n\n\n\n\n\n17/02\n\n\nWebsockets\n, Lab2. TCP/UDP sockets (ESP32)\n\n\nLab 2. instructions\n\n\n\n\n\n\n\n\n22/02\n\n\nInformation representation\n  Lab 2. TCP/UDP (ESP32)\n\n\nLab 2. instructions\n\n\nTasks up to 1.3 from Lab 2.\n\n\n\n\n\n\n24/02\n\n\nREST servers\n Lab 3. Information representation and REST servers\n\n\nLab 3. instructions\n\n\nAll tasks from Lab2\n\n\n\n\n\n\n01/03\n\n\nMQTT\n\n\nLab 3. instructions\n\n\n\n\n\n\n\n\n03/03\n\n\nLab 3. Information representation and REST servers\n\n\nLab 3. instructions\n\n\n\n\n\n\n\n\n08/03\n\n\nLab 4. MQTT (I)\n\n\nLab 4 (I) instructions\n\n\nAll tasks from Lab3\n\n\n\n\n\n\n10/03\n\n\nLab 4. MQTT (II)\n\n\nLab 4 (II) instructions\n\n\n\n\n\n\n\n\n15/03\n\n\nAdvanced MQTT. LWT. Lab4 (II)\n\n\nLab 4 (II) instructions\n\n\nAll tasks from Lab4 (I)\n\n\n\n\n\n\n17/03\n\n\nOTA\n. Lab 4 (II)\n\n\nLab 4 (II) instructions\n\n\n\n\n\n\n\n\n22/03\n\n\nLab 5. Node-RED\n\n\nLab 5. instructions\n\n\nAll tasks from Lab4 (II)\n\n\n\n\n\n\n24/03\n\n\nLab 5. Node-RED\n\n\n\n\n\n\n\n\n\n\n29/03\n\n\nWork on Final Project\n\n\nQuiz\n\n\nAll tasks from Lab5\n\n\n\n\n\n\n31/04\n\n\nWork on Final Project\n\n\nQuiz\n\n\n\n\n\n\n\n\n05/04\n\n\nWork on Final Project\n\n\nQuiz\n\n\n\n\n\n\n\n\n07/04\n\n\nWork on Final Project\n\n\nQuiz",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/#networks-and-protocols-2",
            "text": "",
            "title": "Networks and Protocols 2"
        },
        {
            "location": "/Subjects/NP2/#general-information",
            "text": "This subject will cover different topics about application-level\ncommunication APIs, standard and interfaces, with special emphasis\non Internet of Things inter-communication. Specifically, we will\ncover both Linux and  ESP-IDF  \nprogramming on the ESP32, to fulfill the following specific goals:   Get a global overview of the necessities and particularities of\nIoT from the application communication perspective.  Advocate for open standards for IoT communication.  Introduce the concept of Smart Object, and study how it can be\nported to different APIs and languages.  Introduce different techniques for information representation.  Study a number of IoT frameworks and stream processing platforms.",
            "title": "General information"
        },
        {
            "location": "/Subjects/NP2/#subject-program-and-evaluation-methodology",
            "text": "Program and evaluation",
            "title": "Subject program and evaluation methodology"
        },
        {
            "location": "/Subjects/NP2/#professor",
            "text": "Francisco Igual (figual@ucm.es)",
            "title": "Professor"
        },
        {
            "location": "/Subjects/NP2/#paper-work-assignment",
            "text": "Here you can find description about this individual assignment",
            "title": "Paper work assignment"
        },
        {
            "location": "/Subjects/NP2/#final-programming-project-teams-of-2-people-shared-with-np1",
            "text": "Once ready you will find  here  the details on the final project for this\ncourse.",
            "title": "Final programming project (teams of 2 people), shared with NP1"
        },
        {
            "location": "/Subjects/NP2/#work-groups-for-regular-lab-assignments",
            "text": "Here you can find the current work groups",
            "title": "Work groups (for regular lab assignments)"
        },
        {
            "location": "/Subjects/NP2/#quizzes",
            "text": "All quizzes will be done in  this link . The name of the room is UCMIOTNP2.\nYou MUST enter your email to answer the quizzes (the email address where you received mails from me).",
            "title": "Quizzes"
        },
        {
            "location": "/Subjects/NP2/#schedule",
            "text": "Day/Month  Topic  Lab instructions  Deliverable      18/01  Basic Concepts (I)      20/01  Basic Concepts (II)   Assignment 1    25/01  Smart Objects , Lab 1. TCP/UDP sockets (Linux)  Lab 1. instructions     27/01  Lab 1. TCP/UDP sockets (Linux)  Lab 1. instructions     01/02  Week off (Chinese new year)      03/02  Week off (Chinese new year)      08/02  Transport layer ,  Lab 1. instructions     10/02  Lab 1. TCP/UDP sockets (Linux)  Lab 1. instructions     15/02  Lab 2. TCP/UDP sockets (ESP32)  Lab 2. instructions  All tasks from Lab1.    17/02  Websockets , Lab2. TCP/UDP sockets (ESP32)  Lab 2. instructions     22/02  Information representation   Lab 2. TCP/UDP (ESP32)  Lab 2. instructions  Tasks up to 1.3 from Lab 2.    24/02  REST servers  Lab 3. Information representation and REST servers  Lab 3. instructions  All tasks from Lab2    01/03  MQTT  Lab 3. instructions     03/03  Lab 3. Information representation and REST servers  Lab 3. instructions     08/03  Lab 4. MQTT (I)  Lab 4 (I) instructions  All tasks from Lab3    10/03  Lab 4. MQTT (II)  Lab 4 (II) instructions     15/03  Advanced MQTT. LWT. Lab4 (II)  Lab 4 (II) instructions  All tasks from Lab4 (I)    17/03  OTA . Lab 4 (II)  Lab 4 (II) instructions     22/03  Lab 5. Node-RED  Lab 5. instructions  All tasks from Lab4 (II)    24/03  Lab 5. Node-RED      29/03  Work on Final Project  Quiz  All tasks from Lab5    31/04  Work on Final Project  Quiz     05/04  Work on Final Project  Quiz     07/04  Work on Final Project  Quiz",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/NP2/paperProject/",
            "text": "Individual paper work\n\n\nYou need to prepare a paper work, as explained in\nthe slides of the first class \nPresentation\n.\n\n\nIt is a documentation work in which you are requested to explore a set of documents\nyourself on one of the application-level protocols, technologies and platforms \nused for or focused on IoT systems. \nThe technologies proposed are listed bellow. You are requested to focus\nthe study on its use in your local area or China, however you can expand it to\nAsia or the whole world if you feel like doing it (not required).\n\n\nIn both cases you should study not only the technical aspects of the technology,\nyou should also include known use cases (in the case of choosing one of the\ntechnologies proposed below), expected growth of the technology, direct\ncompetitors and potential future market share. Practical implementations, code\nsnippets, or even protoype codes are also welcome.\n\n\nList of technologies you can consider\n\n\nYou should request one of the topics sending a mail to the professor\n(figual@ucm.es) before \nMarch 1st\n, who will confirm if you can choose \nthe topic.\n\n\nThe topics are:\n\n\n\n\nAdvanced MQTT\n\n\nAdvanced CoAP\n\n\nLWM2M and Smart Objects\n\n\nWebsockets\n\n\nDigital twins\n\n\nAdvanced visualization services and dashboards\n\n\nThe Eclipse IoT project\n\n\nAdvanced JSON and CBOR \n\n\nAmazon Web Services for IoT\n\n\nMicrosoft Azure for IoT\n\n\nGoogle services for IoT\n\n\nAlibaba IoT\n\n\nOTA (Over the Air) updates\n\n\nEdge Computing\n\n\nA comparative study of IoT platforms\n\n\nPractical use cases of any of the studied technologies\n\n\n\n\nDeadline\n\n\nOriginally 8th April.\n\n\nDelivering the project\n\n\nOnce finished, please send me an email (to \nfigual@ucm.es\n)",
            "title": "paperProject"
        },
        {
            "location": "/Subjects/NP2/paperProject/#individual-paper-work",
            "text": "You need to prepare a paper work, as explained in\nthe slides of the first class  Presentation .  It is a documentation work in which you are requested to explore a set of documents\nyourself on one of the application-level protocols, technologies and platforms \nused for or focused on IoT systems. \nThe technologies proposed are listed bellow. You are requested to focus\nthe study on its use in your local area or China, however you can expand it to\nAsia or the whole world if you feel like doing it (not required).  In both cases you should study not only the technical aspects of the technology,\nyou should also include known use cases (in the case of choosing one of the\ntechnologies proposed below), expected growth of the technology, direct\ncompetitors and potential future market share. Practical implementations, code\nsnippets, or even protoype codes are also welcome.",
            "title": "Individual paper work"
        },
        {
            "location": "/Subjects/NP2/paperProject/#list-of-technologies-you-can-consider",
            "text": "You should request one of the topics sending a mail to the professor\n(figual@ucm.es) before  March 1st , who will confirm if you can choose \nthe topic.  The topics are:   Advanced MQTT  Advanced CoAP  LWM2M and Smart Objects  Websockets  Digital twins  Advanced visualization services and dashboards  The Eclipse IoT project  Advanced JSON and CBOR   Amazon Web Services for IoT  Microsoft Azure for IoT  Google services for IoT  Alibaba IoT  OTA (Over the Air) updates  Edge Computing  A comparative study of IoT platforms  Practical use cases of any of the studied technologies",
            "title": "List of technologies you can consider"
        },
        {
            "location": "/Subjects/NP2/paperProject/#deadline",
            "text": "Originally 8th April.",
            "title": "Deadline"
        },
        {
            "location": "/Subjects/NP2/paperProject/#delivering-the-project",
            "text": "Once finished, please send me an email (to  figual@ucm.es )",
            "title": "Delivering the project"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/",
            "text": "Assignment 1\n\n\nDeadline:\n\n\n25/01/22\n\n\nType:\n\n\nIn groups\n\n\nDelivery:\n\n\nVia mail to \nfigual@ucm.es\n indicating \n[Assignment 1] Group number\n in the subject.\n\n\nPart 1\n\n\nIn this assignment, you will work by groups. Discuss with the members of the group and propose\na \nrealistic\n IoT development consisting of, at least,\na number of sensors and actuators distributed in an indoor or outdoor environment (or both).\n\n\nBriefly describe it using a slide, bullet points in a document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.\n\n\nPart 2\n\n\nDevelop with more detail the deployment, with special interest in the following questions:\n\n\n\n\nAre there restrictions in number of messages per time unit?\n\n\nAre there restrictions in latency, bandwidth and other network metrics?\n\n\nWhat is the maximum transmission range between nodes?\n\n\nAre nodes mobile?\n\n\nAre package losses accepted? Is retransmission necessary?\n\n\nIs energy consumption an actual concern?\n\n\nDo nodes need to be maintained/managed remotely?\n\n\nIs bidirectionality in transmission necessary?\n\n\nIs edge computing necessary or recommended?\n\n\nIs security a concern?\n\n\nAny other concern of interest.\n\n\n\n\nWrite down answers to these questions in a slide, document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.\n\n\nPart 3\n\n\nPerform a market study and select:\n\n\n\n\nThe best type of node (board) that can fulfill the restrictions.\n\n\nThe most appropriate network technology (physical/link layer).\n\n\nThe most appropriate application and transport-layer protocols to use at each point of the deployment. \n\n\n\n\nWrite down answers to each topic in a slide, document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.\n\n\nA final report gathering all three parts will be submitted as a final delivery before deadline, and will determine the final grade. \n\nPlease submit one report per group\n.",
            "title": "1"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#assignment-1",
            "text": "",
            "title": "Assignment 1"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#deadline",
            "text": "25/01/22",
            "title": "Deadline:"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#type",
            "text": "In groups",
            "title": "Type:"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#delivery",
            "text": "Via mail to  figual@ucm.es  indicating  [Assignment 1] Group number  in the subject.",
            "title": "Delivery:"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#part-1",
            "text": "In this assignment, you will work by groups. Discuss with the members of the group and propose\na  realistic  IoT development consisting of, at least,\na number of sensors and actuators distributed in an indoor or outdoor environment (or both).  Briefly describe it using a slide, bullet points in a document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.",
            "title": "Part 1"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#part-2",
            "text": "Develop with more detail the deployment, with special interest in the following questions:   Are there restrictions in number of messages per time unit?  Are there restrictions in latency, bandwidth and other network metrics?  What is the maximum transmission range between nodes?  Are nodes mobile?  Are package losses accepted? Is retransmission necessary?  Is energy consumption an actual concern?  Do nodes need to be maintained/managed remotely?  Is bidirectionality in transmission necessary?  Is edge computing necessary or recommended?  Is security a concern?  Any other concern of interest.   Write down answers to these questions in a slide, document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.",
            "title": "Part 2"
        },
        {
            "location": "/Subjects/NP2/Assignments/1/#part-3",
            "text": "Perform a market study and select:   The best type of node (board) that can fulfill the restrictions.  The most appropriate network technology (physical/link layer).  The most appropriate application and transport-layer protocols to use at each point of the deployment.    Write down answers to each topic in a slide, document or any media you consider of \ninterest. After finishing it, a member of the group will need to present it in front of the\nrest of the class.  A final report gathering all three parts will be submitted as a final delivery before deadline, and will determine the final grade.  Please submit one report per group .",
            "title": "Part 3"
        },
        {
            "location": "/Subjects/NP2/P1/",
            "text": "Laboratory 1. Python socket programming\n\n\nGoals\n\n\n\n\nTo get familiar with the Python sockets API.\n\n\nTo develop basic client/server setups based on TCP and UDP using Python.\n\n\nTo be able to analyze traffic generated by a TCP and UDP connection via Wireshark.\n\n\nTo design an application-layer protocol to simulate a client/server application using TCP and UDP.\n\n\nTo observe the difference in generated traffic between UDP and TCP for an equivalent application.\n\n\n(Optionally) To implement multi-threaded servers in Python.\n\n\n\n\nIntroduction\n\n\nThe history of sockets begins with the origin of ARPANET, in 1971, and their\nstandardization by means of an API within the BSD operating system, released\nin 1983, under the name \nBerkeley Sockets\n.\n\n\nWith the popularization of Internet in the 90s, and together with the \nWorld Wide Web\n,\nnetwork programming suffered a relevant evolution.\nWeb servers and browsers were not (and are not) the only applications based on \nsockets. Actually, client/server systems are, as of today, ubiquitous, and include\nall high-level protocols that give support to IoT. Today, even though high-level \nprotocls have evolved till unprecedented sophistication levels, the underlying low-level\ninterface remains unchanged.\n\n\nThe most common application type based on sockets is built on top of the \nclient/server paradigm, where one of the parts acts as a \nserver\n, passively\nwaiting for external connection/requests from a set of one or more \nclients\n.\nIn the following, we will study how to develop this type of paradigm from \nPython, using \nBerkeley sockets\n. There also exist the so-called \n\nUnix domain sockets\n, that allow a direct communication across processes at \nthe same \nhost\n; they are, however, of of the scope of IoT and we will not\nstudy them.\n\n\nThe Python sockets API\n\n\nThe Python \nsocket module\n\nprovides a complete interface to work with the \n\nBerkeley sockets API\n. \nIn this laboratory, we will exclusively work with this API to develop \nclient/server applications using the TCP and UDP protocols.\n\n\nThe main functions and methods of the sockets API are:\n\n\n\n\nsocket()\n.\n\n\nbind()\n.\n\n\nlisten()\n. \n\n\naccept()\n.  \n\n\nconnect()\n. \n\n\nconnect_ex()\n.\n\n\nsend()\n.\n\n\nrecv()\n.\n\n\nclose()\n.\n\n\n\n\nPython provides a consistent and complete API mapped directly to the \naforementioned system calls, typically written in C. As a part of its\nstandard library, Python also provides classes to ease working with low-level\nfunctions. We will not cover it in detail, but the \n\nsocketserver module\n\nprovides an easy way to create network servers. There also exist many \nmodules available to implement high-level protocols (e.g. HTTP or SMTP), \nsee \nthis link\n.\n\n\nTCP sockets\n\n\nIn Python, TCP sockets are created using \nsocket.socket()\n,\nspecifying the socket type as \nsocket.SOCK_STREAM\n. \nThe Transmision Control Protocol (TCP) features two main characteristics:\n\n\n\n\n\n\nIt is reliable\n: loss detection methods are implemented that detect datagram\nlosses and force lost package resubmission.\n\n\n\n\n\n\nGuarantees in-order package delivery\n: data are delivered to higher-levels\n(applications) in the same order as they were sent.\n\n\n\n\n\n\nContrary, UDP sockets are created by means of \nsocket.SOCK_DGRAM\n, and\nthey are neither reliable nor guarantee in-order data delivery. \nHence, it is a responsibility of the application developer to implement\nthose mechanisms manually if desired.\n\n\nThe following picture shows the typical API invocation sequence for TCP:\n\n\n\n\nIn the figure, the left column illustrates the serve, and the right column shows\nthe client of the TCP connection. Observe the necessary invocations to configure\na socket listening for incoming connections:\n\n\n\n\nsocket()\n\n\nbind()\n\n\nlisten()\n\n\naccept()\n\n\n\n\nAt the server, a socket \nlistens\n for potential incoming connections from clients.\nWhen a client rquests a connection, the server \naccepts\n the request, completing \nthe connection.\n\n\nThe client invokes \nconnect()\n to establish a connection with a server, and initiates\nthe \nthree-way handshaking\n protocol to establish the connection.\n\n\nUpon establishment, data are exchanged among client and server via \n\nsend()\n and \nrecv()\n. \n\n\nFinally, the socket is destroyed (the connection is closed) via a \n\nclose()\n invocation at each end.\n\n\nTCP client/server \necho\n example\n\n\nLet us study a simple example to create a client-server pair. In this case,\nthe server just responds to the client with the same string as that received\nfrom the client.\n\n\necho\n server\n\n\n#!/usr/bin/env python3\n\n#### server_echo.py\n\nimport socket\n\nHOST = '127.0.0.1'  # Loopback interface (localhost)\nPORT = 65432        # Listen port (ports higher than 1023 are non-privileged)\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, PORT))\n    s.listen()\n    conn, addr = s.accept()\n    with conn:\n        print('Connected ', addr)\n        while True:\n            data = conn.recv(1024)\n            if not data:\n                break\n            conn.sendall(data)\n\n\n\n\n\n\nNote\n\n\nBy now, do not worry if you do not understand all lines in the code. This\nis just an starting point to develop a simple server. However, it is a good\nidea to copy the code in a text file (e.g. \nserver_echo.py\n) so we can test it\nafterwards.\n\n\n\n\nLet as study line by line the main parts of the code:\n\n\nsocket.socket()\n creates a socket object. Note that, as it is created\nvia a \nwith\n construction, it is not necessary to explicitly invoke\nto \ns.close()\n, even though you need to realize that the object is destroyed\nafter the construction:\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    pass\n\n\n\n\nThe arguments provided to \nsocket()\n specify the address family \n(\nAF_INET\n) \nand socket type (\nSOCK_STREAM\n). \n\nAF_INET\n is the address family of the Internet for IPv4. \n\nSOCK_STREAM\n is the type of socket that allows for the creation of TCP connections.\n\n\nbind()\n is used to associate the socket to a network interface and port number:\n\n\nHOST = '127.0.0.1'  # Loopback interface (localhost)\nPORT = 65432        # Listen port\n\n# ...\n\ns.bind((HOST, PORT))\n\n\n\n\nThe values proviede to \nbind()\n depend on the address family selected for the\nsocket. In the example, as \nAF_INET\n is used, the routine\nexpects a tuple with just two values \n(host, port)\n.\n\n\nTo determine the \nhost\n, it is possible to use a host name, an IP address or an\nempty string. If we use an IP address, it needs to be specified by means of a string\ncontaining a well-formed address.  The address 127.0.0.1 is the standard IPv4 address\nfor the loopback interface, so that only local processes (running at the same host) \nwill be able to communicate with the server. If we provide an empty string, the server\nwill accept incoming connections by via all IPv4 interfaces in the system.\n\n\nThe port number (\nport\n) is specified with an integer value between 1 and 65535,\nand specifies the port (in this case, TCP) that the server will use to accept incoming\nclient connection. Many systems require superuser privilege to listen via privileged\nports (with values between 1 and 1023).\n\n\nFollowing with the example, \nlisten()\n allows for a server to accept, in the future,\nincoming connections via \naccept()\n. In other words, it transforms the socket into a\nlistening socket:\n\n\ns.listen()\nconn, addr = s.accept()\n\n\n\n\nInvoking \naccept()\n \nblocks\n the process and waits for an incoming connection.\nUpon a client connection, it returns a \nsocket\n object that represents\nthe connection, and a tupple (\naddr\n) that contains the address of the client.\nThis tuple contains the values \n(host, port)\n that store the \nIPv4 adress and client port that requests for the connection.\n\n\nNote that, in the example, \nconn\n  is the \nsocket\n object that we will \nuse to communicate with the client:\n\n\nconn, addr = s.accept()\nwith conn:\n    print('Connected ', addr)\n    while True:\n        data = conn.recv(1024)\n        if not data:\n            break\n        conn.sendall(data)\n\n\n\n\nAfter obtaining the object returned by \naccept()\n, \nwe design the server as an infinite loop that repeatedly invokes\nto \nblocking\n \nconn.recv()\n. \nThis way, we read data sent by the client and we resend them without\nmodification using \nconn.sendall()\n.\n\n\nIf \nconn.recv()\n returns an empty object of type \nbytes\n (\nb''\n), it means\nthat the client closed the conection, in which case the loop finishes, destroying\nthe socket after the \nwith\n construction.\n\n\necho\n client\n\n\nLet us observe the general structure of the client (you can use, for example\n\nclient_echo.py\n as a name for the file):\n\n\n#!/usr/bin/env python3\n\n### client_echo.py\n\nimport socket\n\nHOST = '127.0.0.1'  # Server IP\nPORT = 65432        # Listen server port \n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.connect((HOST, PORT))\n    s.sendall(b'Hello, world')\n    data = s.recv(1024)\n\nprint('Received ', repr(data))\n\n\n\n\nCompared with the server, the client structure is simpler; it just\ncreates a new socket object, connects with the server and invokes \n\ns.sendall()\n to send the message. Finally, it waits for the\nresponse using \ns.recv()\n and prints it on screen.\n\n\nEcho client and server execution\n\n\nNext, we will execute the client and server programs to observe the\nstatus of the connection troughout their life cycle.\n\n\nExecute in a terminal the server:\n\n\n$ python3 ./server-echo.py\n\n\n\n\nYou will see that the terminal blocks (actually, the server process remains in \na blocked state) in the invocation:\n\n\nconn, addr = s.accept()\n\n\n\n\nActually, the server is waiting for incoming connections from a client. Open\na sencond terminal and execute the client:\n\n\n$ python3 client-echo.py\nReceived 'Hello, world'\n\n\n\n\nOn the server screen, you should see something similar to:\n\n\n$ python3 ./server-echo.py\nConnected ('127.0.0.1, 61234')\n\n\n\n\nIn this output, the server reports the tuple returned by \n\ns.accept()\n, that includes the IP address and the TCP port. \nThat port number (in the example, 61234) is seleted randomly \nby the operating system and can vary in your execution.\n\n\nTools to analyze the socket status\n\n\nWe can use the \nnetstat\n tool to observe the current status of the \nsockets in any OS (macOS, Linux and even Windows). \nFor example, this would be the output of \nnetstat\n in Linux\nafter executing the server:\n\n\nnetstat -an | grep 65432\nActive connections\nProto  Recv  Sent   Local address           Remote address         Status\ntcp        0      0 127.0.0.1:65432         0.0.0.0:*              LISTEN\n\n\n\n\nNote that we have filtered the output of the \nnetcat\n command\nto match the used port. \nAlso observe the value of all columns, and try to understand if it makes sense\nto you.\n\n\n\n\nNote\n\n\nAnother way to observe the status of the connections is via the command \n\nlsof -i -n\n. Execute it and observe its output.\n\n\n\n\nCapturing network traffic via Wireshark\n\n\nWireshark is an open-source tool widely used to analyze network communication\nprotocols at any layer of the TCP/IP stack (and also other protocols). Wireshark \nimplements a wide range of filters to define search criteria in the traffic\ncaptures. However, in our case, it will not be necessary to use advanced\nfilters.\n\n\nTo execute the took in the virtual machine (or in any basic Linux setup), \njust type in your terminal:\n\n\n$ sudo wireshark\n\n\n\n\nUpon booting, we can start a new traffic capture via the \nmenu \nCapture\n, option \nStart\n. \nThe interface selection screen allows for the definition of the \ninterface we need to intercept. In our case, as we are communicating\ntwo processes on the same machine, we will choose the\n\n\nLoopback\n (lo) interface and we will start the capture.\n\n\n\n\nTask 1.1\n\n\nStart wireshark and prepare a capture on the \nloopback\n interface. \nExecute the TCP \necho\n server and the corresponding client, and analyze\nthe generated traffic. Specifically, observe the connection establishment\nprocedure, use of ACK packages and, in general any other aspect that is of\nyour interest. \nWrite a short report with screenshots of your observations.\n\n\n\n\nUDP sockets\n\n\nThe creation and management of UDP sockets in Python is even simpler. Observe the\nfollowing code, that creates a UDP server using the Python sockets API:\n\n\nimport socket\n\nudp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nudp_socket.bind((\"localhost\", 5005))\n\ndata = udp_socket.recv(512)\nprint(data)\n\n\n\n\nFirst, we import the \nsocket\n module, as for TCP. Obviously, in this case\nthe socket type is of type \n\nsocket.DOCK_DGRAM\n, to indicate that we need to use UDP in the communication.\n\n\nThe program waits for the reception of a packet using the blocking \n\nrecv\n method, with only one parameter: the maximum number of bytes\nwe would like to receive.\n\n\nWhen a packet arrives to the socket, the \nrecv\n method will return \na byte \narray\n, that will be stored in the desired variable.\n\n\nThe submission of data is also simple:\n\n\nimport socket\n\nudp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nudp_socket.bind((\"localhost\", 0))\n\ndata = b\"Hello, world!\"\nudp_socket.sendto(data,(\"localhost\", 5005))\n\n\n\n\nNote how, in this case, we associate (\nbind\n) the socket to a port specifyed \nas 0. This special value indicates to the OS that it needs to choos for the \ntransmission a random source port between those available in the system.\n\n\nNext, we create the data to sumbit, and send them using the method\n\nsendto()\n. This method takes two arguments: data to send, and\ndestination address. Data sent through the socket must be part of a bytes array\nde un \narray de bytes\n (hence, the string to submit needs to be preceeded by\nthe character \nb\n).\n\n\n\n\nTask 1.2\n\n\nCheck that the codes for sending and receiving via UDP work as expected.\n\nWrite a short report with your observations\n\n\n\n\n\n\nNote\n\n\nFrom version 3 on, strings in Python are coded using UNICODE.\nContrary from ASCII, where each character has a direct byte representation, \n\nUNICODE uses integers to represent each character, that need to be encoded\nto obtain a byte representation. One of these schemas is UTF-8. For example,,\nthe following code shows how to encode a UNICODE string onto a bytes \nrepresentation:\n\n\nc= \"Hello\"\ndata = c.encode(\"UTF-8\")\nprint(data, type(data))\n\n\nThat generates:\n\n\nb\"Hello\" <class 'bytes'>\n\n\nthat can be sent directly through the network.\n\n\n\n\nUp to this point, the UDP programs have been completely unidirectional in the\nsubmission/reception of data, but obviously, a UDP socket is a bi-directional\ncommunication channel.\n\n\n\n\nTask 1.3\n\n\nImplement a similar functionality than that of the \necho\n that we \nstudied for TCP, but using UDP. Provide a traffic capture via Wireshark\nand observe the differences between the data transmission in TCP and UDP.\nProvide a discussion about the benefits (or lack of them) of UDP compared\nwith TCP for IoT.\n\n\n\n\nSending binary data via sockets\n\n\nUp to this point, we have studied how to send text strings via TCP or UDP\nsockets, but it is common to find a necessity to send data directly in \nbinary format (e.g. numeric values in floating point or integers). Using the\n\nstruct\n Python module, we can specify which type or types of data are stored\nin a sequence of bytes, and how to decode them. It is also possible to specify\nin which place of the sequence are those data stored, allowing for packing\nmultiple data of different types in a simple manner, and its decoding at the\nother side of the communication channel.\n\n\n\n\nNote\n\n\nCheck all details of the \nstruct\n module on its official\n\ndocumentation\n page.\n\n\n\n\nThe \nstruct\n module provides two interesting methods: \npack\n and \nunpack\n.\n\n\nThe following sentence:\n\n\nstruct.pack(\">iii\", 1, 2, 3)\n\n\n\n\nuses the \npack\n method to perform data packing. \nSpecifically, observe how the method receives two parameters:\n\n\n\n\n\n\nFirst, the format parameter \n\">iii\"\n. It defines how each value in the sequence\n  need to be encoded.  The first character indicates the \nendianness\n, \n  in this case \nbig endian\n \n  (we should use \">\" for big endiand, \"<\" for little endian, and \"=\" for network endianness).\n\n\n\n\n\n\nSecond, the values to pack.\n\n\n\n\n\n\nNote that the format, in addition, includes the number and type of data to pack\n(in this case three integer values). For other data types, check the module's documentation.\n\n\nUnpacking data on the other side of the cahnnel is intuitive:\n\n\na, b, c = struct.unpack( \">iii\" )\n\n\n\n\nNext, we show an example of a client/server TCP setup that leverages the\n\nstruct\n to send two integer numbers and a floating point number between a client\nand a server:\n\n\n\n# Client\n\nimport binascii                                                                             \nimport socket                                                                               \nimport struct                                                                               \nimport sys                                                                                  \n\n# Socket TCP                                                                                \nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                                    \nserver_address = ('localhost', 10001)                                                       \nsock.connect(server_address)                                                                \n\npacked_data = struct.pack(\"=iif\", 1, 4, 2.7)                                                \n\ntry:                                                                                        \n    # Sending data\n    print('Sending \"%s\"' % binascii.hexlify(packed_data))                                  \n    sock.sendall(packed_data)                                                               \n\nfinally:                                                                                    \n    print('Closing socket')                                                                \n    sock.close()                                                                            \n\n\n\n\n\n# Server\n\nimport binascii                                                                             \nimport socket                                                                               \nimport struct                                                                               \nimport sys                                                                                  \n\n# Socket TCP                                                                                \nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                                    \nserver_address = ('localhost', 10001)                                                       \nsock.bind(server_address)                                                                   \nsock.listen(1)                                                                              \n\nwhile True:                                                                                 \n    print('Waiting for incoming connections')                                                 \n    connection, client_address = sock.accept()                                              \n    try:                                                                                    \n        data = connection.recv(1024)                                                        \n        print('Received \"%s\"' % binascii.hexlify(data))                                     \n\n        unpacked_data = struct.unpack(\"=iif\", data)                                         \n        print('Unpacked:', unpacked_data)                                             \n\n    finally:                                                                                \n        connection.close()\n\n\n\n\n\n\nTask 1.4\n\n\nExecute the client/server system and analyze the generated traffic. Look for \nthe binary packed data. Experiment with other types of data and \nendianness\n\nand observe the differences.\n\n\n\n\nDeliverable task\n\n\n\n\nDeliverable task 1\n\n\nDesign a client/server system and implement it using Python. The system\nwill simulate a client sending a number of pieces of data sensed to a server.\nThe protocol to use (format of each packet sent to the server at the application\nlayer) needs to be designed and proposed by the student and described \nprior to starting the coding effort.\nThe final mark will consider positively the use of multiple data types, \nboth in ths sent data and responses from the server. \nThe student will develop a TCP and a UDP version of the solution. The client will submit data in a periodic fashion, and data will be generated randomly.\n\n\nThe deliverable will include the developed codes, and an analysis of the generated\ntraffic, with comments about the overhead (in bytes) introduced by each protocol\nof the transport layer.\n\n\n\n\nMulti-threaded client/server example\n\n\nThe previous examples are perfectly valid and functional, but lack in their design\nof a basic functionality: the server stops attending new incoming requests while\na request from a client is processed. The following examples show simple implementations\nwith multi-threaded support for a client/server system written in Python.\n\n\n# Concurrent TCP server\n\nimport socket, threading\n\nclass ClientThread(threading.Thread):\n    def __init__(self,clientAddress,clientsocket):\n        threading.Thread.__init__(self)\n        self.csocket = clientsocket\n        print (\"New connection added: \", clientAddress)\n    def run(self):\n        print (\"Connection from: \", clientAddress)\n        #self.csocket.send(bytes(\"Hi, This is from Server..\",'utf-8'))\n        msg = ''\n        while True:\n            data = self.csocket.recv(2048)\n            msg = data.decode()\n\n            if msg=='bye':\n              break\n\n            print (\"From the client\", msg)\n            self.csocket.send(bytes(msg,'UTF-8'))\n\n        print (\"Client \", clientAddress , \" disconnected...\")\n\nLOCALHOST = \"127.0.0.1\"\nPORT = 8080\n\nserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\nserver.bind((LOCALHOST, PORT))\n\nprint(\"Server started...\")\nprint(\"Waiting for client requests...\")\n\nserver.listen(1)\n\nwhile True:\n    clientsock, clientAddress = server.accept()\n    newthread = ClientThread(clientAddress, clientsock)\n    newthread.start()\n\n\n\n\n# TCP client. The string *end* indicates disonnection request.\n\nimport socket\n\nSERVER = \"127.0.0.1\"\nPORT = 8080\n\nclient = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nclient.connect((SERVER, PORT))\nclient.sendall(bytes(\"Hello, I am a client!!\",'UTF-8'))\n\nwhile True:\n  in_data =  client.recv(1024)\n\n  print(\"From the server:\" ,in_data.decode())\n  out_data = input()\n  client.sendall(bytes(out_data,'UTF-8'))\n\n  if out_data=='end':\n    break\n\nclient.close()\n\n\n\n\n\n\nTask 1.5\n\n\nStudy the codes for the concurrent server and observe how it manages\nthe creaton of threads to handle an incoming request. Connect simultaneously\nmultiple clients and observe the status of the sockets using the corresponding \ntools. \nWrite a short report with your observations\n.\n\n\n\n\nOptional deliverable\n\n\n\n\nOptional deliverable task 1\n\n\nModify your first deliverable to consider a multi-threaded implmentation\nof the TCP server, following the guidelines of the example codes.\n\n\n\n\nOptional deliverable\n\n\n\n\nOptional deliverable task 1\n\n\nModify the sending protocol so that your UDP applications guarantees\nas much as possible the reception of UDP packages sent from the client,\nand an in-order reception.\nAnalyze again the necessary network traffic in this case compared with a\nTCP scheme.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P1/#laboratory-1-python-socket-programming",
            "text": "",
            "title": "Laboratory 1. Python socket programming"
        },
        {
            "location": "/Subjects/NP2/P1/#goals",
            "text": "To get familiar with the Python sockets API.  To develop basic client/server setups based on TCP and UDP using Python.  To be able to analyze traffic generated by a TCP and UDP connection via Wireshark.  To design an application-layer protocol to simulate a client/server application using TCP and UDP.  To observe the difference in generated traffic between UDP and TCP for an equivalent application.  (Optionally) To implement multi-threaded servers in Python.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP2/P1/#introduction",
            "text": "The history of sockets begins with the origin of ARPANET, in 1971, and their\nstandardization by means of an API within the BSD operating system, released\nin 1983, under the name  Berkeley Sockets .  With the popularization of Internet in the 90s, and together with the  World Wide Web ,\nnetwork programming suffered a relevant evolution.\nWeb servers and browsers were not (and are not) the only applications based on \nsockets. Actually, client/server systems are, as of today, ubiquitous, and include\nall high-level protocols that give support to IoT. Today, even though high-level \nprotocls have evolved till unprecedented sophistication levels, the underlying low-level\ninterface remains unchanged.  The most common application type based on sockets is built on top of the \nclient/server paradigm, where one of the parts acts as a  server , passively\nwaiting for external connection/requests from a set of one or more  clients .\nIn the following, we will study how to develop this type of paradigm from \nPython, using  Berkeley sockets . There also exist the so-called  Unix domain sockets , that allow a direct communication across processes at \nthe same  host ; they are, however, of of the scope of IoT and we will not\nstudy them.",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/NP2/P1/#the-python-sockets-api",
            "text": "The Python  socket module \nprovides a complete interface to work with the  Berkeley sockets API . \nIn this laboratory, we will exclusively work with this API to develop \nclient/server applications using the TCP and UDP protocols.  The main functions and methods of the sockets API are:   socket() .  bind() .  listen() .   accept() .    connect() .   connect_ex() .  send() .  recv() .  close() .   Python provides a consistent and complete API mapped directly to the \naforementioned system calls, typically written in C. As a part of its\nstandard library, Python also provides classes to ease working with low-level\nfunctions. We will not cover it in detail, but the  socketserver module \nprovides an easy way to create network servers. There also exist many \nmodules available to implement high-level protocols (e.g. HTTP or SMTP), \nsee  this link .",
            "title": "The Python sockets API"
        },
        {
            "location": "/Subjects/NP2/P1/#tcp-sockets",
            "text": "In Python, TCP sockets are created using  socket.socket() ,\nspecifying the socket type as  socket.SOCK_STREAM . \nThe Transmision Control Protocol (TCP) features two main characteristics:    It is reliable : loss detection methods are implemented that detect datagram\nlosses and force lost package resubmission.    Guarantees in-order package delivery : data are delivered to higher-levels\n(applications) in the same order as they were sent.    Contrary, UDP sockets are created by means of  socket.SOCK_DGRAM , and\nthey are neither reliable nor guarantee in-order data delivery. \nHence, it is a responsibility of the application developer to implement\nthose mechanisms manually if desired.  The following picture shows the typical API invocation sequence for TCP:   In the figure, the left column illustrates the serve, and the right column shows\nthe client of the TCP connection. Observe the necessary invocations to configure\na socket listening for incoming connections:   socket()  bind()  listen()  accept()   At the server, a socket  listens  for potential incoming connections from clients.\nWhen a client rquests a connection, the server  accepts  the request, completing \nthe connection.  The client invokes  connect()  to establish a connection with a server, and initiates\nthe  three-way handshaking  protocol to establish the connection.  Upon establishment, data are exchanged among client and server via  send()  and  recv() .   Finally, the socket is destroyed (the connection is closed) via a  close()  invocation at each end.",
            "title": "TCP sockets"
        },
        {
            "location": "/Subjects/NP2/P1/#tcp-clientserver-echo-example",
            "text": "Let us study a simple example to create a client-server pair. In this case,\nthe server just responds to the client with the same string as that received\nfrom the client.",
            "title": "TCP client/server echo example"
        },
        {
            "location": "/Subjects/NP2/P1/#echo-server",
            "text": "#!/usr/bin/env python3\n\n#### server_echo.py\n\nimport socket\n\nHOST = '127.0.0.1'  # Loopback interface (localhost)\nPORT = 65432        # Listen port (ports higher than 1023 are non-privileged)\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST, PORT))\n    s.listen()\n    conn, addr = s.accept()\n    with conn:\n        print('Connected ', addr)\n        while True:\n            data = conn.recv(1024)\n            if not data:\n                break\n            conn.sendall(data)   Note  By now, do not worry if you do not understand all lines in the code. This\nis just an starting point to develop a simple server. However, it is a good\nidea to copy the code in a text file (e.g.  server_echo.py ) so we can test it\nafterwards.   Let as study line by line the main parts of the code:  socket.socket()  creates a socket object. Note that, as it is created\nvia a  with  construction, it is not necessary to explicitly invoke\nto  s.close() , even though you need to realize that the object is destroyed\nafter the construction:  with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    pass  The arguments provided to  socket()  specify the address family \n( AF_INET ) \nand socket type ( SOCK_STREAM ).  AF_INET  is the address family of the Internet for IPv4.  SOCK_STREAM  is the type of socket that allows for the creation of TCP connections.  bind()  is used to associate the socket to a network interface and port number:  HOST = '127.0.0.1'  # Loopback interface (localhost)\nPORT = 65432        # Listen port\n\n# ...\n\ns.bind((HOST, PORT))  The values proviede to  bind()  depend on the address family selected for the\nsocket. In the example, as  AF_INET  is used, the routine\nexpects a tuple with just two values  (host, port) .  To determine the  host , it is possible to use a host name, an IP address or an\nempty string. If we use an IP address, it needs to be specified by means of a string\ncontaining a well-formed address.  The address 127.0.0.1 is the standard IPv4 address\nfor the loopback interface, so that only local processes (running at the same host) \nwill be able to communicate with the server. If we provide an empty string, the server\nwill accept incoming connections by via all IPv4 interfaces in the system.  The port number ( port ) is specified with an integer value between 1 and 65535,\nand specifies the port (in this case, TCP) that the server will use to accept incoming\nclient connection. Many systems require superuser privilege to listen via privileged\nports (with values between 1 and 1023).  Following with the example,  listen()  allows for a server to accept, in the future,\nincoming connections via  accept() . In other words, it transforms the socket into a\nlistening socket:  s.listen()\nconn, addr = s.accept()  Invoking  accept()   blocks  the process and waits for an incoming connection.\nUpon a client connection, it returns a  socket  object that represents\nthe connection, and a tupple ( addr ) that contains the address of the client.\nThis tuple contains the values  (host, port)  that store the \nIPv4 adress and client port that requests for the connection.  Note that, in the example,  conn   is the  socket  object that we will \nuse to communicate with the client:  conn, addr = s.accept()\nwith conn:\n    print('Connected ', addr)\n    while True:\n        data = conn.recv(1024)\n        if not data:\n            break\n        conn.sendall(data)  After obtaining the object returned by  accept() , \nwe design the server as an infinite loop that repeatedly invokes\nto  blocking   conn.recv() . \nThis way, we read data sent by the client and we resend them without\nmodification using  conn.sendall() .  If  conn.recv()  returns an empty object of type  bytes  ( b'' ), it means\nthat the client closed the conection, in which case the loop finishes, destroying\nthe socket after the  with  construction.",
            "title": "echo server"
        },
        {
            "location": "/Subjects/NP2/P1/#echo-client",
            "text": "Let us observe the general structure of the client (you can use, for example client_echo.py  as a name for the file):  #!/usr/bin/env python3\n\n### client_echo.py\n\nimport socket\n\nHOST = '127.0.0.1'  # Server IP\nPORT = 65432        # Listen server port \n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.connect((HOST, PORT))\n    s.sendall(b'Hello, world')\n    data = s.recv(1024)\n\nprint('Received ', repr(data))  Compared with the server, the client structure is simpler; it just\ncreates a new socket object, connects with the server and invokes  s.sendall()  to send the message. Finally, it waits for the\nresponse using  s.recv()  and prints it on screen.",
            "title": "echo client"
        },
        {
            "location": "/Subjects/NP2/P1/#echo-client-and-server-execution",
            "text": "Next, we will execute the client and server programs to observe the\nstatus of the connection troughout their life cycle.  Execute in a terminal the server:  $ python3 ./server-echo.py  You will see that the terminal blocks (actually, the server process remains in \na blocked state) in the invocation:  conn, addr = s.accept()  Actually, the server is waiting for incoming connections from a client. Open\na sencond terminal and execute the client:  $ python3 client-echo.py\nReceived 'Hello, world'  On the server screen, you should see something similar to:  $ python3 ./server-echo.py\nConnected ('127.0.0.1, 61234')  In this output, the server reports the tuple returned by  s.accept() , that includes the IP address and the TCP port. \nThat port number (in the example, 61234) is seleted randomly \nby the operating system and can vary in your execution.",
            "title": "Echo client and server execution"
        },
        {
            "location": "/Subjects/NP2/P1/#tools-to-analyze-the-socket-status",
            "text": "We can use the  netstat  tool to observe the current status of the \nsockets in any OS (macOS, Linux and even Windows). \nFor example, this would be the output of  netstat  in Linux\nafter executing the server:  netstat -an | grep 65432\nActive connections\nProto  Recv  Sent   Local address           Remote address         Status\ntcp        0      0 127.0.0.1:65432         0.0.0.0:*              LISTEN  Note that we have filtered the output of the  netcat  command\nto match the used port. \nAlso observe the value of all columns, and try to understand if it makes sense\nto you.   Note  Another way to observe the status of the connections is via the command  lsof -i -n . Execute it and observe its output.",
            "title": "Tools to analyze the socket status"
        },
        {
            "location": "/Subjects/NP2/P1/#capturing-network-traffic-via-wireshark",
            "text": "Wireshark is an open-source tool widely used to analyze network communication\nprotocols at any layer of the TCP/IP stack (and also other protocols). Wireshark \nimplements a wide range of filters to define search criteria in the traffic\ncaptures. However, in our case, it will not be necessary to use advanced\nfilters.  To execute the took in the virtual machine (or in any basic Linux setup), \njust type in your terminal:  $ sudo wireshark  Upon booting, we can start a new traffic capture via the \nmenu  Capture , option  Start . \nThe interface selection screen allows for the definition of the \ninterface we need to intercept. In our case, as we are communicating\ntwo processes on the same machine, we will choose the  Loopback  (lo) interface and we will start the capture.   Task 1.1  Start wireshark and prepare a capture on the  loopback  interface. \nExecute the TCP  echo  server and the corresponding client, and analyze\nthe generated traffic. Specifically, observe the connection establishment\nprocedure, use of ACK packages and, in general any other aspect that is of\nyour interest.  Write a short report with screenshots of your observations.",
            "title": "Capturing network traffic via Wireshark"
        },
        {
            "location": "/Subjects/NP2/P1/#udp-sockets",
            "text": "The creation and management of UDP sockets in Python is even simpler. Observe the\nfollowing code, that creates a UDP server using the Python sockets API:  import socket\n\nudp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nudp_socket.bind((\"localhost\", 5005))\n\ndata = udp_socket.recv(512)\nprint(data)  First, we import the  socket  module, as for TCP. Obviously, in this case\nthe socket type is of type  socket.DOCK_DGRAM , to indicate that we need to use UDP in the communication.  The program waits for the reception of a packet using the blocking  recv  method, with only one parameter: the maximum number of bytes\nwe would like to receive.  When a packet arrives to the socket, the  recv  method will return \na byte  array , that will be stored in the desired variable.  The submission of data is also simple:  import socket\n\nudp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nudp_socket.bind((\"localhost\", 0))\n\ndata = b\"Hello, world!\"\nudp_socket.sendto(data,(\"localhost\", 5005))  Note how, in this case, we associate ( bind ) the socket to a port specifyed \nas 0. This special value indicates to the OS that it needs to choos for the \ntransmission a random source port between those available in the system.  Next, we create the data to sumbit, and send them using the method sendto() . This method takes two arguments: data to send, and\ndestination address. Data sent through the socket must be part of a bytes array\nde un  array de bytes  (hence, the string to submit needs to be preceeded by\nthe character  b ).   Task 1.2  Check that the codes for sending and receiving via UDP work as expected. Write a short report with your observations    Note  From version 3 on, strings in Python are coded using UNICODE.\nContrary from ASCII, where each character has a direct byte representation,  \nUNICODE uses integers to represent each character, that need to be encoded\nto obtain a byte representation. One of these schemas is UTF-8. For example,,\nthe following code shows how to encode a UNICODE string onto a bytes \nrepresentation:  c= \"Hello\"\ndata = c.encode(\"UTF-8\")\nprint(data, type(data))  That generates:  b\"Hello\" <class 'bytes'>  that can be sent directly through the network.   Up to this point, the UDP programs have been completely unidirectional in the\nsubmission/reception of data, but obviously, a UDP socket is a bi-directional\ncommunication channel.   Task 1.3  Implement a similar functionality than that of the  echo  that we \nstudied for TCP, but using UDP. Provide a traffic capture via Wireshark\nand observe the differences between the data transmission in TCP and UDP.\nProvide a discussion about the benefits (or lack of them) of UDP compared\nwith TCP for IoT.",
            "title": "UDP sockets"
        },
        {
            "location": "/Subjects/NP2/P1/#sending-binary-data-via-sockets",
            "text": "Up to this point, we have studied how to send text strings via TCP or UDP\nsockets, but it is common to find a necessity to send data directly in \nbinary format (e.g. numeric values in floating point or integers). Using the struct  Python module, we can specify which type or types of data are stored\nin a sequence of bytes, and how to decode them. It is also possible to specify\nin which place of the sequence are those data stored, allowing for packing\nmultiple data of different types in a simple manner, and its decoding at the\nother side of the communication channel.   Note  Check all details of the  struct  module on its official documentation  page.   The  struct  module provides two interesting methods:  pack  and  unpack .  The following sentence:  struct.pack(\">iii\", 1, 2, 3)  uses the  pack  method to perform data packing. \nSpecifically, observe how the method receives two parameters:    First, the format parameter  \">iii\" . It defines how each value in the sequence\n  need to be encoded.  The first character indicates the  endianness , \n  in this case  big endian  \n  (we should use \">\" for big endiand, \"<\" for little endian, and \"=\" for network endianness).    Second, the values to pack.    Note that the format, in addition, includes the number and type of data to pack\n(in this case three integer values). For other data types, check the module's documentation.  Unpacking data on the other side of the cahnnel is intuitive:  a, b, c = struct.unpack( \">iii\" )  Next, we show an example of a client/server TCP setup that leverages the struct  to send two integer numbers and a floating point number between a client\nand a server:  \n# Client\n\nimport binascii                                                                             \nimport socket                                                                               \nimport struct                                                                               \nimport sys                                                                                  \n\n# Socket TCP                                                                                \nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                                    \nserver_address = ('localhost', 10001)                                                       \nsock.connect(server_address)                                                                \n\npacked_data = struct.pack(\"=iif\", 1, 4, 2.7)                                                \n\ntry:                                                                                        \n    # Sending data\n    print('Sending \"%s\"' % binascii.hexlify(packed_data))                                  \n    sock.sendall(packed_data)                                                               \n\nfinally:                                                                                    \n    print('Closing socket')                                                                \n    sock.close()                                                                              \n# Server\n\nimport binascii                                                                             \nimport socket                                                                               \nimport struct                                                                               \nimport sys                                                                                  \n\n# Socket TCP                                                                                \nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                                    \nserver_address = ('localhost', 10001)                                                       \nsock.bind(server_address)                                                                   \nsock.listen(1)                                                                              \n\nwhile True:                                                                                 \n    print('Waiting for incoming connections')                                                 \n    connection, client_address = sock.accept()                                              \n    try:                                                                                    \n        data = connection.recv(1024)                                                        \n        print('Received \"%s\"' % binascii.hexlify(data))                                     \n\n        unpacked_data = struct.unpack(\"=iif\", data)                                         \n        print('Unpacked:', unpacked_data)                                             \n\n    finally:                                                                                \n        connection.close()   Task 1.4  Execute the client/server system and analyze the generated traffic. Look for \nthe binary packed data. Experiment with other types of data and  endianness \nand observe the differences.",
            "title": "Sending binary data via sockets"
        },
        {
            "location": "/Subjects/NP2/P1/#deliverable-task",
            "text": "Deliverable task 1  Design a client/server system and implement it using Python. The system\nwill simulate a client sending a number of pieces of data sensed to a server.\nThe protocol to use (format of each packet sent to the server at the application\nlayer) needs to be designed and proposed by the student and described \nprior to starting the coding effort.\nThe final mark will consider positively the use of multiple data types, \nboth in ths sent data and responses from the server. \nThe student will develop a TCP and a UDP version of the solution. The client will submit data in a periodic fashion, and data will be generated randomly.  The deliverable will include the developed codes, and an analysis of the generated\ntraffic, with comments about the overhead (in bytes) introduced by each protocol\nof the transport layer.",
            "title": "Deliverable task"
        },
        {
            "location": "/Subjects/NP2/P1/#multi-threaded-clientserver-example",
            "text": "The previous examples are perfectly valid and functional, but lack in their design\nof a basic functionality: the server stops attending new incoming requests while\na request from a client is processed. The following examples show simple implementations\nwith multi-threaded support for a client/server system written in Python.  # Concurrent TCP server\n\nimport socket, threading\n\nclass ClientThread(threading.Thread):\n    def __init__(self,clientAddress,clientsocket):\n        threading.Thread.__init__(self)\n        self.csocket = clientsocket\n        print (\"New connection added: \", clientAddress)\n    def run(self):\n        print (\"Connection from: \", clientAddress)\n        #self.csocket.send(bytes(\"Hi, This is from Server..\",'utf-8'))\n        msg = ''\n        while True:\n            data = self.csocket.recv(2048)\n            msg = data.decode()\n\n            if msg=='bye':\n              break\n\n            print (\"From the client\", msg)\n            self.csocket.send(bytes(msg,'UTF-8'))\n\n        print (\"Client \", clientAddress , \" disconnected...\")\n\nLOCALHOST = \"127.0.0.1\"\nPORT = 8080\n\nserver = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\nserver.bind((LOCALHOST, PORT))\n\nprint(\"Server started...\")\nprint(\"Waiting for client requests...\")\n\nserver.listen(1)\n\nwhile True:\n    clientsock, clientAddress = server.accept()\n    newthread = ClientThread(clientAddress, clientsock)\n    newthread.start()  # TCP client. The string *end* indicates disonnection request.\n\nimport socket\n\nSERVER = \"127.0.0.1\"\nPORT = 8080\n\nclient = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nclient.connect((SERVER, PORT))\nclient.sendall(bytes(\"Hello, I am a client!!\",'UTF-8'))\n\nwhile True:\n  in_data =  client.recv(1024)\n\n  print(\"From the server:\" ,in_data.decode())\n  out_data = input()\n  client.sendall(bytes(out_data,'UTF-8'))\n\n  if out_data=='end':\n    break\n\nclient.close()   Task 1.5  Study the codes for the concurrent server and observe how it manages\nthe creaton of threads to handle an incoming request. Connect simultaneously\nmultiple clients and observe the status of the sockets using the corresponding \ntools.  Write a short report with your observations .",
            "title": "Multi-threaded client/server example"
        },
        {
            "location": "/Subjects/NP2/P1/#optional-deliverable",
            "text": "Optional deliverable task 1  Modify your first deliverable to consider a multi-threaded implmentation\nof the TCP server, following the guidelines of the example codes.",
            "title": "Optional deliverable"
        },
        {
            "location": "/Subjects/NP2/P1/#optional-deliverable_1",
            "text": "Optional deliverable task 1  Modify the sending protocol so that your UDP applications guarantees\nas much as possible the reception of UDP packages sent from the client,\nand an in-order reception.\nAnalyze again the necessary network traffic in this case compared with a\nTCP scheme.",
            "title": "Optional deliverable"
        },
        {
            "location": "/Subjects/NP2/P10/",
            "text": "Pr\u00e1ctica 10. Frameworks IoT y Cloud\n\n\nObjetivos\n\n\nLa pr\u00e1ctica presenta los pasos esenciales que permiten hacer interactuar un\ndispositivo (ESP32) con una infraestructura IoT en la nube. Aunque en este\ncaso utilizaremos Microsoft Azure, los pasos tanto en configuraci\u00f3n remota\ncomo a nivel de nodo son muy similares a los que deber\u00edas seguir para otras\ninfraestructuras (Amazon AWS, Google IoT Core, Aliyun IoT, Tencent Iot o \ncualquier otro). La documentaci\u00f3n de IDF proporciona ejemplos detallados \npara cada uno.\n\n\nEl objetivo de la pr\u00e1ctica es desplegar un sistema de monitorizaci\u00f3n remota\nen Microsoft Power BI, que permita visualizar datos de telemetr\u00eda emitidos\nv\u00eda MQTT por el dispositivo a trav\u00e9s de un \ngateway\n en la nube (llamado en\nel caso de Azure \nIoT Hub\n).\n\n\nIntroducci\u00f3n\n\n\nEl SDK ESP Azure IoT es una infraestructura basada en \nel SDK de Azure par IoT con soporte para C\n(\nazure-iot-sdk-c\n) portado\nsobre ESP-IDF para dar soporte al ESP32. Adem\u00e1s, proporciona un conjunto\nde ejemplos que permiten observar y simplificar el proceso de configuraci\u00f3n\ny conexi\u00f3n al \nframework\n Azure IoT Hub.\n\n\nPreparaci\u00f3n del \nfirmware\n en el ESP32\n\n\nEn la presente pr\u00e1ctica utilizar\u00e1s una placa ESP32 que actuar\u00e1 como cliente\nESP32, con un \nfirmware\n personalizado que implementa la l\u00f3gica de conexi\u00f3n\ne interacci\u00f3n con Azure. En primer lugar:\n\n\n\n\n\n\nConfigura una instalaci\u00f3n de ESP IDF tal y como has hecho en pr\u00e1cticas \nanteriores. Si ya la has configurado y es funcional, no es necesario ninguna\nreinstalaci\u00f3n ni reconfiguraci\u00f3n.\n\n\n\n\n\n\nEn un directorio independiente, clona el repositorio de \n\nESP Azure\n (f\u00edjate en la opci\u00f3n \n--recursive\n, que es imprescindible):\n\n\n\n\n\n\ngit clone --recursive https://github.com/espressif/esp-azure.git\n\n\n\n\nConfiguraci\u00f3n de Microsoft Azure\n\n\nLos siguientes pasos requieren el uso de una cuenta creada con Microsoft\nAzure. Los estudiantes UCM pueden adherirse al programa acad\u00e9mico, que \notorga suficiente cr\u00e9dito para realizar este tipo de pr\u00e1cticas. Aseg\u00farate\nde acceder al \nportal de MS Azure\n y utilizar tu\nusuario y credenciales UCM para ello. \n\n\nCreaci\u00f3n de un Centro de IoT (\nIoT Hub\n)\n\n\nEn la p\u00e1gina principal de Azure, selecciona la opci\u00f3n \"Crear un Recurso\"\n(en el men\u00fa de la parte superior izquierda de la pantalla)\ny a continuaici\u00f3n selecciona \nIoT Hub\n en cuadro \"Buscar en Marketplace\".\n\n\nSelecciona \nIot Hub\n en los resultados de la b\u00fasqueda, y a continuaci\u00f3n\n\"Crear\".\n\n\nEn la pesta\u00f1a \nAspectos B\u00e1sicos\n, completa los campos de la siguiente forma:\n\n\n\n\nSuscripci\u00f3n\n: selecciona la suscripci\u00f3n que desees usar (por defecto, deber\u00eda\naparecer \nAzure para estudiantes\n).\n\n\nGrupo de recursos\n: crea un nuevo grupo de recursos seleccionando la opci\u00f3n \n\nCrear nuevo\n, y ot\u00f3rgale el nombre que desees, por ejemplo \nMIOTGROUP\n.\n\n\nRegi\u00f3n\n: selecciona la regi\u00f3n m\u00e1s cercana a ti (por ejemplo, \nOeste de Europa\n).\n\n\nNombre\n: por \u00faltimo, da un nombre al \nhub\n, por ejemplo \nMIOTHUB\n.\n\n\n\n\nDeja los par\u00e1metros por defecto en la pesta\u00f1a \nRedes\n, y elige como \n\nNivel de precios\n F1 en la pesta\u00f1a \nAdministraci\u00f3n\n. Asigna las etiquetas que\ndesees y finalmente confirma la creaci\u00f3n del \nCentro de IoT\n. Si todo ha ido\nbien, ver\u00e1s un resumen del recurso creado y podr\u00e1s acceder a \u00e9l \npinchando en \n\"Ir al recurso\"\n. Ver\u00e1s una pantalla similar a la siguiente:\n\n\n\n\nEn la secci\u00f3n de \nConfiguraci\u00f3n\n, elige \nDirectivas de acceso compartido\n\ny crea una nueva directiva llamada, por ejemplo \nMIOTPOLICY\n, con permisos \nde lectura y escritura en Registro, y conexi\u00f3n de servicios y dispositivos.\n\n\n\n\nLas pol\u00edticas de \nlectura y escritura en registro\n otorgan derechos\nde acceso al registro de indentidades de Azure. Estos permisos ser\u00e1n\nutilizados por servicios de \nback-end\n para gestionar las identidades\nde dispositivos, por ejemplo.\nLa pol\u00edtica de \nconexi\u00f3n de servicio\n otorga permisos para acceder\na \nendpoints\n de servicio. Los servicios de \nback-end\n podr\u00e1n enviar\ny recibir mensajes de dispositivos.\nLa pol\u00edtica de \nconexi\u00f3n de dispositivo\n otorga permisos para enviar\ny recibir mensajes usando el \nIoT Hub\n. \n\n\nUna vez creada, selecci\u00f3nala y copia la \nCadena de conexi\u00f3n principal (clave principal)\n\nque aparece en pantalla. No es necesario que la muestres, puedes usar el\nbot\u00f3n de copia directamente. \nApunta esta cadena en un fichero de texto.\nEsta es la clave de acceso para el Hub\n.\n\n\nRegistro de un nuevo dispositivo\n\n\nA continuaci\u00f3n, crearemos una nueva identidad de dispositivo  en el\nRegistro de Identidades del \nhub\n IoT que acabas de crear. Para ello:\n\n\n\n\n\n\nEn el men\u00fa de navegaci\u00f3n, abre la opci\u00f3n \n\"Dispositivos de IoT\"\n\ny selecciona \nNuevo\n para crear un nuevo dispositivo.\n\n\n\n\n\n\nDale el nombre que quieras (por ejemplo MIOTDEVICE), pero recu\u00e9rdalo, \ny selecciona \nGuardar\n.\n\n\n\n\n\n\nUna vez creado, selecci\u00f3nalo y copia la \nCadena de conexi\u00f3n principal\n\nque aparece en pantalla. No es necesario que la muestres, puedes usar el\nbot\u00f3n de copia directamente. \nApunta esta cadena en un fichero de texto.\nEsta es la clave de acceso para el dispositivo\n.\n\n\n\n\n\n\nInstalaci\u00f3n de el cliente Azure\n\n\nPara instalar el cliente Azure en Linux, usa la orden:\n\n\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n\n\n\n\nTienes m\u00e1s opciones de instalaci\u00f3n en la \np\u00e1gina\n.\n\n\nUna vez instalado, desde tu terminal, ejecuta el comando\n\naz\n para comprobar que la instalaci\u00f3n fue correcta. Deber\u00edas\nver una salida similar a esta:\n\n\naz\n\nWelcome to Azure CLI!\n---------------------\nUse `az -h` to see available commands or go to https://aka.ms/cli.\n...\n\n\n\n\nInstala la extensi\u00f3n del cliente para Azure IoT:\n\n\naz extension add --name azure-cli-iot-ext\n\n\n\n\nIngresa en el sistema ejecutando (se te pedir\u00e1 autenticaci\u00f3n en \nnavegador, introduce tus credenciales):\n\n\naz login\n\n\n\n\nPara usar el cliente como m\u00e9todo de creaci\u00f3n de un dispositivo, puedes\nutilizar la siguiente orden:\n\n\naz iot hub device-identity create -n [IoTHub Name] -d [Device ID]\n\n\n\n\n\n\nTarea\n\n\nCrea un nuevo dispositivo, distinto al que creaste anteriormente, en\ntu hub. Despu\u00e9s, obt\u00e9n su cadena de conexi\u00f3n usando la orden \n\naz iot hub device-identity show-connection-string -n [IoTHub Name] -d [Device ID]\n. Comprueba que, efectivamente, la creaci\u00f3n del dispositivo es\n\n\n\n\nvisible en la plataforma web.\n\n\nMonitorizaci\u00f3n de valores de telemetr\u00eda del dispositivo y eventos\n\n\nPara observar los datos intercambiados entre el dispositivo y el \nhub\n\nIoT desde l\u00ednea de ocmandos, puedes usar la orden:\n\n\naz iot hub monitor-events -n [IoTHub Name] --login 'cadena de conexion'\n\n\n\n\n(Ten en cuenta que las comillas simples deben estar presentes).\n\n\nDespliegue de un cliente MQTT en el ESP32\n\n\nDir\u00edgete al ejemplo situado en el directorio \n\nexamples/iothub_client_sample_mqtt\n. En \u00e9l, vamos a trabajar con cualquiera\nde los dos dispositivos que has creado en tu \nHub\n. En cualquier caso,\nmuestra su \ncadena de conexi\u00f3n principal\n. Deber\u00e1s ver un valor \nde devoluci\u00f3n de tipo:\n\n\n{\n  \"connectionString\": \"HostName=<azure-iot-hub-name>.azure-devices.net;DeviceId=<azure-iot-device-id>;SharedAccessKey=<base64-encoded-shared-access-key>\"\n}\n\n\n\n\nDeber\u00e1s apuntar (copiar) \u00fanicamente la parte que comienza por \n\nHostName=...\n, hasta el final de la cadena. No incluyas las comillas\ndobles.\n\n\nEjecuta \nmake menuconfig\n. En el men\u00fa \nExample Configuration\n, \nconfigura las credenciales de acceso a tu red WiFi, as\u00ed como la \ncadena de conexi\u00f3n que copiaste en la opci\u00f3n\n\nIOT Hub Device Connection String\n.\n\n\nA continuaci\u00f3n, ejecuta la orden de compilaci\u00f3n, \nflasheado\n y\nmonitorizaci\u00f3n:\n\n\nmake flash monitor\n\n\n\n\nEn una ventana separada, puedes monitorizar los eventos IoT\nen tu \nhub\n usando su cadena de conexi\u00f3n:\n\n\naz iot hub monitor-events -n [IoTHub Name] --login 'Cadena de conexi\u00f3n primaria'\n\n\n\n\nUna vez arrancado y conectado a Internet el dispositivo comenzar\u00e1 a\npublicar mensajes MQTT. El monitor que has lanzado los mostrar\u00e1 como:\n\n\n{\n    \"event\": {\n        \"origin\": \"<azure-iot-device-id>\",\n        \"payload\": \"{\\\"deviceId\\\":\\\"MIOTDEVICE\\\",\\\"windSpeed\\\":13.00,\\\"temperature\\\":22.00,\\\"humidity\\\":67.00}\"\n    }\n}\n\n\n\n\nObserva que incluye tres valores: velocidad del viento, temperatura y humedad.\n\n\n\n\nTarea\n\n\nAnaliza el c\u00f3digo y observa, en la tarea principal, el uso que hace\nde la API de Azure SDK C, as\u00ed como el punto en el que genera el  \n\nmensaje MQTT (y sus valores).\n\n\n\n\nTambi\u00e9n es posible enviar mensajes al dispositivo directamente desde\nl\u00ednea de comandos (observa que estos mensajes se env\u00edan v\u00eda red, no \nv\u00eda puerto serie, a trav\u00e9s del \nHub\n). Por tanto, puedes hacerlo desde\ncualquier punto, no obligatoriamente desde tu PC:\n\n\naz iot device c2d-message send -d [Device Id] -n [IoTHub Name] --data [Data_to_Send]\n\n\n\n\n\n\nNota\n\n\nSi todo ha ido bien, en este punto deber\u00edas estar observando cada uno de los mensajes enviados por tu ESP32 al \nhub\n desde el monitor.\n\n\n\n\nVisualizaci\u00f3n de datos en Microsoft PowerBI\n\n\nEn esta parte, el objetivo es visualizar los datos enviados por tu sensor (temperatura, humedad y \nvelocidad del viento, en la herramienta de visualizaci\u00f3n PowerBI de Microsoft. Aunque PowerBI suele\nutilizarse en entornos de inteligencia de negocio, resulta tambi\u00e9n \u00fatil para reportar datos de cualquier\nelemento de Azure, incluido el \nIoT Hub\n.\n\n\n\n\nNota\n\n\nNecesitar\u00e1s una cuenta de acceso gratuita a PowerBI, que puedes crear con tus credenciales de usuario UCM\ndirectamente en la \np\u00e1gina del producto\n.\n\n\n\n\nAdici\u00f3n de un grupo de consumidores\n\n\nLos grupos de consumidores proporcionan vistas independientes en la secuencia de eventos que permiten a las aplicaciones y a los servicios de Azure consumir datos de forma independiente desde el mismo punto de conexi\u00f3n del centro de eventos. \nVamos a agregar un grupo de consumidores al punto de conexi\u00f3n integrado de tu instancia de \nIoT Hub\n que se usar\u00e1 posteriormente para extraer datos del punto de conexi\u00f3n.\n\n\nPara agregar un grupo de consumidores a su centro de IoT, sigue estos pasos:\n\n\n\n\n\n\nEn el portal de Azure, abre tu \nIoT Hub\n.\n\n\n\n\n\n\nEn el panel izquierdo, selecciona \nPuntos de Conexi\u00f3n Integrados\n, luego\n\nEventos\n en el panel superior derecho, y escribe un nombre en \nGrupos de consumidores\n (por ejemplo,\n\nMIOTGROUP\n). A continuaci\u00f3n, selecciona \nGuardar\n.\n\n\n\n\n\n\nCreaci\u00f3n, configuraci\u00f3n y ejecuci\u00f3n de un trabajo de \nStream Analytics\n\n\nComencemos creando un trabajo de \nStream Analytics\n. Despu\u00e9s de crear el trabajo, \ndefiniremos las entradas, las salidas y la consulta que se usar\u00e1 para recuperar los datos.\n\n\nCreaci\u00f3n de un trabajo de Stream Analytics\n\n\n\n\n\n\nEn el portal de Azure, selecciona \nCrear un recurso -> Internet de las Cosas -> Stream Analytics Job\n.\n\n\n\n\n\n\nEscribe la siguiente informaci\u00f3n para el trabajo:\n\n\n\n\nNombre del trabajo\n: Nombre que se asigna al trabajo; debe ser \u00fanico (por ejemplo, \nMIOTJOB\n).\n\n\nGrupo de recursos\n: Usa el mismo grupo de recursos que definiste para el centro de IoT (por ejemplo, \nMIOTGROUP\n).\n\n\nUbicaci\u00f3n\n: Usa la misma que para el grupo de recursos.\n\n\n\n\n\n\n\n\nSelecciona \nCrear\n.\n\n\n\n\n\n\nAdici\u00f3n de una entrada al trabajo de Stream Analytics\n\n\n\n\nAbre el trabajo de \nStream Analytics\n.\n\n\nEn \nTopolog\u00eda de trabajo\n, selecciona \nEntradas\n.\n\n\n\n\nEn el panel \nEntradas\n, selecciona \nAgregar entrada de flujo\n, y a continuaci\u00f3n, selecciona\n\nIoT Hub\n en la lista desplegable. En el panel de la nueva entrada, escribe la siguiente informaci\u00f3n:\n\n\n\n\nAlias de entrada\n: Un alias \u00fanico para la entrada (por ejemplo, \nMIOTINPUT\n).\n\n\nSeleccionar centro de IoT de entre las suscripciones\n: Selecciona esta opci\u00f3n.\n\n\nSuscripci\u00f3n\n: Usa la suscripci\u00f3n que has utilizado en el resto de la pr\u00e1ctica.\n\n\nIoT Hub\n: Selecciona la instancia de tu \nHub IoT\n tal y como has hecho en el resto de la pr\u00e1ctica.\n\n\nPunto de Conexi\u00f3n\n: Selecciona \nMensajer\u00eda\n.\n\n\nNombre de la directiva de acceso compartido\n: Selecciona  el nombre de la directiva de acceso compartido que quieras que utilice el trabajo de Stream Analytics para tu centro de IoT. Para esta pr\u00e1ctica, puedes seleccionar \nservice\n. La directiva \nservice\n se crea de forma predeterminada en los centros de IoT nuevos y concede permiso de env\u00edo y recepci\u00f3n para los puntos de conexi\u00f3n de la nube que expone el centro de IoT. \n\n\nClave de directiva de acceso compartido\n: Se rellena autom\u00e1ticamente en funci\u00f3n del nombre de directiva de acceso compartido.\n\n\nGrupo de consumidores\n: Selecciona el gruop de consumidores que se cre\u00f3 anteriormente.\n\n\n\n\n\n\n\n\nEl resto de campos pueden dejarse en sus valores predeterminados. Finalmente, selecciona \nGuardar\n.\n\n\nAdici\u00f3n de una salida al trabajo de Stream Analytics\n\n\n\n\n\n\nEn Topolog\u00eda de trabajo, selecciona \nSalidas\n.\n\n\n\n\n\n\nEn el panel \nSalidas\n, selecciona \nAgregar\n y \nPower BI\n.\n\n\n\n\n\n\nEn el panel \nPower BI: Nueva salida panel\n, selecciona \nAutorizar\n y sigue las indicaciones para iniciar sesi\u00f3n en tu cuenta de Power BI.\n\n\n\n\n\n\nUna vez que hayas iniciado sesi\u00f3n en Power BI, escribe la siguiente informaci\u00f3n:\n\n\n\n\nAlias de salida\n: alias \u00fanico para la salida, por ejemplo \nMIOTOUTPUT\n.\n\n\n\u00c1rea de trabajo de grupo\n: selecciona el \u00e1rea de trabajo de grupo de destino.\n\n\nNombre del conjunto de datos\n: escribe un nombre para el conjunto de datos, por ejemplo \nMIOTDATASET\n.\n\n\nNombre de la tabla\n: Escribe un nombre de tabla, por ejemplo \nMIOTTABLE\n.\n\n\nModo de autenticaci\u00f3n\n: Deja la opci\u00f3n predeterminada.\n\n\n\n\n\n\n\n\nConfiguraci\u00f3n de la consulta del trabajo de Stream Analytics\n\n\n\n\nEn \nTopolog\u00eda de trabajo\n, selecciona \nConsulta\n.\n\n\nReemplaza \n[YourInputAlias]\n por el alias de entrada del trabajo.\n\n\nReemplaza \n[YourOutputAlias]\n por el alias de salida del trabajo.\n\n\nSelecciona \nGuardar consulta\n.\n\n\n\n\nEjecuci\u00f3n del trabajo de Stream Analytics\n\n\nEn el trabajo de \nStream Analytics\n, selecciona \n\nInformaci\u00f3n general\n y, a continuaci\u00f3n, elige \nIniciar->Ahora->Iniciar\n. Una vez que el trabajo se inicia\ncorrectamente, su estado cambia de \nDetenido\n a \nEn ejecuci\u00f3n\n.\n\n\nCreaci\u00f3n y publicaci\u00f3n de un informe de Power BI para visualizar los datos\n\n\nEn los pasos siguientes se muestra c\u00f3mo crear y publicar un informe mediante el servicio Power BI: \n\n\n\n\nAseg\u00farate de que la aplicaci\u00f3n (tu ESP32) est\u00e1 ejecut\u00e1ndose.\n\n\nInicia sesi\u00f3n en Power BI.\n\n\nSelecciona tu \u00e1rea de trabajo (\nworkspace\n).\n\n\nSelecciona \nConjunto de datos\n usando el conjunto de datos que creaste en pasos anteriores (corresponde al que creaste en el momento de crear la salida para el trabajo de \nStream Analytics\n.\n\n\nPara dicho conjunto de datos, selecciona \nAgregar Informe\n (el primer icono a la derecha del nombre del conjunto de datos. \n\n\nCrea un gr\u00e1fico de l\u00edneas para mostrar la temperatura en tiempo real en un per\u00edodo determinado. Para ello:\n\n\nEn el panel \nVisualizaciones\n de la p\u00e1gina de creaci\u00f3n de informes, selecciona el icono de gr\u00e1fico de l\u00edneas para agregar un gr\u00e1fico de l\u00edneas.\n\n\nEn el panel \nCampos\n, expande la tabla que especific\u00f3 en el momento de crear la salida para el trabajo de \nStream Analytics\n.\n\n\nArrastra \nEventEnqueuedUtcTime\n (Hora UTC de evento en cola) al Eje en el panel Visualizaciones.\n\n\nArrastra \ntemperature\n (temperatura) a \nValores\n.\n\n\n\n\n\n\n\n\nSe ha creado un gr\u00e1fico de l\u00edneas. El eje X muestra la fecha y hora en la zona horaria UTC. El eje Y muestra la temperatura del sensor:\n\n\n\n\n\n\nTarea\n\n\nA\u00f1ade ahora informaci\u00f3n sobre humedad y velocidad del viento y refresca (actualiza) la visualizaci\u00f3n.\n\n\n\n\n\n\nTarea entregable\n\n\nEn esta pr\u00e1ctica, simplemente se pide que entregues alguna evidencia (por ejemplo, una captura de pantalla con tu ESP32 femitiendo eventos y una captura simult\u00e1nea de PowerBI mostr\u00e1ndolos) del correcto funcionamiento de los pasos listados. Opcionalmente, se puede a\u00f1adir, como informaci\u00f3n emitida desde el ESP32, valores reales de temperatura obtenidos desde un sensor en el ESP32.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P10/#practica-10-frameworks-iot-y-cloud",
            "text": "",
            "title": "Pr\u00e1ctica 10. Frameworks IoT y Cloud"
        },
        {
            "location": "/Subjects/NP2/P10/#objetivos",
            "text": "La pr\u00e1ctica presenta los pasos esenciales que permiten hacer interactuar un\ndispositivo (ESP32) con una infraestructura IoT en la nube. Aunque en este\ncaso utilizaremos Microsoft Azure, los pasos tanto en configuraci\u00f3n remota\ncomo a nivel de nodo son muy similares a los que deber\u00edas seguir para otras\ninfraestructuras (Amazon AWS, Google IoT Core, Aliyun IoT, Tencent Iot o \ncualquier otro). La documentaci\u00f3n de IDF proporciona ejemplos detallados \npara cada uno.  El objetivo de la pr\u00e1ctica es desplegar un sistema de monitorizaci\u00f3n remota\nen Microsoft Power BI, que permita visualizar datos de telemetr\u00eda emitidos\nv\u00eda MQTT por el dispositivo a trav\u00e9s de un  gateway  en la nube (llamado en\nel caso de Azure  IoT Hub ).",
            "title": "Objetivos"
        },
        {
            "location": "/Subjects/NP2/P10/#introduccion",
            "text": "El SDK ESP Azure IoT es una infraestructura basada en \nel SDK de Azure par IoT con soporte para C\n( azure-iot-sdk-c ) portado\nsobre ESP-IDF para dar soporte al ESP32. Adem\u00e1s, proporciona un conjunto\nde ejemplos que permiten observar y simplificar el proceso de configuraci\u00f3n\ny conexi\u00f3n al  framework  Azure IoT Hub.",
            "title": "Introducci\u00f3n"
        },
        {
            "location": "/Subjects/NP2/P10/#preparacion-del-firmware-en-el-esp32",
            "text": "En la presente pr\u00e1ctica utilizar\u00e1s una placa ESP32 que actuar\u00e1 como cliente\nESP32, con un  firmware  personalizado que implementa la l\u00f3gica de conexi\u00f3n\ne interacci\u00f3n con Azure. En primer lugar:    Configura una instalaci\u00f3n de ESP IDF tal y como has hecho en pr\u00e1cticas \nanteriores. Si ya la has configurado y es funcional, no es necesario ninguna\nreinstalaci\u00f3n ni reconfiguraci\u00f3n.    En un directorio independiente, clona el repositorio de  ESP Azure  (f\u00edjate en la opci\u00f3n  --recursive , que es imprescindible):    git clone --recursive https://github.com/espressif/esp-azure.git",
            "title": "Preparaci\u00f3n del firmware en el ESP32"
        },
        {
            "location": "/Subjects/NP2/P10/#configuracion-de-microsoft-azure",
            "text": "Los siguientes pasos requieren el uso de una cuenta creada con Microsoft\nAzure. Los estudiantes UCM pueden adherirse al programa acad\u00e9mico, que \notorga suficiente cr\u00e9dito para realizar este tipo de pr\u00e1cticas. Aseg\u00farate\nde acceder al  portal de MS Azure  y utilizar tu\nusuario y credenciales UCM para ello.",
            "title": "Configuraci\u00f3n de Microsoft Azure"
        },
        {
            "location": "/Subjects/NP2/P10/#creacion-de-un-centro-de-iot-iot-hub",
            "text": "En la p\u00e1gina principal de Azure, selecciona la opci\u00f3n \"Crear un Recurso\"\n(en el men\u00fa de la parte superior izquierda de la pantalla)\ny a continuaici\u00f3n selecciona  IoT Hub  en cuadro \"Buscar en Marketplace\".  Selecciona  Iot Hub  en los resultados de la b\u00fasqueda, y a continuaci\u00f3n\n\"Crear\".  En la pesta\u00f1a  Aspectos B\u00e1sicos , completa los campos de la siguiente forma:   Suscripci\u00f3n : selecciona la suscripci\u00f3n que desees usar (por defecto, deber\u00eda\naparecer  Azure para estudiantes ).  Grupo de recursos : crea un nuevo grupo de recursos seleccionando la opci\u00f3n  Crear nuevo , y ot\u00f3rgale el nombre que desees, por ejemplo  MIOTGROUP .  Regi\u00f3n : selecciona la regi\u00f3n m\u00e1s cercana a ti (por ejemplo,  Oeste de Europa ).  Nombre : por \u00faltimo, da un nombre al  hub , por ejemplo  MIOTHUB .   Deja los par\u00e1metros por defecto en la pesta\u00f1a  Redes , y elige como  Nivel de precios  F1 en la pesta\u00f1a  Administraci\u00f3n . Asigna las etiquetas que\ndesees y finalmente confirma la creaci\u00f3n del  Centro de IoT . Si todo ha ido\nbien, ver\u00e1s un resumen del recurso creado y podr\u00e1s acceder a \u00e9l \npinchando en  \"Ir al recurso\" . Ver\u00e1s una pantalla similar a la siguiente:   En la secci\u00f3n de  Configuraci\u00f3n , elige  Directivas de acceso compartido \ny crea una nueva directiva llamada, por ejemplo  MIOTPOLICY , con permisos \nde lectura y escritura en Registro, y conexi\u00f3n de servicios y dispositivos.   Las pol\u00edticas de  lectura y escritura en registro  otorgan derechos\nde acceso al registro de indentidades de Azure. Estos permisos ser\u00e1n\nutilizados por servicios de  back-end  para gestionar las identidades\nde dispositivos, por ejemplo.\nLa pol\u00edtica de  conexi\u00f3n de servicio  otorga permisos para acceder\na  endpoints  de servicio. Los servicios de  back-end  podr\u00e1n enviar\ny recibir mensajes de dispositivos.\nLa pol\u00edtica de  conexi\u00f3n de dispositivo  otorga permisos para enviar\ny recibir mensajes usando el  IoT Hub .   Una vez creada, selecci\u00f3nala y copia la  Cadena de conexi\u00f3n principal (clave principal) \nque aparece en pantalla. No es necesario que la muestres, puedes usar el\nbot\u00f3n de copia directamente.  Apunta esta cadena en un fichero de texto.\nEsta es la clave de acceso para el Hub .",
            "title": "Creaci\u00f3n de un Centro de IoT (IoT Hub)"
        },
        {
            "location": "/Subjects/NP2/P10/#registro-de-un-nuevo-dispositivo",
            "text": "A continuaci\u00f3n, crearemos una nueva identidad de dispositivo  en el\nRegistro de Identidades del  hub  IoT que acabas de crear. Para ello:    En el men\u00fa de navegaci\u00f3n, abre la opci\u00f3n  \"Dispositivos de IoT\" \ny selecciona  Nuevo  para crear un nuevo dispositivo.    Dale el nombre que quieras (por ejemplo MIOTDEVICE), pero recu\u00e9rdalo, \ny selecciona  Guardar .    Una vez creado, selecci\u00f3nalo y copia la  Cadena de conexi\u00f3n principal \nque aparece en pantalla. No es necesario que la muestres, puedes usar el\nbot\u00f3n de copia directamente.  Apunta esta cadena en un fichero de texto.\nEsta es la clave de acceso para el dispositivo .",
            "title": "Registro de un nuevo dispositivo"
        },
        {
            "location": "/Subjects/NP2/P10/#instalacion-de-el-cliente-azure",
            "text": "Para instalar el cliente Azure en Linux, usa la orden:  curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash  Tienes m\u00e1s opciones de instalaci\u00f3n en la  p\u00e1gina .  Una vez instalado, desde tu terminal, ejecuta el comando az  para comprobar que la instalaci\u00f3n fue correcta. Deber\u00edas\nver una salida similar a esta:  az\n\nWelcome to Azure CLI!\n---------------------\nUse `az -h` to see available commands or go to https://aka.ms/cli.\n...  Instala la extensi\u00f3n del cliente para Azure IoT:  az extension add --name azure-cli-iot-ext  Ingresa en el sistema ejecutando (se te pedir\u00e1 autenticaci\u00f3n en \nnavegador, introduce tus credenciales):  az login  Para usar el cliente como m\u00e9todo de creaci\u00f3n de un dispositivo, puedes\nutilizar la siguiente orden:  az iot hub device-identity create -n [IoTHub Name] -d [Device ID]   Tarea  Crea un nuevo dispositivo, distinto al que creaste anteriormente, en\ntu hub. Despu\u00e9s, obt\u00e9n su cadena de conexi\u00f3n usando la orden  az iot hub device-identity show-connection-string -n [IoTHub Name] -d [Device ID] . Comprueba que, efectivamente, la creaci\u00f3n del dispositivo es   visible en la plataforma web.",
            "title": "Instalaci\u00f3n de el cliente Azure"
        },
        {
            "location": "/Subjects/NP2/P10/#monitorizacion-de-valores-de-telemetria-del-dispositivo-y-eventos",
            "text": "Para observar los datos intercambiados entre el dispositivo y el  hub \nIoT desde l\u00ednea de ocmandos, puedes usar la orden:  az iot hub monitor-events -n [IoTHub Name] --login 'cadena de conexion'  (Ten en cuenta que las comillas simples deben estar presentes).",
            "title": "Monitorizaci\u00f3n de valores de telemetr\u00eda del dispositivo y eventos"
        },
        {
            "location": "/Subjects/NP2/P10/#despliegue-de-un-cliente-mqtt-en-el-esp32",
            "text": "Dir\u00edgete al ejemplo situado en el directorio  examples/iothub_client_sample_mqtt . En \u00e9l, vamos a trabajar con cualquiera\nde los dos dispositivos que has creado en tu  Hub . En cualquier caso,\nmuestra su  cadena de conexi\u00f3n principal . Deber\u00e1s ver un valor \nde devoluci\u00f3n de tipo:  {\n  \"connectionString\": \"HostName=<azure-iot-hub-name>.azure-devices.net;DeviceId=<azure-iot-device-id>;SharedAccessKey=<base64-encoded-shared-access-key>\"\n}  Deber\u00e1s apuntar (copiar) \u00fanicamente la parte que comienza por  HostName=... , hasta el final de la cadena. No incluyas las comillas\ndobles.  Ejecuta  make menuconfig . En el men\u00fa  Example Configuration , \nconfigura las credenciales de acceso a tu red WiFi, as\u00ed como la \ncadena de conexi\u00f3n que copiaste en la opci\u00f3n IOT Hub Device Connection String .  A continuaci\u00f3n, ejecuta la orden de compilaci\u00f3n,  flasheado  y\nmonitorizaci\u00f3n:  make flash monitor  En una ventana separada, puedes monitorizar los eventos IoT\nen tu  hub  usando su cadena de conexi\u00f3n:  az iot hub monitor-events -n [IoTHub Name] --login 'Cadena de conexi\u00f3n primaria'  Una vez arrancado y conectado a Internet el dispositivo comenzar\u00e1 a\npublicar mensajes MQTT. El monitor que has lanzado los mostrar\u00e1 como:  {\n    \"event\": {\n        \"origin\": \"<azure-iot-device-id>\",\n        \"payload\": \"{\\\"deviceId\\\":\\\"MIOTDEVICE\\\",\\\"windSpeed\\\":13.00,\\\"temperature\\\":22.00,\\\"humidity\\\":67.00}\"\n    }\n}  Observa que incluye tres valores: velocidad del viento, temperatura y humedad.   Tarea  Analiza el c\u00f3digo y observa, en la tarea principal, el uso que hace\nde la API de Azure SDK C, as\u00ed como el punto en el que genera el   \nmensaje MQTT (y sus valores).   Tambi\u00e9n es posible enviar mensajes al dispositivo directamente desde\nl\u00ednea de comandos (observa que estos mensajes se env\u00edan v\u00eda red, no \nv\u00eda puerto serie, a trav\u00e9s del  Hub ). Por tanto, puedes hacerlo desde\ncualquier punto, no obligatoriamente desde tu PC:  az iot device c2d-message send -d [Device Id] -n [IoTHub Name] --data [Data_to_Send]   Nota  Si todo ha ido bien, en este punto deber\u00edas estar observando cada uno de los mensajes enviados por tu ESP32 al  hub  desde el monitor.",
            "title": "Despliegue de un cliente MQTT en el ESP32"
        },
        {
            "location": "/Subjects/NP2/P10/#visualizacion-de-datos-en-microsoft-powerbi",
            "text": "En esta parte, el objetivo es visualizar los datos enviados por tu sensor (temperatura, humedad y \nvelocidad del viento, en la herramienta de visualizaci\u00f3n PowerBI de Microsoft. Aunque PowerBI suele\nutilizarse en entornos de inteligencia de negocio, resulta tambi\u00e9n \u00fatil para reportar datos de cualquier\nelemento de Azure, incluido el  IoT Hub .   Nota  Necesitar\u00e1s una cuenta de acceso gratuita a PowerBI, que puedes crear con tus credenciales de usuario UCM\ndirectamente en la  p\u00e1gina del producto .",
            "title": "Visualizaci\u00f3n de datos en Microsoft PowerBI"
        },
        {
            "location": "/Subjects/NP2/P10/#adicion-de-un-grupo-de-consumidores",
            "text": "Los grupos de consumidores proporcionan vistas independientes en la secuencia de eventos que permiten a las aplicaciones y a los servicios de Azure consumir datos de forma independiente desde el mismo punto de conexi\u00f3n del centro de eventos. \nVamos a agregar un grupo de consumidores al punto de conexi\u00f3n integrado de tu instancia de  IoT Hub  que se usar\u00e1 posteriormente para extraer datos del punto de conexi\u00f3n.  Para agregar un grupo de consumidores a su centro de IoT, sigue estos pasos:    En el portal de Azure, abre tu  IoT Hub .    En el panel izquierdo, selecciona  Puntos de Conexi\u00f3n Integrados , luego Eventos  en el panel superior derecho, y escribe un nombre en  Grupos de consumidores  (por ejemplo, MIOTGROUP ). A continuaci\u00f3n, selecciona  Guardar .",
            "title": "Adici\u00f3n de un grupo de consumidores"
        },
        {
            "location": "/Subjects/NP2/P10/#creacion-configuracion-y-ejecucion-de-un-trabajo-de-stream-analytics",
            "text": "Comencemos creando un trabajo de  Stream Analytics . Despu\u00e9s de crear el trabajo, \ndefiniremos las entradas, las salidas y la consulta que se usar\u00e1 para recuperar los datos.",
            "title": "Creaci\u00f3n, configuraci\u00f3n y ejecuci\u00f3n de un trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#creacion-de-un-trabajo-de-stream-analytics",
            "text": "En el portal de Azure, selecciona  Crear un recurso -> Internet de las Cosas -> Stream Analytics Job .    Escribe la siguiente informaci\u00f3n para el trabajo:   Nombre del trabajo : Nombre que se asigna al trabajo; debe ser \u00fanico (por ejemplo,  MIOTJOB ).  Grupo de recursos : Usa el mismo grupo de recursos que definiste para el centro de IoT (por ejemplo,  MIOTGROUP ).  Ubicaci\u00f3n : Usa la misma que para el grupo de recursos.     Selecciona  Crear .",
            "title": "Creaci\u00f3n de un trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#adicion-de-una-entrada-al-trabajo-de-stream-analytics",
            "text": "Abre el trabajo de  Stream Analytics .  En  Topolog\u00eda de trabajo , selecciona  Entradas .   En el panel  Entradas , selecciona  Agregar entrada de flujo , y a continuaci\u00f3n, selecciona IoT Hub  en la lista desplegable. En el panel de la nueva entrada, escribe la siguiente informaci\u00f3n:   Alias de entrada : Un alias \u00fanico para la entrada (por ejemplo,  MIOTINPUT ).  Seleccionar centro de IoT de entre las suscripciones : Selecciona esta opci\u00f3n.  Suscripci\u00f3n : Usa la suscripci\u00f3n que has utilizado en el resto de la pr\u00e1ctica.  IoT Hub : Selecciona la instancia de tu  Hub IoT  tal y como has hecho en el resto de la pr\u00e1ctica.  Punto de Conexi\u00f3n : Selecciona  Mensajer\u00eda .  Nombre de la directiva de acceso compartido : Selecciona  el nombre de la directiva de acceso compartido que quieras que utilice el trabajo de Stream Analytics para tu centro de IoT. Para esta pr\u00e1ctica, puedes seleccionar  service . La directiva  service  se crea de forma predeterminada en los centros de IoT nuevos y concede permiso de env\u00edo y recepci\u00f3n para los puntos de conexi\u00f3n de la nube que expone el centro de IoT.   Clave de directiva de acceso compartido : Se rellena autom\u00e1ticamente en funci\u00f3n del nombre de directiva de acceso compartido.  Grupo de consumidores : Selecciona el gruop de consumidores que se cre\u00f3 anteriormente.     El resto de campos pueden dejarse en sus valores predeterminados. Finalmente, selecciona  Guardar .",
            "title": "Adici\u00f3n de una entrada al trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#adicion-de-una-salida-al-trabajo-de-stream-analytics",
            "text": "En Topolog\u00eda de trabajo, selecciona  Salidas .    En el panel  Salidas , selecciona  Agregar  y  Power BI .    En el panel  Power BI: Nueva salida panel , selecciona  Autorizar  y sigue las indicaciones para iniciar sesi\u00f3n en tu cuenta de Power BI.    Una vez que hayas iniciado sesi\u00f3n en Power BI, escribe la siguiente informaci\u00f3n:   Alias de salida : alias \u00fanico para la salida, por ejemplo  MIOTOUTPUT .  \u00c1rea de trabajo de grupo : selecciona el \u00e1rea de trabajo de grupo de destino.  Nombre del conjunto de datos : escribe un nombre para el conjunto de datos, por ejemplo  MIOTDATASET .  Nombre de la tabla : Escribe un nombre de tabla, por ejemplo  MIOTTABLE .  Modo de autenticaci\u00f3n : Deja la opci\u00f3n predeterminada.",
            "title": "Adici\u00f3n de una salida al trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#configuracion-de-la-consulta-del-trabajo-de-stream-analytics",
            "text": "En  Topolog\u00eda de trabajo , selecciona  Consulta .  Reemplaza  [YourInputAlias]  por el alias de entrada del trabajo.  Reemplaza  [YourOutputAlias]  por el alias de salida del trabajo.  Selecciona  Guardar consulta .",
            "title": "Configuraci\u00f3n de la consulta del trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#ejecucion-del-trabajo-de-stream-analytics",
            "text": "En el trabajo de  Stream Analytics , selecciona  Informaci\u00f3n general  y, a continuaci\u00f3n, elige  Iniciar->Ahora->Iniciar . Una vez que el trabajo se inicia\ncorrectamente, su estado cambia de  Detenido  a  En ejecuci\u00f3n .",
            "title": "Ejecuci\u00f3n del trabajo de Stream Analytics"
        },
        {
            "location": "/Subjects/NP2/P10/#creacion-y-publicacion-de-un-informe-de-power-bi-para-visualizar-los-datos",
            "text": "En los pasos siguientes se muestra c\u00f3mo crear y publicar un informe mediante el servicio Power BI:    Aseg\u00farate de que la aplicaci\u00f3n (tu ESP32) est\u00e1 ejecut\u00e1ndose.  Inicia sesi\u00f3n en Power BI.  Selecciona tu \u00e1rea de trabajo ( workspace ).  Selecciona  Conjunto de datos  usando el conjunto de datos que creaste en pasos anteriores (corresponde al que creaste en el momento de crear la salida para el trabajo de  Stream Analytics .  Para dicho conjunto de datos, selecciona  Agregar Informe  (el primer icono a la derecha del nombre del conjunto de datos.   Crea un gr\u00e1fico de l\u00edneas para mostrar la temperatura en tiempo real en un per\u00edodo determinado. Para ello:  En el panel  Visualizaciones  de la p\u00e1gina de creaci\u00f3n de informes, selecciona el icono de gr\u00e1fico de l\u00edneas para agregar un gr\u00e1fico de l\u00edneas.  En el panel  Campos , expande la tabla que especific\u00f3 en el momento de crear la salida para el trabajo de  Stream Analytics .  Arrastra  EventEnqueuedUtcTime  (Hora UTC de evento en cola) al Eje en el panel Visualizaciones.  Arrastra  temperature  (temperatura) a  Valores .     Se ha creado un gr\u00e1fico de l\u00edneas. El eje X muestra la fecha y hora en la zona horaria UTC. El eje Y muestra la temperatura del sensor:    Tarea  A\u00f1ade ahora informaci\u00f3n sobre humedad y velocidad del viento y refresca (actualiza) la visualizaci\u00f3n.    Tarea entregable  En esta pr\u00e1ctica, simplemente se pide que entregues alguna evidencia (por ejemplo, una captura de pantalla con tu ESP32 femitiendo eventos y una captura simult\u00e1nea de PowerBI mostr\u00e1ndolos) del correcto funcionamiento de los pasos listados. Opcionalmente, se puede a\u00f1adir, como informaci\u00f3n emitida desde el ESP32, valores reales de temperatura obtenidos desde un sensor en el ESP32.",
            "title": "Creaci\u00f3n y publicaci\u00f3n de un informe de Power BI para visualizar los datos"
        },
        {
            "location": "/Subjects/NP2/P2/",
            "text": "Laboratory 2. TCP and UDP Sockets in ESP-IDF\n\n\nGoals\n\n\n\n\nTo familiarize with the sockets API in C.   \n\n\nTo develop basic schemas for client/server systems based con TCP and UDP using C.\n\n\nTo be ablo to analyze generated traffic in a TCP and UDP connection via Wireshark.\n\n\nTo design a an application-layer protocol to simulate an application based on\n  the client/server paradigm using TCP and UDP to interact between a host and the\n  ESP32 board.\n\n\n\n\nIntroduction\n\n\nIn the previous laboratory, we studied how to develop simple client/server\nsystems using Python, both for TCP and for UDP.\nIn this lab, we will study and develop network components (TCP and UDP \nclients and servers) that can execute on the ESP32 leveraging the facilities\noffered by ESP-IDF. Also, we will demonstrate that it is possible to interact\nclients and servers executing on the virtual machine (programmed via Python) and\non the board (using the C sockets API).\n\n\nThe C sockets API\n\n\nFuntions for byte ordering\n\n\nAs TCP/IP is a universal standard, and it allows for communicating across virtually\nany platform and architecture, it is necessary to get a byte ordering method so that\nbig-endian and little-endian machines can communicate in a transparent and correct way.\nTo accomplish this requirement, routines are usually provided to reorder and adapt\nbyte ordering. In platforms in which data are already correctly ordered, these functions \ndo not present any special functionality, but anyway, its usage is necessary so that the \ncommunication among pairs is correct.\n\n\nTypical functions for data reordering are:\n\nhtons\n, \nhtonl\n, \nntohs\n y \nntohl\n. \nTheir name explains their semantics: \n\nhost to network (short)\n\n\nhost to network (long)\n, \n\nnetwork to host (short)\n and \n\nnetwork to host (long)\n,\nconverting datatypes \nshort\n and \nlong\n from the format used in network\ntransmissions (\nnetwork\n) to a \nhost\n representation. \nHence, when we send binary data over the network, it will need to be transformed using \n\nhton*\n and upon receiving it, using \nntoh*\n.\n\n\nData structures\n\n\nBefore studyin the sockets API, it is necessary to show the goal of a set of data \nstructures used in all of them. The most important is \n\nsockaddr_in\n, defined as follows:\n\n\nstruct sockaddr_in\n{\n    short          sin_family;\n    u_short        sin_port;\n    struct in_addr sin_addr;\n    char           sin_zero[8];\n};\n\n\n\n\nThe structure \nin_addr\n used in \nsockaddr_in\n is defined as:\n\n\nstruct in_addr\n{\n    u_long s_addr;\n};\n\n\n\n\nThis one consists on a field of type \nunsigned long int\n that contains the \nIP address associated with the socket.\n\n\nThe structure \nsockaddr_in\n contains two important fields:\n\n\n\n\nsin_family\n: indicating that the socket belongs to a specific family of protocols\n  (we will use the constant \nAF_INET\n for IPv4).\n\n\nsin_port\n: the port associated to the socket.\n\n\n\n\nBasic API\n\n\nsocket()\n\n\n\n\nPrototype:\n\n\n\n\nint socket(int family, int type, int protocol);\n\n\n\n\n\n\n\n\nDescription: Creates a communication \nendpoint\n and returs a file descriptor to handle it. \n\n\n\n\n\n\nParameters: \n\n\n\n\nfamily\n:  \nAF_INET\n (IPv4), \nAF_INET6\n (IPv6).\n\n\ntype\n: \nSOCK_DGRAM\n (UDP), \nSOCK_STREAM\n (TCP), \nSOCK_RAW\n.\n\n\nprotocol\n: Typically 0 (not used in Internet sorckets).\n\n\n\n\n\n\n\n\nReturn value: On success, returns a socket descriptor. \n                    Returns \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman socket\n.\n\n\n\n\n\n\nbind()\n\n\n\n\nPrototype:\n\n\n\n\nint bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\n\n\n\n\n\n\n\n\nDescription: Binds a \nsocket\n to an address specified by \naddr\n.\n  Usually, it is necessary to assign a local addres via this function before\n  a TCP socket can receive connections.\n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n:  \nsocket\n descriptor (returned by \nsocket\n).\n\n\naddr\n: address to bind (see structure in previous section).\n\n\naddrlen\n: length (in bytes) of the previous structure.\n\n\n\n\n\n\n\n\nReturn value: On success, returns 0.  Returns \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman bind\n.\n\n\n\n\n\n\nlisten()\n\n\n\n\nPrototype:\n\n\n\n\nint listen(int sockfd, int backlog);\n\n\n\n\n\n\n\n\nDescription: Marks the \nsocket\n as \npassive\n, that is, \n  a \nsocket\n that will be used to accept incoming connections using \naccept\n.\n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n:  \nsocket\n descriptor (returned by \nsocket\n).\n\n\nbacklog\n: maximum length for the pending connections queue for the socket.\n\n\n\n\n\n\n\n\nReturn value: On success, returns 0.  Returns \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman listen\n.\n\n\n\n\n\n\naccept()\n\n\n\n\nPrototype:\n\n\n\n\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\n\n\n\n\n\n\n\n\nDescription: In connection-oriented \nsockets\n, extracts the first request for connection \n  from the pending connection queue for the \nsocket\n,\n  creates a new \nconnected socket\n and returns its descriptor. \n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n: \nsocket\n descriptor (returned by \nsocket\n).\n\n\naddr\n:  pointer to a structure of type \nsockaddr\n, whose fields\n  will be filled with the date of the remote socket address.\n\n\naddrlen\n: size fo the \naddr\n structure.\n\n\n\n\n\n\n\n\nReturn value: On success, returns 0.  Returns \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman accept\n.\n\n\n\n\n\n\nconnect()\n\n\n\n\nPrototype:\n\n\n\n\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\n\n\n\n\n\n\n\n\nDescription: Connects the \nsocket\n to the address specified by \n  \naddr\n. If the \nsocket\n is UDP, \naddr\n will be the only addres to which data will be sent\n  by default, and the only one from which datagrams will be received.\n  For TCP, this call intiates the connection procedure to the specified address.\n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n:  \nsocket\n descriptor (returned by \nsocket\n).\n\n\naddr\n:  pointer to a \nsockaddr\n structure, whose fields\n  indicate the address of the destination connection.\n\n\naddrlen\n: size of the \naddr\n structure.\n\n\n\n\n\n\n\n\nReturn value: On success, returns 0.  Returns \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman connect\n.\n\n\n\n\n\n\nsend()\n\n\n\n\nPrototype:\n\n\n\n\nssize_t send(int sockfd, const void *buf, size_t len, int flags);\n\n\n\n\n\n\n\n\nDescription: In a connected \nsocket\n (that is, with a known recepient)\n  transmits messages to a remote socket.\n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n:  sending socket descriptor.\n\n\nbuf\n:  sending \nbuffer\n where message is stored.\n\n\nlen\n: number of bytes to send.\n\n\n\n\n\n\n\n\nReturn value: On success, returns the amount of bytes sent. \n-1\n if error.\n\n\n\n\n\n\nDetails: \nman send\n.\n\n\n\n\n\n\nrecv()\n/\nrecvfrom()\n\n\n\n\nPrototype:\n\n\n\n\nssize_t recv(int sockfd, void *buf, size_t len, int flags);\n\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,\n                 struct sockaddr *src_addr, socklen_t *addrlen);\n\n\n\n\n\n\n\n\n\nDescription: Receive messages from a \nsocket\n, both in connection-oriented and \n  connectionless sockets. \nrecvfrom\n receives output parameters that store information \n  about the origin of the message.\n\n\n\n\n\n\nParameters: \n\n\n\n\nsockfd\n:  socket descriptor.\n\n\nbuf\n:  reception \nbuffer\n where the received message will be stored.\n\n\nlen\n: number of bytes to receive.\n\n\nsrc_addr\n: address of the remote end of th socket (communication origin).\n\n\naddrlen\n: \nsrc_addr\n structure size.\n\n\n\n\n\n\n\n\nValor de retorno: If success, number of received bytes. \n-1\n if error.\n\n\n\n\n\n\nDetails: (\nman recv\n and \nman recv_from\n).\n\n\n\n\n\n\nclose()\n\n\n\n\nPrototype:\n\n\n\n\nint close(int fd);\n\n\n\n\n\n\n\n\nDescription: Closes a socket.\n\n\n\n\n\n\nParameters: \n\n\n\n\nfd\n:  \nsocket\n descriptor.\n\n\n\n\n\n\n\n\nDetails: \nman close\n.\n\n\n\n\n\n\nExamples\n\n\nIn the following, we propose a number of complete examples that illustrate the\nuse of the sockets API in C for the development of client/server systems. For each\none, check that, effectively, the use and sequence of application of each call follows\nthe directives in the figure:\n\n\n\n\n\n\nTask 1.1\n\n\nCompile (\ngcc example.c -o example.x\n) and execute (\n./example.x\n) each pair\nof codes and check its correct functionality. Study carefully the use of each\nroutine and how the previous directives are followed.\n\n\n\n\nExample: a TCP client\n\n\n#include <arpa/inet.h>\n#include <stdio.h>\n#include <string.h>\n#include <sys/socket.h>\n#include <unistd.h>\n#include <netinet/in.h>\n\n\nint main() {\n        const int server_port = 9000;\n\n        struct sockaddr_in server_address;\n        memset(&server_address, 0, sizeof(server_address));\n        server_address.sin_family = AF_INET;\n\n        server_address.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n        server_address.sin_port = htons(server_port);\n\n        int sock;\n        if ((sock = socket(PF_INET, SOCK_STREAM, 0)) < 0) {\n                printf(\"Error in socket\\n\");\n                return 1;\n        }\n\n        if (connect(sock, (struct sockaddr*)&server_address,\n                    sizeof(server_address)) < 0) {\n                printf(\"Error in connect\\n\");\n                return 1;\n        }\n\n        const char* data_to_send = \"Hello, NP2!!\";\n        send(sock, data_to_send, strlen(data_to_send), 0);\n\n        int n = 0;\n        int len = 0, maxlen = 100;\n        char buffer[maxlen];\n        char* pbuffer = buffer;\n\n        while ((n = recv(sock, pbuffer, maxlen, 0)) > 0) {\n                pbuffer += n;\n                maxlen -= n;\n                len += n;\n\n                buffer[len] = '\\0';\n                printf(\"Received: '%s'\\n\", buffer);\n        }\n\n        close(sock);\n        return 0;\n}\n\n\n\n\nExample: a TCP server\n\n\n#include <arpa/inet.h>\n#include <netinet/in.h>\n#include <stdbool.h>\n#include <stdio.h>\n#include <string.h>\n#include <unistd.h>\n\nint main(int argc, char *argv[]) {\n        int SERVER_PORT = 9000;\n\n        struct sockaddr_in server_address;\n        memset(&server_address, 0, sizeof(server_address));\n        server_address.sin_family = AF_INET;\n\n        server_address.sin_port = htons(SERVER_PORT);\n\n        server_address.sin_addr.s_addr = htonl(INADDR_ANY);\n\n        int listen_sock;\n        if ((listen_sock = socket(PF_INET, SOCK_STREAM, 0)) < 0) {\n                printf(\"Error in socket\\n\");\n                return 1;\n        }\n\n        if ((bind(listen_sock, (struct sockaddr *)&server_address,\n                  sizeof(server_address))) < 0) {\n                printf(\"Error in bind\\n\");\n                return 1;\n        }\n\n        int wait_size = 16;  \n\n        if (listen(listen_sock, wait_size) < 0) {\n                printf(\"Error in listen\\n\");\n                return 1;\n        }\n\n        struct sockaddr_in client_address;\n        int client_address_len = 0;\n\n        while (true) {\n                int sock;\n                if ((sock =\n                         accept(listen_sock, (struct sockaddr *)&client_address,\n                                &client_address_len)) < 0) {\n                        printf(\"Error in accept\\n\");\n                        return 1;\n                }\n\n                int n = 0;\n                int len = 0, maxlen = 100;\n                char buffer[maxlen];\n                char *pbuffer = buffer;\n\n                printf(\"Cliente conectado con IP: %s\\n\",\n                       inet_ntoa(client_address.sin_addr));\n\n                while ((n = recv(sock, pbuffer, maxlen, 0)) > 0) {\n                        pbuffer += n;\n                        maxlen -= n;\n                        len += n;\n\n                        printf(\"Received: '%s'\\n\", buffer);\n\n                        send(sock, buffer, len, 0);\n                }\n\n                close(sock);\n        }\n\n        close(listen_sock);\n        return 0;\n}\n\n\n\n\n\n\nTask 1.2\n\n\nReproduce the logic of the previous client/server \necho\n system using UDP.\n\n\n\n\nMessage construction\n\n\nIn order to send messages that encapsulate different types of data in \none invocation, you can define a message as follows:\n\n\ntypedef struct {\n  int x;\n  int y;\n} message;\n\n\n\n\nGiving value to each field and sending the structure offering the address of the\nstructure:\n\n\nmessage.x = x; message.y = y;\nsend( socketfd, &message, sizeof( message ), 0 );\n\n\n\n\n\n\nTask 1.3\n\n\nModify the UDP client to encapsulate and send a structure with different\nfields (for example, two integers), that will be received by a Python server \nfollowing the directives of Lab 1. In this case, do not use fields of \nfloating point type (we will see how to do it in the future). The goal of the\nTask is to demonstrate that a client programmed in C and a server programmed\nin Python can communicate transparently. Hence, it is not expected from you to\ndevelop a complex system.\n\n\n\n\nClient/server systems on the ESP32\n\n\nThe reason behind the previous exercises lies on the fact that the TCP/IP\nstack implemented in ESP-IDF (\nLightweight TCP/IP (lwIP)\n) \nimplements almost at 100% that API. Hence, the basic\nfirmware structure for a client/server and its API remains unmodified.\n\n\nIn this last section, we will work with two basic examples of implementation of \nclient/server systems TCP and UDP on the ESP32, with the goal of studying its functionality,\ncheck its interoperability and perform modifications to adapt them to a hypothetical IoT application.\n\n\nUDP client/server on the ESP32\n\n\nIn this part, you will work with two examples provided within the examples collection\nfrom ESP-IDF. Hence, copy in your workspace (out of the main ESP-IDF tree) both examples:\n\n\n\n\nServer UDP\n: \nexamples/protocols/sockets/udp_server/\n\n\nCient UDP\n: \nexamples/protocols/sockets/udp_client/\n\n\n\n\nGeneral structure\n\n\nObserve the codes (\nudp_server.c\n for the server, and \nudp_client.c\n for the client). \nCheck that both the basic structure of both components and the invocations\nto the sockets API match with those seen for the \necho\n system programmed in C.\n\n\nRegarding the main task (function \napp_main\n) observe that it performs a series\nof invoations to configuration APIs of some subsystems from FreeRTOS, mainly:\n\n\n// Initializes the NVS (Non-volatile storage) by default.\nESP_ERROR_CHECK(nvs_flash_init());\n// Initializes the ESP-NETIF infrastructure.\nESP_ERROR_CHECK(esp_netif_init());\n// Creates the main default event loop.\nESP_ERROR_CHECK(esp_event_loop_create_default());\n\n/* This funtion configures WiFi or Ethernet, as selected via menunconfig.\n*/\nESP_ERROR_CHECK(example_connect());\n\nxTaskCreate(udp_server_task, \"udp_server\", 4096, NULL, 5, NULL);\n\n\n\n\n\n\n\n\nexample_connect()\n, function outside ESP-IDF, that establishes a WiFi or Ethernet connection. The function is blocking, and returns when a connection has been established.\n\n\n\n\n\n\nThe features of the WiFi connection (SSID and password) must be provided via \nmenuconfig\n.\n\n\n\n\n\n\nThe goal of ESP-NETIF is to provide an abstraction layer on top of the TCP/IP stack, so that it can be migrated without modifications on user codes. You can check the documentation in the \n  \noficial webpage\n.\n\n\n\n\n\n\nLast, a task is created that executes the server logic (same for the client).\n\n\n\n\n\n\nObserve that, in the code, the error messages are annotated using the macro\n  \nESP_LOGE\n and the informative ones with \nESP_LOGI\n; try to follow this mechanism in your codes.\n\n\n\n\n\n\nDeployment. Option 1\n\n\nIn this case, you will deploy a client on an ESP32 and a server in the other.\nObviously, both ESP32s must be part of the same wireless network,\nso they will be connected to the same access point (at home or at class, you can\nuse a mobile phone for that). Configure the following point in the infrastructure:\n\n\n\n\n\n\nConfigure the SSID and password of the access point via \nmenuconfig\n before compiling\nand flashing the code both in the client and in the server.\n\n\n\n\n\n\nIn the server, configure via \nmenuconfig\n the listen port.\n\n\n\n\n\n\nBoot first the server node and take note of the proposed IP by the access point; use it in the client to configure the destintation IP of the communication. Do not forget to also configure the destination port using that configured for the server.\n\n\n\n\n\n\nAt this point, you can boot the client and you should be communicating two ESP32 nodes via UDP.\n\n\nDeployment. Option 2\n\n\nIf you only have one node, or just want to test other way of communication\nbetween a PC node and an ESP32, you can use any of the system tools:\n\n\n\n\nNote\n\n\nTake into account that your PC (that is, the virtual machine) and the ESP32\nmust be part of the same network. To accomplish it, stop your virtual machine and\nadd a new network interface of type \nbridge\n connected to the WiFi interface of your PC.\nProceeding this way, you will have an interface with IP within the network, granted \ndirectly by your access point.\n\n\n\n\n\n\nTo receive a UDP packge via a port /that is, emulate a UDP server):\n\n\n\n\nnc -ul -p 3333\n\n\n\n\n\n\nTo send a UDP package to a remote IP/port (that is, emulate a client):\n\n\n\n\nnc -u IP_REMOTE 3333\n\n\n\n\nIn the \nscripts\n folder of the examples folder, you can find small client/server UDP \nPythhon exmaples that you can also use.\n\n\nTCP client/server on the ESP32\n\n\nThe deployment of the client and server in their TCP version is equivalent to UDP.\n\n\n\n\nTo receive a TCP package via a port (that is, to emulate a TCP server):\n\n\n\n\nnc -l IP -p 3333\n\n\n\n\n\n\nTo send a TCP package to a remote IP/port (that is, emulate a client):\n\n\n\n\nnc IP 3333\n\n\n\n\nAgain, you can find TCP Python scripts to use on the \nscripts\n folder.\n\n\n\n\nTask\n\n\nExperiment with the examples provide in ESP-IDF (client/server\nTCP and UDP) and execute them on the ESP32.\n\n\n\n\n\n\nDeliverable task\n\n\nAt this point, you will have a set of codes that implement client/server systems both\nin a host (using Python and/or C) and on the ESP32 (using C and ESP-IDF), and you should\nhave checked their correct functioning.\n\n\nSpecifically, you should have developed:\n\n\n\n\n\n\nA client/server system developed for Lab1, written in Python and implementing a basic application-level protocol proposed by you.\n\n\n\n\n\n\nBasic C code for the implementation of a client/server \necho\n system, with codes given in this Lab.\n\n\n\n\n\n\nBasic C/ESP-IDF codes to implement client/servers \necho\n on the ESP32.\n\n\n\n\n\n\nAs a deliverable task, you need to adapt your deliverable of Lab 1 so that both\nclient and server can work on the host (using Python or C) and on the ESP32. You will\ndeliver the developed codes and a short report with screen capture and explanations \nthat demonstrate the correctness of the system.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P2/#laboratory-2-tcp-and-udp-sockets-in-esp-idf",
            "text": "",
            "title": "Laboratory 2. TCP and UDP Sockets in ESP-IDF"
        },
        {
            "location": "/Subjects/NP2/P2/#goals",
            "text": "To familiarize with the sockets API in C.     To develop basic schemas for client/server systems based con TCP and UDP using C.  To be ablo to analyze generated traffic in a TCP and UDP connection via Wireshark.  To design a an application-layer protocol to simulate an application based on\n  the client/server paradigm using TCP and UDP to interact between a host and the\n  ESP32 board.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP2/P2/#introduction",
            "text": "In the previous laboratory, we studied how to develop simple client/server\nsystems using Python, both for TCP and for UDP.\nIn this lab, we will study and develop network components (TCP and UDP \nclients and servers) that can execute on the ESP32 leveraging the facilities\noffered by ESP-IDF. Also, we will demonstrate that it is possible to interact\nclients and servers executing on the virtual machine (programmed via Python) and\non the board (using the C sockets API).",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/NP2/P2/#the-c-sockets-api",
            "text": "",
            "title": "The C sockets API"
        },
        {
            "location": "/Subjects/NP2/P2/#funtions-for-byte-ordering",
            "text": "As TCP/IP is a universal standard, and it allows for communicating across virtually\nany platform and architecture, it is necessary to get a byte ordering method so that\nbig-endian and little-endian machines can communicate in a transparent and correct way.\nTo accomplish this requirement, routines are usually provided to reorder and adapt\nbyte ordering. In platforms in which data are already correctly ordered, these functions \ndo not present any special functionality, but anyway, its usage is necessary so that the \ncommunication among pairs is correct.  Typical functions for data reordering are: htons ,  htonl ,  ntohs  y  ntohl . \nTheir name explains their semantics:  host to network (short)  host to network (long) ,  network to host (short)  and  network to host (long) ,\nconverting datatypes  short  and  long  from the format used in network\ntransmissions ( network ) to a  host  representation. \nHence, when we send binary data over the network, it will need to be transformed using  hton*  and upon receiving it, using  ntoh* .",
            "title": "Funtions for byte ordering"
        },
        {
            "location": "/Subjects/NP2/P2/#data-structures",
            "text": "Before studyin the sockets API, it is necessary to show the goal of a set of data \nstructures used in all of them. The most important is  sockaddr_in , defined as follows:  struct sockaddr_in\n{\n    short          sin_family;\n    u_short        sin_port;\n    struct in_addr sin_addr;\n    char           sin_zero[8];\n};  The structure  in_addr  used in  sockaddr_in  is defined as:  struct in_addr\n{\n    u_long s_addr;\n};  This one consists on a field of type  unsigned long int  that contains the \nIP address associated with the socket.  The structure  sockaddr_in  contains two important fields:   sin_family : indicating that the socket belongs to a specific family of protocols\n  (we will use the constant  AF_INET  for IPv4).  sin_port : the port associated to the socket.",
            "title": "Data structures"
        },
        {
            "location": "/Subjects/NP2/P2/#basic-api",
            "text": "",
            "title": "Basic API"
        },
        {
            "location": "/Subjects/NP2/P2/#socket",
            "text": "Prototype:   int socket(int family, int type, int protocol);    Description: Creates a communication  endpoint  and returs a file descriptor to handle it.     Parameters:    family :   AF_INET  (IPv4),  AF_INET6  (IPv6).  type :  SOCK_DGRAM  (UDP),  SOCK_STREAM  (TCP),  SOCK_RAW .  protocol : Typically 0 (not used in Internet sorckets).     Return value: On success, returns a socket descriptor. \n                    Returns  -1  if error.    Details:  man socket .",
            "title": "socket()"
        },
        {
            "location": "/Subjects/NP2/P2/#bind",
            "text": "Prototype:   int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);    Description: Binds a  socket  to an address specified by  addr .\n  Usually, it is necessary to assign a local addres via this function before\n  a TCP socket can receive connections.    Parameters:    sockfd :   socket  descriptor (returned by  socket ).  addr : address to bind (see structure in previous section).  addrlen : length (in bytes) of the previous structure.     Return value: On success, returns 0.  Returns  -1  if error.    Details:  man bind .",
            "title": "bind()"
        },
        {
            "location": "/Subjects/NP2/P2/#listen",
            "text": "Prototype:   int listen(int sockfd, int backlog);    Description: Marks the  socket  as  passive , that is, \n  a  socket  that will be used to accept incoming connections using  accept .    Parameters:    sockfd :   socket  descriptor (returned by  socket ).  backlog : maximum length for the pending connections queue for the socket.     Return value: On success, returns 0.  Returns  -1  if error.    Details:  man listen .",
            "title": "listen()"
        },
        {
            "location": "/Subjects/NP2/P2/#accept",
            "text": "Prototype:   int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);    Description: In connection-oriented  sockets , extracts the first request for connection \n  from the pending connection queue for the  socket ,\n  creates a new  connected socket  and returns its descriptor.     Parameters:    sockfd :  socket  descriptor (returned by  socket ).  addr :  pointer to a structure of type  sockaddr , whose fields\n  will be filled with the date of the remote socket address.  addrlen : size fo the  addr  structure.     Return value: On success, returns 0.  Returns  -1  if error.    Details:  man accept .",
            "title": "accept()"
        },
        {
            "location": "/Subjects/NP2/P2/#connect",
            "text": "Prototype:   int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);    Description: Connects the  socket  to the address specified by \n   addr . If the  socket  is UDP,  addr  will be the only addres to which data will be sent\n  by default, and the only one from which datagrams will be received.\n  For TCP, this call intiates the connection procedure to the specified address.    Parameters:    sockfd :   socket  descriptor (returned by  socket ).  addr :  pointer to a  sockaddr  structure, whose fields\n  indicate the address of the destination connection.  addrlen : size of the  addr  structure.     Return value: On success, returns 0.  Returns  -1  if error.    Details:  man connect .",
            "title": "connect()"
        },
        {
            "location": "/Subjects/NP2/P2/#send",
            "text": "Prototype:   ssize_t send(int sockfd, const void *buf, size_t len, int flags);    Description: In a connected  socket  (that is, with a known recepient)\n  transmits messages to a remote socket.    Parameters:    sockfd :  sending socket descriptor.  buf :  sending  buffer  where message is stored.  len : number of bytes to send.     Return value: On success, returns the amount of bytes sent.  -1  if error.    Details:  man send .",
            "title": "send()"
        },
        {
            "location": "/Subjects/NP2/P2/#recvrecvfrom",
            "text": "Prototype:   ssize_t recv(int sockfd, void *buf, size_t len, int flags);\n\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,\n                 struct sockaddr *src_addr, socklen_t *addrlen);    Description: Receive messages from a  socket , both in connection-oriented and \n  connectionless sockets.  recvfrom  receives output parameters that store information \n  about the origin of the message.    Parameters:    sockfd :  socket descriptor.  buf :  reception  buffer  where the received message will be stored.  len : number of bytes to receive.  src_addr : address of the remote end of th socket (communication origin).  addrlen :  src_addr  structure size.     Valor de retorno: If success, number of received bytes.  -1  if error.    Details: ( man recv  and  man recv_from ).",
            "title": "recv()/recvfrom()"
        },
        {
            "location": "/Subjects/NP2/P2/#close",
            "text": "Prototype:   int close(int fd);    Description: Closes a socket.    Parameters:    fd :   socket  descriptor.     Details:  man close .",
            "title": "close()"
        },
        {
            "location": "/Subjects/NP2/P2/#examples",
            "text": "In the following, we propose a number of complete examples that illustrate the\nuse of the sockets API in C for the development of client/server systems. For each\none, check that, effectively, the use and sequence of application of each call follows\nthe directives in the figure:    Task 1.1  Compile ( gcc example.c -o example.x ) and execute ( ./example.x ) each pair\nof codes and check its correct functionality. Study carefully the use of each\nroutine and how the previous directives are followed.",
            "title": "Examples"
        },
        {
            "location": "/Subjects/NP2/P2/#example-a-tcp-client",
            "text": "#include <arpa/inet.h>\n#include <stdio.h>\n#include <string.h>\n#include <sys/socket.h>\n#include <unistd.h>\n#include <netinet/in.h>\n\n\nint main() {\n        const int server_port = 9000;\n\n        struct sockaddr_in server_address;\n        memset(&server_address, 0, sizeof(server_address));\n        server_address.sin_family = AF_INET;\n\n        server_address.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n        server_address.sin_port = htons(server_port);\n\n        int sock;\n        if ((sock = socket(PF_INET, SOCK_STREAM, 0)) < 0) {\n                printf(\"Error in socket\\n\");\n                return 1;\n        }\n\n        if (connect(sock, (struct sockaddr*)&server_address,\n                    sizeof(server_address)) < 0) {\n                printf(\"Error in connect\\n\");\n                return 1;\n        }\n\n        const char* data_to_send = \"Hello, NP2!!\";\n        send(sock, data_to_send, strlen(data_to_send), 0);\n\n        int n = 0;\n        int len = 0, maxlen = 100;\n        char buffer[maxlen];\n        char* pbuffer = buffer;\n\n        while ((n = recv(sock, pbuffer, maxlen, 0)) > 0) {\n                pbuffer += n;\n                maxlen -= n;\n                len += n;\n\n                buffer[len] = '\\0';\n                printf(\"Received: '%s'\\n\", buffer);\n        }\n\n        close(sock);\n        return 0;\n}",
            "title": "Example: a TCP client"
        },
        {
            "location": "/Subjects/NP2/P2/#example-a-tcp-server",
            "text": "#include <arpa/inet.h>\n#include <netinet/in.h>\n#include <stdbool.h>\n#include <stdio.h>\n#include <string.h>\n#include <unistd.h>\n\nint main(int argc, char *argv[]) {\n        int SERVER_PORT = 9000;\n\n        struct sockaddr_in server_address;\n        memset(&server_address, 0, sizeof(server_address));\n        server_address.sin_family = AF_INET;\n\n        server_address.sin_port = htons(SERVER_PORT);\n\n        server_address.sin_addr.s_addr = htonl(INADDR_ANY);\n\n        int listen_sock;\n        if ((listen_sock = socket(PF_INET, SOCK_STREAM, 0)) < 0) {\n                printf(\"Error in socket\\n\");\n                return 1;\n        }\n\n        if ((bind(listen_sock, (struct sockaddr *)&server_address,\n                  sizeof(server_address))) < 0) {\n                printf(\"Error in bind\\n\");\n                return 1;\n        }\n\n        int wait_size = 16;  \n\n        if (listen(listen_sock, wait_size) < 0) {\n                printf(\"Error in listen\\n\");\n                return 1;\n        }\n\n        struct sockaddr_in client_address;\n        int client_address_len = 0;\n\n        while (true) {\n                int sock;\n                if ((sock =\n                         accept(listen_sock, (struct sockaddr *)&client_address,\n                                &client_address_len)) < 0) {\n                        printf(\"Error in accept\\n\");\n                        return 1;\n                }\n\n                int n = 0;\n                int len = 0, maxlen = 100;\n                char buffer[maxlen];\n                char *pbuffer = buffer;\n\n                printf(\"Cliente conectado con IP: %s\\n\",\n                       inet_ntoa(client_address.sin_addr));\n\n                while ((n = recv(sock, pbuffer, maxlen, 0)) > 0) {\n                        pbuffer += n;\n                        maxlen -= n;\n                        len += n;\n\n                        printf(\"Received: '%s'\\n\", buffer);\n\n                        send(sock, buffer, len, 0);\n                }\n\n                close(sock);\n        }\n\n        close(listen_sock);\n        return 0;\n}   Task 1.2  Reproduce the logic of the previous client/server  echo  system using UDP.",
            "title": "Example: a TCP server"
        },
        {
            "location": "/Subjects/NP2/P2/#message-construction",
            "text": "In order to send messages that encapsulate different types of data in \none invocation, you can define a message as follows:  typedef struct {\n  int x;\n  int y;\n} message;  Giving value to each field and sending the structure offering the address of the\nstructure:  message.x = x; message.y = y;\nsend( socketfd, &message, sizeof( message ), 0 );   Task 1.3  Modify the UDP client to encapsulate and send a structure with different\nfields (for example, two integers), that will be received by a Python server \nfollowing the directives of Lab 1. In this case, do not use fields of \nfloating point type (we will see how to do it in the future). The goal of the\nTask is to demonstrate that a client programmed in C and a server programmed\nin Python can communicate transparently. Hence, it is not expected from you to\ndevelop a complex system.",
            "title": "Message construction"
        },
        {
            "location": "/Subjects/NP2/P2/#clientserver-systems-on-the-esp32",
            "text": "The reason behind the previous exercises lies on the fact that the TCP/IP\nstack implemented in ESP-IDF ( Lightweight TCP/IP (lwIP) ) \nimplements almost at 100% that API. Hence, the basic\nfirmware structure for a client/server and its API remains unmodified.  In this last section, we will work with two basic examples of implementation of \nclient/server systems TCP and UDP on the ESP32, with the goal of studying its functionality,\ncheck its interoperability and perform modifications to adapt them to a hypothetical IoT application.",
            "title": "Client/server systems on the ESP32"
        },
        {
            "location": "/Subjects/NP2/P2/#udp-clientserver-on-the-esp32",
            "text": "In this part, you will work with two examples provided within the examples collection\nfrom ESP-IDF. Hence, copy in your workspace (out of the main ESP-IDF tree) both examples:   Server UDP :  examples/protocols/sockets/udp_server/  Cient UDP :  examples/protocols/sockets/udp_client/",
            "title": "UDP client/server on the ESP32"
        },
        {
            "location": "/Subjects/NP2/P2/#general-structure",
            "text": "Observe the codes ( udp_server.c  for the server, and  udp_client.c  for the client). \nCheck that both the basic structure of both components and the invocations\nto the sockets API match with those seen for the  echo  system programmed in C.  Regarding the main task (function  app_main ) observe that it performs a series\nof invoations to configuration APIs of some subsystems from FreeRTOS, mainly:  // Initializes the NVS (Non-volatile storage) by default.\nESP_ERROR_CHECK(nvs_flash_init());\n// Initializes the ESP-NETIF infrastructure.\nESP_ERROR_CHECK(esp_netif_init());\n// Creates the main default event loop.\nESP_ERROR_CHECK(esp_event_loop_create_default());\n\n/* This funtion configures WiFi or Ethernet, as selected via menunconfig.\n*/\nESP_ERROR_CHECK(example_connect());\n\nxTaskCreate(udp_server_task, \"udp_server\", 4096, NULL, 5, NULL);    example_connect() , function outside ESP-IDF, that establishes a WiFi or Ethernet connection. The function is blocking, and returns when a connection has been established.    The features of the WiFi connection (SSID and password) must be provided via  menuconfig .    The goal of ESP-NETIF is to provide an abstraction layer on top of the TCP/IP stack, so that it can be migrated without modifications on user codes. You can check the documentation in the \n   oficial webpage .    Last, a task is created that executes the server logic (same for the client).    Observe that, in the code, the error messages are annotated using the macro\n   ESP_LOGE  and the informative ones with  ESP_LOGI ; try to follow this mechanism in your codes.",
            "title": "General structure"
        },
        {
            "location": "/Subjects/NP2/P2/#deployment-option-1",
            "text": "In this case, you will deploy a client on an ESP32 and a server in the other.\nObviously, both ESP32s must be part of the same wireless network,\nso they will be connected to the same access point (at home or at class, you can\nuse a mobile phone for that). Configure the following point in the infrastructure:    Configure the SSID and password of the access point via  menuconfig  before compiling\nand flashing the code both in the client and in the server.    In the server, configure via  menuconfig  the listen port.    Boot first the server node and take note of the proposed IP by the access point; use it in the client to configure the destintation IP of the communication. Do not forget to also configure the destination port using that configured for the server.    At this point, you can boot the client and you should be communicating two ESP32 nodes via UDP.",
            "title": "Deployment. Option 1"
        },
        {
            "location": "/Subjects/NP2/P2/#deployment-option-2",
            "text": "If you only have one node, or just want to test other way of communication\nbetween a PC node and an ESP32, you can use any of the system tools:   Note  Take into account that your PC (that is, the virtual machine) and the ESP32\nmust be part of the same network. To accomplish it, stop your virtual machine and\nadd a new network interface of type  bridge  connected to the WiFi interface of your PC.\nProceeding this way, you will have an interface with IP within the network, granted \ndirectly by your access point.    To receive a UDP packge via a port /that is, emulate a UDP server):   nc -ul -p 3333   To send a UDP package to a remote IP/port (that is, emulate a client):   nc -u IP_REMOTE 3333  In the  scripts  folder of the examples folder, you can find small client/server UDP \nPythhon exmaples that you can also use.",
            "title": "Deployment. Option 2"
        },
        {
            "location": "/Subjects/NP2/P2/#tcp-clientserver-on-the-esp32",
            "text": "The deployment of the client and server in their TCP version is equivalent to UDP.   To receive a TCP package via a port (that is, to emulate a TCP server):   nc -l IP -p 3333   To send a TCP package to a remote IP/port (that is, emulate a client):   nc IP 3333  Again, you can find TCP Python scripts to use on the  scripts  folder.   Task  Experiment with the examples provide in ESP-IDF (client/server\nTCP and UDP) and execute them on the ESP32.    Deliverable task  At this point, you will have a set of codes that implement client/server systems both\nin a host (using Python and/or C) and on the ESP32 (using C and ESP-IDF), and you should\nhave checked their correct functioning.  Specifically, you should have developed:    A client/server system developed for Lab1, written in Python and implementing a basic application-level protocol proposed by you.    Basic C code for the implementation of a client/server  echo  system, with codes given in this Lab.    Basic C/ESP-IDF codes to implement client/servers  echo  on the ESP32.    As a deliverable task, you need to adapt your deliverable of Lab 1 so that both\nclient and server can work on the host (using Python or C) and on the ESP32. You will\ndeliver the developed codes and a short report with screen capture and explanations \nthat demonstrate the correctness of the system.",
            "title": "TCP client/server on the ESP32"
        },
        {
            "location": "/Subjects/NP2/P3/",
            "text": "Pr\u00e1ctica 3. Seguridad (TLS y DTLS)\n\n\nObjetivos\n\n\n\n\nObservar el comportamiento de TLS y DTLS para el intercambio cifrado de mensajes.\n\n\nConocer las diferencias b\u00e1sicas entre TLS y DTLS.\n\n\nConocer una API b\u00e1sica de programaci\u00f3n de sistemas cliente/servidor usando TLS y DTLS (WolfSSL).\n\n\nConocer una API b\u00e1sica de programaci\u00f3n de sistemas cliente/servidor en ESP-IDF (ESP-TLS).\n\n\n\n\nContenido del paquete proporcionado y setup b\u00e1sico\n\n\nEl paquete proporcionado (puedes descargarlo \naqu\u00ed\n) \nincluye ejemplos de sistemas cliente/servidor\nprogramados utilizando TLS y DTLS mediante el uso de la biblioteca WolfSSL.\nEstos c\u00f3digos est\u00e1n dise\u00f1ados para ejecutarse exclusivamente en un sistema\nLinux, y requieren la instalaci\u00f3n de los paquetes de desarrollo WolfSSL. \n\n\nPara realizar la instalaci\u00f3n, ejecuta en tu m\u00e1quina virtual (esta l\u00ednea\npodr\u00eda cambiar si usas otra distribuci\u00f3n de Linux, en cuyo caso deber\u00e1s\nbuscar los paquetes equivalentes):\n\n\nsudo apt-get install libwolfssl-dev libwolfssl24\n\n\n\n\nUna vez hecho esto, prueba a realizar la compilaci\u00f3n tanto del ejemplo\nTLS como DTLS utilizando la orden \nmake\n en el directorio correspondiente. Si\ntodo ha ido bien, puedes continuar con el an\u00e1lisis de los c\u00f3digos en la \nsiguiente secci\u00f3n.\n\n\nCliente/servidor TLS. Ejemplo b\u00e1sico en host\n\n\nServidor TLS\n\n\nAnalizaremos en primer lugar el c\u00f3digo b\u00e1sico del servidor TLS. Para ello, \nobserva el contenido del fchero \ntls/server-tls.c\n.\n\n\nCabeceras y constantes\n\n\nEl uso de WolfSSL requiere la inclusi\u00f3n de dos cabeceras b\u00e1sicas:\n\n\n#include <wolfssl/options.h>\n#include <wolfssl/ssl.h>\n\n\n\n\nAdem\u00e1s, ya que ser\u00e1n necesarios en el desarrollo, definiremos las rutas al\ncertificado (clave p\u00fablica) del servidor y su clave privada:\n\n\n#define CERT_FILE \"../certs/server-cert.pem\"\n#define KEY_FILE  \"../certs/server-key.pem\"\n\n\n\n\nObserva adem\u00e1s que el puerto de escucha del servidor ser\u00e1 el \n11111\n.\n\n\nObjetos b\u00e1sicos WolfSSL. Contexto y objeto SSL\n\n\nDefiniremos dos objetos b\u00e1sicos que se utilizar\u00e1n de forma recurrente\nen el c\u00f3digo:\n\n\nWOLFSSL_CTX* ctx;\nWOLFSSL*     ssl;\n\n\n\n\nEl contexto (\nctx\n) incluye valores globales para cada conexi\u00f3n SSL, incluyendo\ninformaci\u00f3n sobre certificados. Es posible utilizar un mismo contexto para \nm\u00faltiples conexiones, siempre que compartan caracter\u00edsticas. Para crear un \nnuevo contexto, utilizaremos la funci\u00f3n \nwolfSSL_CTX_new\n como sigue:\n\n\n/* Create and initialize WOLFSSL_CTX */\nif ((ctx = wolfSSL_CTX_new(wolfTLSv1_2_server_method())) == NULL) {\n  fprintf(stderr, \"ERROR: failed to create WOLFSSL_CTX\\n\");\n  return -1;\n}\n\n\n\n\nEl argumento proporcionado incluye informaci\u00f3n sobre la versi\u00f3n de protocolo\na utilizar. Actualmente, WolfSSL soporta SSL 3.0,\nTLS 1.1, TLS 1.2,  DTLS 1.0 y DTLS 1.2. En este caso, para la parte cliente,\nlas funciones a utilizar como argumento ser\u00edan:\n\n\n\n\nwolfSSLv3_server_method();     // SSLv3\n\n\nwolfTLSv1_server_method();     // TLSv1\n\n\nwolfTLSv1_1_server_method();   // TLSv1.1\n\n\nwolfTLSv1_2_server_method();   // TLSv1.2\n\n\nwolfDTLSv1_server_method();    // DTLS\n\n\nwolfDTLSv1_2_server_method();  // DTLS 1.2\n\n\n\n\nEn segundo lugar, es necesario cargar nuestra CA (Autoridad Certificadora)\nen el contexto, para que cualquier cliente pueda verificar, en el momento de\nsu conexi\u00f3n, la identidad del sevidor. Para ello, usamos la funci\u00f3n\n\nwolfSSL_CTX_use_certificate_file\n de la siguiente manera:\n\n\n/* Load server certificates into WOLFSSL_CTX */\nif (wolfSSL_CTX_use_certificate_file(ctx, CERT_FILE, SSL_FILETYPE_PEM)\n        != SSL_SUCCESS) {\n  fprintf(stderr, \"ERROR: failed to load %s, please check the file.\\n\",\n                CERT_FILE);\n  return -1;\n}\n\n\n\n\nDel mismo modo, el servidor deber\u00e1 incluir su clave privada en formato PEM:\n\n\n/* Load server key into WOLFSSL_CTX */\nif (wolfSSL_CTX_use_PrivateKey_file(ctx, KEY_FILE, SSL_FILETYPE_PEM)\n        != SSL_SUCCESS) {\n  fprintf(stderr, \"ERROR: failed to load %s, please check the file.\\n\",\n                KEY_FILE);\n  return -1;\n}\n\n\n\n\nA continuaci\u00f3n, observa como el c\u00f3digo de escucha y aceptaci\u00f3n de conexiones\nentrantes no difier de cualquier c\u00f3digo que hayas desarrollado previamente\npara aceptar conexiones entrantes TCP (\nbind\n, + \nlisten\n + \naccept\n).\n\n\nJusto tras la conexi\u00f3n (\naccept\n), resulta necesario crear un nuevo objeto\nSSL, as\u00ed como asociar el descriptor de socket con la nueva sesi\u00f3n (conexi\u00f3n)\nTLS:\n\n\n/* Create a WOLFSSL object */\nif ((ssl = wolfSSL_new(ctx)) == NULL) {\n  fprintf(stderr, \"ERROR: failed to create WOLFSSL object\\n\");\n  return -1;\n}\n\n/* Attach wolfSSL to the socket */\nwolfSSL_set_fd(ssl, connd);\n\n/* Establish TLS connection */\nret = wolfSSL_accept(ssl);\nif (ret != SSL_SUCCESS) {\n  fprintf(stderr, \"wolfSSL_accept error = %d\\n\",\n                wolfSSL_get_error(ssl, ret));\n  return -1;\n}\n\n\n\n\nA partir de este punto, podemos enviar y recibir datos a trav\u00e9s del socket\n(y por tanto de la conexi\u00f3n TLS) de forma muy similar a como lo hacemos \ncon el enfoque cl\u00e1sico. As\u00ed, para recibir datos:\n\n\nif (wolfSSL_read(ssl, buff, sizeof(buff)-1) == -1) {\n  fprintf(stderr, \"ERROR: failed to read\\n\");\n  return -1;\n}\n\n\n\n\nY para enviar datos de vuelta:\n\n\n/* Reply back to the client */\nif (wolfSSL_write(ssl, buff, len) != len) {\n  fprintf(stderr, \"ERROR: failed to write\\n\");\n  return -1;\n}\n\n\n\n\nPor \u00faltimo, finalizaremos la conexi\u00f3n con la invocaci\u00f3n de la funci\u00f3n\n\nwolfSSL_free(ssl)\n.\n\n\n!!! note Tarea \n    El cliente proporcionado sigue una estrategia de implementaci\u00f3n similar.\n    Compara ambos c\u00f3digos (cliente y servidor) y aseg\u00farate de entender las\n    diferencias entre ellos.\n\n\n\n\nTarea entregable\n\n\nCompila y ejecuta el sistema cliente/servidor TLS y obt\u00e9n capturas de\ntr\u00e1fico tanto de las fases de establecimiento de conexi\u00f3n como de las\nfases de transferencia de datos. En base a lo aprendido en las clases\nde teor\u00eda y la documentaci\u00f3n adicional sobre TLS y wolfSSL, redacta \nun breve informe que resuma el proceso de \nhandshake\n y transferencia\nde datos en TLS tomando como base los paquetes reales observados para\nesta conexi\u00f3n.\n\n\n\n\nCliente/servidor DTLS. Ejemplo b\u00e1sico en host\n\n\nEl desarrollo de un sistema b\u00e1sico cliente/servidor con soporte DTLS utilizando\nWolfSSL es muy similar al visto anteriormente para TLS. Como detalle adicional,\nla inicializaci\u00f3n de la infraestructura debe realizarse indicando el soporte\npara DTLS en sus versiones 1.0 o 1.2:\n\n\n\n\n\n\nwolfDTLSv1_client_method();    // DTLS 1.0\n\n\n\n\n\n\nwolfDTLSv1_2_client_method();  // DTLS 1.2\n\n\n\n\n\n\nEl resto del c\u00f3digo sigue una filosof\u00eda similar a TLS, adaptado, obviamente,\na las caracter\u00edsticas de UDP (tipo de socket, ausencia de conexi\u00f3n, etc.), por\nlo que se deja como ejercicio su an\u00e1lisis y ejecuci\u00f3n.\n\n\n\n\nTarea entregable\n\n\nAnaliza, compila y ejecuta los c\u00f3digos correspondientes al sistema cliente/servidor\nDTLS. Realiza capturas de tr\u00e1fico y comp\u00e1ralas, paquete a paquete, con las generadas\npara un patr\u00f3n de tr\u00e1fico similar en el caso de TLS. Incide en sus similitudes\ny diferencias, tanto a nivel de \nhandshake\n como de transferencia de datos. Observa,\nen este \u00faltimo caso, la aparici\u00f3n de nuevos campos de encabezado en los env\u00edos\nde datos DTLS. \u00bfCu\u00e1l/cu\u00e1les son esos campos y por qu\u00e9 aparecen? Realiza una comparativa\ndel tr\u00e1fico total generado en ambos casos para exactamente la misma cantidad de datos \ntransferidos.\n\n\n\n\nTLS en el ESP32. El componente ESP-TLS\n\n\nESP-IDF proporciona un componente (ESP-TLS) que ofrece una interfaz (API)\nsimplificada para acceder a funcionalidad b\u00e1sica TLS. A\u00fan as\u00ed, ofrece \nuna funcionalidad suficientemente amplia como para implementar casos de uso\ncomunes en entornos IoT. \n\n\nLa API de ESP-TLS es sencilla,y se basa en el uso de cuatro funciones b\u00e1sicas:\n\n\nEstablecimiento de conexi\u00f3n TLS (\nesp_tls_conn_new()\n)\n\n\n\n\nPrototipo:\n\n\n\n\nesp_tls_t *esp_tls_conn_new(const char *hostname, int hostlen, int port, constesp_tls_cfg_t *cfg)\n\n\n\n\n\n\n\n\nDescripci\u00f3n: Crea una nueva conexi\u00f3n TLS/SSL bloqueante, estableciendo dicha\n  conexi\u00f3n contra un servidor establecido. \n\n\n\n\n\n\nPar\u00e1metros: \n\n\n\n\nhostname\n: Identificaci\u00f3n del host.\n\n\nhostlen\n: Longitud del par\u00e1metro \nhostname\n.\n\n\nport\n: Puerto de conexi\u00f3n con el host.\n\n\ncfg\n: Configuraci\u00f3n de la conexi\u00f3n TLS.\n\n\n\n\n\n\n\n\nValor de retorno: Puntero a \nesp_tls_t\n (manejador de la conexi\u00f3n).\n                    Devuelve \nNULL\n si se produce un error en la conexi\u00f3n.\n\n\n\n\n\n\nDestrucci\u00f3n de conexi\u00f3n TLS (\nesp_tls_conn_delete()\n)\n\n\nvoid esp_tls_conn_delete(esp_tls_t *tls)\n\n\n\n\n\n\n\n\nDescripci\u00f3n: Cierra la conexi\u00f3n TLS/SSL. \n\n\n\n\n\n\nPar\u00e1metros: \n\n\n\n\ntls\n: Manejador de la conexi\u00f3n.\n\n\n\n\n\n\n\n\nEscritura de datos (\nesp_tls_conn_read()\n)\n\n\nstatic ssize_t esp_tls_conn_write(esp_tls_t *tls, const void *data, size_t datalen)\n\n\n\n\n\n\n\n\nDescripci\u00f3n: Escribe en la conexi\u00f3n TLS/SSL indicada el contenido del buffer\n  \ndata\n.\n\n\n\n\n\n\nPar\u00e1metros: \n\n\n\n\ntls\n: Manejador de la conexi\u00f3n. \n\n\ndata\n: Buffer de env\u00edo.\n\n\ndatalen\n: Longitud del buffer de env\u00edo (o n\u00famero m\u00e1ximo \n   de bytes a escribir).\n\n\n\n\n\n\n\n\nValor de retorno: \n\n\n\n\n>=0\n: \u00e9xito en el env\u00edo. N\u00famero de bytes efectivamente enviados.\n\n\n<0\n: error en el env\u00edo.\n\n\n\n\n\n\n\n\nLectura de datos (\nesp_tls_conn_read()\n)\n\n\nstatic ssize_t esp_tls_conn_read(esp_tls_t *tls, void *data, size_t datalen)\n\n\n\n\n\n\n\n\nDescripci\u00f3n: Lee desde la conexi\u00f3n TLS/SSL indicada hacia el buffer \ndata\n.\n\n\n\n\n\n\nPar\u00e1metros: \n\n\n\n\ntls\n: Manejador de la conexi\u00f3n. \n\n\ndata\n: Buffer de recepci\u00f3n.\n\n\ndatalen\n: Longitud del buffer de recepci\u00f3n (o n\u00famero m\u00e1ximo \n   de bytes a leer).\n\n\n\n\n\n\n\n\nValor de retorno: \n\n\n\n\n>0\n: \u00e9xito en la recepci\u00f3n. N\u00famero de bytes efectivamente le\u00eddos.\n\n\n=0\n: error en la recepci\u00f3n. La conexi\u00f3n se cerr\u00f3.\n\n\n<0\n: error en la recepci\u00f3n. \n\n\n\n\n\n\n\n\nEstructura b\u00e1sica de un cliente TCP usando ESP-IDF\n\n\nUn cliente TCP implementado sobre ESP-IDF para dar soporte TLS, \nrequiere ciertas modificaciones con respecto a la versi\u00f3n sin TLS. \nDe hecho, el uso de ESP-IDF simplifica el c\u00f3digo del cliente (puedes \ncompararlo con tus clientes TCP desarrollados en sesiones anteriores). La\nestructura b\u00e1sica resultar\u00eda:\n\n\n/// Includes anteriores.\n#include \"esp_tls.h\"\n\n// Puede tomarse desde menuconfig.\n#define HOST_IP_ADDR DIRECCION_DE_HOST\n#define PORT PUERTO \n\nstatic const char *payload = \"Hola, mundo via TLS\";\n\n// ...\n\nstatic void tls_client_task( void  *pvParameters )\n{\n  // ...\n\n  // Configuraci\u00f3n de ESP-TLS (vac\u00edo para opciones defecto).\n  esp_tls_cfg_t cfg = { };\n\n  // Creaci\u00f3n de conexi\u00f3n.\n  struct esp_tls *tls = esp_tls_conn_new( HOST_IP_ADDR, longitud, PORT, &cfg);\n\n  // Chequeo de errores.\n  // ...\n\n  // Env\u00edo de datos.\n  ret = esp_tls_conn_write(tls, payload, strlen(payload));\n\n  // Chequeo de errores.\n  // ...\n\n  // Lectura de datos\n  ret = esp_tls_conn_read(tls, (char *)rx_buffer, 128);\n\n  // Chequeo de errores.\n  // ...\n\n  // Destrucci\u00f3n de la conexi\u00f3n\n  esp_tls_conn_delete( tls );\n\n  vTaskDelete( NULL );\n}\n\nvoid app_main( void )\n{\n  // ...\n}\n\n\n\n\nObserva como, efectivamente, el c\u00f3digo del cliente se simplifica en gran \nmedida con respecto a tu cliente TCP original. \n\n\nToma el c\u00f3digo del proyecto que\nutilizaste para desarrollar tu cliente TCP original y, siguiendo las anteriores\ndirectivas, adapta la \u00fanica tarea a crear (por ejemplo, puede recibir el\nnombre \ntls_client_task\n) para que realice un env\u00edo y recepci\u00f3n de datos \n(una cadena) al servidor TLS que probaste en el \nhost\n. Puedes valerte para ello\nde la base del ejemplo \nexamples/protocols/https_request\n, obviamente adaptando\nla totalidad de su c\u00f3digo para que se comporte como un simple cliente \necho\n.\n\n\n!!! note Tarea\n    Compila y ejecuta el cliente TLS en el ESP32, y consigue que interact\u00fae con\n    el servidor TLS que probaste anteriormente en el \nhost\n. Comprueba que, efectivamente,\n    los datos se transfieren cifrados entre ambos extremos, y que el intercambio de \n    paquetes es similar al que observaste entre cliente y servidor en el \nhost\n.\n\n\n\n\nTarea entregable\n\n\nAdapta tu sistema cliente/servidor TCP desarrollado en la anterior pr\u00e1ctica\npara que se ejecute sobre el binomio \nhost\n/ESP32 utlizando TLS. \nEntrega el c\u00f3digo generado junto con una captura de tr\u00e1fico que demuestre su \ncorrecto funcionamiento.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P3/#practica-3-seguridad-tls-y-dtls",
            "text": "",
            "title": "Pr\u00e1ctica 3. Seguridad (TLS y DTLS)"
        },
        {
            "location": "/Subjects/NP2/P3/#objetivos",
            "text": "Observar el comportamiento de TLS y DTLS para el intercambio cifrado de mensajes.  Conocer las diferencias b\u00e1sicas entre TLS y DTLS.  Conocer una API b\u00e1sica de programaci\u00f3n de sistemas cliente/servidor usando TLS y DTLS (WolfSSL).  Conocer una API b\u00e1sica de programaci\u00f3n de sistemas cliente/servidor en ESP-IDF (ESP-TLS).",
            "title": "Objetivos"
        },
        {
            "location": "/Subjects/NP2/P3/#contenido-del-paquete-proporcionado-y-setup-basico",
            "text": "El paquete proporcionado (puedes descargarlo  aqu\u00ed ) \nincluye ejemplos de sistemas cliente/servidor\nprogramados utilizando TLS y DTLS mediante el uso de la biblioteca WolfSSL.\nEstos c\u00f3digos est\u00e1n dise\u00f1ados para ejecutarse exclusivamente en un sistema\nLinux, y requieren la instalaci\u00f3n de los paquetes de desarrollo WolfSSL.   Para realizar la instalaci\u00f3n, ejecuta en tu m\u00e1quina virtual (esta l\u00ednea\npodr\u00eda cambiar si usas otra distribuci\u00f3n de Linux, en cuyo caso deber\u00e1s\nbuscar los paquetes equivalentes):  sudo apt-get install libwolfssl-dev libwolfssl24  Una vez hecho esto, prueba a realizar la compilaci\u00f3n tanto del ejemplo\nTLS como DTLS utilizando la orden  make  en el directorio correspondiente. Si\ntodo ha ido bien, puedes continuar con el an\u00e1lisis de los c\u00f3digos en la \nsiguiente secci\u00f3n.",
            "title": "Contenido del paquete proporcionado y setup b\u00e1sico"
        },
        {
            "location": "/Subjects/NP2/P3/#clienteservidor-tls-ejemplo-basico-en-host",
            "text": "",
            "title": "Cliente/servidor TLS. Ejemplo b\u00e1sico en host"
        },
        {
            "location": "/Subjects/NP2/P3/#servidor-tls",
            "text": "Analizaremos en primer lugar el c\u00f3digo b\u00e1sico del servidor TLS. Para ello, \nobserva el contenido del fchero  tls/server-tls.c .",
            "title": "Servidor TLS"
        },
        {
            "location": "/Subjects/NP2/P3/#cabeceras-y-constantes",
            "text": "El uso de WolfSSL requiere la inclusi\u00f3n de dos cabeceras b\u00e1sicas:  #include <wolfssl/options.h>\n#include <wolfssl/ssl.h>  Adem\u00e1s, ya que ser\u00e1n necesarios en el desarrollo, definiremos las rutas al\ncertificado (clave p\u00fablica) del servidor y su clave privada:  #define CERT_FILE \"../certs/server-cert.pem\"\n#define KEY_FILE  \"../certs/server-key.pem\"  Observa adem\u00e1s que el puerto de escucha del servidor ser\u00e1 el  11111 .",
            "title": "Cabeceras y constantes"
        },
        {
            "location": "/Subjects/NP2/P3/#objetos-basicos-wolfssl-contexto-y-objeto-ssl",
            "text": "Definiremos dos objetos b\u00e1sicos que se utilizar\u00e1n de forma recurrente\nen el c\u00f3digo:  WOLFSSL_CTX* ctx;\nWOLFSSL*     ssl;  El contexto ( ctx ) incluye valores globales para cada conexi\u00f3n SSL, incluyendo\ninformaci\u00f3n sobre certificados. Es posible utilizar un mismo contexto para \nm\u00faltiples conexiones, siempre que compartan caracter\u00edsticas. Para crear un \nnuevo contexto, utilizaremos la funci\u00f3n  wolfSSL_CTX_new  como sigue:  /* Create and initialize WOLFSSL_CTX */\nif ((ctx = wolfSSL_CTX_new(wolfTLSv1_2_server_method())) == NULL) {\n  fprintf(stderr, \"ERROR: failed to create WOLFSSL_CTX\\n\");\n  return -1;\n}  El argumento proporcionado incluye informaci\u00f3n sobre la versi\u00f3n de protocolo\na utilizar. Actualmente, WolfSSL soporta SSL 3.0,\nTLS 1.1, TLS 1.2,  DTLS 1.0 y DTLS 1.2. En este caso, para la parte cliente,\nlas funciones a utilizar como argumento ser\u00edan:   wolfSSLv3_server_method();     // SSLv3  wolfTLSv1_server_method();     // TLSv1  wolfTLSv1_1_server_method();   // TLSv1.1  wolfTLSv1_2_server_method();   // TLSv1.2  wolfDTLSv1_server_method();    // DTLS  wolfDTLSv1_2_server_method();  // DTLS 1.2   En segundo lugar, es necesario cargar nuestra CA (Autoridad Certificadora)\nen el contexto, para que cualquier cliente pueda verificar, en el momento de\nsu conexi\u00f3n, la identidad del sevidor. Para ello, usamos la funci\u00f3n wolfSSL_CTX_use_certificate_file  de la siguiente manera:  /* Load server certificates into WOLFSSL_CTX */\nif (wolfSSL_CTX_use_certificate_file(ctx, CERT_FILE, SSL_FILETYPE_PEM)\n        != SSL_SUCCESS) {\n  fprintf(stderr, \"ERROR: failed to load %s, please check the file.\\n\",\n                CERT_FILE);\n  return -1;\n}  Del mismo modo, el servidor deber\u00e1 incluir su clave privada en formato PEM:  /* Load server key into WOLFSSL_CTX */\nif (wolfSSL_CTX_use_PrivateKey_file(ctx, KEY_FILE, SSL_FILETYPE_PEM)\n        != SSL_SUCCESS) {\n  fprintf(stderr, \"ERROR: failed to load %s, please check the file.\\n\",\n                KEY_FILE);\n  return -1;\n}  A continuaci\u00f3n, observa como el c\u00f3digo de escucha y aceptaci\u00f3n de conexiones\nentrantes no difier de cualquier c\u00f3digo que hayas desarrollado previamente\npara aceptar conexiones entrantes TCP ( bind , +  listen  +  accept ).  Justo tras la conexi\u00f3n ( accept ), resulta necesario crear un nuevo objeto\nSSL, as\u00ed como asociar el descriptor de socket con la nueva sesi\u00f3n (conexi\u00f3n)\nTLS:  /* Create a WOLFSSL object */\nif ((ssl = wolfSSL_new(ctx)) == NULL) {\n  fprintf(stderr, \"ERROR: failed to create WOLFSSL object\\n\");\n  return -1;\n}\n\n/* Attach wolfSSL to the socket */\nwolfSSL_set_fd(ssl, connd);\n\n/* Establish TLS connection */\nret = wolfSSL_accept(ssl);\nif (ret != SSL_SUCCESS) {\n  fprintf(stderr, \"wolfSSL_accept error = %d\\n\",\n                wolfSSL_get_error(ssl, ret));\n  return -1;\n}  A partir de este punto, podemos enviar y recibir datos a trav\u00e9s del socket\n(y por tanto de la conexi\u00f3n TLS) de forma muy similar a como lo hacemos \ncon el enfoque cl\u00e1sico. As\u00ed, para recibir datos:  if (wolfSSL_read(ssl, buff, sizeof(buff)-1) == -1) {\n  fprintf(stderr, \"ERROR: failed to read\\n\");\n  return -1;\n}  Y para enviar datos de vuelta:  /* Reply back to the client */\nif (wolfSSL_write(ssl, buff, len) != len) {\n  fprintf(stderr, \"ERROR: failed to write\\n\");\n  return -1;\n}  Por \u00faltimo, finalizaremos la conexi\u00f3n con la invocaci\u00f3n de la funci\u00f3n wolfSSL_free(ssl) .  !!! note Tarea \n    El cliente proporcionado sigue una estrategia de implementaci\u00f3n similar.\n    Compara ambos c\u00f3digos (cliente y servidor) y aseg\u00farate de entender las\n    diferencias entre ellos.   Tarea entregable  Compila y ejecuta el sistema cliente/servidor TLS y obt\u00e9n capturas de\ntr\u00e1fico tanto de las fases de establecimiento de conexi\u00f3n como de las\nfases de transferencia de datos. En base a lo aprendido en las clases\nde teor\u00eda y la documentaci\u00f3n adicional sobre TLS y wolfSSL, redacta \nun breve informe que resuma el proceso de  handshake  y transferencia\nde datos en TLS tomando como base los paquetes reales observados para\nesta conexi\u00f3n.",
            "title": "Objetos b\u00e1sicos WolfSSL. Contexto y objeto SSL"
        },
        {
            "location": "/Subjects/NP2/P3/#clienteservidor-dtls-ejemplo-basico-en-host",
            "text": "El desarrollo de un sistema b\u00e1sico cliente/servidor con soporte DTLS utilizando\nWolfSSL es muy similar al visto anteriormente para TLS. Como detalle adicional,\nla inicializaci\u00f3n de la infraestructura debe realizarse indicando el soporte\npara DTLS en sus versiones 1.0 o 1.2:    wolfDTLSv1_client_method();    // DTLS 1.0    wolfDTLSv1_2_client_method();  // DTLS 1.2    El resto del c\u00f3digo sigue una filosof\u00eda similar a TLS, adaptado, obviamente,\na las caracter\u00edsticas de UDP (tipo de socket, ausencia de conexi\u00f3n, etc.), por\nlo que se deja como ejercicio su an\u00e1lisis y ejecuci\u00f3n.   Tarea entregable  Analiza, compila y ejecuta los c\u00f3digos correspondientes al sistema cliente/servidor\nDTLS. Realiza capturas de tr\u00e1fico y comp\u00e1ralas, paquete a paquete, con las generadas\npara un patr\u00f3n de tr\u00e1fico similar en el caso de TLS. Incide en sus similitudes\ny diferencias, tanto a nivel de  handshake  como de transferencia de datos. Observa,\nen este \u00faltimo caso, la aparici\u00f3n de nuevos campos de encabezado en los env\u00edos\nde datos DTLS. \u00bfCu\u00e1l/cu\u00e1les son esos campos y por qu\u00e9 aparecen? Realiza una comparativa\ndel tr\u00e1fico total generado en ambos casos para exactamente la misma cantidad de datos \ntransferidos.",
            "title": "Cliente/servidor DTLS. Ejemplo b\u00e1sico en host"
        },
        {
            "location": "/Subjects/NP2/P3/#tls-en-el-esp32-el-componente-esp-tls",
            "text": "ESP-IDF proporciona un componente (ESP-TLS) que ofrece una interfaz (API)\nsimplificada para acceder a funcionalidad b\u00e1sica TLS. A\u00fan as\u00ed, ofrece \nuna funcionalidad suficientemente amplia como para implementar casos de uso\ncomunes en entornos IoT.   La API de ESP-TLS es sencilla,y se basa en el uso de cuatro funciones b\u00e1sicas:",
            "title": "TLS en el ESP32. El componente ESP-TLS"
        },
        {
            "location": "/Subjects/NP2/P3/#establecimiento-de-conexion-tls-esp_tls_conn_new",
            "text": "Prototipo:   esp_tls_t *esp_tls_conn_new(const char *hostname, int hostlen, int port, constesp_tls_cfg_t *cfg)    Descripci\u00f3n: Crea una nueva conexi\u00f3n TLS/SSL bloqueante, estableciendo dicha\n  conexi\u00f3n contra un servidor establecido.     Par\u00e1metros:    hostname : Identificaci\u00f3n del host.  hostlen : Longitud del par\u00e1metro  hostname .  port : Puerto de conexi\u00f3n con el host.  cfg : Configuraci\u00f3n de la conexi\u00f3n TLS.     Valor de retorno: Puntero a  esp_tls_t  (manejador de la conexi\u00f3n).\n                    Devuelve  NULL  si se produce un error en la conexi\u00f3n.",
            "title": "Establecimiento de conexi\u00f3n TLS (esp_tls_conn_new())"
        },
        {
            "location": "/Subjects/NP2/P3/#destruccion-de-conexion-tls-esp_tls_conn_delete",
            "text": "void esp_tls_conn_delete(esp_tls_t *tls)    Descripci\u00f3n: Cierra la conexi\u00f3n TLS/SSL.     Par\u00e1metros:    tls : Manejador de la conexi\u00f3n.",
            "title": "Destrucci\u00f3n de conexi\u00f3n TLS (esp_tls_conn_delete())"
        },
        {
            "location": "/Subjects/NP2/P3/#escritura-de-datos-esp_tls_conn_read",
            "text": "static ssize_t esp_tls_conn_write(esp_tls_t *tls, const void *data, size_t datalen)    Descripci\u00f3n: Escribe en la conexi\u00f3n TLS/SSL indicada el contenido del buffer\n   data .    Par\u00e1metros:    tls : Manejador de la conexi\u00f3n.   data : Buffer de env\u00edo.  datalen : Longitud del buffer de env\u00edo (o n\u00famero m\u00e1ximo \n   de bytes a escribir).     Valor de retorno:    >=0 : \u00e9xito en el env\u00edo. N\u00famero de bytes efectivamente enviados.  <0 : error en el env\u00edo.",
            "title": "Escritura de datos (esp_tls_conn_read())"
        },
        {
            "location": "/Subjects/NP2/P3/#lectura-de-datos-esp_tls_conn_read",
            "text": "static ssize_t esp_tls_conn_read(esp_tls_t *tls, void *data, size_t datalen)    Descripci\u00f3n: Lee desde la conexi\u00f3n TLS/SSL indicada hacia el buffer  data .    Par\u00e1metros:    tls : Manejador de la conexi\u00f3n.   data : Buffer de recepci\u00f3n.  datalen : Longitud del buffer de recepci\u00f3n (o n\u00famero m\u00e1ximo \n   de bytes a leer).     Valor de retorno:    >0 : \u00e9xito en la recepci\u00f3n. N\u00famero de bytes efectivamente le\u00eddos.  =0 : error en la recepci\u00f3n. La conexi\u00f3n se cerr\u00f3.  <0 : error en la recepci\u00f3n.",
            "title": "Lectura de datos (esp_tls_conn_read())"
        },
        {
            "location": "/Subjects/NP2/P3/#estructura-basica-de-un-cliente-tcp-usando-esp-idf",
            "text": "Un cliente TCP implementado sobre ESP-IDF para dar soporte TLS, \nrequiere ciertas modificaciones con respecto a la versi\u00f3n sin TLS. \nDe hecho, el uso de ESP-IDF simplifica el c\u00f3digo del cliente (puedes \ncompararlo con tus clientes TCP desarrollados en sesiones anteriores). La\nestructura b\u00e1sica resultar\u00eda:  /// Includes anteriores.\n#include \"esp_tls.h\"\n\n// Puede tomarse desde menuconfig.\n#define HOST_IP_ADDR DIRECCION_DE_HOST\n#define PORT PUERTO \n\nstatic const char *payload = \"Hola, mundo via TLS\";\n\n// ...\n\nstatic void tls_client_task( void  *pvParameters )\n{\n  // ...\n\n  // Configuraci\u00f3n de ESP-TLS (vac\u00edo para opciones defecto).\n  esp_tls_cfg_t cfg = { };\n\n  // Creaci\u00f3n de conexi\u00f3n.\n  struct esp_tls *tls = esp_tls_conn_new( HOST_IP_ADDR, longitud, PORT, &cfg);\n\n  // Chequeo de errores.\n  // ...\n\n  // Env\u00edo de datos.\n  ret = esp_tls_conn_write(tls, payload, strlen(payload));\n\n  // Chequeo de errores.\n  // ...\n\n  // Lectura de datos\n  ret = esp_tls_conn_read(tls, (char *)rx_buffer, 128);\n\n  // Chequeo de errores.\n  // ...\n\n  // Destrucci\u00f3n de la conexi\u00f3n\n  esp_tls_conn_delete( tls );\n\n  vTaskDelete( NULL );\n}\n\nvoid app_main( void )\n{\n  // ...\n}  Observa como, efectivamente, el c\u00f3digo del cliente se simplifica en gran \nmedida con respecto a tu cliente TCP original.   Toma el c\u00f3digo del proyecto que\nutilizaste para desarrollar tu cliente TCP original y, siguiendo las anteriores\ndirectivas, adapta la \u00fanica tarea a crear (por ejemplo, puede recibir el\nnombre  tls_client_task ) para que realice un env\u00edo y recepci\u00f3n de datos \n(una cadena) al servidor TLS que probaste en el  host . Puedes valerte para ello\nde la base del ejemplo  examples/protocols/https_request , obviamente adaptando\nla totalidad de su c\u00f3digo para que se comporte como un simple cliente  echo .  !!! note Tarea\n    Compila y ejecuta el cliente TLS en el ESP32, y consigue que interact\u00fae con\n    el servidor TLS que probaste anteriormente en el  host . Comprueba que, efectivamente,\n    los datos se transfieren cifrados entre ambos extremos, y que el intercambio de \n    paquetes es similar al que observaste entre cliente y servidor en el  host .   Tarea entregable  Adapta tu sistema cliente/servidor TCP desarrollado en la anterior pr\u00e1ctica\npara que se ejecute sobre el binomio  host /ESP32 utlizando TLS. \nEntrega el c\u00f3digo generado junto con una captura de tr\u00e1fico que demuestre su \ncorrecto funcionamiento.",
            "title": "Estructura b\u00e1sica de un cliente TCP usando ESP-IDF"
        },
        {
            "location": "/Subjects/NP2/P4/",
            "text": "Pr\u00e1ctica 4. Protocolos b\u00e1sicos de capa de aplicaci\u00f3n. Websockets\n\n\nObjetivos\n\n\n\n\nConocer el m\u00f3dulo Python \nwebsockets\n para desarrollar sistemas b\u00e1sicos\n  cliente/servidor utilizando \nwebsockets\n.\n\n\nEstudar el intercambio de mensajes entre un cliente y un servidor \n  \nwebsockets\n, tanto en la fase de \nhandshake\n como de intercambio de datos.\n\n\nConseguir interactuar con un servidor \nwebsockets\n utilizando un navegador\n  web como cliente.\n\n\nEstudiar mecanismos de mantenimiento y publicaci\u00f3n de estado a clientes \n  conectados, t\u00edpicos en un entorno IoT.\n\n\nEstudiar el componente \nwebsockets client\n en ESP-IDF, y desarrollar un \n  \nfirmware\n b\u00e1sico que interact\u00fae con un servidor Python.\n\n\nIntroducir la gesti\u00f3n de objetos JSON en ESP-IDF.\n\n\n\n\nLos ficheros necesarios para completar la pr\u00e1ctica pueden descargarse\n\naqu\u00ed\n.\n\n\nEjemplo b\u00e1sico: sistema cliente/servidor usando Websockets en Python (\u00b4client1.py, server1.py`)\n\n\nEn primer lugar, introducimos el uso del m\u00f3dulo Python\n\nwebsockets\n, que proporciona\ntoda la funcionalidad necesaria para desarrollar sistemas cliente/servidor\nutilizando \nwebsockets\n.\n\n\nEl m\u00f3dulo \nwebsockets\n proporciona la funcionalidad necesaria tanto a nivel de cliente\ncomo de servidor para implementar sistemas basados en dicho protocolo. Concretamente,\nlas funciones de alto nivel que proporciona est\u00e1n basadas en una API de bajo\nnivel que implementa las dos fases principales del protocolo \nwebsockets\n:\n\n\n\n\nHandshake\n de apertura de comunicaci\u00f3n, en forma de peticiones \nHTTP upgrade\n.\n\n\nTransferencia de datos, y finalizaci\u00f3n de la comunicaci\u00f3n con un \nhandshake\n de cierre\nde conexi\u00f3n.\n\n\n\n\nLa primera fase est\u00e1 dise\u00f1ada para integrarse con software HTTP (cliente y servidor)\nexistente, y proporciona una implementaci\u00f3n m\u00ednima para construir, parsear y \nvalidar peticiones y respuestas HTTP.\n\n\nLa segunda fase implementa el n\u00facleo del protocolo \nwebsockets\n, y proporciona\nuna implementaci\u00f3n completa basada en el \nm\u00f3dulo \nasyncio\n) \nde Python. \n\n\nPara utilizar el m\u00f3dulo \nwebsockets\n de Python, primero lo instalaremos v\u00eda\n\npip\n:\n\n\npip install websockets\n\n\n\n\nUn ejemplo b\u00e1sico se puede basar en un cliente que env\u00eda una cadena a un \nservidor, y queda a la espera de recibir un mensaje de respuesta por parte\nde \u00e9ste, tal y como hemos visto en otras pr\u00e1cticas. \n\n\nDesarrollar la parte servidora para dicha aplicaci\u00f3n resulta sencillo. Observa\nel siguiente c\u00f3digo:\n\n\n#!/usr/bin/env python\n\nimport asyncio\nimport websockets\n\nasync def hello(websocket, path):\n    name = await websocket.recv()\n    print(f\"< {name}\")\n\n    greeting = f\"Hello {name}!\"\n\n    await websocket.send(greeting)\n    print(f\"> {greeting}\")\n\nstart_server = websockets.serve(hello, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()\n\n\n\n\nEl paradigma de programaci\u00f3n utilizado en este ejemplo (basado en el \nm\u00f3dulo \nasyncio\n) queda fuera\ndel prop\u00f3sito de la pr\u00e1ctica (aunque se invita al alumno a estudiarlo, ya\nque aporta importantes ventajas a nivel de sencillez de desarrollo en \naplicaciones de red). En cualquier caso, el anterior servidor ejecuta\nuna (co)rutina manejadora \nhello\n para cada conexi\u00f3n \nwebsocket\n establecida; \nadem\u00e1s, se cierra dicha conexi\u00f3n cuando dicha (co)rutina finaliza.\n\n\nConcretamente, las funciones de inter\u00e9s en este caso son:\n\n\nawait websockets.server.serve(ws_handler, host=None, port=None, # ...\n\n\n\n\nCrea, incializa y devuelve un objeto \nservidor Websocket\n asociado al \nhost y puerto seleccionados. En un contexto de programaci\u00f3n as\u00edncrona (como\nel del ejemplo, el servidor finaliza autom\u00e1ticamente al salir de dicho contexto).\n\n\nCuando un cliente conecta al host y puerto espec\u00edficados, se acepta la conexi\u00f3n,\nque es tratada por la (co)rutina \nws_handler\n (en el ejemplo, \nhello\n). Antes\nde delegar la conexi\u00f3n a la (co)rutina, se lleva a cabo el \nhandshake\n de \napertura \nwebsocket\n.\n\n\nawait recv()\n\n\n\n\nRecibe el siguiente mensaje, devolviendo una cadena si el \nframe\n recibido\nes de texto, o un \narray\n de bytes si es binario.\n\n\nawait send(message)\n\n\n\n\nEnv\u00eda un mensaje. \nmessage\n puede er una cadena, o un array de bytes. En \nel primer caso, se env\u00eda un \nframe\n de texto; en el segundo caso, \nun \nframe\n binario.\n\n\nA continuaci\u00f3n se muestra un ejemplo de cliente \nwebsocket\n para interactuar\ncon el anterior servidor:\n\n\n#!/usr/bin/env python\n\nimport asyncio\nimport websockets\n\nasync def hello():\n    uri = \"ws://localhost:8765\"\n    async with websockets.connect(uri) as websocket:\n        name = input(\"What's your name? \")\n\n        await websocket.send(name)\n        print(f\"> {name}\")\n\n        greeting = await websocket.recv()\n        print(f\"< {greeting}\")\n\nasyncio.get_event_loop().run_until_complete(hello())\n\n\n\n\nEl c\u00f3digo en este caso es sencillo, ya que \u00fanicamente se basa en la planificaci\u00f3n\n(ejecuci\u00f3n) de una (co)rutina llamada \nhello\n, que establece una conexi\u00f3n con\nun servidor \nwebsocket\n v\u00eda \nconnect\n, enviando y recibiendo un par de mensajes.\n\n\nawait websockets.client.connect(uri, # ...\n\n\n\n\nConecta con un servidor \nwebsocket\n en la URI determinada. La conexi\u00f3n se cierra\nal abandonar el contexto as\u00edncrono (es decir, la (co)rutina \nhello\n).\n\n\n\n\nTarea entregable\n\n\nEjecuta el servidor en una terminal de tu m\u00e1quina virtual, y a continuaci\u00f3n\nel cliente en otra. Analiza el tr\u00e1fico intercambiado y responde a las siguientes\npreguntas:\n\n\n\n\n\u00bfEn qu\u00e9 protocolo de capa de transporte se basa la comunicaci\u00f3n v\u00eda Websockets?\n\n\nEn la fase de \nhandshake\n, \u00bfqu\u00e9 peticiones HTTP se intercambian? Analiza\nsus emisores y destinatarios, e investiga el cometido principal de cada uno de\nlos campos de sus encabezados (f\u00edjate principalmente en el campo \nUpgrade\n y \nlos campos espec\u00edficos para Websockets).\n\n\nEn la fase de intercambio de datos, \u00bfqu\u00e9 \nopcode\n se especifica en el encabezado\nde cada paquete? \u00bfPor qu\u00e9?\n\n\n\u00bfSe env\u00edan los datos en claro o cifrados?\n\n\n\u00bfQu\u00e9 \nopcode\n se a\u00f1ade en los mensajes de cierre de conexi\u00f3n?\n\n\n\n\n\n\nInteractuando con un navegador web (\nclient_for_web.html\n, \nserver_for_web.py\n)\n\n\nAunque fuera del inter\u00e9s de esta pr\u00e1ctica, es conveniente observar una de las\nventajas de \nwebsockets\n: el env\u00edo as\u00edncrono bidireccional de informaci\u00f3n, y \nobservarlo a trav\u00e9s de un navegador web convencional (la mayor\u00eda de navegadores\nmodernos soportan \nwebsockets\n a trav\u00e9s de \nscripts Javascript\n).\n\n\nEn este caso, simplemente observa la interacci\u00f3n de un servidor \nwebsocket\n \nque env\u00eda mensajes que incluyen la hora actual separados un n\u00famero aleatorio\nde tiempo entre ellos:\n\n\n#!/usr/bin/env python\n\n# WS server that sends messages at random intervals\n\nimport asyncio\nimport datetime\nimport random\nimport websockets\n\nasync def time(websocket, path):\n    while True:\n        now = datetime.datetime.utcnow().isoformat() + \"Z\"\n        await websocket.send(now)\n        await asyncio.sleep(random.random() * 3)\n\nstart_server = websockets.serve(time, \"127.0.0.1\", 5678)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()\n\n\n\n\nCon un cliente (una p\u00e1gina HTML) que establece la conexi\u00f3n v\u00eda \nwebsockets\n,\ny muestra en la misma un elemento de texto con la marca de tiempo recibida \ntras la recepci\u00f3n de cada mensaje:\n\n\n<!DOCTYPE html>\n<html>\n    <head>\n        <title>WebSocket demo</title>\n    </head>\n    <body>\n        <script>\n            var ws = new WebSocket(\"ws://127.0.0.1:5678/\"),\n                messages = document.createElement('ul');\n            ws.onmessage = function (event) {\n                var messages = document.getElementsByTagName('ul')[0],\n                    message = document.createElement('li'),\n                    content = document.createTextNode(event.data);\n                message.appendChild(content);\n                messages.appendChild(message);\n            };\n            document.body.appendChild(messages);\n        </script>\n    </body>\n</html>\n\n\n\n\n\n\nTarea\n\n\nEjecuta el servidor en tu m\u00e1quina virtual y, tras guardar el c\u00f3digo fuente\ndel cliente en un fichero \ncliente.html\n, \u00e1brelo con un navegador. Observa\ncomo la p\u00e1gina se actualiza a medida que recibe mensajes a trav\u00e9s del \nsocket. Si quieres, puedes observar el intercambio de mensajes. \u00bfQu\u00e9 ocurre\nsi, en otra pesta\u00f1a, vuelves a abrir la p\u00e1gina cliente?\n\n\n\n\nUn ejemplo m\u00e1s complejo: sincronizaci\u00f3n entre m\u00faltiples clientes (\nserver2.py\n, \nclient.html\n)\n\n\nUn servidor \nwebsocket\n puede recibir eventos desde distintos clientes, procesarlos\npara, por ejemplo, mantener actualizado un estado a nivel de aplicaci\u00f3n, y \nsincronizar dicho estado entre todos los clientes conectados, envi\u00e1ndoles mensajes\nde forma as\u00edncrona a trav\u00e9s del socket bidireccional, a modo de \"notificaciones\n\npush\n\".\n\n\nA continuaci\u00f3n, se muestra el c\u00f3digo de un servidor que mantiene dos tipos \nde informaci\u00f3n de estado siempre actualizada: el valor de un contador\n(\nSTATE\n), que puede\nser modificado por los clientes conectados sumando o restando uno a su valor\na trav\u00e9s de mensajes enviados por el \nsocket\n; y el n\u00famero de clientes \nconectados (\nUSERS\n).\n\n\n#!/usr/bin/env python\n\nimport asyncio\nimport json\nimport logging\nimport websockets\n\nlogging.basicConfig()\n\nSTATE = {\"value\": 0}\n\nUSERS = set()\n\n\ndef state_event():\n    return json.dumps({\"type\": \"state\", **STATE})\n\n\ndef users_event():\n    return json.dumps({\"type\": \"users\", \"count\": len(USERS)})\n\n\nasync def notify_state():\n    if USERS:  # asyncio.wait doesn't accept an empty list\n        message = state_event()\n        await asyncio.wait([user.send(message) for user in USERS])\n\n\nasync def notify_users():\n    if USERS:  # asyncio.wait doesn't accept an empty list\n        message = users_event()\n        await asyncio.wait([user.send(message) for user in USERS])\n\n\nasync def register(websocket):\n    USERS.add(websocket)\n    await notify_users()\n\n\nasync def unregister(websocket):\n    USERS.remove(websocket)\n    await notify_users()\n\n\nasync def counter(websocket, path):\n    # register(websocket) sends user_event() to websocket\n    await register(websocket)\n    try:\n        await websocket.send(state_event())\n        async for message in websocket:\n            data = json.loads(message)\n            if data[\"action\"] == \"minus\":\n                STATE[\"value\"] -= 1\n                await notify_state()\n            elif data[\"action\"] == \"plus\":\n                STATE[\"value\"] += 1\n                await notify_state()\n            else:\n                logging.error(\"unsupported event: {}\", data)\n    finally:\n        await unregister(websocket)\n\n\nstart_server = websockets.serve(counter, \"localhost\", 6789)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()\n\n\n\n\nObserva el c\u00f3digo del servidor. \n\n\nEl manejador \ncounter\n procesa cada conexi\u00f3n\nentrante, registrando a su entrada a un nuevo cliente en el sistema (\nregister\n)\ny desregistr\u00e1ndolo antes de finalizar (\nunregister\n). Ante cada registro\no desregistro, se notifica a los usuarios este hecho, enviando a cada\ncliente un peque\u00f1o texto en formato JSON cuyo contenido es:\n\n\n{\"type\": \"users\", \"count\": usuarios}\n\n\n\n\nEs decir, un mensaje con dos campos (veremos JSON en la pr\u00f3xima pr\u00e1ctica):\ncampo \ntype\n, con valor fijo \nusers\n, y campo \ncount\n, con un valor entero \nque indica el n\u00famero de clientes conectados.\n\n\nA continuaci\u00f3n, para cada mensaje recibido a trav\u00e9s del socket, \u00e9ste se procesa,\nesperando tambi\u00e9n un fichero JSON con la acci\u00f3n que el cliente solicita (sumar\no restar 1 al contador), por ejemplo:\n\n\n {\"action\": \"minus\"}\n\n\n\n\no\n\n\n {\"action\": \"plus\"}\n\n\n\n\nEn funci\u00f3n de la acci\u00f3n solicitada, el servidor actualiza el valor de \nSTATE\n,\ny env\u00eda (rutina \nnotify_state\n) dicho valor actualizado a TODOS los clientes\nconectados mediante un peque\u00f1o mensaje de texto en formato JSON:\n\n\n{\"type\": \"state\", \"value\": VALOR}\n\n\n\n\nLa parte cliente sigue la misma filosof\u00eda, utilizando de nuevo el navegador\ncomo plataforma para visualizar la interacci\u00f3n con el cliente. El c\u00f3digo HTML\nque puedes abrir en tu navegador es el siguiente:\n\n\n<!DOCTYPE html>\n<html>\n    <head>\n        <title>WebSocket demo</title>\n        <style type=\"text/css\">\n            body {\n                font-family: \"Courier New\", sans-serif;\n                text-align: center;\n            }\n            .buttons {\n                font-size: 4em;\n                display: flex;\n                justify-content: center;\n            }\n            .button, .value {\n                line-height: 1;\n                padding: 2rem;\n                margin: 2rem;\n                border: medium solid;\n                min-height: 1em;\n                min-width: 1em;\n            }\n            .button {\n                cursor: pointer;\n                user-select: none;\n            }\n            .minus {\n                color: red;\n            }\n            .plus {\n                color: green;\n            }\n            .value {\n                min-width: 2em;\n            }\n            .state {\n                font-size: 2em;\n            }\n        </style>\n    </head>\n    <body>\n        <div class=\"buttons\">\n            <div class=\"minus button\">-</div>\n            <div class=\"value\">?</div>\n            <div class=\"plus button\">+</div>\n        </div>\n        <div class=\"state\">\n            <span class=\"users\">?</span> online\n        </div>\n        <script>\n            var minus = document.querySelector('.minus'),\n                plus = document.querySelector('.plus'),\n                value = document.querySelector('.value'),\n                users = document.querySelector('.users'),\n                websocket = new WebSocket(\"ws://127.0.0.1:6789/\");\n            minus.onclick = function (event) {\n                websocket.send(JSON.stringify({action: 'minus'}));\n            }\n            plus.onclick = function (event) {\n                websocket.send(JSON.stringify({action: 'plus'}));\n            }\n            websocket.onmessage = function (event) {\n                data = JSON.parse(event.data);\n                switch (data.type) {\n                    case 'state':\n                        value.textContent = data.value;\n                        break;\n                    case 'users':\n                        users.textContent = (\n                            data.count.toString() + \" user\" +\n                            (data.count == 1 ? \"\" : \"s\"));\n                        break;\n                    default:\n                        console.error(\n                            \"unsupported event\", data);\n                }\n            };\n        </script>\n    </body>\n</html>\n\n\n\n\nObserva c\u00f3mo el \nscript\n env\u00eda mensajes de suma o resta en formato JSON acorde\nal esperado por el servidor, y procesa los mensajes de entrada actualizando\nla informaci\u00f3n mostrada en pantalla recibida acerca del valor del contador\nactualizado y n\u00famero de usuarios.\n\n\n\n\nTarea\n\n\nEjecuta el servidor en tu m\u00e1quina virtual, y m\u00faltiples clientes en distintas\nventanas/pesta\u00f1as del navegador (con ventanas lo ver\u00e1s mejor). Interact\u00faa\ndesde un cliente aumentando o reduciendo el valor del contador, y observa\nc\u00f3mo dicho valor es actualizado (a trav\u00e9s del servidor) en el resto de\nclientes abiertos. Conecta y desconecta nuevos clientes y observa tambi\u00e9n\ncomo el campo correspondiente en la p\u00e1gina web se actualiza correctamente. \nSi quieres, puedes analizar el tr\u00e1fico \nWebsockets\n generado v\u00eda \nWireshark.\n\n\n\n\nWebsockets en el ESP32\n\n\nEl soporte a nivel de cliente para el protocolo \nwebsockets\n est\u00e1 integrado\nen ESP-IDF a trav\u00e9sd el componente \nwebsocket client\n, cuya documentaci\u00f3n\npuede consultarse a trav\u00e9s de este \nenlace\n.\n\n\nEl componente \nwebsocket client\n ofrece soporte para el protocolo \nwebsocket\n\nsobre TCP y tambi\u00e9n, opcionalmente, sobre TLS. Como todos los componentes\nen ESP-IDF, el componente \nwebsocket\n emite eventos que pueden ser tratados\npor parte de la aplicaci\u00f3n, entre los cuales destacan:\n\n\n\n\nWEBSOCKET_EVENT_CONNECTED\n: se emite una vez el cliente se ha conectado\n  al servidor, sin intercambio de datos.\n\n\nWEBSOCKET_EVENT_DISCONNECTED\n: se emite en el instante de la desconexi\u00f3n\n  entre cliente y servidor.\n\n\nWEBSOCKET_EVENT_DATA\n: se emite al recibir datos desde el servidor.\n\n\n\n\nEste \u00faltimo evento es de especial inter\u00e9s para nosotros, ya que accarrea la\nconstrucci\u00f3n de una estructura de tipo \nesp_websocket_event_data_t\n en la que\nse almacena el mensaje recibido desde el servidor (tanto en sus campos de\ncontrol como de datos). Algunos campos de inter\u00e9s dentro de la estructura son:\n\n\n\n\nconst char * data_ptr\n: puntero a los datos recibidos (\npayload\n).\n\n\ndata_len\n: tama\u00f1o (en bytes) de los datos recibidos.\n\n\nop_code\n: c\u00f3digo de operaci\u00f3n asociado al mensaje recibido.\n\n\n\n\nLa documentaci\u00f3n del componente ofrece informaci\u00f3n sobre campos adicionales,\nde menor inter\u00e9s para nosotros.\n\n\nObservemos el c\u00f3digo de una posible funci\u00f3n manejadora de eventos del componente\n\nwebsocket\n:\n\n\nstatic void websocket_event_handler(void *handler_args, esp_event_base_t base, int32_t event_id, void *event_data)\n{\n    esp_websocket_event_data_t *data = (esp_websocket_event_data_t *)event_data;\n    switch (event_id) {\n    case WEBSOCKET_EVENT_CONNECTED:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_CONNECTED\");\n        break;\n    case WEBSOCKET_EVENT_DISCONNECTED:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_DISCONNECTED\");\n        break;\n    case WEBSOCKET_EVENT_DATA:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_DATA\");\n        ESP_LOGI(TAG, \"Received opcode=%d\", data->op_code);\n        if (data->op_code == 0x08 && data->data_len == 2) {\n            ESP_LOGW(TAG, \"Received closed message with code=%d\", 256*data->data_ptr[0] + data->data_ptr[1]);\n        } else {\n            ESP_LOGW(TAG, \"Received=%.*s\", data->data_len, (char *)data->data_ptr);\n        }\n        ESP_LOGW(TAG, \"Total payload length=%d, data_len=%d, current payload offset=%d\\r\\n\", data->payload_len, data->data_len, data->payload_offset);\n\n        xTimerReset(shutdown_signal_timer, portMAX_DELAY);\n        break;\n    case WEBSOCKET_EVENT_ERROR:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_ERROR\");\n        break;\n    }\n}\n\n\n\n\nObserva el c\u00f3digo. En funci\u00f3n del par\u00e1metro \nevent_id\n, el manejador toma\nun camino de ejecuci\u00f3n u otro. Centr\u00e9monos en la recepci\u00f3n de un evento de\ntipo \n\u1e80EBSOCKET_EVENT_DATA\n; a trav\u00e9s de los distintos campos de la estructura\nde informaci\u00f3n recibida (\nevent_data\n), es posible:\n\n\n\n\nObtener y mostrar el c\u00f3digo de la operaci\u00f3n (\nop_code\n).\n\n\nMostrar el contenido del mensaje recibido   (\ndata_ptr\n).\n\n\nMostrar el tama\u00f1o del mensaje recibido (\ndata_len\n y \npayload_len\n).\n\n\n\n\n\n\nPreguntas\n\n\n\n\n\u00bfCu\u00e1l es la diferencia entre los campos \ndata_len\n y \npayload_len\n?\n\n\n\u00bfPor qu\u00e9 el programa realiza un tratamiento especial cuando \n\nop_code == 8\n?\n\n\n\n\n\n\nDada la anterior funci\u00f3n manejadora, la inicializaci\u00f3n de un cliente\n\nwebsockets\n en el ESP32 es sencilla, y se resume en los siguientes pasos:\n\n\n\n\nConfiguraci\u00f3n de URI (host + puerto)\n\n\n\n\nesp_websocket_client_config_t websocket_cfg = {};\nwebsocket_cfg.uri = \"ws://localhost:123\";\nesp_websocket_client_handle_t client = esp_websocket_client_init(&websocket_cfg);\n\n\n\n\n\n\nAsociaci\u00f3n de manejador a eventos *Websocket\n*\n\n\n\n\nesp_websocket_register_events(client, WEBSOCKET_EVENT_ANY, websocket_event_handler, (void *)client);\n\n\n\n\n\n\nInicializaci\u00f3n del cliente\n\n\n\n\nesp_websocket_client_start(client);\n\n\n\n\nA partir de este punto, la interacci\u00f3n con el servidor se puede realizar en \nbase a funciones de env\u00edo de texto o binario:\n\n\nint esp_websocket_client_send(esp_websocket_client_handle_tclient, const char *data, int len, TickType_t timeout)\n\nesp_websocket_client_send_bin(esp_websocket_client_handle_tclient, const char *data, int len, TickType_t timeout)\n\n\n\n\nNo existen funciones de recepci\u00f3n, ya que \u00e9sta es impl\u00edcita y se notifica v\u00eda\neventos.\n\n\nEjemplo b\u00e1sico: cliente \necho\n\n\nVeremos en primer lugar un ejemplo completo de cliente ejecutado sobre\nel ESP32. En este punto, configura, compila, flashea y monitoriza el ejemplo\n\nexamples/protocols/websockets\n.\n\n\nEl ejemplo simplemente conecta con un servidor \necho\n \nWebsockets\n en la nube\n(disponible en \nws://websockets.org\n). Dicho servidor simplemente espera, por\nparte de cada cliente, el env\u00edo a trav\u00e9s de la conexi\u00f3n de una cadena, \nrespondiendo con la misma cadena en sentido contrario, siempre usando el \nmismo \nsocket\n.\n\n\n\n\nTarea\n\n\nObserva el c\u00f3digo del ejemplo y su ejecuci\u00f3n. Determina cu\u00e1l es el\nfuncionamiento del ejemplo, y comprueba que los fragmentos de c\u00f3digo \nanteriores tienen su funci\u00f3n dentro del c\u00f3digo completo. \u00bfC\u00f3mo implementa\nel programa la espera limitada en tiempo si no se recibe ning\u00fan paquete\ntras cierto per\u00edodo?\n\n\n\n\nEjercicio entregable: Comunicaci\u00f3n as\u00edncrona\n\n\nEl objetivo del ejercicio entregable es conseguir que el ESP32 se comunique con\nel servidor Python que se prob\u00f3 en la secci\u00f3n anterior, y que implementaba \ncomunicaci\u00f3n bidireccional para mantener y difundir el estado interno (contador\ny n\u00famero de clientes conectados) entre todos los clientes conectados.\n\n\nPara ello, se pide modificar el ejemplo de cliente \necho\n para que:\n\n\n\n\nEl cliente conecte con el servidor Python especificando su IP y puerto.\n\n\nEl cliente sea cien por cien pasivo, es decir, no env\u00ede nunca mensajes \nal servidor.\n\n\nLa funci\u00f3n de manejo de paquetes recibidos trate de forma especial el tipo de\nmensajes esperado por parte del servidor. Recuerda que se pueden recibir dos\ntipos de mensajes de texto:\n\n\nMensajes de estado:\n\n\n\n\n{\"type\": \"users\", \"count\": usuarios}\n\n\n\n\n\n\nMensajes de usuarios:\n\n\n\n\n{\"type\": \"state\", \"value\": VALOR}\n\n\n\n\nObserva que ambos mensajes, pese a ser recibidos como texto, corresponden con\nuna representaci\u00f3n JSON de la informaci\u00f3n. Para tratarla desde ESP-IDF, \npuedes hacer uso del componente cJSON del \nframework\n. Por ejemplo, para \ntratar un mensaje de entrada de tipo \"state\", podr\u00edamos a\u00f1adir la siguiente\nsecuencia de c\u00f3digo en nuestro manejador:\n\n\n#include \"cJSON.h\"\n\n// ...\n\nif( data->op_code == 1 ) { // Text frame only.\n  cJSON *root = cJSON_Parse((char*)data->data_ptr);\n  char *type = cJSON_GetObjectItem(root,\"type\")->valuestring;\n  ESP_LOGI(TAG, \"type=%s\",type);\n\n  int field = 0;\n\n  if( strcmp( type, \"state\" ) == 0) {\n    field = cJSON_GetObjectItem(root,\"value\")->valueint;\n    ESP_LOGI(TAG, \"value=%d\",field);\n  }\n}\n\n\n\n\n\n\nTarea entregable\n\n\nModifica el \nfirmware\n de ejemplo \nwebsockets\n para que pueda comunicarse\nen modo lectura con el servidor Python que mantiene y publicita estado, cuyo\nc\u00f3digo se te proporciona. El programa ESP-IDF, al menos, mostar\u00e1 por pantalla\nun mensaje con los datos asociados cada vez que se reciban paquetes de tipo\ntexto (\nstate\n o \nusers\n). Tambi\u00e9n mostrar\u00e1 un mensaje cada vez que el \nservidor env\u00ede un mensaje de tipo \nping\n o \npong\n (para ello, consulta\nel RFC que describe el protocolo para determinar el \nopcode\n asociado).\n\n\nPara comprobar el funcionamiento de la soluci\u00f3n, arranca el servidor y al\nmenos dos clientes web. Cuando arranques el ESP32, ambos deber\u00e1n incrementar\nel n\u00famero de clientes reportado, en respuesta al mensaje enviado por el \nservidor. Cuando cualquiera de los clientes web incremente el valor del \ncontador, el ESP32 recibir\u00e1 un mensaje con el valor actualizado, del mismo\nmodo que cuando cierres uno de los navegadores web.\n\n\n\n\n\n\nTarea opcional\n\n\nModifica el c\u00f3digo para que el cliente, peri\u00f3dicamente, env\u00ede un mensaje\nde petici\u00f3n de suma o resta siguiendo las especificaciones y tipos de\nmensaje que se explicaron anteriormente.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P4/#practica-4-protocolos-basicos-de-capa-de-aplicacion-websockets",
            "text": "",
            "title": "Pr\u00e1ctica 4. Protocolos b\u00e1sicos de capa de aplicaci\u00f3n. Websockets"
        },
        {
            "location": "/Subjects/NP2/P4/#objetivos",
            "text": "Conocer el m\u00f3dulo Python  websockets  para desarrollar sistemas b\u00e1sicos\n  cliente/servidor utilizando  websockets .  Estudar el intercambio de mensajes entre un cliente y un servidor \n   websockets , tanto en la fase de  handshake  como de intercambio de datos.  Conseguir interactuar con un servidor  websockets  utilizando un navegador\n  web como cliente.  Estudiar mecanismos de mantenimiento y publicaci\u00f3n de estado a clientes \n  conectados, t\u00edpicos en un entorno IoT.  Estudiar el componente  websockets client  en ESP-IDF, y desarrollar un \n   firmware  b\u00e1sico que interact\u00fae con un servidor Python.  Introducir la gesti\u00f3n de objetos JSON en ESP-IDF.   Los ficheros necesarios para completar la pr\u00e1ctica pueden descargarse aqu\u00ed .",
            "title": "Objetivos"
        },
        {
            "location": "/Subjects/NP2/P4/#ejemplo-basico-sistema-clienteservidor-usando-websockets-en-python-client1py-server1py",
            "text": "En primer lugar, introducimos el uso del m\u00f3dulo Python websockets , que proporciona\ntoda la funcionalidad necesaria para desarrollar sistemas cliente/servidor\nutilizando  websockets .  El m\u00f3dulo  websockets  proporciona la funcionalidad necesaria tanto a nivel de cliente\ncomo de servidor para implementar sistemas basados en dicho protocolo. Concretamente,\nlas funciones de alto nivel que proporciona est\u00e1n basadas en una API de bajo\nnivel que implementa las dos fases principales del protocolo  websockets :   Handshake  de apertura de comunicaci\u00f3n, en forma de peticiones  HTTP upgrade .  Transferencia de datos, y finalizaci\u00f3n de la comunicaci\u00f3n con un  handshake  de cierre\nde conexi\u00f3n.   La primera fase est\u00e1 dise\u00f1ada para integrarse con software HTTP (cliente y servidor)\nexistente, y proporciona una implementaci\u00f3n m\u00ednima para construir, parsear y \nvalidar peticiones y respuestas HTTP.  La segunda fase implementa el n\u00facleo del protocolo  websockets , y proporciona\nuna implementaci\u00f3n completa basada en el \nm\u00f3dulo  asyncio ) \nde Python.   Para utilizar el m\u00f3dulo  websockets  de Python, primero lo instalaremos v\u00eda pip :  pip install websockets  Un ejemplo b\u00e1sico se puede basar en un cliente que env\u00eda una cadena a un \nservidor, y queda a la espera de recibir un mensaje de respuesta por parte\nde \u00e9ste, tal y como hemos visto en otras pr\u00e1cticas.   Desarrollar la parte servidora para dicha aplicaci\u00f3n resulta sencillo. Observa\nel siguiente c\u00f3digo:  #!/usr/bin/env python\n\nimport asyncio\nimport websockets\n\nasync def hello(websocket, path):\n    name = await websocket.recv()\n    print(f\"< {name}\")\n\n    greeting = f\"Hello {name}!\"\n\n    await websocket.send(greeting)\n    print(f\"> {greeting}\")\n\nstart_server = websockets.serve(hello, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()  El paradigma de programaci\u00f3n utilizado en este ejemplo (basado en el \nm\u00f3dulo  asyncio ) queda fuera\ndel prop\u00f3sito de la pr\u00e1ctica (aunque se invita al alumno a estudiarlo, ya\nque aporta importantes ventajas a nivel de sencillez de desarrollo en \naplicaciones de red). En cualquier caso, el anterior servidor ejecuta\nuna (co)rutina manejadora  hello  para cada conexi\u00f3n  websocket  establecida; \nadem\u00e1s, se cierra dicha conexi\u00f3n cuando dicha (co)rutina finaliza.  Concretamente, las funciones de inter\u00e9s en este caso son:  await websockets.server.serve(ws_handler, host=None, port=None, # ...  Crea, incializa y devuelve un objeto  servidor Websocket  asociado al \nhost y puerto seleccionados. En un contexto de programaci\u00f3n as\u00edncrona (como\nel del ejemplo, el servidor finaliza autom\u00e1ticamente al salir de dicho contexto).  Cuando un cliente conecta al host y puerto espec\u00edficados, se acepta la conexi\u00f3n,\nque es tratada por la (co)rutina  ws_handler  (en el ejemplo,  hello ). Antes\nde delegar la conexi\u00f3n a la (co)rutina, se lleva a cabo el  handshake  de \napertura  websocket .  await recv()  Recibe el siguiente mensaje, devolviendo una cadena si el  frame  recibido\nes de texto, o un  array  de bytes si es binario.  await send(message)  Env\u00eda un mensaje.  message  puede er una cadena, o un array de bytes. En \nel primer caso, se env\u00eda un  frame  de texto; en el segundo caso, \nun  frame  binario.  A continuaci\u00f3n se muestra un ejemplo de cliente  websocket  para interactuar\ncon el anterior servidor:  #!/usr/bin/env python\n\nimport asyncio\nimport websockets\n\nasync def hello():\n    uri = \"ws://localhost:8765\"\n    async with websockets.connect(uri) as websocket:\n        name = input(\"What's your name? \")\n\n        await websocket.send(name)\n        print(f\"> {name}\")\n\n        greeting = await websocket.recv()\n        print(f\"< {greeting}\")\n\nasyncio.get_event_loop().run_until_complete(hello())  El c\u00f3digo en este caso es sencillo, ya que \u00fanicamente se basa en la planificaci\u00f3n\n(ejecuci\u00f3n) de una (co)rutina llamada  hello , que establece una conexi\u00f3n con\nun servidor  websocket  v\u00eda  connect , enviando y recibiendo un par de mensajes.  await websockets.client.connect(uri, # ...  Conecta con un servidor  websocket  en la URI determinada. La conexi\u00f3n se cierra\nal abandonar el contexto as\u00edncrono (es decir, la (co)rutina  hello ).   Tarea entregable  Ejecuta el servidor en una terminal de tu m\u00e1quina virtual, y a continuaci\u00f3n\nel cliente en otra. Analiza el tr\u00e1fico intercambiado y responde a las siguientes\npreguntas:   \u00bfEn qu\u00e9 protocolo de capa de transporte se basa la comunicaci\u00f3n v\u00eda Websockets?  En la fase de  handshake , \u00bfqu\u00e9 peticiones HTTP se intercambian? Analiza\nsus emisores y destinatarios, e investiga el cometido principal de cada uno de\nlos campos de sus encabezados (f\u00edjate principalmente en el campo  Upgrade  y \nlos campos espec\u00edficos para Websockets).  En la fase de intercambio de datos, \u00bfqu\u00e9  opcode  se especifica en el encabezado\nde cada paquete? \u00bfPor qu\u00e9?  \u00bfSe env\u00edan los datos en claro o cifrados?  \u00bfQu\u00e9  opcode  se a\u00f1ade en los mensajes de cierre de conexi\u00f3n?",
            "title": "Ejemplo b\u00e1sico: sistema cliente/servidor usando Websockets en Python (\u00b4client1.py, server1.py`)"
        },
        {
            "location": "/Subjects/NP2/P4/#interactuando-con-un-navegador-web-client_for_webhtml-server_for_webpy",
            "text": "Aunque fuera del inter\u00e9s de esta pr\u00e1ctica, es conveniente observar una de las\nventajas de  websockets : el env\u00edo as\u00edncrono bidireccional de informaci\u00f3n, y \nobservarlo a trav\u00e9s de un navegador web convencional (la mayor\u00eda de navegadores\nmodernos soportan  websockets  a trav\u00e9s de  scripts Javascript ).  En este caso, simplemente observa la interacci\u00f3n de un servidor  websocket  \nque env\u00eda mensajes que incluyen la hora actual separados un n\u00famero aleatorio\nde tiempo entre ellos:  #!/usr/bin/env python\n\n# WS server that sends messages at random intervals\n\nimport asyncio\nimport datetime\nimport random\nimport websockets\n\nasync def time(websocket, path):\n    while True:\n        now = datetime.datetime.utcnow().isoformat() + \"Z\"\n        await websocket.send(now)\n        await asyncio.sleep(random.random() * 3)\n\nstart_server = websockets.serve(time, \"127.0.0.1\", 5678)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()  Con un cliente (una p\u00e1gina HTML) que establece la conexi\u00f3n v\u00eda  websockets ,\ny muestra en la misma un elemento de texto con la marca de tiempo recibida \ntras la recepci\u00f3n de cada mensaje:  <!DOCTYPE html>\n<html>\n    <head>\n        <title>WebSocket demo</title>\n    </head>\n    <body>\n        <script>\n            var ws = new WebSocket(\"ws://127.0.0.1:5678/\"),\n                messages = document.createElement('ul');\n            ws.onmessage = function (event) {\n                var messages = document.getElementsByTagName('ul')[0],\n                    message = document.createElement('li'),\n                    content = document.createTextNode(event.data);\n                message.appendChild(content);\n                messages.appendChild(message);\n            };\n            document.body.appendChild(messages);\n        </script>\n    </body>\n</html>   Tarea  Ejecuta el servidor en tu m\u00e1quina virtual y, tras guardar el c\u00f3digo fuente\ndel cliente en un fichero  cliente.html , \u00e1brelo con un navegador. Observa\ncomo la p\u00e1gina se actualiza a medida que recibe mensajes a trav\u00e9s del \nsocket. Si quieres, puedes observar el intercambio de mensajes. \u00bfQu\u00e9 ocurre\nsi, en otra pesta\u00f1a, vuelves a abrir la p\u00e1gina cliente?",
            "title": "Interactuando con un navegador web (client_for_web.html, server_for_web.py)"
        },
        {
            "location": "/Subjects/NP2/P4/#un-ejemplo-mas-complejo-sincronizacion-entre-multiples-clientes-server2py-clienthtml",
            "text": "Un servidor  websocket  puede recibir eventos desde distintos clientes, procesarlos\npara, por ejemplo, mantener actualizado un estado a nivel de aplicaci\u00f3n, y \nsincronizar dicho estado entre todos los clientes conectados, envi\u00e1ndoles mensajes\nde forma as\u00edncrona a trav\u00e9s del socket bidireccional, a modo de \"notificaciones push \".  A continuaci\u00f3n, se muestra el c\u00f3digo de un servidor que mantiene dos tipos \nde informaci\u00f3n de estado siempre actualizada: el valor de un contador\n( STATE ), que puede\nser modificado por los clientes conectados sumando o restando uno a su valor\na trav\u00e9s de mensajes enviados por el  socket ; y el n\u00famero de clientes \nconectados ( USERS ).  #!/usr/bin/env python\n\nimport asyncio\nimport json\nimport logging\nimport websockets\n\nlogging.basicConfig()\n\nSTATE = {\"value\": 0}\n\nUSERS = set()\n\n\ndef state_event():\n    return json.dumps({\"type\": \"state\", **STATE})\n\n\ndef users_event():\n    return json.dumps({\"type\": \"users\", \"count\": len(USERS)})\n\n\nasync def notify_state():\n    if USERS:  # asyncio.wait doesn't accept an empty list\n        message = state_event()\n        await asyncio.wait([user.send(message) for user in USERS])\n\n\nasync def notify_users():\n    if USERS:  # asyncio.wait doesn't accept an empty list\n        message = users_event()\n        await asyncio.wait([user.send(message) for user in USERS])\n\n\nasync def register(websocket):\n    USERS.add(websocket)\n    await notify_users()\n\n\nasync def unregister(websocket):\n    USERS.remove(websocket)\n    await notify_users()\n\n\nasync def counter(websocket, path):\n    # register(websocket) sends user_event() to websocket\n    await register(websocket)\n    try:\n        await websocket.send(state_event())\n        async for message in websocket:\n            data = json.loads(message)\n            if data[\"action\"] == \"minus\":\n                STATE[\"value\"] -= 1\n                await notify_state()\n            elif data[\"action\"] == \"plus\":\n                STATE[\"value\"] += 1\n                await notify_state()\n            else:\n                logging.error(\"unsupported event: {}\", data)\n    finally:\n        await unregister(websocket)\n\n\nstart_server = websockets.serve(counter, \"localhost\", 6789)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()  Observa el c\u00f3digo del servidor.   El manejador  counter  procesa cada conexi\u00f3n\nentrante, registrando a su entrada a un nuevo cliente en el sistema ( register )\ny desregistr\u00e1ndolo antes de finalizar ( unregister ). Ante cada registro\no desregistro, se notifica a los usuarios este hecho, enviando a cada\ncliente un peque\u00f1o texto en formato JSON cuyo contenido es:  {\"type\": \"users\", \"count\": usuarios}  Es decir, un mensaje con dos campos (veremos JSON en la pr\u00f3xima pr\u00e1ctica):\ncampo  type , con valor fijo  users , y campo  count , con un valor entero \nque indica el n\u00famero de clientes conectados.  A continuaci\u00f3n, para cada mensaje recibido a trav\u00e9s del socket, \u00e9ste se procesa,\nesperando tambi\u00e9n un fichero JSON con la acci\u00f3n que el cliente solicita (sumar\no restar 1 al contador), por ejemplo:   {\"action\": \"minus\"}  o   {\"action\": \"plus\"}  En funci\u00f3n de la acci\u00f3n solicitada, el servidor actualiza el valor de  STATE ,\ny env\u00eda (rutina  notify_state ) dicho valor actualizado a TODOS los clientes\nconectados mediante un peque\u00f1o mensaje de texto en formato JSON:  {\"type\": \"state\", \"value\": VALOR}  La parte cliente sigue la misma filosof\u00eda, utilizando de nuevo el navegador\ncomo plataforma para visualizar la interacci\u00f3n con el cliente. El c\u00f3digo HTML\nque puedes abrir en tu navegador es el siguiente:  <!DOCTYPE html>\n<html>\n    <head>\n        <title>WebSocket demo</title>\n        <style type=\"text/css\">\n            body {\n                font-family: \"Courier New\", sans-serif;\n                text-align: center;\n            }\n            .buttons {\n                font-size: 4em;\n                display: flex;\n                justify-content: center;\n            }\n            .button, .value {\n                line-height: 1;\n                padding: 2rem;\n                margin: 2rem;\n                border: medium solid;\n                min-height: 1em;\n                min-width: 1em;\n            }\n            .button {\n                cursor: pointer;\n                user-select: none;\n            }\n            .minus {\n                color: red;\n            }\n            .plus {\n                color: green;\n            }\n            .value {\n                min-width: 2em;\n            }\n            .state {\n                font-size: 2em;\n            }\n        </style>\n    </head>\n    <body>\n        <div class=\"buttons\">\n            <div class=\"minus button\">-</div>\n            <div class=\"value\">?</div>\n            <div class=\"plus button\">+</div>\n        </div>\n        <div class=\"state\">\n            <span class=\"users\">?</span> online\n        </div>\n        <script>\n            var minus = document.querySelector('.minus'),\n                plus = document.querySelector('.plus'),\n                value = document.querySelector('.value'),\n                users = document.querySelector('.users'),\n                websocket = new WebSocket(\"ws://127.0.0.1:6789/\");\n            minus.onclick = function (event) {\n                websocket.send(JSON.stringify({action: 'minus'}));\n            }\n            plus.onclick = function (event) {\n                websocket.send(JSON.stringify({action: 'plus'}));\n            }\n            websocket.onmessage = function (event) {\n                data = JSON.parse(event.data);\n                switch (data.type) {\n                    case 'state':\n                        value.textContent = data.value;\n                        break;\n                    case 'users':\n                        users.textContent = (\n                            data.count.toString() + \" user\" +\n                            (data.count == 1 ? \"\" : \"s\"));\n                        break;\n                    default:\n                        console.error(\n                            \"unsupported event\", data);\n                }\n            };\n        </script>\n    </body>\n</html>  Observa c\u00f3mo el  script  env\u00eda mensajes de suma o resta en formato JSON acorde\nal esperado por el servidor, y procesa los mensajes de entrada actualizando\nla informaci\u00f3n mostrada en pantalla recibida acerca del valor del contador\nactualizado y n\u00famero de usuarios.   Tarea  Ejecuta el servidor en tu m\u00e1quina virtual, y m\u00faltiples clientes en distintas\nventanas/pesta\u00f1as del navegador (con ventanas lo ver\u00e1s mejor). Interact\u00faa\ndesde un cliente aumentando o reduciendo el valor del contador, y observa\nc\u00f3mo dicho valor es actualizado (a trav\u00e9s del servidor) en el resto de\nclientes abiertos. Conecta y desconecta nuevos clientes y observa tambi\u00e9n\ncomo el campo correspondiente en la p\u00e1gina web se actualiza correctamente. \nSi quieres, puedes analizar el tr\u00e1fico  Websockets  generado v\u00eda \nWireshark.",
            "title": "Un ejemplo m\u00e1s complejo: sincronizaci\u00f3n entre m\u00faltiples clientes (server2.py, client.html)"
        },
        {
            "location": "/Subjects/NP2/P4/#websockets-en-el-esp32",
            "text": "El soporte a nivel de cliente para el protocolo  websockets  est\u00e1 integrado\nen ESP-IDF a trav\u00e9sd el componente  websocket client , cuya documentaci\u00f3n\npuede consultarse a trav\u00e9s de este  enlace .  El componente  websocket client  ofrece soporte para el protocolo  websocket \nsobre TCP y tambi\u00e9n, opcionalmente, sobre TLS. Como todos los componentes\nen ESP-IDF, el componente  websocket  emite eventos que pueden ser tratados\npor parte de la aplicaci\u00f3n, entre los cuales destacan:   WEBSOCKET_EVENT_CONNECTED : se emite una vez el cliente se ha conectado\n  al servidor, sin intercambio de datos.  WEBSOCKET_EVENT_DISCONNECTED : se emite en el instante de la desconexi\u00f3n\n  entre cliente y servidor.  WEBSOCKET_EVENT_DATA : se emite al recibir datos desde el servidor.   Este \u00faltimo evento es de especial inter\u00e9s para nosotros, ya que accarrea la\nconstrucci\u00f3n de una estructura de tipo  esp_websocket_event_data_t  en la que\nse almacena el mensaje recibido desde el servidor (tanto en sus campos de\ncontrol como de datos). Algunos campos de inter\u00e9s dentro de la estructura son:   const char * data_ptr : puntero a los datos recibidos ( payload ).  data_len : tama\u00f1o (en bytes) de los datos recibidos.  op_code : c\u00f3digo de operaci\u00f3n asociado al mensaje recibido.   La documentaci\u00f3n del componente ofrece informaci\u00f3n sobre campos adicionales,\nde menor inter\u00e9s para nosotros.  Observemos el c\u00f3digo de una posible funci\u00f3n manejadora de eventos del componente websocket :  static void websocket_event_handler(void *handler_args, esp_event_base_t base, int32_t event_id, void *event_data)\n{\n    esp_websocket_event_data_t *data = (esp_websocket_event_data_t *)event_data;\n    switch (event_id) {\n    case WEBSOCKET_EVENT_CONNECTED:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_CONNECTED\");\n        break;\n    case WEBSOCKET_EVENT_DISCONNECTED:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_DISCONNECTED\");\n        break;\n    case WEBSOCKET_EVENT_DATA:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_DATA\");\n        ESP_LOGI(TAG, \"Received opcode=%d\", data->op_code);\n        if (data->op_code == 0x08 && data->data_len == 2) {\n            ESP_LOGW(TAG, \"Received closed message with code=%d\", 256*data->data_ptr[0] + data->data_ptr[1]);\n        } else {\n            ESP_LOGW(TAG, \"Received=%.*s\", data->data_len, (char *)data->data_ptr);\n        }\n        ESP_LOGW(TAG, \"Total payload length=%d, data_len=%d, current payload offset=%d\\r\\n\", data->payload_len, data->data_len, data->payload_offset);\n\n        xTimerReset(shutdown_signal_timer, portMAX_DELAY);\n        break;\n    case WEBSOCKET_EVENT_ERROR:\n        ESP_LOGI(TAG, \"WEBSOCKET_EVENT_ERROR\");\n        break;\n    }\n}  Observa el c\u00f3digo. En funci\u00f3n del par\u00e1metro  event_id , el manejador toma\nun camino de ejecuci\u00f3n u otro. Centr\u00e9monos en la recepci\u00f3n de un evento de\ntipo  \u1e80EBSOCKET_EVENT_DATA ; a trav\u00e9s de los distintos campos de la estructura\nde informaci\u00f3n recibida ( event_data ), es posible:   Obtener y mostrar el c\u00f3digo de la operaci\u00f3n ( op_code ).  Mostrar el contenido del mensaje recibido   ( data_ptr ).  Mostrar el tama\u00f1o del mensaje recibido ( data_len  y  payload_len ).    Preguntas   \u00bfCu\u00e1l es la diferencia entre los campos  data_len  y  payload_len ?  \u00bfPor qu\u00e9 el programa realiza un tratamiento especial cuando  op_code == 8 ?    Dada la anterior funci\u00f3n manejadora, la inicializaci\u00f3n de un cliente websockets  en el ESP32 es sencilla, y se resume en los siguientes pasos:   Configuraci\u00f3n de URI (host + puerto)   esp_websocket_client_config_t websocket_cfg = {};\nwebsocket_cfg.uri = \"ws://localhost:123\";\nesp_websocket_client_handle_t client = esp_websocket_client_init(&websocket_cfg);   Asociaci\u00f3n de manejador a eventos *Websocket *   esp_websocket_register_events(client, WEBSOCKET_EVENT_ANY, websocket_event_handler, (void *)client);   Inicializaci\u00f3n del cliente   esp_websocket_client_start(client);  A partir de este punto, la interacci\u00f3n con el servidor se puede realizar en \nbase a funciones de env\u00edo de texto o binario:  int esp_websocket_client_send(esp_websocket_client_handle_tclient, const char *data, int len, TickType_t timeout)\n\nesp_websocket_client_send_bin(esp_websocket_client_handle_tclient, const char *data, int len, TickType_t timeout)  No existen funciones de recepci\u00f3n, ya que \u00e9sta es impl\u00edcita y se notifica v\u00eda\neventos.",
            "title": "Websockets en el ESP32"
        },
        {
            "location": "/Subjects/NP2/P4/#ejemplo-basico-cliente-echo",
            "text": "Veremos en primer lugar un ejemplo completo de cliente ejecutado sobre\nel ESP32. En este punto, configura, compila, flashea y monitoriza el ejemplo examples/protocols/websockets .  El ejemplo simplemente conecta con un servidor  echo   Websockets  en la nube\n(disponible en  ws://websockets.org ). Dicho servidor simplemente espera, por\nparte de cada cliente, el env\u00edo a trav\u00e9s de la conexi\u00f3n de una cadena, \nrespondiendo con la misma cadena en sentido contrario, siempre usando el \nmismo  socket .   Tarea  Observa el c\u00f3digo del ejemplo y su ejecuci\u00f3n. Determina cu\u00e1l es el\nfuncionamiento del ejemplo, y comprueba que los fragmentos de c\u00f3digo \nanteriores tienen su funci\u00f3n dentro del c\u00f3digo completo. \u00bfC\u00f3mo implementa\nel programa la espera limitada en tiempo si no se recibe ning\u00fan paquete\ntras cierto per\u00edodo?",
            "title": "Ejemplo b\u00e1sico: cliente echo"
        },
        {
            "location": "/Subjects/NP2/P4/#ejercicio-entregable-comunicacion-asincrona",
            "text": "El objetivo del ejercicio entregable es conseguir que el ESP32 se comunique con\nel servidor Python que se prob\u00f3 en la secci\u00f3n anterior, y que implementaba \ncomunicaci\u00f3n bidireccional para mantener y difundir el estado interno (contador\ny n\u00famero de clientes conectados) entre todos los clientes conectados.  Para ello, se pide modificar el ejemplo de cliente  echo  para que:   El cliente conecte con el servidor Python especificando su IP y puerto.  El cliente sea cien por cien pasivo, es decir, no env\u00ede nunca mensajes \nal servidor.  La funci\u00f3n de manejo de paquetes recibidos trate de forma especial el tipo de\nmensajes esperado por parte del servidor. Recuerda que se pueden recibir dos\ntipos de mensajes de texto:  Mensajes de estado:   {\"type\": \"users\", \"count\": usuarios}   Mensajes de usuarios:   {\"type\": \"state\", \"value\": VALOR}  Observa que ambos mensajes, pese a ser recibidos como texto, corresponden con\nuna representaci\u00f3n JSON de la informaci\u00f3n. Para tratarla desde ESP-IDF, \npuedes hacer uso del componente cJSON del  framework . Por ejemplo, para \ntratar un mensaje de entrada de tipo \"state\", podr\u00edamos a\u00f1adir la siguiente\nsecuencia de c\u00f3digo en nuestro manejador:  #include \"cJSON.h\"\n\n// ...\n\nif( data->op_code == 1 ) { // Text frame only.\n  cJSON *root = cJSON_Parse((char*)data->data_ptr);\n  char *type = cJSON_GetObjectItem(root,\"type\")->valuestring;\n  ESP_LOGI(TAG, \"type=%s\",type);\n\n  int field = 0;\n\n  if( strcmp( type, \"state\" ) == 0) {\n    field = cJSON_GetObjectItem(root,\"value\")->valueint;\n    ESP_LOGI(TAG, \"value=%d\",field);\n  }\n}   Tarea entregable  Modifica el  firmware  de ejemplo  websockets  para que pueda comunicarse\nen modo lectura con el servidor Python que mantiene y publicita estado, cuyo\nc\u00f3digo se te proporciona. El programa ESP-IDF, al menos, mostar\u00e1 por pantalla\nun mensaje con los datos asociados cada vez que se reciban paquetes de tipo\ntexto ( state  o  users ). Tambi\u00e9n mostrar\u00e1 un mensaje cada vez que el \nservidor env\u00ede un mensaje de tipo  ping  o  pong  (para ello, consulta\nel RFC que describe el protocolo para determinar el  opcode  asociado).  Para comprobar el funcionamiento de la soluci\u00f3n, arranca el servidor y al\nmenos dos clientes web. Cuando arranques el ESP32, ambos deber\u00e1n incrementar\nel n\u00famero de clientes reportado, en respuesta al mensaje enviado por el \nservidor. Cuando cualquiera de los clientes web incremente el valor del \ncontador, el ESP32 recibir\u00e1 un mensaje con el valor actualizado, del mismo\nmodo que cuando cierres uno de los navegadores web.    Tarea opcional  Modifica el c\u00f3digo para que el cliente, peri\u00f3dicamente, env\u00ede un mensaje\nde petici\u00f3n de suma o resta siguiendo las especificaciones y tipos de\nmensaje que se explicaron anteriormente.",
            "title": "Ejercicio entregable: Comunicaci\u00f3n as\u00edncrona"
        },
        {
            "location": "/Subjects/NP2/P5/",
            "text": "Laboratory 3. REST servers and information representation. JSON and CBOR\n\n\nGoals\n\n\n\n\n\n\nTo understand the mechanisms offered by ESP-IDF for the creation of\na REST HTTP server.\n\n\n\n\n\n\nTo implement, via the mechanisms offered by ESP-IDF, a REST API extended for the ESP32.\n\n\n\n\n\n\nTo understand the basic concepts to represent data via JSON.\n\n\n\n\n\n\nTo implement, via de \ncJSON\n library, a message type personalized for the\nexchanges of data between client and server.\n\n\n\n\n\n\nTo undrestand the basic concepts to represent information via CBOR, and to \nevaluate the advantages compared with JSON.\n\n\n\n\n\n\nTo implement, via the \ntinycbor\n library, a message type personalized for the \ndata exchanges between client an server, comparing the payload sizes w.r.t. JSON.\n\n\n\n\n\n\nDevelopment of a REST server in ESP-IDF\n\n\nIn the first part of the laboratory, we will see how to develop, using the\nfunctionalities offered by ESP-IDF, a HTTP server that exposes an API REST. We will\nbe able to interact, in read and write modes, with a server (in our case, a ESP32).\n\n\nSpecifically, we will work with the example\n\nexample/protocols/http_server/rest_server\n of the IDF distribution.\n\n\nAPI description\n\n\nThe example builds a simple interface (API) with three \nendpoints\n that allow an\ninteraction with different functionality of the ESP32. Note that, both the URLs and the\nfunctionality associated with them is totally tunable, and can be extended according to\nthe needs of our application.\n\n\nThe next table summarizes the functionality of each \nendpoint\n, and possible examples\nof values sent or returned by the server:\n\n\n\n\n\n\n\n\nAPI\n\n\nMethod\n\n\nExample of read/write resource\n\n\nDescription\n\n\nURL\n\n\n\n\n\n\n\n\n\n\n/api/v1/system/info\n\n\nGET\n\n\n{\nversion:\"v4.0-dev\",\ncores:2\n}\n\n\nUsed by the clients to obtaine information of the board (version, core numbers, ...)\n\n\n/\n\n\n\n\n\n\n/api/v1/temp/raw\n\n\nGET\n\n\n{\nraw:22\n}\n\n\nUsed by the clients to obtain temperature data from a sensor (unavailable in the ESP32)\n\n\n/chart\n\n\n\n\n\n\n/api/v1/light/brightness\n\n\nPOST\n\n\n{ \nred:160,\ngreen:160,\nblue:160\n}\n\n\nUsed by the clients to wirte on the board control values to control luminosity of LEDS\n\n\n/light\n\n\n\n\n\n\n\n\nConfiguration and compilation of the example\n\n\nFirst, configure, compile and flash the example. In this case, the instructions\nare divided in two parts: compilation of the \nfirmware\n for the ESP32, and preparation\nof a web client that will allow us to interact with it. This last part is not strictly\nnecessary, but it will help us in the interaction with the device in a visual manner until\nwe study how to do it via command line.\n\n\nThrough the configuation menu, configure a name for your device (e.g., 'esp_home_yourname'),\nand configure the deploy mode (\nWebsite deploy mode\n) to \n\nDeploy website to SPI Nor Flash\n. Finally, configure the credentials \nof the WiFi access point, using the same methodology as that used in Lab 2.\n\n\nSecond, you will need to install the necessary components to deploy the web \nclient. For that, navigate to the \n\nfront/web-demo\n folder, where\nthe source code for the client resides. Execute the following commands:\n\n\nsudo apt-get update\nsudo apt-get install npm node-vue*\nnpm install\nnpm run build \n\n\n\n\nAt this point you can execute, from the base directory of the example, the orders for compilation and flashing:\n\n\nidf.py build\nidf.py flash\nidf.py monitor\n\n\n\n\nInteraction with the device via web interface\n\n\nIf everything is correct, you will be able to observe in the output of the monitorization\nthe IP provided to the ESP32. Open a web browser on the virtual machine or your PC (connected in the\nsame network as that of the ESP32), navigate to the IP of the ESP32, and you should observe a page like\nthe following:\n\n\n\n\nThis is a web page served by the ESP32, that will allow you to interact with it. Specifically, the\npage offers two functionalities:\n\n\n\n\n\n\nChart\n: periodically checks the temperature value returned by the ESP32 via the \nendpoint\n \n/api/v1/temp/raw\n.\n\n\n\n\n\n\nLight\n: allows to send to the ESP32 new values for the three components of luminosity that could (hypothetically) equip the ESP32.\n\n\n\n\n\n\n\n\nTask 1.1\n\n\nInteract with the light sensor of the ESP32 sending different values. Observe how the\nthe output of the monitorization on the ESP32 responds showing the received values. Analyze the\ngenerated traffic for one of those requests using Wireshark. How are the submitted values encoded?\nHow are the periodic data for temperature encoded?\n\n\n\n\nInteraction with the device via command line (\ncurl\n)\n\n\ncurl\n is a tool oriented to the transfer of files through the networ. \nAmong others (many) functionalities, \ncurl\n supports the\n\nGET\n and \nPUT\n methods from HTTP, just the necessary tools to perform read and write\nrequests on our HTTP REST server.\n\n\nSpecifically, in order to perform an HTTP \n\nGET\n request on our server:\n\n\ncurl http://IP/URI\n\n\n\n\nFor example, the request:\n\n\ncurl http://192.168.1.26/api/v1/temp/raw\n\n\n\n\n(being \n192.168.1.26\n the IP of the ESP32)\nwill respond with the value of instantaneous temperature.\n\n\nSimilarly, to write (method \nPOST\n) on the server, we will use the \nparameter \n-d\n, followed by the resource to submit. Take into account that it is responsibility\nof the client to send a resource well-formed and that can be interpreted by the device:\n\n\ncurl -d '{\"red\":70,\"green\":80,\"blue\":99}' -H \"Content-Type: application/json\" \n-X POST http://192.168.1.26/api/v1/light/brightness\n\n\n\n\nNote that we have included the type of resource submitted (\nJSON\n) and the requested operation\n(\nPOST\n). We will come back to this shortly.\n\n\n\n\nTask 1.2\n\n\nCheck that the traffic generated for each order is the same that you observed in the case of the web client. Note what happens if you check a non-existant \ncheckpoint\n, or if you submit an incorrect JSON.\n\n\n\n\nImplementation of a HTTP server with REST API\n\n\nThe implementation of a HTTP server in ESP-IDF is delegated to the \n\nHTTP Server\n component, that implements all the functionality required for \nthat end in an efficient and light way. The construction of a server can be summarized\nin three main functions (study the implementation of the \n\nstart_rest_server\n function in \nrest_server.c\n):\n\n\n\n\n\n\nhttpd_start\n: creates an instance of a HTTP server, and allocates resources fo it\naccording to a configuration. Depending on the generated traffic (URIs requested), specific\nhanlders will be used defined by the programmer to analyze it and, if necessary, to send\nback responses to the client.\n\n\n\n\n\n\nhttpd_stop\n: finalizes the HTTP server, closing any previously establised connections with clients.\n\n\n\n\n\n\nhttpd_register_uri_handler\n: registers a handler (a function defined by the user) to serve a request on a\nspecific URI. The structure provided has fields to indicate the target URI\n(\nuri\n), \nthe method that is expected to receive (\nmethod\n, for example \nHTTPD_GET\n\nor \nHTTPD_POST\n) and a pointer to a function that will process the request\nreceived via the indicated URI. That function will only be executed if the\nmethod matches with that requested.\n\n\n\n\n\n\nThe function \nstart_rest_server\n of the example provides the necessary basic mechanisms\nfor the creation of the previously described API. Hence, to create the\n\nendpoint\n \n/api/v1/system/info\n we will, first, register it on the server, \npreparing previously a structure of type \nhttpd_uri_t\n:\n\n\nhttpd_uri_t system_info_get_uri = {\n        .uri = \"/api/v1/system/info\",\n        .method = HTTP_GET,\n        .handler = system_info_get_handler,\n        .user_ctx = rest_context\n    };\n    httpd_register_uri_handler(server, &system_info_get_uri);\n\n\n\n\nIn this case, the operation associated to the invocation of the handler will be, exclusively, \n\nGET\n; actually, if we invoce a \nPOST\n method on this \nendpoint\n, the\nserver will respond automatically with a warning statint that the method is not supported.\n\n\nThe procedure to process the funtion \n\nGET\n is performed via the function\n\nsystem_info_get_handler\n, and the schema is, anyway, simple:\n\n\nstatic esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Setup response.\n    httpd_resp_set_type(req, \"application/json\");\n\n    // Setup response buffer.\n    char * buffer = // In the example prepare a JSON response.\n\n    // Sending response.\n    https_resp_sendstr( req, buffer  );\n\n    return ESP_OK;\n\n\n\n\nAlternatively, if the response is binary, we could use the method\n\nhttps_resp_send( req, buffer, buffer_len  )\n to process it and send it\n(you will need this to send a binary CBOR buffer).\n\n\nThe creation of an \nendpoint\n with support for the \nPOST\n method is a little\nbit longer, but the registration is the same as in the previous example:\n\n\n    /* URI handler for light brightness control */\n    httpd_uri_t light_brightness_post_uri = {\n        .uri = \"/api/v1/light/brightness\",\n        .method = HTTP_POST,\n        .handler = light_brightness_post_handler,\n        .user_ctx = rest_context\n    };\n    httpd_register_uri_handler(server, &light_brightness_post_uri);\n\n\n\n\nNote that the body of the function \nlight_brightness_post_handler\n. The reception\nof the object sent by the client is performed based on multiple invocations\nto \nhttpd_req_recv\n:\n\n\n/* Simple handler for light brightness control */\nstatic esp_err_t light_brightness_post_handler(httpd_req_t *req)\n{\n    int total_len = req->content_len;\n    int cur_len = 0;\n    char *buf = ((rest_server_context_t *)(req->user_ctx))->scratch;\n    int received = 0;\n    if (total_len >= SCRATCH_BUFSIZE) {\n        /* Respond with 500 Internal Server Error */\n        httpd_resp_send_err(req, HTTPD_500_INTERNAL_SERVER_ERROR, \"content too long\");\n        return ESP_FAIL;\n    }\n    while (cur_len < total_len) {\n        received = httpd_req_recv(req, buf + cur_len, total_len);\n        if (received <= 0) {\n            /* Respond with 500 Internal Server Error */\n            httpd_resp_send_err(req, HTTPD_500_INTERNAL_SERVER_ERROR, \"Failed to post control value\");\n            return ESP_FAIL;\n        }\n        cur_len += received;\n    }\n    buf[total_len] = '\\0';\n\n    /// A partir de este punto, disponemos en buf del objeto recibido v\u00eda HTTP.\n    /// ... \n\n\n\n\n\n\nTask 1.3\n\n\nObserve and study the codes of the handlers implemented in the example. \nExtend the API offered to create a new \nendpoint\n that allows to obtain \nthe temperature (random number), but transforming it to Fahrenheit degrees. In this cas, \nthe value returned in the JSON file will be a number in floating point format \n(you will see how to do this in the next section. By now, you can use an integer value).\n\n\n\n\nInformation representation. JSON\n\n\nJSON is a data representation format based on text for the exchange of\ndata between systems. It was created originally as a literal notation\nfor Javascript objects, but given its adoption (as of today, it is a real\nalternative for XML), it is considered an independent component from the\nlanguage. \n\n\nThe datatypes supported by JSON include:\n\n\n\n\n\n\nNumeric values: allowing numbers with and without sign, and with decimal\npart in dot-separated notation.\n\n\n\n\n\n\nStrings: sequences of zero or more characters.\n\n\n\n\n\n\nBooleans: \ntrue\n and \nfalse\n.\n\n\n\n\n\n\nArrays: ordered lists of zero or more values of any type, separated by commas with\n\n[ ]\n signs.\n\n\n\n\n\n\nObjects: unordered collections of pairs \n<name>:<value>\n, separated by commas with\n\n{ }\n signs.\n\n\n\n\n\n\nESP-IDF includes the \ncJSON\n\ncomponent to parse and build objects of JSON type in a simple and consistent way.\nThe cJSON library represents JSON data using a simple structure:\n\n\n/* The cJSON structure: */\ntypedef struct cJSON\n{\n    struct cJSON *next;\n    struct cJSON *prev;\n    struct cJSON *child;\n    int type;\n    char *valuestring;\n    /* writing to valueint is DEPRECATED, use cJSON_SetNumberValue instead */\n    int valueint;\n    double valuedouble;\n    char *string;\n} cJSON;\n\n\n\n\nThe \ntype\n field inforems about the type of data contained in the object:\n\n\n\n\ncJSON_False\n (\ncJSON_IsFalse()\n): false boolean value.\n\n\ncJSON_True\n (\ncJSON_IsTrue()\n): true boolean value.\n\n\ncJSON_NULL\n (\ncJSON_IsNULL()\n): null value.\n\n\ncJSON_Number\n (\ncJSON_IsNumber()\n): numeric value. This value is stored in the field\n\nvaluedouble\n as a floating point and at \nvalueint\n as an integer.\n\n\ncJSON_String\n (\ncJSON_IsString()\n): string value, stored in the field \n\nvaluestring\n as an array of bytes terminated by null character ('\\0').\n\n\ncJSON_Array\n (\ncJSON_IsArray()\n): array of values. In the field\n\nchild\n, it stores a linked list with the elements of the array, terminated by NULL.\n\n\ncJSON_Object\n (\ncJSON_IsObject()\n): object value. \nIts values are stored in the same manner than in the previous array, but in this case in the field \n\nstring\n it stores the keys of the object as a list.\n\n\n\n\nCreataion and parsing of a JSON structure\n\n\nFor each datatype, there exists a routine associated with the name\n\ncJSON_Create...\n that allows to create an item of the corresponding type. \nAll these functions allocate enough memory to host the created data.\n\n\nGiven a JSON object as a string, it is possible to analyze it (parse it) \nusing the function \ncJSON_Parse\n:\n\n\ncJSON * json = cJSON_Parse( string );\n\n\n\n\nIn order to print the contents of a JSON structure in in text mode, we can use the\nfunction \ncJSON_Print(json)\n:\n\n\nchar * string = cJSON_Print( json );\n\n\n\n\nExamples\n\n\nObserve again the contents of the handler funtions in the REST server. Specifically, \nfocus on the funtion \nsystem_info_get_handler\n, that builds\na JSON object with two fields, of type string (\"version\") y numeric (\"cores\"):\n\n\n/* Simple handler for getting system handler */\nstatic esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Preparation of the datatype of the response.\n    httpd_resp_set_type(req, \"application/json\");\n\n    // Creation of the JSON object.\n    cJSON *root = cJSON_CreateObject();\n\n    // Obtention of the data.\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n\n    // Add a string field.\n    cJSON_AddStringToObject(root, \"version\", IDF_VER);\n\n    // Add a numeric field.\n    cJSON_AddNumberToObject(root, \"cores\", chip_info.cores);\n\n    // Print the string prior to submission.\n    const char *sys_info = cJSON_Print(root);\n\n    // Send header + JSON object in text mode via HTTP.\n    httpd_resp_sendstr(req, sys_info);\n\n    // Free resources.\n    free((void *)sys_info);\n\n    // Free resources for JSON. \n    cJSON_Delete(root);\n\n    return ESP_OK;\n}\n\n\n\n\nThe funtion \nlight_brightness_post_handler\n parsess the received JSON object. Analyze its body:\n\n\n    // buf contains the string received via HTTP (method POST).\n    // ...\n    // Parse the JSON object.\n    cJSON *root = cJSON_Parse(buf);\n\n    // Obtain three numeric values (RGB).\n    int red = cJSON_GetObjectItem(root, \"red\")->valueint;\n    int green = cJSON_GetObjectItem(root, \"green\")->valueint;\n    int blue = cJSON_GetObjectItem(root, \"blue\")->valueint;\n\n    // Show on screen the parsed values.\n    ESP_LOGI(REST_TAG, \"Light control: red = %d, green = %d, blue = %d\", red, green, blue);\n\n    // Free JSON resources.\n    cJSON_Delete(root);\n\n    // Submit a generic response in text mode.\n    httpd_resp_sendstr(req, \"Post control value successfully\");\n\n    return ESP_OK;\n\n\n\n\n\n\nTask 1.4\n\n\nExtend the previous task to add the data in floating point format about the Fahrenheit temperature.\n\n\n\n\n\n\nTask 1.5\n\n\nCreate a new \nendpoint\n that uses a more complex object format (in JSON), including \ndifferent types of data that can give response to a hypothetical IoT environment.\nDocument the generated API and the format of the objects. If you consider it necessary, include\nWireshark captures to illustrate the exchange of messages. Specifically, it will be interesting\nto analyze the number of bytes transported to send/receive JSON messages.\n\n\n\n\nInformation representation. CBOR\n\n\nCBOR (\nConcise Binary Object Representation\n) is the recommended serialization\nformat in many IoT stacks, specifically in those based on CoAP. \nEven though it is a binary format, CBOR is similar in many ways with JSON, as it\nfollows the same data model: numeric values, strings, arrays, maps (objects in JSON)\nand null/boolean values.\n\n\nHowever, differently from JSON, a CBOR object is autodescriptive, and this is\none if its advantages: it is possible to exchange data between a client and a server\nwithout using a pre-defined schema of data known by both parties.\n\n\nThe fact of being a binary format implies improvements w.r.t. JSON, for example when \ntransporting binary data (cipher keys, graphics, floating point values, among others); these\ndata were encoded in JSON using, for example base64 format, adding complexity in the \nprocess of codification/decodification. \nIn general, the use of a binary format implies less complexity when integrating in applications, \nand this is why it is considered to be optimum in low-power devices, such as IoT devices. \n\n\nThe CBOR format is documented in \nRFC 7049\n,\nso it is considered to be a well documented standard, and stable for the future.\n\n\nCBOR on the ESP32\n\n\nESP-IDF includes the library \ntinyCBOR\n that \nhelps with the encoding of data into CBOR format, parsing\nCBOR structures and convering those structures bot to text format and to JSON.\nTinyCBOR is maintained as a free software project by Intel, and its documentation\n(that you should read as a reference) is available at \nenlace\n.\n\n\nLet us study the logics of \ntinyCBOR\n through an example (you can find it\nin the \nexamples/protocols/cbor\n folder of IDF). The example\nshows the necessary mechanisms to, first, create a CBOR object using the library and,\nsecond, to convert the object to a JSON representation and parse it:\n\n\nCompile, flash and execute the example. You should see that the output is similar to: \n\n\nI (320) example: encoded buffer size 67\nI (320) example: convert CBOR to JSON\n[{\"chip\":\"esp32\",\"unicore\":false,\"ip\":[192,168,1,100]},3.1400001049041748,\"simple(99)\",\"2019-07-10 09:00:00+0000\",\"undefined\"]\nI (340) example: decode CBOR manually\nArray[\n  Map{\n    chip\n    esp32\n    unicore\n    false\n    ip\n    Array[\n      192\n      168\n      1\n      100\n    ]\n  }\n  3.14\n  simple(99)\n  2019-07-10 09:00:00+0000\n  undefined\n]\n\n\n\n\nNote that the structure of a CBOR objct is complex: it is composed by an array with five elements:\n\n\n\n\nA \nmap\n (unnordered set of pairs \nkey-value\n) combining strings, booleans and a second array to specify an IP address.\n\n\nA floating point value (3.14).\n\n\nA numeric \"simple\" value (99).\n\n\nA date (as a string)\n\n\nAn undefined value.\n\n\n\n\nThe \nfirmware\n proceeds in three stages:\n\n\nStage 1: creation (codification) of a CBOR object\n\n\nObserve the body of the main task (\napp_main\n). The encoder for CBOR is based on two variables:\n\n\nCborEncoder Root_encoder; // CBOR encoder.\nuint8_t buf[100];         // Buffer to allocate the CBOR object (array of bytes).\n\n\n\n\nSecond, and as we will use an array and a map, we will need constructors specifically desinged for those objects:\n\n\n// Array creation.\nCborEncoder array_encoder;\nCborEncoder map_encoder;\n\ncbor_encoder_create_array(&root_encoder, &array_encoder, 5); // [\n  // 1. Map creation.\n  cbor_encoder_create_map(&array_encoder, &map_encoder, 3); // {\n\n\n\n\nFrom this point on, we can proceed with the construction of the objects following the desired schema:\n\n\n  // chip: esp32 (string:string)\n  cbor_encode_text_stringz(&map_encoder, \"chip\");\n  cbor_encode_text_stringz(&map_encoder, \"esp32\");\n\n  // unicore: false (string:boolean)\n  cbor_encode_text_stringz(&map_encoder, \"unicore\");\n  cbor_encode_boolean(&map_encoder, false);\n\n  // IP:[192,168,1,100] (string:array)\n  cbor_encode_text_stringz(&map_encoder, \"ip\");\n\n    CborEncoder array2;\n\n    cbor_encoder_create_array(&map_encoder, &array2, 4); // [\n\n    // Numeric values.\n    cbor_encode_uint(&array2, 192);\n    cbor_encode_uint(&array2, 168);\n    cbor_encode_uint(&array2, 1);\n    cbor_encode_uint(&array2, 100);\n\n    cbor_encoder_close_container(&map_encoder, &array2);        // ]\n\n cbor_encoder_close_container(&array_encoder, &map_encoder); // }\n\n// 2. Flotanting point\ncbor_encode_float(&array_encoder, 3.14);\n\n// 3. Simple value \ncbor_encode_simple_value(&array_encoder, 99);\n\n// 4. String \ncbor_encode_text_stringz(&array_encoder, \"2019-07-10 09:00:00+0000\");\n\n// 5. Undefined value.\ncbor_encode_undefined(&array_encoder);\ncbor_encoder_close_container(&root_encoder, &array_encoder); // ]\n\n// Show the size of the created buffer.\nESP_LOGI(TAG, \"encoded buffer size %d\", cbor_encoder_get_buffer_size(&root_encoder, buf));\n\n\n\n\nStage 2: conversion to JSON\n\n\nThe conversion to JSON (typically to visualize or debug) can be done as follows:\n\n\n    // Initialize the cbor parser and the value iterator\n    cbor_parser_init(buf, sizeof(buf), 0, &root_parser, &it);\n\n    ESP_LOGI(TAG, \"convert CBOR to JSON\");\n    // Dump the values in JSON format\n    cbor_value_to_json(stdout, &it, 0);\n\n\n\n\nStage 3: manually parsing a CBOR object\n\n\nLast, the manual parsing of a CBOR object is left as an exercise for the student,\nand it is implemented in the funtion \nexample_dump_cbor_buffer\n of the example.\nBasically, the function iterates over each one of the elements of the CBOR object,\nchecking each element and acting consequently. \nFor those types that are complex (e.g. arrays or maps), the function is invoked recursively\ntill finding a basic datatype. In this case, it just prints on screen its value (e.g. in the case\nof an integer, case \nCborIntegerType\n).\n\n\n\n\nTask 1.5\n\n\nExtend the REST API with a new \nendpoint\n that allows obtaining the same information than \nthe JSON \nendpoint\n developed in the last task, but in this case, using CBOR. The goal of the\ntask is to compare the amount of generated traffic in each representation, so it is suggested to\nuse a relatively complex object (different numeric types, arrays or maps). Next, we include \nadditional notes that will help you in the solution for debugging purposes, observing the returned\nvalues by the HTTP server.\n\n\n\n\nAdditional notes: creation and query of a CBOR \nendpoint\n in the REST API\n\n\nThe modifications to carry out in the handler funtion of the endpoint to answer with a CBOR\nobject are minimal. Actually, they are focused simply on the type of response and the mechanism to send it, namely:\n\n\nstatic esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Response type. \n    httpd_resp_set_type(req, \"application/cbor\");\n\n    CborEncoder root_encoder;\n    uint8_t buf[100];\n\n    // CBOR encoder\n    cbor_encoder_init(&root_encoder, buf, sizeof(buf), 0);\n\n    // Encoding CBOR.\n    // ...\n\n    // Send response, checking previously the size of the encoded buffer.\n    httpd_resp_send(req, (char*)buf, cbor_encoder_get_buffer_size( &root_encoder, buf));\n\n    return ESP_OK;\n\n\n\n\nTo query from command line on this endpoint, we can use directly \ncurl\n, redirecting the received\noutput to a file (e.g.  \noutput.cbor\n):\n\n\ncurl http://192.168.1.26/api/v1/system/info > output.cbor\n\n\n\n\nIf we visualize the contents of the file, we can observe that it contains binary data, \ndificult to analayze. In the following, we well see different visualization mechanisms.\n\n\nAdditional notes: visualizing CBOR data\n\n\nA visualization option consists on using the web \ncbor.me\n.\nIn the right panel, you can paste the binary contents read. If you need to \nperform a conversion before pasting on the web, you can do it with:\n\n\nxxd -ps output.cbor\n\n\n\n\nAn output example (to be pased on the right panel of the web), could be:\n\n\n$ xxd -ps output.cbor \n85a3646368697065657370333267756e69636f7265f46269708418c018a8\n011864fa4048f5c3f8637818323031392d30372d31302030393a30303a30\n302b30303030f7\n\n\n\n\nYou shouls see a similar output as the one shown next (take into accounnt that\nthe tools automatically indents the contents of the right panel; rememebre that you need to just paste the output generated by \nxxd\n):\n\n\n\n\nOther visualization option can be a Python program (it could actually be integrated \nwithin your TCP/UDP client/server, for example) that makes use of the \n\ncbor2\n module (\ndocumentation\n). To check\nhow it works, first install it:\n\n\npip install cbor2\n\n\n\n\nAnd theck if it effectively works using the following Python program:\n\n\nfrom cbor2 import dumps, loads, dump, load\n\nwith open('output.cbor', 'rb') as fp:\n    obj = load(fp)\n\nprint(obj)\n\n\n\n\nWhen executed, you will observe the contents of the object:\n\n\npython cbor.py\n[{'chip': 'esp32', 'unicore': False, 'ip': [192, 168, 1, 100]}, 3.140000104904175, CBORSimpleValue(value=99), '2019-07-10 09:00:00+0000', undefined]",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P5/#laboratory-3-rest-servers-and-information-representation-json-and-cbor",
            "text": "",
            "title": "Laboratory 3. REST servers and information representation. JSON and CBOR"
        },
        {
            "location": "/Subjects/NP2/P5/#goals",
            "text": "To understand the mechanisms offered by ESP-IDF for the creation of\na REST HTTP server.    To implement, via the mechanisms offered by ESP-IDF, a REST API extended for the ESP32.    To understand the basic concepts to represent data via JSON.    To implement, via de  cJSON  library, a message type personalized for the\nexchanges of data between client and server.    To undrestand the basic concepts to represent information via CBOR, and to \nevaluate the advantages compared with JSON.    To implement, via the  tinycbor  library, a message type personalized for the \ndata exchanges between client an server, comparing the payload sizes w.r.t. JSON.",
            "title": "Goals"
        },
        {
            "location": "/Subjects/NP2/P5/#development-of-a-rest-server-in-esp-idf",
            "text": "In the first part of the laboratory, we will see how to develop, using the\nfunctionalities offered by ESP-IDF, a HTTP server that exposes an API REST. We will\nbe able to interact, in read and write modes, with a server (in our case, a ESP32).  Specifically, we will work with the example example/protocols/http_server/rest_server  of the IDF distribution.",
            "title": "Development of a REST server in ESP-IDF"
        },
        {
            "location": "/Subjects/NP2/P5/#api-description",
            "text": "The example builds a simple interface (API) with three  endpoints  that allow an\ninteraction with different functionality of the ESP32. Note that, both the URLs and the\nfunctionality associated with them is totally tunable, and can be extended according to\nthe needs of our application.  The next table summarizes the functionality of each  endpoint , and possible examples\nof values sent or returned by the server:     API  Method  Example of read/write resource  Description  URL      /api/v1/system/info  GET  { version:\"v4.0-dev\", cores:2 }  Used by the clients to obtaine information of the board (version, core numbers, ...)  /    /api/v1/temp/raw  GET  { raw:22 }  Used by the clients to obtain temperature data from a sensor (unavailable in the ESP32)  /chart    /api/v1/light/brightness  POST  {  red:160, green:160, blue:160 }  Used by the clients to wirte on the board control values to control luminosity of LEDS  /light",
            "title": "API description"
        },
        {
            "location": "/Subjects/NP2/P5/#configuration-and-compilation-of-the-example",
            "text": "First, configure, compile and flash the example. In this case, the instructions\nare divided in two parts: compilation of the  firmware  for the ESP32, and preparation\nof a web client that will allow us to interact with it. This last part is not strictly\nnecessary, but it will help us in the interaction with the device in a visual manner until\nwe study how to do it via command line.  Through the configuation menu, configure a name for your device (e.g., 'esp_home_yourname'),\nand configure the deploy mode ( Website deploy mode ) to  Deploy website to SPI Nor Flash . Finally, configure the credentials \nof the WiFi access point, using the same methodology as that used in Lab 2.  Second, you will need to install the necessary components to deploy the web \nclient. For that, navigate to the  front/web-demo  folder, where\nthe source code for the client resides. Execute the following commands:  sudo apt-get update\nsudo apt-get install npm node-vue*\nnpm install\nnpm run build   At this point you can execute, from the base directory of the example, the orders for compilation and flashing:  idf.py build\nidf.py flash\nidf.py monitor",
            "title": "Configuration and compilation of the example"
        },
        {
            "location": "/Subjects/NP2/P5/#interaction-with-the-device-via-web-interface",
            "text": "If everything is correct, you will be able to observe in the output of the monitorization\nthe IP provided to the ESP32. Open a web browser on the virtual machine or your PC (connected in the\nsame network as that of the ESP32), navigate to the IP of the ESP32, and you should observe a page like\nthe following:   This is a web page served by the ESP32, that will allow you to interact with it. Specifically, the\npage offers two functionalities:    Chart : periodically checks the temperature value returned by the ESP32 via the  endpoint   /api/v1/temp/raw .    Light : allows to send to the ESP32 new values for the three components of luminosity that could (hypothetically) equip the ESP32.     Task 1.1  Interact with the light sensor of the ESP32 sending different values. Observe how the\nthe output of the monitorization on the ESP32 responds showing the received values. Analyze the\ngenerated traffic for one of those requests using Wireshark. How are the submitted values encoded?\nHow are the periodic data for temperature encoded?",
            "title": "Interaction with the device via web interface"
        },
        {
            "location": "/Subjects/NP2/P5/#interaction-with-the-device-via-command-line-curl",
            "text": "curl  is a tool oriented to the transfer of files through the networ. \nAmong others (many) functionalities,  curl  supports the GET  and  PUT  methods from HTTP, just the necessary tools to perform read and write\nrequests on our HTTP REST server.  Specifically, in order to perform an HTTP  GET  request on our server:  curl http://IP/URI  For example, the request:  curl http://192.168.1.26/api/v1/temp/raw  (being  192.168.1.26  the IP of the ESP32)\nwill respond with the value of instantaneous temperature.  Similarly, to write (method  POST ) on the server, we will use the \nparameter  -d , followed by the resource to submit. Take into account that it is responsibility\nof the client to send a resource well-formed and that can be interpreted by the device:  curl -d '{\"red\":70,\"green\":80,\"blue\":99}' -H \"Content-Type: application/json\" \n-X POST http://192.168.1.26/api/v1/light/brightness  Note that we have included the type of resource submitted ( JSON ) and the requested operation\n( POST ). We will come back to this shortly.   Task 1.2  Check that the traffic generated for each order is the same that you observed in the case of the web client. Note what happens if you check a non-existant  checkpoint , or if you submit an incorrect JSON.",
            "title": "Interaction with the device via command line (curl)"
        },
        {
            "location": "/Subjects/NP2/P5/#implementation-of-a-http-server-with-rest-api",
            "text": "The implementation of a HTTP server in ESP-IDF is delegated to the  HTTP Server  component, that implements all the functionality required for \nthat end in an efficient and light way. The construction of a server can be summarized\nin three main functions (study the implementation of the  start_rest_server  function in  rest_server.c ):    httpd_start : creates an instance of a HTTP server, and allocates resources fo it\naccording to a configuration. Depending on the generated traffic (URIs requested), specific\nhanlders will be used defined by the programmer to analyze it and, if necessary, to send\nback responses to the client.    httpd_stop : finalizes the HTTP server, closing any previously establised connections with clients.    httpd_register_uri_handler : registers a handler (a function defined by the user) to serve a request on a\nspecific URI. The structure provided has fields to indicate the target URI\n( uri ), \nthe method that is expected to receive ( method , for example  HTTPD_GET \nor  HTTPD_POST ) and a pointer to a function that will process the request\nreceived via the indicated URI. That function will only be executed if the\nmethod matches with that requested.    The function  start_rest_server  of the example provides the necessary basic mechanisms\nfor the creation of the previously described API. Hence, to create the endpoint   /api/v1/system/info  we will, first, register it on the server, \npreparing previously a structure of type  httpd_uri_t :  httpd_uri_t system_info_get_uri = {\n        .uri = \"/api/v1/system/info\",\n        .method = HTTP_GET,\n        .handler = system_info_get_handler,\n        .user_ctx = rest_context\n    };\n    httpd_register_uri_handler(server, &system_info_get_uri);  In this case, the operation associated to the invocation of the handler will be, exclusively,  GET ; actually, if we invoce a  POST  method on this  endpoint , the\nserver will respond automatically with a warning statint that the method is not supported.  The procedure to process the funtion  GET  is performed via the function system_info_get_handler , and the schema is, anyway, simple:  static esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Setup response.\n    httpd_resp_set_type(req, \"application/json\");\n\n    // Setup response buffer.\n    char * buffer = // In the example prepare a JSON response.\n\n    // Sending response.\n    https_resp_sendstr( req, buffer  );\n\n    return ESP_OK;  Alternatively, if the response is binary, we could use the method https_resp_send( req, buffer, buffer_len  )  to process it and send it\n(you will need this to send a binary CBOR buffer).  The creation of an  endpoint  with support for the  POST  method is a little\nbit longer, but the registration is the same as in the previous example:      /* URI handler for light brightness control */\n    httpd_uri_t light_brightness_post_uri = {\n        .uri = \"/api/v1/light/brightness\",\n        .method = HTTP_POST,\n        .handler = light_brightness_post_handler,\n        .user_ctx = rest_context\n    };\n    httpd_register_uri_handler(server, &light_brightness_post_uri);  Note that the body of the function  light_brightness_post_handler . The reception\nof the object sent by the client is performed based on multiple invocations\nto  httpd_req_recv :  /* Simple handler for light brightness control */\nstatic esp_err_t light_brightness_post_handler(httpd_req_t *req)\n{\n    int total_len = req->content_len;\n    int cur_len = 0;\n    char *buf = ((rest_server_context_t *)(req->user_ctx))->scratch;\n    int received = 0;\n    if (total_len >= SCRATCH_BUFSIZE) {\n        /* Respond with 500 Internal Server Error */\n        httpd_resp_send_err(req, HTTPD_500_INTERNAL_SERVER_ERROR, \"content too long\");\n        return ESP_FAIL;\n    }\n    while (cur_len < total_len) {\n        received = httpd_req_recv(req, buf + cur_len, total_len);\n        if (received <= 0) {\n            /* Respond with 500 Internal Server Error */\n            httpd_resp_send_err(req, HTTPD_500_INTERNAL_SERVER_ERROR, \"Failed to post control value\");\n            return ESP_FAIL;\n        }\n        cur_len += received;\n    }\n    buf[total_len] = '\\0';\n\n    /// A partir de este punto, disponemos en buf del objeto recibido v\u00eda HTTP.\n    /// ...    Task 1.3  Observe and study the codes of the handlers implemented in the example. \nExtend the API offered to create a new  endpoint  that allows to obtain \nthe temperature (random number), but transforming it to Fahrenheit degrees. In this cas, \nthe value returned in the JSON file will be a number in floating point format \n(you will see how to do this in the next section. By now, you can use an integer value).",
            "title": "Implementation of a HTTP server with REST API"
        },
        {
            "location": "/Subjects/NP2/P5/#information-representation-json",
            "text": "JSON is a data representation format based on text for the exchange of\ndata between systems. It was created originally as a literal notation\nfor Javascript objects, but given its adoption (as of today, it is a real\nalternative for XML), it is considered an independent component from the\nlanguage.   The datatypes supported by JSON include:    Numeric values: allowing numbers with and without sign, and with decimal\npart in dot-separated notation.    Strings: sequences of zero or more characters.    Booleans:  true  and  false .    Arrays: ordered lists of zero or more values of any type, separated by commas with [ ]  signs.    Objects: unordered collections of pairs  <name>:<value> , separated by commas with { }  signs.    ESP-IDF includes the  cJSON \ncomponent to parse and build objects of JSON type in a simple and consistent way.\nThe cJSON library represents JSON data using a simple structure:  /* The cJSON structure: */\ntypedef struct cJSON\n{\n    struct cJSON *next;\n    struct cJSON *prev;\n    struct cJSON *child;\n    int type;\n    char *valuestring;\n    /* writing to valueint is DEPRECATED, use cJSON_SetNumberValue instead */\n    int valueint;\n    double valuedouble;\n    char *string;\n} cJSON;  The  type  field inforems about the type of data contained in the object:   cJSON_False  ( cJSON_IsFalse() ): false boolean value.  cJSON_True  ( cJSON_IsTrue() ): true boolean value.  cJSON_NULL  ( cJSON_IsNULL() ): null value.  cJSON_Number  ( cJSON_IsNumber() ): numeric value. This value is stored in the field valuedouble  as a floating point and at  valueint  as an integer.  cJSON_String  ( cJSON_IsString() ): string value, stored in the field  valuestring  as an array of bytes terminated by null character ('\\0').  cJSON_Array  ( cJSON_IsArray() ): array of values. In the field child , it stores a linked list with the elements of the array, terminated by NULL.  cJSON_Object  ( cJSON_IsObject() ): object value. \nIts values are stored in the same manner than in the previous array, but in this case in the field  string  it stores the keys of the object as a list.",
            "title": "Information representation. JSON"
        },
        {
            "location": "/Subjects/NP2/P5/#creataion-and-parsing-of-a-json-structure",
            "text": "For each datatype, there exists a routine associated with the name cJSON_Create...  that allows to create an item of the corresponding type. \nAll these functions allocate enough memory to host the created data.  Given a JSON object as a string, it is possible to analyze it (parse it) \nusing the function  cJSON_Parse :  cJSON * json = cJSON_Parse( string );  In order to print the contents of a JSON structure in in text mode, we can use the\nfunction  cJSON_Print(json) :  char * string = cJSON_Print( json );",
            "title": "Creataion and parsing of a JSON structure"
        },
        {
            "location": "/Subjects/NP2/P5/#examples",
            "text": "Observe again the contents of the handler funtions in the REST server. Specifically, \nfocus on the funtion  system_info_get_handler , that builds\na JSON object with two fields, of type string (\"version\") y numeric (\"cores\"):  /* Simple handler for getting system handler */\nstatic esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Preparation of the datatype of the response.\n    httpd_resp_set_type(req, \"application/json\");\n\n    // Creation of the JSON object.\n    cJSON *root = cJSON_CreateObject();\n\n    // Obtention of the data.\n    esp_chip_info_t chip_info;\n    esp_chip_info(&chip_info);\n\n    // Add a string field.\n    cJSON_AddStringToObject(root, \"version\", IDF_VER);\n\n    // Add a numeric field.\n    cJSON_AddNumberToObject(root, \"cores\", chip_info.cores);\n\n    // Print the string prior to submission.\n    const char *sys_info = cJSON_Print(root);\n\n    // Send header + JSON object in text mode via HTTP.\n    httpd_resp_sendstr(req, sys_info);\n\n    // Free resources.\n    free((void *)sys_info);\n\n    // Free resources for JSON. \n    cJSON_Delete(root);\n\n    return ESP_OK;\n}  The funtion  light_brightness_post_handler  parsess the received JSON object. Analyze its body:      // buf contains the string received via HTTP (method POST).\n    // ...\n    // Parse the JSON object.\n    cJSON *root = cJSON_Parse(buf);\n\n    // Obtain three numeric values (RGB).\n    int red = cJSON_GetObjectItem(root, \"red\")->valueint;\n    int green = cJSON_GetObjectItem(root, \"green\")->valueint;\n    int blue = cJSON_GetObjectItem(root, \"blue\")->valueint;\n\n    // Show on screen the parsed values.\n    ESP_LOGI(REST_TAG, \"Light control: red = %d, green = %d, blue = %d\", red, green, blue);\n\n    // Free JSON resources.\n    cJSON_Delete(root);\n\n    // Submit a generic response in text mode.\n    httpd_resp_sendstr(req, \"Post control value successfully\");\n\n    return ESP_OK;   Task 1.4  Extend the previous task to add the data in floating point format about the Fahrenheit temperature.    Task 1.5  Create a new  endpoint  that uses a more complex object format (in JSON), including \ndifferent types of data that can give response to a hypothetical IoT environment.\nDocument the generated API and the format of the objects. If you consider it necessary, include\nWireshark captures to illustrate the exchange of messages. Specifically, it will be interesting\nto analyze the number of bytes transported to send/receive JSON messages.",
            "title": "Examples"
        },
        {
            "location": "/Subjects/NP2/P5/#information-representation-cbor",
            "text": "CBOR ( Concise Binary Object Representation ) is the recommended serialization\nformat in many IoT stacks, specifically in those based on CoAP. \nEven though it is a binary format, CBOR is similar in many ways with JSON, as it\nfollows the same data model: numeric values, strings, arrays, maps (objects in JSON)\nand null/boolean values.  However, differently from JSON, a CBOR object is autodescriptive, and this is\none if its advantages: it is possible to exchange data between a client and a server\nwithout using a pre-defined schema of data known by both parties.  The fact of being a binary format implies improvements w.r.t. JSON, for example when \ntransporting binary data (cipher keys, graphics, floating point values, among others); these\ndata were encoded in JSON using, for example base64 format, adding complexity in the \nprocess of codification/decodification. \nIn general, the use of a binary format implies less complexity when integrating in applications, \nand this is why it is considered to be optimum in low-power devices, such as IoT devices.   The CBOR format is documented in  RFC 7049 ,\nso it is considered to be a well documented standard, and stable for the future.",
            "title": "Information representation. CBOR"
        },
        {
            "location": "/Subjects/NP2/P5/#cbor-on-the-esp32",
            "text": "ESP-IDF includes the library  tinyCBOR  that \nhelps with the encoding of data into CBOR format, parsing\nCBOR structures and convering those structures bot to text format and to JSON.\nTinyCBOR is maintained as a free software project by Intel, and its documentation\n(that you should read as a reference) is available at  enlace .  Let us study the logics of  tinyCBOR  through an example (you can find it\nin the  examples/protocols/cbor  folder of IDF). The example\nshows the necessary mechanisms to, first, create a CBOR object using the library and,\nsecond, to convert the object to a JSON representation and parse it:  Compile, flash and execute the example. You should see that the output is similar to:   I (320) example: encoded buffer size 67\nI (320) example: convert CBOR to JSON\n[{\"chip\":\"esp32\",\"unicore\":false,\"ip\":[192,168,1,100]},3.1400001049041748,\"simple(99)\",\"2019-07-10 09:00:00+0000\",\"undefined\"]\nI (340) example: decode CBOR manually\nArray[\n  Map{\n    chip\n    esp32\n    unicore\n    false\n    ip\n    Array[\n      192\n      168\n      1\n      100\n    ]\n  }\n  3.14\n  simple(99)\n  2019-07-10 09:00:00+0000\n  undefined\n]  Note that the structure of a CBOR objct is complex: it is composed by an array with five elements:   A  map  (unnordered set of pairs  key-value ) combining strings, booleans and a second array to specify an IP address.  A floating point value (3.14).  A numeric \"simple\" value (99).  A date (as a string)  An undefined value.   The  firmware  proceeds in three stages:",
            "title": "CBOR on the ESP32"
        },
        {
            "location": "/Subjects/NP2/P5/#stage-1-creation-codification-of-a-cbor-object",
            "text": "Observe the body of the main task ( app_main ). The encoder for CBOR is based on two variables:  CborEncoder Root_encoder; // CBOR encoder.\nuint8_t buf[100];         // Buffer to allocate the CBOR object (array of bytes).  Second, and as we will use an array and a map, we will need constructors specifically desinged for those objects:  // Array creation.\nCborEncoder array_encoder;\nCborEncoder map_encoder;\n\ncbor_encoder_create_array(&root_encoder, &array_encoder, 5); // [\n  // 1. Map creation.\n  cbor_encoder_create_map(&array_encoder, &map_encoder, 3); // {  From this point on, we can proceed with the construction of the objects following the desired schema:    // chip: esp32 (string:string)\n  cbor_encode_text_stringz(&map_encoder, \"chip\");\n  cbor_encode_text_stringz(&map_encoder, \"esp32\");\n\n  // unicore: false (string:boolean)\n  cbor_encode_text_stringz(&map_encoder, \"unicore\");\n  cbor_encode_boolean(&map_encoder, false);\n\n  // IP:[192,168,1,100] (string:array)\n  cbor_encode_text_stringz(&map_encoder, \"ip\");\n\n    CborEncoder array2;\n\n    cbor_encoder_create_array(&map_encoder, &array2, 4); // [\n\n    // Numeric values.\n    cbor_encode_uint(&array2, 192);\n    cbor_encode_uint(&array2, 168);\n    cbor_encode_uint(&array2, 1);\n    cbor_encode_uint(&array2, 100);\n\n    cbor_encoder_close_container(&map_encoder, &array2);        // ]\n\n cbor_encoder_close_container(&array_encoder, &map_encoder); // }\n\n// 2. Flotanting point\ncbor_encode_float(&array_encoder, 3.14);\n\n// 3. Simple value \ncbor_encode_simple_value(&array_encoder, 99);\n\n// 4. String \ncbor_encode_text_stringz(&array_encoder, \"2019-07-10 09:00:00+0000\");\n\n// 5. Undefined value.\ncbor_encode_undefined(&array_encoder);\ncbor_encoder_close_container(&root_encoder, &array_encoder); // ]\n\n// Show the size of the created buffer.\nESP_LOGI(TAG, \"encoded buffer size %d\", cbor_encoder_get_buffer_size(&root_encoder, buf));",
            "title": "Stage 1: creation (codification) of a CBOR object"
        },
        {
            "location": "/Subjects/NP2/P5/#stage-2-conversion-to-json",
            "text": "The conversion to JSON (typically to visualize or debug) can be done as follows:      // Initialize the cbor parser and the value iterator\n    cbor_parser_init(buf, sizeof(buf), 0, &root_parser, &it);\n\n    ESP_LOGI(TAG, \"convert CBOR to JSON\");\n    // Dump the values in JSON format\n    cbor_value_to_json(stdout, &it, 0);",
            "title": "Stage 2: conversion to JSON"
        },
        {
            "location": "/Subjects/NP2/P5/#stage-3-manually-parsing-a-cbor-object",
            "text": "Last, the manual parsing of a CBOR object is left as an exercise for the student,\nand it is implemented in the funtion  example_dump_cbor_buffer  of the example.\nBasically, the function iterates over each one of the elements of the CBOR object,\nchecking each element and acting consequently. \nFor those types that are complex (e.g. arrays or maps), the function is invoked recursively\ntill finding a basic datatype. In this case, it just prints on screen its value (e.g. in the case\nof an integer, case  CborIntegerType ).   Task 1.5  Extend the REST API with a new  endpoint  that allows obtaining the same information than \nthe JSON  endpoint  developed in the last task, but in this case, using CBOR. The goal of the\ntask is to compare the amount of generated traffic in each representation, so it is suggested to\nuse a relatively complex object (different numeric types, arrays or maps). Next, we include \nadditional notes that will help you in the solution for debugging purposes, observing the returned\nvalues by the HTTP server.",
            "title": "Stage 3: manually parsing a CBOR object"
        },
        {
            "location": "/Subjects/NP2/P5/#additional-notes-creation-and-query-of-a-cbor-endpoint-in-the-rest-api",
            "text": "The modifications to carry out in the handler funtion of the endpoint to answer with a CBOR\nobject are minimal. Actually, they are focused simply on the type of response and the mechanism to send it, namely:  static esp_err_t system_info_get_handler(httpd_req_t *req)\n{\n    // Response type. \n    httpd_resp_set_type(req, \"application/cbor\");\n\n    CborEncoder root_encoder;\n    uint8_t buf[100];\n\n    // CBOR encoder\n    cbor_encoder_init(&root_encoder, buf, sizeof(buf), 0);\n\n    // Encoding CBOR.\n    // ...\n\n    // Send response, checking previously the size of the encoded buffer.\n    httpd_resp_send(req, (char*)buf, cbor_encoder_get_buffer_size( &root_encoder, buf));\n\n    return ESP_OK;  To query from command line on this endpoint, we can use directly  curl , redirecting the received\noutput to a file (e.g.   output.cbor ):  curl http://192.168.1.26/api/v1/system/info > output.cbor  If we visualize the contents of the file, we can observe that it contains binary data, \ndificult to analayze. In the following, we well see different visualization mechanisms.",
            "title": "Additional notes: creation and query of a CBOR endpoint in the REST API"
        },
        {
            "location": "/Subjects/NP2/P5/#additional-notes-visualizing-cbor-data",
            "text": "A visualization option consists on using the web  cbor.me .\nIn the right panel, you can paste the binary contents read. If you need to \nperform a conversion before pasting on the web, you can do it with:  xxd -ps output.cbor  An output example (to be pased on the right panel of the web), could be:  $ xxd -ps output.cbor \n85a3646368697065657370333267756e69636f7265f46269708418c018a8\n011864fa4048f5c3f8637818323031392d30372d31302030393a30303a30\n302b30303030f7  You shouls see a similar output as the one shown next (take into accounnt that\nthe tools automatically indents the contents of the right panel; rememebre that you need to just paste the output generated by  xxd ):   Other visualization option can be a Python program (it could actually be integrated \nwithin your TCP/UDP client/server, for example) that makes use of the  cbor2  module ( documentation ). To check\nhow it works, first install it:  pip install cbor2  And theck if it effectively works using the following Python program:  from cbor2 import dumps, loads, dump, load\n\nwith open('output.cbor', 'rb') as fp:\n    obj = load(fp)\n\nprint(obj)  When executed, you will observe the contents of the object:  python cbor.py\n[{'chip': 'esp32', 'unicore': False, 'ip': [192, 168, 1, 100]}, 3.140000104904175, CBORSimpleValue(value=99), '2019-07-10 09:00:00+0000', undefined]",
            "title": "Additional notes: visualizing CBOR data"
        },
        {
            "location": "/Subjects/NP2/P5/notas/",
            "text": "Implementaci\u00f3n de una interfaz REST v\u00eda HTTP\n\n\nEjemplo\n\n\n\n\nEjemplo: restful_server\n\n\nnavegar a front/webdemo\n\n\napt-get install npm node-vue*\n\n\nnpm install y npm run build en direcrorio front/web-demo\n\n\nidf.py build",
            "title": "Notas"
        },
        {
            "location": "/Subjects/NP2/P5/notas/#implementacion-de-una-interfaz-rest-via-http",
            "text": "",
            "title": "Implementaci\u00f3n de una interfaz REST v\u00eda HTTP"
        },
        {
            "location": "/Subjects/NP2/P5/notas/#ejemplo",
            "text": "Ejemplo: restful_server  navegar a front/webdemo  apt-get install npm node-vue*  npm install y npm run build en direcrorio front/web-demo  idf.py build",
            "title": "Ejemplo"
        },
        {
            "location": "/Subjects/NP2/P6/",
            "text": "Laboratory 4. MQTT (I). Deployment of clients and servers/brokers. Traffic analysis\n\n\nObjectives\n\n\n\n\n\n\nTo familiarize with the use of brokers and clients for subscription/publication using MQTT.\n\n\n\n\n\n\nTo deploy a system based on MQTT locally, including broker and clients.\n\n\n\n\n\n\nTo use Eclipse Paho to integrate functionality for MQTT in Python programs.\n\n\n\n\n\n\nTo familiarize with the use of MQTT wildcards.\n\n\n\n\n\n\nPublication/subscription on a broker in the cloud\n\n\nIn this first part, we will use a server/broker available in the cloud for its use\nfrom users (\ntest.mosquitto.org\n). \nThis server is usually employed for testing and debugging, and you need to realize that\nall the information published on it can be read by any subscriptor. Take this into account\nwhen publishing important information via MQTT.\n\n\nThe server listens on the following ports:\n\n\n\n\n1883\n: MQTT, no encryption.\n\n\n8883\n: MQTT, with encryption.\n\n\n8884\n: MQTT, with encryption, user certificate required.\n\n\n8080\n: MQTT over WebSockets, without encryption.\n\n\n8081\n: MQTT over WebSockets, with encryption.\n\n\n\n\nIn order to perform publications/subscriptions on the broker, we will use\nthe \nmosquitto\n distribution from the Eclipse IoT projecto.\nEven thourgh \nmosquitto\n is mainly an implementation of an MQTT broker, we will use it in this\nstep as a client; this will allow us to subscribe or publish on any MQTT topic.\n\n\nFirst, install \nmosquitto\n:\n\n\nsudo apt-get install mosquitto mosquitto-clients mosquitto-dev libmosquitto*\n\n\n\n\nProvided there were no errors, you will find two binaries ready for execution:\n\n\n\n\nmosquitto_sub\n: to subscribe to a given topic via a broker.\n\n\nmosquitto_pub\n: to publish a message associated to a given topic via a  broker.\n\n\n\n\n\n\nTask\n\n\nObserve the help of both commands, using the argument \n--help\n. Identify\n\nthe parameters that allow specifying the destination broker, the topic to use and, when publishing\nthe message to send.\n\n\n\n\nLet us subscribe to the topic \n#\n in the broker, using the order:\n\n\nmosquitto_sub -h test.mosquitto.org  -t \"#\"\n\n\n\n\n\n\nTask\n\n\nPause the output (Ctrl+C) as soon as you can. What are the messages you are observing?\n\n\n\n\nNext, we will complete a process of publication/subscription with a known topic (e.g. \n\n/MIOT/yourname/\n). In order to publish a message under this topic:\n\n\nmosquitto_pub -h test.mosquitto.org -t \"/MIOT/tunombre\" -m \"Hola, soy tunombre\"\n\n\n\n\n\n\nTask\n\n\nSubscribe to the topic \n/MIOT/yourname\n and observe if you can receive the results\nafter the corresponding publication. How could you subscribe to all messages published\nby your classmates?\n\n\n\n\n\n\nTask\n\n\nPerform an analysis of the message excghanges necessary for a process of \npublication/subscription on the test broker. Study the type of protocol\nof the transport layer that is used by MQTT, data and control messages, protocol\noverhead and, in general, any aspect that you consider of interest.\n\n\n\n\nDeploying a local broker using Eclipse Mosquitto\n\n\nThe use of a remote server presents advantages (ease of use), but a series of \ninconvenients (security, lack of configuration mechanisms, ...).\n\n\nIn this section, we will configure a \nmosquitto\n borker to deploy a local\nMQTT infrastructure under our control.\n\n\nBooting a broker (server) in mosquitto is performed via the command \nmosquitto\n:\n\n\nmosquitto [-c config file] [ -d | --daemon ] [-p port number] [-v]\n\n\n\n\nHowever, in many Linux distributions, the broker boots by default on system boot, \nand it is executed continously in background. In order to check the status of \nthe broker, you can execute:\n\n\nsudo service mosquitto status\n\n\n\n\nYou will observe a message that indicates that the service is active. The options\n\nrestart\n, \nstart\n or \nstop\n will allow you to control the status of the broker.\n\n\n\n\nTask\n\n\nCheck that, with the broker online, you can perform a subscription/publication\nprocess on it.\n\n\n\n\nThe mosquitto broker allows a monitorization of statistics and information of its\nstatus using the MQTT protocol. Hence, the topics \n$SYS\n return, periodically\nor when an event occurs, the information of the status of the broker. You can\nquery more details in the manual page of \nmosquitto\n\n(command \nman mosquitto\n), under the section \nBROKER STATUS\n.\n\n\n\n\nTask\n\n\nQuery the status of the broker while you perform subscription/publication processes,\nreporting received/sent bytes, number of active/inactive connections, and number of \nsent/received bytes by the broker.\n\n\n\n\nDeveloping a local client using Eclipse Paho\n\n\nThe clients \nmosquitto_pub\n and \nmosquitto_sub\n are bsically tools for development and\ntesting, but it is interesting to know libraries that allow the integration\nof MQTT into existing programs. One of them is \nEclipse Paho\n. \nPaho is an infrastructure devleloped by the Eclipse IoT project to support implementations\nof protocols of instant messaging (M2M and IoT), even though as of today, it is exclusively\nfocused on MQTT.\n\n\nIn our case, we will use the Python version of the library, that can be installed via:\n\n\npip install paho-mqtt\n\n\n\n\nAll documentation for the module is available via \nthis link\n.\n\n\nThe deployment of simple example for a client that connects to a broker and subscribes to the\n\n$SYS\n topic, printing all received messages, would result, using Paho from Python, in:\n\n\nimport paho.mqtt.client as mqtt\n\n# Callback function invoked qhen the client receives a CONNACK from the broker.\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connected with result code \"+str(rc))\n\n    # Subscribin in on_connect() makes sure that if connection is lost and restablished,\n    # the subscription will be renewed\n    client.subscribe(\"$SYS/#\")\n\n# Callback function upon publication message reception (PUBLISH) from the broker.\ndef on_message(client, userdata, msg):\n    print(msg.topic+\" \"+str(msg.payload))\n\nclient = mqtt.Client()\nclient.on_connect = on_connect\nclient.on_message = on_message\n\nclient.connect(\"mqtt.eclipse.org\", 1883, 60)\n\n# Blocking call that processes network traffic, invokes callbacks and handles broker reconnections.\nclient.loop_forever()\n\n\n\n\nThe client class can be used to:\n\n\n\n\nCreate an instance of an MQTT client.\n\n\nConnect to a \nbroker\n using the functions of the \nconnect*()\n family.\n\n\nInvoke functions of the \nloop*()\n family to maintain data traffic with the server.\n\n\nUse \nsubscribe()\n to subscribe to a topic or receiving messages.\n\n\nUse \npublish()\n to publish messages in the broker.\n\n\nUse \ndisconnect()\n to disconnect from the broker.\n\n\n\n\nThe callbacks will be invoked automatically to allow processing events. Among other, we highlight:\n\n\n\n\nON_CONNECT\n: invoked when the broker responds to our connection request. Example:\n\n\n\n\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connection returned result: \"+connack_string(rc))\n\n\n\n\n\n\nON_DISCONNECT\n: invoked when the client disconnects from the broker. Example:\n\n\n\n\ndef on_disconnect(client, userdata, rc):\n    if rc != 0:\n        print(\"Unexpected disconnection.\")\n\n\n\n\n\n\nON_MESSAGE\n: invoked when a message on a topic is received and the client is subscribed:\nExample:\n\n\n\n\ndef on_message(client, userdata, message):\n    print(\"Received message '\" + str(message.payload) + \"' on topic '\"\n        + message.topic + \"' with QoS \" + str(message.qos))\n\n\n\n\nIn order to publish on a punctual manner on a broker (without keeping a connection\nopen), it is possible to use the following sequence of orders:\n\n\nimport paho.mqtt.publish as publish\n\npublish.single(\"paho/test/single\", \"payload\", hostname=\"mqtt.eclipse.org\")\n\n\n\n\nSimilarly, we can subscribe only to a topic with a blocking call as:\n\n\nimport paho.mqtt.subscribe as subscribe\n\nmsg = subscribe.simple(\"paho/test/simple\", hostname=\"mqtt.eclipse.org\")\nprint(\"%s %s\" % (msg.topic, msg.payload))\n\n\n\n\nAll the information and documentation for the module can be found \nhere\n.\n\n\nWildcards\n\n\nIn addition of using complete topics for the subscription process, topics can include wildcards\nin their structure. \n\n+\n is the wildcard used to obtain correspondences with a unique level of the hierarchy. Hence\nfor a topic \na/b/c/d\n, the following subscriptions would match:\n\n\n\n\na/b/c/d\n\n\n+/b/c/d\n\n\na/+/c/d\n\n\na/+/+/d\n\n\n+/+/+/+\n\n\n\n\nBut not the following:\n\n\n\n\na/b/c\n\n\nb/+/c/d\n\n\n+/+/+\n\n\n\n\nThe second wildcard supported is \n#\n, and permits matchings on any successive level of the \nhierarchy. Hence for a topic \na/b/c/d\n, the following subscriptions would match:\n\n\n\n\na/b/c/d\n\n\n#\n\n\na/#\n\n\na/b/#\n\n\na/b/c/#\n\n\n+/b/c/#\n\n\n\n\n\n\nTask\n\n\nEach student will propose a solution to monitor traffic on an intelligent building\nvia MQTT. For that, the building will be composed by:\n\n\n\n\nAn identifier: \nBUILDING_NAME\n.\n\n\nA set of floors, identified by the string \nP_NUMFLOOR\n.\n\n\nFor each plant, four wings (north -N-, south -S-, east -E-, west -O-)\n\n\nAt each wing, a set of rooms, identified by a numeric value.\n\n\nFor each room, four sensors: TEMP (temperature), HUM (humidity), LUX (luminosity), VIBR (vibration).\n\n\n\n\nFirst, design the hierarcy of topics that allows a correct monitorization of the buildings.\n\n\nSecond, you will develop a Python client that publishes, periodically and in a random manner,\nJSON objects (optionally, you can use CBOR) that include values for temperature, humidity, luminosity\nor vibration for a specific room of the building, also chosen randomly, via a topic. These messages\nwill be  separated in time a random number of seconds.\n\n\nThird, define the wildcards that allow querying for different types of information in a hierarchical\nfashion. For example:\n\n\n\n\nAll messages of temperature for the building.\n\n\nAll messages of vibration for the west wing of the second floor of the building.\n\n\nAll sensorization messages for the room number 4 of the south wing of floor 7 in the building.\n\n\n...\n\n\n\n\nLast, develop a Python program that acts as an alarm, and that shows on screen messages only if a \nreceived value is above a pre-established threshold. In that case, the program will show\nthe building, floor, wing, room and sensor that produced the alarm, together with its numeric value.\n\n\nYou can use the  \nJSON module\n\nto parse the receive objects.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P6/#laboratory-4-mqtt-i-deployment-of-clients-and-serversbrokers-traffic-analysis",
            "text": "",
            "title": "Laboratory 4. MQTT (I). Deployment of clients and servers/brokers. Traffic analysis"
        },
        {
            "location": "/Subjects/NP2/P6/#objectives",
            "text": "To familiarize with the use of brokers and clients for subscription/publication using MQTT.    To deploy a system based on MQTT locally, including broker and clients.    To use Eclipse Paho to integrate functionality for MQTT in Python programs.    To familiarize with the use of MQTT wildcards.",
            "title": "Objectives"
        },
        {
            "location": "/Subjects/NP2/P6/#publicationsubscription-on-a-broker-in-the-cloud",
            "text": "In this first part, we will use a server/broker available in the cloud for its use\nfrom users ( test.mosquitto.org ). \nThis server is usually employed for testing and debugging, and you need to realize that\nall the information published on it can be read by any subscriptor. Take this into account\nwhen publishing important information via MQTT.  The server listens on the following ports:   1883 : MQTT, no encryption.  8883 : MQTT, with encryption.  8884 : MQTT, with encryption, user certificate required.  8080 : MQTT over WebSockets, without encryption.  8081 : MQTT over WebSockets, with encryption.   In order to perform publications/subscriptions on the broker, we will use\nthe  mosquitto  distribution from the Eclipse IoT projecto.\nEven thourgh  mosquitto  is mainly an implementation of an MQTT broker, we will use it in this\nstep as a client; this will allow us to subscribe or publish on any MQTT topic.  First, install  mosquitto :  sudo apt-get install mosquitto mosquitto-clients mosquitto-dev libmosquitto*  Provided there were no errors, you will find two binaries ready for execution:   mosquitto_sub : to subscribe to a given topic via a broker.  mosquitto_pub : to publish a message associated to a given topic via a  broker.    Task  Observe the help of both commands, using the argument  --help . Identify \nthe parameters that allow specifying the destination broker, the topic to use and, when publishing\nthe message to send.   Let us subscribe to the topic  #  in the broker, using the order:  mosquitto_sub -h test.mosquitto.org  -t \"#\"   Task  Pause the output (Ctrl+C) as soon as you can. What are the messages you are observing?   Next, we will complete a process of publication/subscription with a known topic (e.g.  /MIOT/yourname/ ). In order to publish a message under this topic:  mosquitto_pub -h test.mosquitto.org -t \"/MIOT/tunombre\" -m \"Hola, soy tunombre\"   Task  Subscribe to the topic  /MIOT/yourname  and observe if you can receive the results\nafter the corresponding publication. How could you subscribe to all messages published\nby your classmates?    Task  Perform an analysis of the message excghanges necessary for a process of \npublication/subscription on the test broker. Study the type of protocol\nof the transport layer that is used by MQTT, data and control messages, protocol\noverhead and, in general, any aspect that you consider of interest.",
            "title": "Publication/subscription on a broker in the cloud"
        },
        {
            "location": "/Subjects/NP2/P6/#deploying-a-local-broker-using-eclipse-mosquitto",
            "text": "The use of a remote server presents advantages (ease of use), but a series of \ninconvenients (security, lack of configuration mechanisms, ...).  In this section, we will configure a  mosquitto  borker to deploy a local\nMQTT infrastructure under our control.  Booting a broker (server) in mosquitto is performed via the command  mosquitto :  mosquitto [-c config file] [ -d | --daemon ] [-p port number] [-v]  However, in many Linux distributions, the broker boots by default on system boot, \nand it is executed continously in background. In order to check the status of \nthe broker, you can execute:  sudo service mosquitto status  You will observe a message that indicates that the service is active. The options restart ,  start  or  stop  will allow you to control the status of the broker.   Task  Check that, with the broker online, you can perform a subscription/publication\nprocess on it.   The mosquitto broker allows a monitorization of statistics and information of its\nstatus using the MQTT protocol. Hence, the topics  $SYS  return, periodically\nor when an event occurs, the information of the status of the broker. You can\nquery more details in the manual page of  mosquitto \n(command  man mosquitto ), under the section  BROKER STATUS .   Task  Query the status of the broker while you perform subscription/publication processes,\nreporting received/sent bytes, number of active/inactive connections, and number of \nsent/received bytes by the broker.",
            "title": "Deploying a local broker using Eclipse Mosquitto"
        },
        {
            "location": "/Subjects/NP2/P6/#developing-a-local-client-using-eclipse-paho",
            "text": "The clients  mosquitto_pub  and  mosquitto_sub  are bsically tools for development and\ntesting, but it is interesting to know libraries that allow the integration\nof MQTT into existing programs. One of them is  Eclipse Paho . \nPaho is an infrastructure devleloped by the Eclipse IoT project to support implementations\nof protocols of instant messaging (M2M and IoT), even though as of today, it is exclusively\nfocused on MQTT.  In our case, we will use the Python version of the library, that can be installed via:  pip install paho-mqtt  All documentation for the module is available via  this link .  The deployment of simple example for a client that connects to a broker and subscribes to the $SYS  topic, printing all received messages, would result, using Paho from Python, in:  import paho.mqtt.client as mqtt\n\n# Callback function invoked qhen the client receives a CONNACK from the broker.\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connected with result code \"+str(rc))\n\n    # Subscribin in on_connect() makes sure that if connection is lost and restablished,\n    # the subscription will be renewed\n    client.subscribe(\"$SYS/#\")\n\n# Callback function upon publication message reception (PUBLISH) from the broker.\ndef on_message(client, userdata, msg):\n    print(msg.topic+\" \"+str(msg.payload))\n\nclient = mqtt.Client()\nclient.on_connect = on_connect\nclient.on_message = on_message\n\nclient.connect(\"mqtt.eclipse.org\", 1883, 60)\n\n# Blocking call that processes network traffic, invokes callbacks and handles broker reconnections.\nclient.loop_forever()  The client class can be used to:   Create an instance of an MQTT client.  Connect to a  broker  using the functions of the  connect*()  family.  Invoke functions of the  loop*()  family to maintain data traffic with the server.  Use  subscribe()  to subscribe to a topic or receiving messages.  Use  publish()  to publish messages in the broker.  Use  disconnect()  to disconnect from the broker.   The callbacks will be invoked automatically to allow processing events. Among other, we highlight:   ON_CONNECT : invoked when the broker responds to our connection request. Example:   def on_connect(client, userdata, flags, rc):\n    print(\"Connection returned result: \"+connack_string(rc))   ON_DISCONNECT : invoked when the client disconnects from the broker. Example:   def on_disconnect(client, userdata, rc):\n    if rc != 0:\n        print(\"Unexpected disconnection.\")   ON_MESSAGE : invoked when a message on a topic is received and the client is subscribed:\nExample:   def on_message(client, userdata, message):\n    print(\"Received message '\" + str(message.payload) + \"' on topic '\"\n        + message.topic + \"' with QoS \" + str(message.qos))  In order to publish on a punctual manner on a broker (without keeping a connection\nopen), it is possible to use the following sequence of orders:  import paho.mqtt.publish as publish\n\npublish.single(\"paho/test/single\", \"payload\", hostname=\"mqtt.eclipse.org\")  Similarly, we can subscribe only to a topic with a blocking call as:  import paho.mqtt.subscribe as subscribe\n\nmsg = subscribe.simple(\"paho/test/simple\", hostname=\"mqtt.eclipse.org\")\nprint(\"%s %s\" % (msg.topic, msg.payload))  All the information and documentation for the module can be found  here .",
            "title": "Developing a local client using Eclipse Paho"
        },
        {
            "location": "/Subjects/NP2/P6/#wildcards",
            "text": "In addition of using complete topics for the subscription process, topics can include wildcards\nin their structure.  +  is the wildcard used to obtain correspondences with a unique level of the hierarchy. Hence\nfor a topic  a/b/c/d , the following subscriptions would match:   a/b/c/d  +/b/c/d  a/+/c/d  a/+/+/d  +/+/+/+   But not the following:   a/b/c  b/+/c/d  +/+/+   The second wildcard supported is  # , and permits matchings on any successive level of the \nhierarchy. Hence for a topic  a/b/c/d , the following subscriptions would match:   a/b/c/d  #  a/#  a/b/#  a/b/c/#  +/b/c/#    Task  Each student will propose a solution to monitor traffic on an intelligent building\nvia MQTT. For that, the building will be composed by:   An identifier:  BUILDING_NAME .  A set of floors, identified by the string  P_NUMFLOOR .  For each plant, four wings (north -N-, south -S-, east -E-, west -O-)  At each wing, a set of rooms, identified by a numeric value.  For each room, four sensors: TEMP (temperature), HUM (humidity), LUX (luminosity), VIBR (vibration).   First, design the hierarcy of topics that allows a correct monitorization of the buildings.  Second, you will develop a Python client that publishes, periodically and in a random manner,\nJSON objects (optionally, you can use CBOR) that include values for temperature, humidity, luminosity\nor vibration for a specific room of the building, also chosen randomly, via a topic. These messages\nwill be  separated in time a random number of seconds.  Third, define the wildcards that allow querying for different types of information in a hierarchical\nfashion. For example:   All messages of temperature for the building.  All messages of vibration for the west wing of the second floor of the building.  All sensorization messages for the room number 4 of the south wing of floor 7 in the building.  ...   Last, develop a Python program that acts as an alarm, and that shows on screen messages only if a \nreceived value is above a pre-established threshold. In that case, the program will show\nthe building, floor, wing, room and sensor that produced the alarm, together with its numeric value.  You can use the   JSON module \nto parse the receive objects.",
            "title": "Wildcards"
        },
        {
            "location": "/Subjects/NP2/P6-II/",
            "text": "Laboratory 4. MQTT (II). Client deployments on the ESP32\n\n\nObjectives\n\n\n\n\n\n\nTo get familiar with the MQTT component in ESP-IDF.\n\n\n\n\n\n\nTo deploy a complete MQTT client on the ESP32, including routines for publication and subscription.\n\n\n\n\n\n\nTo implement QoS and LWT on the ESP32.\n\n\n\n\n\n\nThe MQTT component in ESP-IDF\n\n\nThe ESP-MQTT component is an implementation of the MQTT protocol (in its\nclient part), that allows the implementation of complete MQTT clients on the\nESP32, including routines for publication and subscription to brokers.\n\n\nThe component supports MQTT over TCP by default, and advanced functionalities\nsuch as SSL/TLS support or MQTT over Websockets. In addition, it allows the\ndeployment of multiple instances of MQTT clients on the same boar; the component\nimplements advanced parameters supported by MQTT, such as authentication\n(using username and password), \nlast will\n messages and three\nlevels of QoS.\n\n\nEvents\n\n\nAs other components, the interactiin between the MQTT client and the application\nis based on the reception and treatment of events, being the most important:\n\n\n\n\nMQTT_EVENT_BEFORE_CONNECT\n: The client has been initialized and is about to\ncommence the connection process with the remote broker.\n\n\nMQTT_EVENT_CONNECTED\n: The client has successfully established a connection with the\nbroker and it is ready to send and receive data.\n\n\nMQTT_EVENT_DISCONNECTED\n: The client has aborted the connection.\n\n\nMQTT_EVENT_SUBSCRIBED\n: The broker has confirmed the request for subscription from the client.\nData will contain the ID of the subscription message.\n\n\nMQTT_EVENT_UNSUBSCRIBED\n: The broker confirms the request of desubsuscription from the client. \nData will contain the ID of the desubscription message.\n\n\nMQTT_EVENT_PUBLISHED\n: The broker has sent an ACK for the reception of a message\npreviously published by a client. This event will only be produced when QoS is\n1 or 2, as the level 0 for QoS does not use ACKs. Data associated with the event will contain\nthe ID of the published message.\n\n\nMQTT_EVENT_DATA\n: The client has received a message published by the broker. Data associated\nto the event will contain the ID of the message, name of the topic and received data (an its length).\n\n\n\n\nAPI\n\n\n\n\nesp_mqtt_client_handle_t esp_mqtt_client_init(const esp_mqtt_client_config_t *config)\n\n\n\n\nInitialization routine for the MQTT client. It returns a connection handler, or NULL in case of error.\nThe \nconfig\n paramter is a structure with the parameters that will rule the connection, being \nthe most important\n(see \nthe component documentation\n\nfor additional parameters):\n\n\n\n\nesp_event_loop_handle_t event_loop_handle\n: hanlder for MQTT events.\n\n\nconst char *uri\n: URI of the MQTT \nbroker\n.\n\n\nuint32_t port\n: port of the MQTT \nbroker\n.\n\n\nconst char *username\n: username, in case it is supported by the broker.\n\n\nconst char *password\n: password, in case it is supported by the broker.\n\n\nconst char *lwt_topic\n: topic of the LWT message (\nLast Will and Testament\n).\n\n\nconst char *lwt_msg\n: contents of the LWT message.\n\n\nint lwt_qos\n: QoS of the LWT message.\n\n\nint lwt_retain\n: flag \nretain\n for the LWT message.\n\n\nint lwt_msg_len\n: length of the LWT message.\n\n\n\n\nint keepalive\n: value for the \nkeepalive\n timer (by default 120 seconds).\n\n\n\n\n\n\nesp_err_t esp_mqtt_client_start(esp_mqtt_client_handle_t client)\n\n\n\n\n\n\nBoot routine for the MQTT client. Its only parameter is the handler returned by the previous routine.\n\n\n\n\nint esp_mqtt_client_subscribe(esp_mqtt_client_handle_t client, const char *topic, int qos)\n\n\n\n\nSubscribes the client to a topic with a given QoS via the third parameter. The client must\nbe connected to the broker to send the subscription message.\n\n\n\n\nint esp_mqtt_client_unsubscribe(esp_mqtt_client_handle_t client, const char *topic)\n\n\n\n\nDesubscribes\n the client from a given topic. The client must be connected to the \nbroker to send the corresponding message.\n\n\n\n\nint esp_mqtt_client_publish(esp_mqtt_client_handle_t client, const char *topic, const char *data, int len, int qos, int retain)\n\n\n\n\nThe client publishes a message on the broker. The client does not need to be connected\nto the broker to send the publication message. In that case, if \n\nqos=0\n, messages will be discarded,\n\nand if \nqos>=1\n, messages will be queued waiting to be sent.\nThe routine returs the identifier of the published message (if \nqos=0\n, the return value will be always 0)\nor \n-1\n in case of error.\n\n\nParameters of interest:\n\n\n\n\nclient\n: MQTT client handler.\n\n\ntopic\n: topic (as a string) under whigh the message will be published.\n\n\ndata\n: contents of the message to publish (it is possible to publish a message withouth contents if \nNULL\n is used).\n\n\nlen\n: lenght, in bytes, of the data to send. If \n0\n is provided, it is calculated based on the length of the \ndata\n string.\n\n\nqos\n: desired QoS level.\n\n\nretain\n: flag \nRetain\n.\n\n\n\n\n\n\nTask\n\n\nAnalyze the example \nexamples/protocols/mqtt/tcp\n, and configure it so that\nit uses as a broker the mosquitto broker you deployed in your Virtual Machine\n(first, make sure that both the Virtual Machine and the ESP32 belong to the same network).\n\n\nPerform tests for publication and subscription in the Virtual Machine that \nallow you to visualize the messages published by the ESP32 in your terminal,\nand the messages published from the terminal in the monitor output of the \nESP32.\n\n\nModify the example and analyze the generated traffic (via Wireshark)\nfor the following cases:\n\n\n\n\nPublication of messages with QoS levels 0, 1 and 2. \n\n\nActivation and deactivatio of the \nretain\n flag in the publication from the ESP32.\n\n\nConfiguration of a LWT message with the topic \n/disconnected\n. For that,\nreduce the valua of \nkeepalive\n to 10 seconds, so that the detection of a \ndisconnection is faster. You should observe the submission of a message\nwith the selected topic upon the timer expiration, starting from a forced\ndisconnection of the ESP32 (you will need to be subscribed to it from Linux).\n\n\n\n\n\n\n\n\nTask\n\n\nModify the example so that it is integrated in your building monitoring\nand alarm system. The firmware will proceed by creating a task that, periodically\n(every \ninterval\n seconds) publishes a random value for the four monitored values.\n\n\nIn addition, you will need to design a system based on MQTT so that you can control,\nexternally, the behavior of the sensor, attending to:\n\n\n\n\nThe time (\ninterval\n) that will pass between publications will be configurable via\na message published from your terminal, to which the ESP32 will be subscribed.\n\n\nThe sensorization (and data publicaiton) will be activated or deactivated on demand, \nvia a publication from your Linux terminal and subscription from the ESP32 to a specific topic.\n\n\n\n\nFor example, imagine that your sensor publishes messages under the topic\n\n/BUILDING_3/P_4/N/12/(TEMP|HUM|LUX|VIBR)\n. To control the interval of \npublication time from that ESP32, and fix it to 1 second, we could publish a \nmessage using:\n\n\nmosquitto_pub -t /BUILDING_3/P_4/N/12/interval\n -m \"1000\" -h IP_BROKER\n\n\nTo disable the sensor:\n\n\nmosquitto_pub -t /BUILDING_3/P_4/N/12/disable\n -m \"\" -h IP_BROKER\n\n\nTo enable the sensor:\n\n\nmosquitto_pub -t /BUILDING_3/P_4/N/12/enable\n -m \"\" -h IP_BROKER\n\n\n\n\nOptionally, you can extend your solution so that each sensor is activated or deactivated\nindividually on demand. For that to happen, choose and document the selected topic that you \nshould employ.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P6-II/#laboratory-4-mqtt-ii-client-deployments-on-the-esp32",
            "text": "",
            "title": "Laboratory 4. MQTT (II). Client deployments on the ESP32"
        },
        {
            "location": "/Subjects/NP2/P6-II/#objectives",
            "text": "To get familiar with the MQTT component in ESP-IDF.    To deploy a complete MQTT client on the ESP32, including routines for publication and subscription.    To implement QoS and LWT on the ESP32.",
            "title": "Objectives"
        },
        {
            "location": "/Subjects/NP2/P6-II/#the-mqtt-component-in-esp-idf",
            "text": "The ESP-MQTT component is an implementation of the MQTT protocol (in its\nclient part), that allows the implementation of complete MQTT clients on the\nESP32, including routines for publication and subscription to brokers.  The component supports MQTT over TCP by default, and advanced functionalities\nsuch as SSL/TLS support or MQTT over Websockets. In addition, it allows the\ndeployment of multiple instances of MQTT clients on the same boar; the component\nimplements advanced parameters supported by MQTT, such as authentication\n(using username and password),  last will  messages and three\nlevels of QoS.",
            "title": "The MQTT component in ESP-IDF"
        },
        {
            "location": "/Subjects/NP2/P6-II/#events",
            "text": "As other components, the interactiin between the MQTT client and the application\nis based on the reception and treatment of events, being the most important:   MQTT_EVENT_BEFORE_CONNECT : The client has been initialized and is about to\ncommence the connection process with the remote broker.  MQTT_EVENT_CONNECTED : The client has successfully established a connection with the\nbroker and it is ready to send and receive data.  MQTT_EVENT_DISCONNECTED : The client has aborted the connection.  MQTT_EVENT_SUBSCRIBED : The broker has confirmed the request for subscription from the client.\nData will contain the ID of the subscription message.  MQTT_EVENT_UNSUBSCRIBED : The broker confirms the request of desubsuscription from the client. \nData will contain the ID of the desubscription message.  MQTT_EVENT_PUBLISHED : The broker has sent an ACK for the reception of a message\npreviously published by a client. This event will only be produced when QoS is\n1 or 2, as the level 0 for QoS does not use ACKs. Data associated with the event will contain\nthe ID of the published message.  MQTT_EVENT_DATA : The client has received a message published by the broker. Data associated\nto the event will contain the ID of the message, name of the topic and received data (an its length).",
            "title": "Events"
        },
        {
            "location": "/Subjects/NP2/P6-II/#api",
            "text": "esp_mqtt_client_handle_t esp_mqtt_client_init(const esp_mqtt_client_config_t *config)   Initialization routine for the MQTT client. It returns a connection handler, or NULL in case of error.\nThe  config  paramter is a structure with the parameters that will rule the connection, being \nthe most important\n(see  the component documentation \nfor additional parameters):   esp_event_loop_handle_t event_loop_handle : hanlder for MQTT events.  const char *uri : URI of the MQTT  broker .  uint32_t port : port of the MQTT  broker .  const char *username : username, in case it is supported by the broker.  const char *password : password, in case it is supported by the broker.  const char *lwt_topic : topic of the LWT message ( Last Will and Testament ).  const char *lwt_msg : contents of the LWT message.  int lwt_qos : QoS of the LWT message.  int lwt_retain : flag  retain  for the LWT message.  int lwt_msg_len : length of the LWT message.   int keepalive : value for the  keepalive  timer (by default 120 seconds).    esp_err_t esp_mqtt_client_start(esp_mqtt_client_handle_t client)    Boot routine for the MQTT client. Its only parameter is the handler returned by the previous routine.   int esp_mqtt_client_subscribe(esp_mqtt_client_handle_t client, const char *topic, int qos)   Subscribes the client to a topic with a given QoS via the third parameter. The client must\nbe connected to the broker to send the subscription message.   int esp_mqtt_client_unsubscribe(esp_mqtt_client_handle_t client, const char *topic)   Desubscribes  the client from a given topic. The client must be connected to the \nbroker to send the corresponding message.   int esp_mqtt_client_publish(esp_mqtt_client_handle_t client, const char *topic, const char *data, int len, int qos, int retain)   The client publishes a message on the broker. The client does not need to be connected\nto the broker to send the publication message. In that case, if  qos=0 , messages will be discarded, \nand if  qos>=1 , messages will be queued waiting to be sent.\nThe routine returs the identifier of the published message (if  qos=0 , the return value will be always 0)\nor  -1  in case of error.  Parameters of interest:   client : MQTT client handler.  topic : topic (as a string) under whigh the message will be published.  data : contents of the message to publish (it is possible to publish a message withouth contents if  NULL  is used).  len : lenght, in bytes, of the data to send. If  0  is provided, it is calculated based on the length of the  data  string.  qos : desired QoS level.  retain : flag  Retain .    Task  Analyze the example  examples/protocols/mqtt/tcp , and configure it so that\nit uses as a broker the mosquitto broker you deployed in your Virtual Machine\n(first, make sure that both the Virtual Machine and the ESP32 belong to the same network).  Perform tests for publication and subscription in the Virtual Machine that \nallow you to visualize the messages published by the ESP32 in your terminal,\nand the messages published from the terminal in the monitor output of the \nESP32.  Modify the example and analyze the generated traffic (via Wireshark)\nfor the following cases:   Publication of messages with QoS levels 0, 1 and 2.   Activation and deactivatio of the  retain  flag in the publication from the ESP32.  Configuration of a LWT message with the topic  /disconnected . For that,\nreduce the valua of  keepalive  to 10 seconds, so that the detection of a \ndisconnection is faster. You should observe the submission of a message\nwith the selected topic upon the timer expiration, starting from a forced\ndisconnection of the ESP32 (you will need to be subscribed to it from Linux).     Task  Modify the example so that it is integrated in your building monitoring\nand alarm system. The firmware will proceed by creating a task that, periodically\n(every  interval  seconds) publishes a random value for the four monitored values.  In addition, you will need to design a system based on MQTT so that you can control,\nexternally, the behavior of the sensor, attending to:   The time ( interval ) that will pass between publications will be configurable via\na message published from your terminal, to which the ESP32 will be subscribed.  The sensorization (and data publicaiton) will be activated or deactivated on demand, \nvia a publication from your Linux terminal and subscription from the ESP32 to a specific topic.   For example, imagine that your sensor publishes messages under the topic /BUILDING_3/P_4/N/12/(TEMP|HUM|LUX|VIBR) . To control the interval of \npublication time from that ESP32, and fix it to 1 second, we could publish a \nmessage using:  mosquitto_pub -t /BUILDING_3/P_4/N/12/interval  -m \"1000\" -h IP_BROKER  To disable the sensor:  mosquitto_pub -t /BUILDING_3/P_4/N/12/disable  -m \"\" -h IP_BROKER  To enable the sensor:  mosquitto_pub -t /BUILDING_3/P_4/N/12/enable  -m \"\" -h IP_BROKER   Optionally, you can extend your solution so that each sensor is activated or deactivated\nindividually on demand. For that to happen, choose and document the selected topic that you \nshould employ.",
            "title": "API"
        },
        {
            "location": "/Subjects/NP2/P7/",
            "text": "Pr\u00e1ctica 7. El protocolo CoAP\n\n\nObjetivos\n\n\nEl objetivo de esta pr\u00e1ctica es realizar una introducci\u00f3n al protocolo\nCoAP, uno de los m\u00e1s extendidos a d\u00eda de hoy para llevar a cabo comunicaciones\nM2M. Los objetivos did\u00e1cticos de la pr\u00e1ctica son:\n\n\n\n\nEntender la estructura cliente-servidor del protocolo CoAP.\n\n\nComprender los mensajes utilizados para establecer una comunicaci\u00f3n CoAP, \ntanto a nivel de sintaxis como de sem\u00e1ntica.\n\n\nModificar una aplicaci\u00f3n cliente/servidor ejemplo basada en \nlibcoap\n que realice una comunicaci\u00f3n \nsencilla a trav\u00e9s del protocolo CoAP en un entorno Linux.\n\n\nEstudiar el componente \nlibcoap\n en ESP-IDF para reproducir el comportamiento\ndel servidor CoAP para ofrecer su fucionalidad desde un ESP32. \n\n\n\n\nInstalaci\u00f3n y requisitos previos\n\n\nEn esta pr\u00e1ctica realizaremos un estudio del protocolo CoAP utilizando una \nimplementaci\u00f3n ya desarrollada para un sistema cliente/servidor que hace uso\ndel protocolo CoAP, distribuida a trav\u00e9s de la biblioteca \nlibcoap\n. \nN\u00f3tese que se trata de una pr\u00e1ctica introductoria, ya\nque el protocolo CoAP se utilizar\u00e1, en sucesivas pr\u00e1cticas, para dar soporte\na protocolos de m\u00e1s alto nivel (principalmente LWM2M).\n\n\nEl objetivo principal de la pr\u00e1ctica es, pues, introducir a alto nivel las \ncaracter\u00edsticas de CoAP como protocolo de capa de aplicaci\u00f3n, as\u00ed como ser\ncapaces de interactuar con un servidor existente a trav\u00e9s de herramientas\nya desarrolladas. De forma adicional, se estudiar\u00e1 la posibilidad de \nimplementar un servidor CoAP en el ESP32.\n\n\nInstalaci\u00f3n de requisitos adicionales y \nlibcoap\n\n\nEn primer lugar, instalemos los prerequisitos necesarios para hacer funcionar\n{\\tt libcoap}. Para ello, en la m\u00e1quina virtual, ejecutaremos las siguientes\n\u00f3rdenes:\n\n\nsudo apt-get update\nsudo apt-get install libtool\n\n\n\n\nProcedemos ahora con la instalaci\u00f3n de {\\tt libcoap}. Para ello, descarga la \u00faltima\nversi\u00f3n de la biblioteca desde la p\u00e1gina web del proyecto, descompr\u00edmelo y pasa a la\nfase de compilaci\u00f3n e instalaci\u00f3n:\n\n\nsh autogen.sh\n./configure --enable-examples --enable-dtls --with-openssl --disable-documentation\nmake\nmake install\n\n\n\n\nSi no hay ning\u00fan error, \nlibcoap\n se habr\u00e1 instalado con \u00e9xito. Ser\u00e1 de especial\ninter\u00e9s para nosotros la instalaci\u00f3n de programas servidor (\ncoap-server\n)\ny cliente (\ncoap-client\n) de ejemplo en el directorio \nexamples\n.\n\n\n\n\nTarea\n\n\nEjecuta los programas servidor y cliente CoAP del directorio \nexamples\n. \nEstudia sus opciones y par\u00e1metros de configuraci\u00f3n. \n\u00bfEn qu\u00e9 puertos y bajo qu\u00e9 protocolos escucha el servidor CoAP tras su\narranque?\n\n\n\n\nIntercambio de mensajes CoAP\n\n\n\n\nTarea entregable\n\n\nEn la presente secci\u00f3n se proponen\ndistintos intercambios de mensajes CoAP entre el cliente y el servidor de ejemplo\nproporcionados como parte de la instalaci\u00f3n de \nlibcoap\n. Para cada uno de ellos,\nse pide un estudio b\u00e1sico de los paquetes intercambiados, haciendo especial hincapi\u00e9\nen la pila de protocolos utilizados, contenido de los paquetes y n\u00famero de paquetes\nintercambiados. Este estudio, incluyendo capturas y comentarios adicionales, \nconformar\u00e1 el entregable asociado a la pr\u00e1ctica.\n\n\n\n\nArranque del servidor CoAP\n\n\nEn primer lugar, realizaremos un intercambio b\u00e1sico de mensajes CoAP entre el\ncliente y el servidor. Para ello, abriremos dos terminales desde las que ejecutaremos,\nrespectivamente, el servidor y el cliente. \n\n\n\n\nTarea\n\n\nInvestiga las opciones disponibles\nen el cliente y servidor con respecto a la cantidad de mensajes de depuraci\u00f3n a mostrar.\nEjecuta el servidor CoAP con suficiente nivel de detalle en los mensajes de depuraci\u00f3n.\n\n\n\n\nUna vez arrancado el servidor, ejecuta la orden correspondiente desde l\u00ednea de \n\u00f3rdenes para averiguar qu\u00e9 puertos ha abierto, y por tanto c\u00f3mo nos podemos comunicar\ncon \u00e9l. Averigua si estos puertos son bien conocidos \nwell-known\n, valor menor a 1024) y, en su caso,\nc\u00f3mo pueden modificarse.\n\n\nObtenci\u00f3n de informaci\u00f3n del servidor (\nResource Discovery\n)\n\n\nEn primer lugar, obtendremos la informaci\u00f3n sobre los recursos disponibles en el\nservidor CoAP. Para ello, realizaremos una petici\u00f3n \nGET\n sobre el recurso\n\n/.well-known/core\n del servidor. Esta transacci\u00f3n nos devolver\u00e1 los recursos\ndisponibles en el mismo, as\u00ed como algunas caracter\u00edsticas adicionales.\n\n\n\n\nTarea\n\n\n\u00bfQu\u00e9 recursos est\u00e1n disponibles\nen el servidor? Estudia el c\u00f3digo fuente del mismo para observar la correlaci\u00f3n entre\nlos recursos descubiertos y los programados en el c\u00f3digo. Averigua el significado \nde los atributos \nrt\n, \nct\n, \nif\n y *title.\n\n\n\n\nObtenci\u00f3n de informaci\u00f3n desde recursos\n\n\nUtilizando el cliente CoAP proporcionado, resulta sencillo realizar consultas para \nobtener datos desde el servidor. Para ello, utilizaremos la acci\u00f3n (verbo) {\\tt GET},\nseguido del recurso a consultar y, opcionalmente, de una consulta concreta. \n\n\n\n\nTarea\n\n\nConsulta la marca de tiempo\nproporcionada por el servidor en modo legible (por ejemplo, \nDec 13 14:20:43\n), y\ntambi\u00e9n en forma de \nticks\n de reloj, utilizando la consulta adecuada. \u00bfQu\u00e9 valor \nde retorno (c\u00f3digo) incluye la respuesta CoAP si el proceso ha tenido \u00e9xito?\n\n\n\n\nModificaci\u00f3n de recursos\n\n\nAl igual que con el verbo GET, es posible realizar modificaciones en el servidor \nutilizando el verbo PUT. Consulta la ayuda del cliente proporcionado para observar\nalg\u00fan ejemplo que d\u00e9 soporte a esta funcionalidad.\n\n\n\n\nTarea\n\n\nModifica la marca de tiempo que proporciona el servidor CoAP. \n\u00bfQu\u00e9 valor de retorno (c\u00f3digo) incluye la respuesta CoAP si el proceso ha tenido \u00e9xito?\n\n\n\n\nEliminaci\u00f3n y creaci\u00f3n de recursos\n\n\nEs posible eliminar un determinado recurso (en el ejemplo, el temporizador), utilizando\nel verbo \nDELETE\n. Investiga c\u00f3mo hacerlo desde el cliente proporcionado.\n\n\n\n\nTarea\n\n\nElimina el recurso \ntime\n del servidor y, a continuaci\u00f3n, modifica la marca de tiempo mediante una orden\n\nPUT\n}. \u00bfQu\u00e9 valores de retorno (c\u00f3digo) se devuelven en ambos casos?}\n\n\n\n\nSuscripci\u00f3n (observaci\u00f3n) de recursos\n\n\nEs posible suscribirse a los cambios en el valor de un recurso utilizando la opci\u00f3n\n\n-s\n del cliente. \n\n\n\n\nTarea\n\n\nActiva la observaci\u00f3n sobre el recurso \ntime\n del servidor y analiza tanto la\nfrecuencia de respuesta como el intercambio de mensajes producido (a trav\u00e9s\nde \nWireshark\n). \u00bfSe producen peticiones peri\u00f3dicas usando \nGET\n?\n\n\n\n\nCoAP sobre TCP\n\n\nAlternativamente, CoAP puede funcionar utilizando el protocolo de capa de transporte\nTCP. En este caso, como es l\u00f3gico, se establecer\u00e1 una conexi\u00f3n entre cliente y servidor\nprevia a cualquier intercambio de datos.\n\n\n\n\nTarea\n\n\nFuerza el uso de TCP en el cliente mediante la opci\u00f3n correspondiente y estudia las principales diferencias entre\nlos mensajes intercambiados con respecto al uso de UDP.\n\u00bfCu\u00e1l es la eficiencia al utilizar UDP y TCP como protocolos de transporte para CoAP?\n\n\n\n\nTareas entregables\n\n\n\n\nTarea entregable\n\n\nDeber\u00e1s entregar una memoria en la que\nse incida en detalles observados y aprendidos acerca del protocolo CoAP, con\nespecial atenci\u00f3n a las capturas obtenidas a trav\u00e9s de Wireshark.\n\n\n\n\n\n\nTarea entregable\n\n\nEstudia el c\u00f3digo del servidor proporcionado, especialmente de la funci\u00f3n\n\ninit_resources\n, y a\u00f1ade un nuevo recurso llamado \ntemperature\n. \nEste recurso aceptar\u00e1 dos consultas distintas: \n?celsius\n (consulta por defecto)\ndevolver\u00e1 el valor de temperatura expresado en grados cent\u00edgrados, mientras que\n\n\\tt fahrenheit\n devolver\u00e1 la temperatura en grados Fahrenheit. En este caso, el valor\nde temperatura se obtendr\u00e1 directamente a trav\u00e9s de un n\u00famero aleatorio, pero se\nvalorar\u00e1 su obtenci\u00f3n a partir de un sensor real.\n\n\n\n\n\n\nTarea entregable\n\n\nESP-IDF incluye un port de \nlibcoap\n. El ejemplo \n\nexamples/protocols/coap_server\n implementa un servidor CoAP b\u00e1sico, con \nun s\u00f3lo recurso (puedes consultarlo t\u00fa mismo/a obteniendo la informaci\u00f3n\ndel recurso \n/well-known/core\n). Analiza el c\u00f3digo y observa que la \nbiblioteca \nlibcoap\n se utiliza de forma exacta a como has estudiado\nen el c\u00f3digo del servidor de ejemplo. Se pide modificar el \nfirmware\n\npara dar soporte al recurso \ntime\n de forma id\u00e9ntica (con la misma \nsem\u00e1ntica) que la utilizada en el \nhost\n.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P7/#practica-7-el-protocolo-coap",
            "text": "",
            "title": "Pr\u00e1ctica 7. El protocolo CoAP"
        },
        {
            "location": "/Subjects/NP2/P7/#objetivos",
            "text": "El objetivo de esta pr\u00e1ctica es realizar una introducci\u00f3n al protocolo\nCoAP, uno de los m\u00e1s extendidos a d\u00eda de hoy para llevar a cabo comunicaciones\nM2M. Los objetivos did\u00e1cticos de la pr\u00e1ctica son:   Entender la estructura cliente-servidor del protocolo CoAP.  Comprender los mensajes utilizados para establecer una comunicaci\u00f3n CoAP, \ntanto a nivel de sintaxis como de sem\u00e1ntica.  Modificar una aplicaci\u00f3n cliente/servidor ejemplo basada en  libcoap  que realice una comunicaci\u00f3n \nsencilla a trav\u00e9s del protocolo CoAP en un entorno Linux.  Estudiar el componente  libcoap  en ESP-IDF para reproducir el comportamiento\ndel servidor CoAP para ofrecer su fucionalidad desde un ESP32.",
            "title": "Objetivos"
        },
        {
            "location": "/Subjects/NP2/P7/#instalacion-y-requisitos-previos",
            "text": "En esta pr\u00e1ctica realizaremos un estudio del protocolo CoAP utilizando una \nimplementaci\u00f3n ya desarrollada para un sistema cliente/servidor que hace uso\ndel protocolo CoAP, distribuida a trav\u00e9s de la biblioteca  libcoap . \nN\u00f3tese que se trata de una pr\u00e1ctica introductoria, ya\nque el protocolo CoAP se utilizar\u00e1, en sucesivas pr\u00e1cticas, para dar soporte\na protocolos de m\u00e1s alto nivel (principalmente LWM2M).  El objetivo principal de la pr\u00e1ctica es, pues, introducir a alto nivel las \ncaracter\u00edsticas de CoAP como protocolo de capa de aplicaci\u00f3n, as\u00ed como ser\ncapaces de interactuar con un servidor existente a trav\u00e9s de herramientas\nya desarrolladas. De forma adicional, se estudiar\u00e1 la posibilidad de \nimplementar un servidor CoAP en el ESP32.",
            "title": "Instalaci\u00f3n y requisitos previos"
        },
        {
            "location": "/Subjects/NP2/P7/#instalacion-de-requisitos-adicionales-y-libcoap",
            "text": "En primer lugar, instalemos los prerequisitos necesarios para hacer funcionar\n{\\tt libcoap}. Para ello, en la m\u00e1quina virtual, ejecutaremos las siguientes\n\u00f3rdenes:  sudo apt-get update\nsudo apt-get install libtool  Procedemos ahora con la instalaci\u00f3n de {\\tt libcoap}. Para ello, descarga la \u00faltima\nversi\u00f3n de la biblioteca desde la p\u00e1gina web del proyecto, descompr\u00edmelo y pasa a la\nfase de compilaci\u00f3n e instalaci\u00f3n:  sh autogen.sh\n./configure --enable-examples --enable-dtls --with-openssl --disable-documentation\nmake\nmake install  Si no hay ning\u00fan error,  libcoap  se habr\u00e1 instalado con \u00e9xito. Ser\u00e1 de especial\ninter\u00e9s para nosotros la instalaci\u00f3n de programas servidor ( coap-server )\ny cliente ( coap-client ) de ejemplo en el directorio  examples .   Tarea  Ejecuta los programas servidor y cliente CoAP del directorio  examples . \nEstudia sus opciones y par\u00e1metros de configuraci\u00f3n. \n\u00bfEn qu\u00e9 puertos y bajo qu\u00e9 protocolos escucha el servidor CoAP tras su\narranque?",
            "title": "Instalaci\u00f3n de requisitos adicionales y libcoap"
        },
        {
            "location": "/Subjects/NP2/P7/#intercambio-de-mensajes-coap",
            "text": "Tarea entregable  En la presente secci\u00f3n se proponen\ndistintos intercambios de mensajes CoAP entre el cliente y el servidor de ejemplo\nproporcionados como parte de la instalaci\u00f3n de  libcoap . Para cada uno de ellos,\nse pide un estudio b\u00e1sico de los paquetes intercambiados, haciendo especial hincapi\u00e9\nen la pila de protocolos utilizados, contenido de los paquetes y n\u00famero de paquetes\nintercambiados. Este estudio, incluyendo capturas y comentarios adicionales, \nconformar\u00e1 el entregable asociado a la pr\u00e1ctica.",
            "title": "Intercambio de mensajes CoAP"
        },
        {
            "location": "/Subjects/NP2/P7/#arranque-del-servidor-coap",
            "text": "En primer lugar, realizaremos un intercambio b\u00e1sico de mensajes CoAP entre el\ncliente y el servidor. Para ello, abriremos dos terminales desde las que ejecutaremos,\nrespectivamente, el servidor y el cliente.    Tarea  Investiga las opciones disponibles\nen el cliente y servidor con respecto a la cantidad de mensajes de depuraci\u00f3n a mostrar.\nEjecuta el servidor CoAP con suficiente nivel de detalle en los mensajes de depuraci\u00f3n.   Una vez arrancado el servidor, ejecuta la orden correspondiente desde l\u00ednea de \n\u00f3rdenes para averiguar qu\u00e9 puertos ha abierto, y por tanto c\u00f3mo nos podemos comunicar\ncon \u00e9l. Averigua si estos puertos son bien conocidos  well-known , valor menor a 1024) y, en su caso,\nc\u00f3mo pueden modificarse.",
            "title": "Arranque del servidor CoAP"
        },
        {
            "location": "/Subjects/NP2/P7/#obtencion-de-informacion-del-servidor-resource-discovery",
            "text": "En primer lugar, obtendremos la informaci\u00f3n sobre los recursos disponibles en el\nservidor CoAP. Para ello, realizaremos una petici\u00f3n  GET  sobre el recurso /.well-known/core  del servidor. Esta transacci\u00f3n nos devolver\u00e1 los recursos\ndisponibles en el mismo, as\u00ed como algunas caracter\u00edsticas adicionales.   Tarea  \u00bfQu\u00e9 recursos est\u00e1n disponibles\nen el servidor? Estudia el c\u00f3digo fuente del mismo para observar la correlaci\u00f3n entre\nlos recursos descubiertos y los programados en el c\u00f3digo. Averigua el significado \nde los atributos  rt ,  ct ,  if  y *title.",
            "title": "Obtenci\u00f3n de informaci\u00f3n del servidor (Resource Discovery)"
        },
        {
            "location": "/Subjects/NP2/P7/#obtencion-de-informacion-desde-recursos",
            "text": "Utilizando el cliente CoAP proporcionado, resulta sencillo realizar consultas para \nobtener datos desde el servidor. Para ello, utilizaremos la acci\u00f3n (verbo) {\\tt GET},\nseguido del recurso a consultar y, opcionalmente, de una consulta concreta.    Tarea  Consulta la marca de tiempo\nproporcionada por el servidor en modo legible (por ejemplo,  Dec 13 14:20:43 ), y\ntambi\u00e9n en forma de  ticks  de reloj, utilizando la consulta adecuada. \u00bfQu\u00e9 valor \nde retorno (c\u00f3digo) incluye la respuesta CoAP si el proceso ha tenido \u00e9xito?",
            "title": "Obtenci\u00f3n de informaci\u00f3n desde recursos"
        },
        {
            "location": "/Subjects/NP2/P7/#modificacion-de-recursos",
            "text": "Al igual que con el verbo GET, es posible realizar modificaciones en el servidor \nutilizando el verbo PUT. Consulta la ayuda del cliente proporcionado para observar\nalg\u00fan ejemplo que d\u00e9 soporte a esta funcionalidad.   Tarea  Modifica la marca de tiempo que proporciona el servidor CoAP. \n\u00bfQu\u00e9 valor de retorno (c\u00f3digo) incluye la respuesta CoAP si el proceso ha tenido \u00e9xito?",
            "title": "Modificaci\u00f3n de recursos"
        },
        {
            "location": "/Subjects/NP2/P7/#eliminacion-y-creacion-de-recursos",
            "text": "Es posible eliminar un determinado recurso (en el ejemplo, el temporizador), utilizando\nel verbo  DELETE . Investiga c\u00f3mo hacerlo desde el cliente proporcionado.   Tarea  Elimina el recurso  time  del servidor y, a continuaci\u00f3n, modifica la marca de tiempo mediante una orden PUT }. \u00bfQu\u00e9 valores de retorno (c\u00f3digo) se devuelven en ambos casos?}",
            "title": "Eliminaci\u00f3n y creaci\u00f3n de recursos"
        },
        {
            "location": "/Subjects/NP2/P7/#suscripcion-observacion-de-recursos",
            "text": "Es posible suscribirse a los cambios en el valor de un recurso utilizando la opci\u00f3n -s  del cliente.    Tarea  Activa la observaci\u00f3n sobre el recurso  time  del servidor y analiza tanto la\nfrecuencia de respuesta como el intercambio de mensajes producido (a trav\u00e9s\nde  Wireshark ). \u00bfSe producen peticiones peri\u00f3dicas usando  GET ?",
            "title": "Suscripci\u00f3n (observaci\u00f3n) de recursos"
        },
        {
            "location": "/Subjects/NP2/P7/#coap-sobre-tcp",
            "text": "Alternativamente, CoAP puede funcionar utilizando el protocolo de capa de transporte\nTCP. En este caso, como es l\u00f3gico, se establecer\u00e1 una conexi\u00f3n entre cliente y servidor\nprevia a cualquier intercambio de datos.   Tarea  Fuerza el uso de TCP en el cliente mediante la opci\u00f3n correspondiente y estudia las principales diferencias entre\nlos mensajes intercambiados con respecto al uso de UDP.\n\u00bfCu\u00e1l es la eficiencia al utilizar UDP y TCP como protocolos de transporte para CoAP?",
            "title": "CoAP sobre TCP"
        },
        {
            "location": "/Subjects/NP2/P7/#tareas-entregables",
            "text": "Tarea entregable  Deber\u00e1s entregar una memoria en la que\nse incida en detalles observados y aprendidos acerca del protocolo CoAP, con\nespecial atenci\u00f3n a las capturas obtenidas a trav\u00e9s de Wireshark.    Tarea entregable  Estudia el c\u00f3digo del servidor proporcionado, especialmente de la funci\u00f3n init_resources , y a\u00f1ade un nuevo recurso llamado  temperature . \nEste recurso aceptar\u00e1 dos consultas distintas:  ?celsius  (consulta por defecto)\ndevolver\u00e1 el valor de temperatura expresado en grados cent\u00edgrados, mientras que \\tt fahrenheit  devolver\u00e1 la temperatura en grados Fahrenheit. En este caso, el valor\nde temperatura se obtendr\u00e1 directamente a trav\u00e9s de un n\u00famero aleatorio, pero se\nvalorar\u00e1 su obtenci\u00f3n a partir de un sensor real.    Tarea entregable  ESP-IDF incluye un port de  libcoap . El ejemplo  examples/protocols/coap_server  implementa un servidor CoAP b\u00e1sico, con \nun s\u00f3lo recurso (puedes consultarlo t\u00fa mismo/a obteniendo la informaci\u00f3n\ndel recurso  /well-known/core ). Analiza el c\u00f3digo y observa que la \nbiblioteca  libcoap  se utiliza de forma exacta a como has estudiado\nen el c\u00f3digo del servidor de ejemplo. Se pide modificar el  firmware \npara dar soporte al recurso  time  de forma id\u00e9ntica (con la misma \nsem\u00e1ntica) que la utilizada en el  host .",
            "title": "Tareas entregables"
        },
        {
            "location": "/Subjects/NP2/P8/",
            "text": "Pr\u00e1ctica 8. El protocolo LWM2M\n\n\nObjetivos\n\n\n\n\nFamiliarizarse con el protocolo LWM2M, tanto en la interacci\u00f3n con servidores\ncomo en la generaci\u00f3n y definici\u00f3n de objetos y recursos.\n\n\nFamiliarizarse con el protocolo de \nbootstrapping\n LWM2M y entender su\nimportancia en entornos reales.\n\n\nConocer dos herramientas para el desarrollo de sistemas basados en LWM2M:\nWakaama y Leshan.\n\n\nExperimentar con el proceso de definici\u00f3n de objetos en Wakaama.\n\n\nObservar y poner en marcha un proceso de provisionamiento (\nbootstrapping\n)\nusando Wakaama.\n\n\nDesplegar servidores locales LWM2M usando tanto Wakaama como Leshan.\n\n\n\n\nEl protocolo LWM2M\n\n\nOMA Lightweight M2M (LWM2M) es un protocolo impulsado por la Open Mobile\nAlliance para la comunicaci\u00f3n M2M entre dispositivos y su gesti\u00f3n en entornos\nIoT. LWM2M est\u00e1 construido sobre el protocolo CoAP, y soporta, a nivel de \ntransporte, el protocolo UDP (tambi\u00e9n presenta soporte para SMS). \nEntre las funcionalidades b\u00e1sicas de LWM2M destacan la existencia de servidores\nLWM2M, \nbootstrapping\n, control de acceso, gesti\u00f3n de dispositivos, \nactualizaciones de \nfirmware\n, localizaci\u00f3n o estad\u00edsticas de conectividad. \nAdem\u00e1s, soporta seguridad a trav\u00e9s de DTLS.\n\n\nConcretamente, la primera especificaci\u00f3n de LWM2M (versi\u00f3n 1.0) introdujo las\nsiguientes caracter\u00edsticas b\u00e1sicas:\n\n\n\n\nDefinici\u00f3n de un modelo simple para la definici\u00f3n de recursos, basado en objetos.\n\n\nDefinici\u00f3n de operaciones de creaci\u00f3n, consulta, modificaci\u00f3n, borrado y \n  configuraci\u00f3n de recursos.\n\n\nObservaci\u00f3n/notificaci\u00f3n sobre recursos.\n\n\nSoporte para formato de datos JSON, texto plano y TLV.\n\n\nColas de mensajes para soportar modos de bajo consumo en dispositivos.\n\n\nSoporte para m\u00faltiples servidores LWM2M.\n\n\nObjetos b\u00e1sicos LWM2M: Seguridad, Servidor, Control de Acceso, Dispositivo,\nConectividad, Actualizaci\u00f3n de Firmware, Localizaci\u00f3n, Estad\u00edsticas de \nConectividad. Para m\u00e1s informaci\u00f3n sobre los objetos predefinidos, \nconsulta el \nsiguiente enlace\n.\n\n\n\n\nVersiones subsiguientes del protocolo (1.1 y 1.2) introdujeron caracter\u00edsticas\nadicionales, como por ejemplo:\n\n\n\n\nMejora del proceso de \nbootstrapping\n.\n\n\nMejora del soporte para PKI.\n\n\nSoporte para TCP/TLS.\n\n\nSoporte para CBOR.\n\n\nSoporte para MQTT y HTTP como protocolos subyacentes.\n\n\n\n\nImplementaciones LWM2M\n\n\nEn la presente pr\u00e1ctica, utilizaremos dos paquetes de \nsoftware\n pertenecientes\nal proyecto Eclipse IoT, ambos con soporte completo para LWM2M. Cada uno de\nellos presenta ventajas e inconvenientes que es necesario conocer. \n\n\nEclipse Wakaama\n\n\nEclipse Wakaama es un conjunto de ficheros fuente escritos en C que permiten ser integrados\nen cualquier proyecto para proporcionar funcionalidad de \ncliente\n, \nservidor\n\ny \nservidor de bootstrap\n LWM2M hasta su versi\u00f3n 1.1. \nEn el lado cliente, Wakaama permite la \ndefinici\u00f3n de objetos conforme al est\u00e1ndar, as\u00ed como la recepci\u00f3n de comandos\ndesde servidores y su enrutado hacia el objeto u objetos correspondientes. Desde\nel punto de vista servidor, Wakaama proporciona APIs para enviar comandos a \nclientes LWM2M registrados. \n\n\nTodo el proyecto es compatible con POSIX, y en esta pr\u00e1ctica experimentaremos \ncon su funcionalidad trabajando desde Linux (modo cliente, servidor y \nservidor de \nbootstrap\n) y desde el ESP32 (modo cliente).\n\n\nInstalaci\u00f3n\n\n\nUtilizaremos una versi\u00f3n espec\u00edfica que permitir\u00e1 ser ejecutada tanto en \nLinux como en el ESP32. Para ello, clonamos en primer lugar la versi\u00f3n \ncorrespondiente del proyecto (es importante que utilices este\n\ncommit\n espec\u00edfico):\n\n\ngit clone https://github.com/eclipse/wakaama.git\ncd wakaama\ngit reset --hard 31d64c0c41fae9653c1fa53ef58d1a44e49017fa\n\n\n\n\nEl proyecto Wakaama proporciona cuatro componentes que utilizaremos durante\nla pr\u00e1ctica, todos dentro del directorio \nexamples\n:\n\n\n\n\nbootstrap_server\n: implementa un servidor de \nbootstrap\n con l\u00ednea de \n  comandos propia.\n\n\nclient\n: implementa un cliente complejo, con definici\u00f3n de nueve objetos\n  que siguen las especificaciones de la OMA m\u00e1s uno propio, \n  y soporte para \nbootstrapping\n.\n\n\nlightclient\n: implementa un cliente sencillo, con definici\u00f3n de tres objetos\n  seg\u00fan especificaciones OMA y un cuarto objeto propio.\n\n\nserver\n: implementa un servidor LWM2M que ofrece l\u00ednea de comandos para\n  la interacci\u00f3n con clientes registrados.\n\n\n\n\nEl modo de compilar cada uno de los ejemplos es exactamente el mismo:\n\n\n\n\nDir\u00edgete al directorio del ejemplo.\n\n\nCrea un directorio \nbuild\n y accede a \u00e9l.\n\n\nConfigura el proyecto con la orden \ncmake ..\n.\n\n\nCompila el ejemplo con la orden \nmake\n.\n\n\n\n\nSi todo ha ido bien, deber\u00edas tener un binario distinto en el directorio\n\nbuild\n correspondiente, con los que trabajar\u00e1s el resto de la pr\u00e1ctica.\n\n\n\n\nTarea\n\n\nCompila cada uno de los ejemplos anteriormente mencionados en tu m\u00e1quina\nvirtual, utilizando los par\u00e1metros por defecto para cada uno de ellos.\n\n\n\n\nEclipse Leshan\n\n\nEclipse Leshan es un proyecto alternativo que proporciona implementaciones en\nJava de clientes, servidores y servidores de \nbootstrap\n LWM2M, y est\u00e1 especialmente\ndise\u00f1ado para ser adaptable y extensible, permitiendo a los desarrolladores \nimplementar sus propias versiones de cada uno de los tres anteriores elmentos\nadaptados a sus necesidades espec\u00edficas. Al igual que Wakaama, Leshan proporciona\nla definici\u00f3n e interacci\u00f3n con objetos IPSO, construcci\u00f3n sobre DTLS y\nutilizaci\u00f3n de CoAP como protocolo subyacente.\n\n\nAdem\u00e1s, el proyecto proporciona dos servidores de test que resultan muy \u00fatiles\n a la hora de desarrollar, v\u00e9ase:\n\n\n\n\nServidor LWM2M en \nleshan.eclipseprojects.io\n, disponible en \ncoap://leshan.eclipseprojects.io:5683 y coaps://leshan.eclipseprojects.io:5684\n.\n\n\nServidor de \nbootstrap\n en \nleshan.eclipseprojects.io/bs\n, disponible en \ncoap://leshan.eclipseprojects.io:5783 y coaps://leshan.eclipseprojects.io:5784\n.\n\n\n\n\nInstalaci\u00f3n\n\n\nInstala en primer lugar los prerequisitos necesarios para la correcta instalaci\u00f3n\nde Leshan (pueden variar en funci\u00f3n de tu distribuci\u00f3n Linux):\n\n\nsudo apt-get update\nsudo apt-get install openjdk-14-jdk maven git-core\n\n\n\n\nClona el repositorio oficial de Leshan desde la siguiente direcci\u00f3n:\n\n\ngit clone https://github.com/eclipse/leshan.git\n\n\n\n\nPor \u00faltimo, compila el proyecto:\n\n\ncd leshan\nmvn clean install\n\n\n\n\nTras la fase de instalaci\u00f3n, podr\u00e1s lanzar tanto el servidor LWM2M:\n\n\njava -jar leshan-server-demo/target/leshan-server-demo-*-SNAPSHOT-jar-with-dependencies.jar \n\n\n\n\nLa opci\u00f3n \n-h\n te permitir\u00e1 observar la ayuda del servidor.\n\n\nComo el servidor de \nbootstrapping\n:\n\n\njava -jar leshan-bsserver-demo/target/leshan-bsserver-demo-*-SNAPSHOT-jar-with-dependencies.jar\n\n\n\n\nLa opci\u00f3n \n-h\n te permitir\u00e1 observar la ayuda del servidor.\n\n\nEn ambos casos, la salida asociada a la ejecuci\u00f3n de los servidores nos \nindicar\u00e1n la URL que podremos consultar desde cualquier navegador para \nobtener informaci\u00f3n del mismo, as\u00ed como la URL y puerto de escucha de cada\nuno, que deberemos indicar en los clientes correspondientes.\n\n\n\n\nTarea\n\n\nInstala Eclipse Leshan y arranca el servidor LWM2M. Accede a la p\u00e1gina\nweb de gesti\u00f3n y comprueba que efectivamente funciona. A continucaci\u00f3n,\ndetenlo y haz lo propio con el servidor de \nbootstrapping\n.\n\n\n\n\nEclipse Wakaama. Cliente y servidor LWM2M\n\n\nEl objetivo principal de esta parte de la pr\u00e1ctica ser\u00e1 disponer de un sistema\ncompleto LWM2M basado en un cliente y dos servidores (uno LWM2M, otro de\n\nbootstrapping\n), todos funcionando bajo Eclipse Wakaama.\n\n\nPara ello, en primer lugar, arrancaremos el servidor Wakaama en una de las\nterminales. Observa que el servidor, tras arrancar, expone una sencilla\nl\u00ednea de comandos que podemos aprovechar para interactuar con \u00e9l:\n\n\n./lwm2mserver \n\n> help\nhelp    Type 'help [COMMAND]' for more details on a command.\nlist    List registered clients.\nread    Read from a client.\ndisc    Discover resources of a client.\nwrite   Write to a client.\ntime    Write time-related attributes to a client.\nattr    Write value-related attributes to a client.\nclear   Clear attributes of a client.\nexec    Execute a client resource.\ndel Delete a client Object instance.\ncreate  Create an Object instance.\nobserve Observe from a client.\ncancel  Cancel an observe.\nq   Quit the server.\n\n\n\n\n\nLa orden \nhelp\n muestra la ayuda global, pudi\u00e9ndose especializar para cada\ncomando concreto:\n\n\n> help read\n read CLIENT# URI\n   CLIENT#: client number as returned by command 'list'\n   URI: uri to read such as /3, /3/0/2, /1024/11, /1024/0/1\nResult will be displayed asynchronously.\n\n\n\n\nSi en este instante listamos un los clientes registrados, veremos que no\nhay ninguno:\n\n\n> list\nNo client.\n\n\n\n\nEn segundo lugar, vamos a arrancar el cliente Wakaama. Por defecto, este cliente\nintentar\u00e1 conectar con un servidor LWM2M existente en \nlocalhost\n, puerto \n5683. En cualquier caso, estos valores pueden modificarse en la propia \ninvocaci\u00f3n (consulta la opci\u00f3n \n-h\n para m\u00e1s informaci\u00f3n sobre par\u00e1metros\ndisponibles):\n\n\n./lwm2mclient\nTrying to bind LWM2M Client to port 56830\nLWM2M Client \"testlwm2mclient\" started on port 56830\n> Opening connection to server at ::1:5683\n -> State: STATE_REGISTERING\n13 bytes received from [::1]:5683\n64 41 69 06  06 69 E8 86  82 72 64 01  30  dAi..i...rd.0\n -> State: STATE_READY\n\n\n> help\nhelp    Type 'help [COMMAND]' for more details on a command.\nlist    List known servers.\nchange  Change the value of resource.\nupdate  Trigger a registration update\nbootstrap   Initiate a DI bootstrap process\ndispb   Display current backup of objects/instances/resources\n        (only security and server objects are backupped)\nls  List Objects and Instances\ndisp    Display current objects/instances/resources\ndump    Dump an Object\nadd Add support of object 31024\nrm  Remove support of object 31024\nquit    Quit the client gracefully.\n^C  Quit the client abruptly (without sending a de-register message).\n\n>  -> State: STATE_READY\n\n\n\n\nAl igual que el servidor, el cliente soporta la introducci\u00f3n de comandos\npor parte del usuario.  Observa que hemos ejecutado el comando \nhelp\n\npara mostrar los comandos disponibles. \n\n\nAdem\u00e1s, el cliente ha pasado desde un estado \nSTATE_REGISTERING\n a un estado\n\nSTATE_READY\n, lo que significa que se ha registrado correctamente en el \nservidor con el nombre \ntestlwm2mclient\n.\n\n\nObserva ahora la salida del servidor, y ver\u00e1s que \u00e9ste ha realizado un \nproceso de descubrimiento de recursos en el cliente conectado. Concretamente,\nel servidor reporta la informaci\u00f3n relativa al nuevo cliente conectado:\n\n\nNew client #0 registered.\nClient #0:\n    name: \"testlwm2mclient\"\n    version: \"1.1\"\n    binding: \"UDP\"\n    lifetime: 300 sec\n    objects: /1/0, /2/0, /3/0, /4/0, /5/0, /6/0, /7/0, /31024/10, /31024/11, /31024/12, \n\n\n\n\nConcretamente, el n\u00famero asociado al cliente es el \n0\n. Podemos recuperar\nesta informaci\u00f3n en todo momento con el comando \nlist\n en el servidor.\n\n\nEn el cliente, puedes seleccionar el nombre que se utilizar\u00e1 en el proceso\nde registro con la opci\u00f3n \n-n\n.\n\n\n\n\nTarea entregable\n\n\nObserva, utilizando Wireshark, el proceso de registro de un cliente en un\nservidor, y analiza el contenido del mensaje o mensajes intercambiados entre\nambos. \u00bfQu\u00e9 protocolos se utilizan?\n\n\n\n\nEl cliente con el que estamos trabajando es suficientemente complejo en su\nfuncionamiento, y permite observar c\u00f3mo se implementa el soporte tanto para\nobjetos predefinidos por la OMA como para objetos propios. Concretamente,\nel cliente implementa nueve objetos distintos:\n\n\n\n\nSecurity Object\n (\nid=0\n).\n\n\nServer Object\n (\nid=1\n).\n\n\nAccess Control Object\n (\nid=2\n), como un simple esqueleto, sin funcionalidad asociada.\n\n\nDevice Object\n (\nid=3\n), que contiene (y devuelve) valores espec\u00edficos \ncodificados en base al ap\u00e9ndice E de la especificaci\u00f3n t\u00e9cnica de LWM2M.\n\n\nConnectivity Monitoring Object\n (\nid=4\n), como un simple esqueleto, sin funcionalidad.\n\n\nFirmware Update Object\n (\nid=5\n), como un simple esqueleto, sin funcionalidad.\n\n\nLocation Object\n (\nid=6\n), como un simple esqueleto, sin funcionalidad.\n\n\nConnectivity Statistics Object\n (\nid=7\n), como un simple esqueleto, sin funcionalidad.\n\n\nTest Object\n (\nid=31024\n), con la siguiente descripci\u00f3n:\n\n\n\n\nObjetos:\n\n\n\n\n\n\n\n\nObjeto\n\n\nID\n\n\nMultiples Instancias\n\n\nObligatorio\n\n\n\n\n\n\n\n\n\n\nTest\n\n\n31024\n\n\nS\u00ed\n\n\nNo\n\n\n\n\n\n\n\n\nRecurso:\n\n\n\n\n\n\n\n\nNombre\n\n\nID\n\n\nOperaciones\n\n\nM\u00faltiples Instancias\n\n\nObligatorio\n\n\nTipo\n\n\nRango\n\n\n\n\n\n\n\n\n\n\ntest\n\n\n1\n\n\nR/W\n\n\nNo\n\n\nYes\n\n\nInteger\n\n\n0-255\n\n\n\n\n\n\nexec\n\n\n2\n\n\nE\n\n\nNo\n\n\nYes\n\n\n\n\n\n\n\n\n\n\ndec\n\n\n3\n\n\nR/W\n\n\nNo\n\n\nYes\n\n\nFloat\n\n\n\n\n\n\n\n\n\n\nEn el cliente, el comando \ndump\n nos permitir\u00e1 observar el contenido de una \ninstancia determinada de un objeto, o de todas ellas. En el servidor, el\ncomando \nread\n nos permitir\u00e1 hacer lo propio.\n\n\n\n\nTarea entregable\n\n\nAnaliza el valor actual de los objetos \n/3\n y el objeto de test, tanto desde\nel cliente (comando \ndump\n) como desde el servidor (comando \nread\n). En \n\u00faltimo caso, realiza una captura de tr\u00e1fico v\u00eda Wireshark y analiza los \nmensajes intercambiados entre ambos extremos.\n\n\n\n\nPara escribir en un determinado recurso desde el servidor, podemos hacer\nuso del comando \nwrite\n de la siguiente forma:\n\n\nwrite 0 /31024/10/1 91\n\n\n\n\nAs\u00ed, estar\u00edamos escribiendo en el recurso \n1\n de la instancia \n10\n del objeto\n\n31024\n el valor entero 91.\n\n\n\n\nTarea entregable\n\n\nRealiza escrituras en objetos del cliente y analiza el nuevo valor, comprobando\nque efectivamente se han llevado a cabo. \nRealiza una captura de tr\u00e1fico v\u00eda Wireshark y analiza los \nmensajes intercambiados entre ambos extremos en el caso de una escritura.\nObserva tambi\u00e9n que el servidor permite la observaci\u00f3n de recursos espec\u00edficos\n(comando \nobserve\n).\nExperimenta con esta opci\u00f3n y observa el tr\u00e1fico generado (puedes modificar\nel valor de un recurso desde el propio cliente y ver qu\u00e9 ocurre en el servidor).\n\n\n\n\nPor \u00faltimo, con la orden \nquit\n desconectamos del servidor. Observa tambi\u00e9n\nlos mensajes CoAP que se generan en este caso.\n\n\nDefinici\u00f3n de un objeto en Eclipse Wakaama\n\n\nComo has podido observar, el ejemplo de cliente define una serie de objetos,\nalgunos especificados por la OMA, y otros personalizados. En este \u00faltimo\ncaso, al que nos referiremos como \ntest_object\n, se utilizan e ilustran \nalgunas de las funcionalidades b\u00e1sicas de Wakaama como infraestructura\npara el desarrollo de Smart Objects v\u00eda LWM2M.\n\n\nObserva tanto el c\u00f3digo del cliente LWM2M (fichero fuente \nlwm2mclient.c\n del\nejemplo \nclient\n) como la definici\u00f3n del objeto de test (fichero fuente\n\ntest_object.c\n). \n\n\nEl primer fichero implementa la l\u00f3gica principal del cliente, \nincluyendo gesti\u00f3n de la conexi\u00f3n, l\u00f3gica de an\u00e1lisis de comandos introducidos\npor el usuario, gesti\u00f3n de \nbootstrapping\n, etc. Concretamente, nos interesa\nanalizar las l\u00edneas relativas a la invocaci\u00f3n de la funci\u00f3n \nget_test_object\n,\nen cuyo interior se definen tanto los recursos como el comportamiento de \nnuestro cliente ante distintos tipos de operaciones sobre ellos. Observa que,\nal igual que para nuestro objeto de test, existen funciones similares \npara el resto de objetos definidos (obviamente podr\u00edan existir m\u00e1s), con un\nfichero fuente donde se define el comportamiento de cada uno de ellos.\n\n\nUno de estos objetos es \ntest_object.c\n. La principal funci\u00f3n de entrada\na este m\u00f3dulo es precisamente \nget_test_object()\n. Observa que, en ella, \nse define el identificador del objeto, as\u00ed como cada uno de los recursos que\nexpone (en este caso, tres), sus valores iniciales, \ny las funciones que se utilizar\u00e1n como \ncallbacks\n asociados a cada posible operaci\u00f3n:\n\n\n  lwm2m_object_t * testObj;\n\n    testObj = (lwm2m_object_t *)lwm2m_malloc(sizeof(lwm2m_object_t));\n\n    if (NULL != testObj)\n    {\n        int i; \n        prv_instance_t * targetP;\n\n        memset(testObj, 0, sizeof(lwm2m_object_t));\n\n        testObj->objID = TEST_OBJECT_ID;\n        for (i=0 ; i < 3 ; i++)\n        {\n            targetP = (prv_instance_t *)lwm2m_malloc(sizeof(prv_instance_t));\n            if (NULL == targetP) return NULL;\n            memset(targetP, 0, sizeof(prv_instance_t));\n            targetP->shortID = 10 + i;\n            targetP->test    = 20 + i;\n            targetP->dec     = -30 + i + (double)i/100.0;\n            testObj->instanceList = LWM2M_LIST_ADD(testObj->instanceList, targetP);\n        }\n        /*\n         * From a single instance object, two more functions are available.\n         * - The first one (createFunc) create a new instance and filled it with the provided informations. If an ID is\n         *   provided a check is done for verifying his disponibility, or a new one is generated.\n         * - The other one (deleteFunc) delete an instance by removing it from the instance list (and freeing the memory\n         *   allocated to it)\n         */\n        testObj->readFunc = prv_read;\n        testObj->discoverFunc = prv_discover;\n        testObj->writeFunc = prv_write;\n        testObj->executeFunc = prv_exec;\n        testObj->createFunc = prv_create;\n        testObj->deleteFunc = prv_delete;\n    }\n\n    return testObj;\n\n\n\n\nEstas funciones de \ncallback\n est\u00e1n definidas en el propio fichero, y su \ncontenido es personalizable en funci\u00f3n del dise\u00f1o del objeto. Observemos, \npor ejemplo, el contenido de la funci\u00f3n asociada a la lectura, \nprv_read\n:\n\n\nstatic uint8_t prv_read(uint16_t instanceId,\n                        int * numDataP,\n                        lwm2m_data_t ** dataArrayP,\n                        lwm2m_object_t * objectP)\n{\n    prv_instance_t * targetP;\n    int i;\n\n    targetP = (prv_instance_t *)lwm2m_list_find(objectP->instanceList, instanceId);\n    if (NULL == targetP) return COAP_404_NOT_FOUND;\n\n    if (*numDataP == 0)\n    {\n        *dataArrayP = lwm2m_data_new(2);\n        if (*dataArrayP == NULL) return COAP_500_INTERNAL_SERVER_ERROR;\n        *numDataP = 2;\n        (*dataArrayP)[0].id = 1;\n        (*dataArrayP)[1].id = 3;\n    }\n\n    for (i = 0 ; i < *numDataP ; i++)\n    {\n        switch ((*dataArrayP)[i].id)\n        {\n        case 1:\n            lwm2m_data_encode_int(targetP->test, *dataArrayP + i);\n            break;\n        case 2:\n            return COAP_405_METHOD_NOT_ALLOWED;\n        case 3:\n            lwm2m_data_encode_float(targetP->dec, *dataArrayP + i);\n            break;\n        default:\n            return COAP_404_NOT_FOUND;\n        }\n    }\n\n    return COAP_205_CONTENT;\n}\n\n\n\n\nObserva que en primer lugar se busca la instancia del objeto solicitada, \ndevolvi\u00e9ndose el error correspondiente en caso de no existir (puedes \ncomprobar esta funcionalidad solicitando desde el servidor la lectura de \nuna instancia inexistente).\n\n\nEl par\u00e1metro \nnumDataP\n nos indica el recurso concreto que se desea leer, o\ntodos si dicho valor es 0.\n\n\nTras tomar el valor actual a servir, \u00e9ste se codifica en funci\u00f3n del tipo de\ndatos predefinido para el recurso espec\u00edfico solicitado. En caso de no \nestar soportado el m\u00e9todo para un recurso espec\u00edfico, se devuelve el error\ncorrespondiente (en este caso \n405\n). En caso de solicitar un recurso inexistente,\nse devuelve el error \n404\n.\n\n\n\n\nTarea\n\n\nComprueba que el comportamiento del objeto de test es el esperado, interactuando\ncon \u00e9l desde el servidor utilizando todos los m\u00e9todos disponibles. Puedes modificar\nsu comportamiento, a\u00f1adir invocaciones a rutinas de \nlog\n, o lo que consideres\nde utilidad.\n\n\n\n\nEclipse Wakaama. \nBootstrapping\n\n\nEn este punto, el cliente Wakaama se conecta directamente con el servidor \nque hemos lanzado, y cuya direcci\u00f3n IP y puerto son los proporcionados por \ndefecto en el c\u00f3digo. Llevado el cliente a un sensor, esto har\u00eda que nunca\npudiese variar, durante el ciclo de vida del mismo, el servidor (o servidores)\na los que conecta. Esto hace tambi\u00e9n que un cliente pueda \u00fanicamente conectar\ncon un servidor LWM2M, cuando en algunas ocasiones es deseable replicar los\nmensajes enviados a m\u00faltiples servidores, bien por razones de tolerancia\na fallos, o bien por necesidades de la aplicaci\u00f3n.\n\n\nPara solucionar este problema, los \nfirmwares\n de f\u00e1brica suelen conocer \u00fanicamente\nla direcci\u00f3n o direcciones fijas de uno o varios servidores de \nbootstrap\n que,\nante peticiones de provisionamiento, proporcionan al cliente las credenciales\nde seguridad y las direcciones de los servidores LWM2M en los que deben \nregistrarse. As\u00ed, resulta sencillo manejar din\u00e1micamente ambos aspectos sin necesitar\n\nreflashear\n el \nfirmware\n del sensor.\n\n\nEn nuestro caso, utilizaremos un sencillo servidor de \nbootstrap\n proporcionado\npor Wakaama, aunque Leshan ofrece mecanismos mucho m\u00e1s sofisticados para realizar\neste mismo proceso, con su propio esqueleto de servidor \nbootstrap\n e interfaces\nREST (con monitores web) para gestionar el proceso.\n\n\nEn primer lugar, dir\u00edgete al directorio que contiene el servidor \nbootstrap\n de\nWakaama. All\u00ed encontrar\u00e1s un fichero de configuraci\u00f3n \n(\nbootstrap_server.ini\n) para el proceso de \n\nbootstrapping\n, cuyo contenido es completamente estructurado. El servidor,\nante una petici\u00f3n de \nbootstrapping\n por parte de un cliente, responde en \nfunci\u00f3n del contenido del fichero, que sigue las siguientes directivas:\n\n\nLas secciones soportadas son \n[Server]\n y \n[Endpoint]\n.\n\n\n[Server]\n describe una cuenta en un servidor LWM2M:\n\n\nLas claves soportadas en esta secci\u00f3n son:\n\n\n\n\nid: Identificador del servidor. (OBLIGATORIO).\n\n\nuri: URI del servidor LWM2M (OBLIGATORIO).\n\n\nbootstrap: YES o NO. Determina si este servidor es un servidor de bootstrap. Su valor por defecto es NO.\n\n\nlifetime: tiempo de vida del registro (opcional).\n\n\nsecurity: modo de seguridad. Valores soportados: NoSec, PSK, RPK and\n              Certificate (OBLIGATORIO).\n\n\npublic: clave p\u00fablica o identidad del cliente, definida por el recurso\n            \n/0/x/3\n.\n\n\nserver: clave p\u00fablica del servidor, definida por el recurso \n/0/x/4\n.\n\n\nsecret: clave privada definida por el recurso \n/0/x/5\n.\n\n\n\n\n[Endpoint]\n contiene las operaciones de \nbootstrapping\n Si no se especifica\nun nombre (Name) las operaciones se enviar\u00e1n a cualquier cliente desconocido\nque solicite \nbootstrapping\n\nSi se especifica, las operaciones se enviar\u00e1n s\u00f3lo al cliente con el correspondiente\nnombre. Las operaciones se env\u00edan en el orden definido en el fichero.\n\n\nLas claves soportadas en esta secci\u00f3n son:\n  - Name: Nombre del cliente (OPCIONAL).\n  - Delete: Debe ser una URI LWM2M v\u00e1lida, incluida \n/\n. Env\u00eda una operaci\u00f3n\ndelete en la URI indicada.\n  - Server: [Value] es un ID de servidor que debe existir en la secci\u00f3n correspondiente.\nEnv\u00eda operaciones de escritura sobre el objeto correspondiente del cliente para\ndefinir el servidor sobre el que debe conectar.\n\n\n\n\nTarea\n\n\nAnaliza e intenta entender el contenido por defecto del fichero de \n\nbootstrapping\n proporcionado. Puedes de momento obviar los par\u00e1metros referentes\na seguridad, ya que los trataremos en la pr\u00f3xima pr\u00e1ctica.\n\n\n\n\n\n\nTarea entregable\n\n\nModifica el fichero de configuraci\u00f3n para que, ante la petici\u00f3n de un cliente\ncon nombre determinado, conecte, por este orden, a un servidor LWM2M en la \nm\u00e1quina local, y al servidor de pruebas de Leshan en Internet. Adem\u00e1s, elimina\ncualquier intento de borrado de recursos en la informaci\u00f3n de \nbootstrapping\n \npara dicho cliente.\n\n\n\n\nPara arrancar el servidor \nbootstrap\n, basta con ejecutar (puedes utilizar\notro fichero de configuraci\u00f3n):\n\n\n./build/bootstrap_server -f bootstrap_server.ini\n\n\n\n\nEl servidor quedar\u00e1 a la espera de peticiones por parte del cualquier cliente\nen el puerto 5685, tal y como indica su salida. Se puede forzar un proceso\nde \nbootstrapping\n con el comando \nboot\n, pero en este punto no es necesario.\n\n\nA continuaci\u00f3n, lanzaremos un cliente indicando que deseamos un proceso de\n\nbootstrapping\n contra el servidor local. \nAseg\u00farate de dar un nombre a tu\ndispositivo que te permita diferenciarlo de cualquier otro\n:\n\n\n\n\nNota importante\n\n\nAntes de realizar este ejercicio, debes modificar una l\u00ednea del fichero\n\nlwm2mclient.c\n, reemplazando la l\u00ednea que contiene \ndata.addressFamily = AF_INET6;\n\npor \ndata.addressFamily = AF_INET;\n.\n\n\n\n\n./lwm2mclient -h localhost -p 5685 -b -c -n midispositivo\nTrying to bind LWM2M Client to port 56830\nLWM2M Client \"testlwm2mclient\" started on port 56830\n> New Battery Level: 38\nvalue changed!\nOpening connection to server at localhost:5685\n -> State: STATE_BOOTSTRAPPING\n -> State: STATE_BOOTSTRAPPING\n -> State: STATE_BOOTSTRAPPING\n\n\n\n\n\nObserva que las opciones de invocaci\u00f3n han cambiado, y hemos usado \n-b\n para indicar\nque deseamos un proceso de \nbootstrapping\n contra el servidor proporcionado. Como\nnota adicional, la opci\u00f3n \n-c\n simplemente actualiza de forma peri\u00f3dica la lectura\ndel nivel de bater\u00eda (esto no es en absoluto obligatorio, pero as\u00ed podremos\nobservar sus cambios desde el servidor).\n\n\nSi todo ha ido bien, el cliente estar\u00e1 ahora registrado en dos servidores:\nel local Wakaama (observa su salida) y el remoto Leshan, al que puedes acceder\na trav\u00e9s de la direcci\u00f3n \nleshan.eclipseprojects.io\n.\n\n\nEclipse Leshan. Despliegue de un servidor local\n\n\nEn este punto, tu cliente deber\u00eda estar conectado tanto a tu servidor LWM2M Wakaama\nlocal, como a un servidor Leshan en la nube. Aprovecha esta situaci\u00f3n para observar\nlas funcionalides del servidor Leshan. Deber\u00edas, para un dispositivo con nombre\n\n\"foo\"\n observar algo como esto:\n\n\n\n\nObserva que todos y cada uno de los objetos de los que hablamos anteriormente\nse muestran ahora en pantalla tras el proceso de registro. Adem\u00e1s, para aquellos\nque son bien conocidos (estandarizados por la OMA), se muestran nombres legibles,\nno s\u00f3lo URIs. \n\n\n\n\nTarea\n\n\nBusca y observa el recurso que te indica el nivel de bater\u00eda del cliente, y \nobserva c\u00f3mo se actualiza autom\u00e1ticamente cuando var\u00eda en el cliente (ver\u00e1s \na la vez un cambio en el servidor y un mensaje en el cliente). Interact\u00faa\ncon el objeto de \ntest\n que se defini\u00f3 anteriormente. En todos los casos,\nobserva que, efectivamente, el tr\u00e1fico generado corresponde al esperado.\n\n\n\n\nPara replicar dicha instalaci\u00f3n en tu m\u00e1quina local, rescata la instalaci\u00f3n\nde Leshan que realizaste en la primera parte de la pr\u00e1ctica, y arranca el \nservidor LWM2M usando la siguiente orden:\n\n\njava -jar leshan-server-demo/target/leshan-server-demo-*-SNAPSHOT-jar-with-dependencies.jar\n\n\n\n\n\n\nTarea entregable\n\n\nArranca el servidor Leshan para que escuche en un puerto diferente al que \nest\u00e1 escuchando ya el servidor Wakaama, para que puedan convivir en la misma \nm\u00e1quina. Modifica tu proceso de provisionamiento para que el cliente o clientes\nse conecten a ambos servidores.\n\n\n\n\n\n\nTarea entregable\n\n\nEl principal objetivo de esta parte es que seas capaz de definir un objeto \ne instanciarlo, con una cantidad de recursos suficientemente rica como para\nobservar y ejercitar las capacidades de LWM2M en general, y de Eclipse\nWakaama en particular. Por ello, se pide que definas, en primer lugar, \nuno o m\u00faltiples objetos y sus recursos que podr\u00edan formar parte de un \nhipot\u00e9tico sensor IoT. En segundo lugar, se pide que, siguiendo las \ndirectivas del c\u00f3digo analizado, lo implementes en Eclipse Wakaama y seas\ncapaz de interactuar con \u00e9l desde un servidor Leshan y/o Wakaama utilizando\nadem\u00e1s un proceso de provisionamiento o \nbootstrapping\n.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P8/#practica-8-el-protocolo-lwm2m",
            "text": "",
            "title": "Pr\u00e1ctica 8. El protocolo LWM2M"
        },
        {
            "location": "/Subjects/NP2/P8/#objetivos",
            "text": "Familiarizarse con el protocolo LWM2M, tanto en la interacci\u00f3n con servidores\ncomo en la generaci\u00f3n y definici\u00f3n de objetos y recursos.  Familiarizarse con el protocolo de  bootstrapping  LWM2M y entender su\nimportancia en entornos reales.  Conocer dos herramientas para el desarrollo de sistemas basados en LWM2M:\nWakaama y Leshan.  Experimentar con el proceso de definici\u00f3n de objetos en Wakaama.  Observar y poner en marcha un proceso de provisionamiento ( bootstrapping )\nusando Wakaama.  Desplegar servidores locales LWM2M usando tanto Wakaama como Leshan.",
            "title": "Objetivos"
        },
        {
            "location": "/Subjects/NP2/P8/#el-protocolo-lwm2m",
            "text": "OMA Lightweight M2M (LWM2M) es un protocolo impulsado por la Open Mobile\nAlliance para la comunicaci\u00f3n M2M entre dispositivos y su gesti\u00f3n en entornos\nIoT. LWM2M est\u00e1 construido sobre el protocolo CoAP, y soporta, a nivel de \ntransporte, el protocolo UDP (tambi\u00e9n presenta soporte para SMS). \nEntre las funcionalidades b\u00e1sicas de LWM2M destacan la existencia de servidores\nLWM2M,  bootstrapping , control de acceso, gesti\u00f3n de dispositivos, \nactualizaciones de  firmware , localizaci\u00f3n o estad\u00edsticas de conectividad. \nAdem\u00e1s, soporta seguridad a trav\u00e9s de DTLS.  Concretamente, la primera especificaci\u00f3n de LWM2M (versi\u00f3n 1.0) introdujo las\nsiguientes caracter\u00edsticas b\u00e1sicas:   Definici\u00f3n de un modelo simple para la definici\u00f3n de recursos, basado en objetos.  Definici\u00f3n de operaciones de creaci\u00f3n, consulta, modificaci\u00f3n, borrado y \n  configuraci\u00f3n de recursos.  Observaci\u00f3n/notificaci\u00f3n sobre recursos.  Soporte para formato de datos JSON, texto plano y TLV.  Colas de mensajes para soportar modos de bajo consumo en dispositivos.  Soporte para m\u00faltiples servidores LWM2M.  Objetos b\u00e1sicos LWM2M: Seguridad, Servidor, Control de Acceso, Dispositivo,\nConectividad, Actualizaci\u00f3n de Firmware, Localizaci\u00f3n, Estad\u00edsticas de \nConectividad. Para m\u00e1s informaci\u00f3n sobre los objetos predefinidos, \nconsulta el  siguiente enlace .   Versiones subsiguientes del protocolo (1.1 y 1.2) introdujeron caracter\u00edsticas\nadicionales, como por ejemplo:   Mejora del proceso de  bootstrapping .  Mejora del soporte para PKI.  Soporte para TCP/TLS.  Soporte para CBOR.  Soporte para MQTT y HTTP como protocolos subyacentes.",
            "title": "El protocolo LWM2M"
        },
        {
            "location": "/Subjects/NP2/P8/#implementaciones-lwm2m",
            "text": "En la presente pr\u00e1ctica, utilizaremos dos paquetes de  software  pertenecientes\nal proyecto Eclipse IoT, ambos con soporte completo para LWM2M. Cada uno de\nellos presenta ventajas e inconvenientes que es necesario conocer.",
            "title": "Implementaciones LWM2M"
        },
        {
            "location": "/Subjects/NP2/P8/#eclipse-wakaama",
            "text": "Eclipse Wakaama es un conjunto de ficheros fuente escritos en C que permiten ser integrados\nen cualquier proyecto para proporcionar funcionalidad de  cliente ,  servidor \ny  servidor de bootstrap  LWM2M hasta su versi\u00f3n 1.1. \nEn el lado cliente, Wakaama permite la \ndefinici\u00f3n de objetos conforme al est\u00e1ndar, as\u00ed como la recepci\u00f3n de comandos\ndesde servidores y su enrutado hacia el objeto u objetos correspondientes. Desde\nel punto de vista servidor, Wakaama proporciona APIs para enviar comandos a \nclientes LWM2M registrados.   Todo el proyecto es compatible con POSIX, y en esta pr\u00e1ctica experimentaremos \ncon su funcionalidad trabajando desde Linux (modo cliente, servidor y \nservidor de  bootstrap ) y desde el ESP32 (modo cliente).",
            "title": "Eclipse Wakaama"
        },
        {
            "location": "/Subjects/NP2/P8/#instalacion",
            "text": "Utilizaremos una versi\u00f3n espec\u00edfica que permitir\u00e1 ser ejecutada tanto en \nLinux como en el ESP32. Para ello, clonamos en primer lugar la versi\u00f3n \ncorrespondiente del proyecto (es importante que utilices este commit  espec\u00edfico):  git clone https://github.com/eclipse/wakaama.git\ncd wakaama\ngit reset --hard 31d64c0c41fae9653c1fa53ef58d1a44e49017fa  El proyecto Wakaama proporciona cuatro componentes que utilizaremos durante\nla pr\u00e1ctica, todos dentro del directorio  examples :   bootstrap_server : implementa un servidor de  bootstrap  con l\u00ednea de \n  comandos propia.  client : implementa un cliente complejo, con definici\u00f3n de nueve objetos\n  que siguen las especificaciones de la OMA m\u00e1s uno propio, \n  y soporte para  bootstrapping .  lightclient : implementa un cliente sencillo, con definici\u00f3n de tres objetos\n  seg\u00fan especificaciones OMA y un cuarto objeto propio.  server : implementa un servidor LWM2M que ofrece l\u00ednea de comandos para\n  la interacci\u00f3n con clientes registrados.   El modo de compilar cada uno de los ejemplos es exactamente el mismo:   Dir\u00edgete al directorio del ejemplo.  Crea un directorio  build  y accede a \u00e9l.  Configura el proyecto con la orden  cmake .. .  Compila el ejemplo con la orden  make .   Si todo ha ido bien, deber\u00edas tener un binario distinto en el directorio build  correspondiente, con los que trabajar\u00e1s el resto de la pr\u00e1ctica.   Tarea  Compila cada uno de los ejemplos anteriormente mencionados en tu m\u00e1quina\nvirtual, utilizando los par\u00e1metros por defecto para cada uno de ellos.",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/Subjects/NP2/P8/#eclipse-leshan",
            "text": "Eclipse Leshan es un proyecto alternativo que proporciona implementaciones en\nJava de clientes, servidores y servidores de  bootstrap  LWM2M, y est\u00e1 especialmente\ndise\u00f1ado para ser adaptable y extensible, permitiendo a los desarrolladores \nimplementar sus propias versiones de cada uno de los tres anteriores elmentos\nadaptados a sus necesidades espec\u00edficas. Al igual que Wakaama, Leshan proporciona\nla definici\u00f3n e interacci\u00f3n con objetos IPSO, construcci\u00f3n sobre DTLS y\nutilizaci\u00f3n de CoAP como protocolo subyacente.  Adem\u00e1s, el proyecto proporciona dos servidores de test que resultan muy \u00fatiles\n a la hora de desarrollar, v\u00e9ase:   Servidor LWM2M en  leshan.eclipseprojects.io , disponible en  coap://leshan.eclipseprojects.io:5683 y coaps://leshan.eclipseprojects.io:5684 .  Servidor de  bootstrap  en  leshan.eclipseprojects.io/bs , disponible en  coap://leshan.eclipseprojects.io:5783 y coaps://leshan.eclipseprojects.io:5784 .",
            "title": "Eclipse Leshan"
        },
        {
            "location": "/Subjects/NP2/P8/#instalacion_1",
            "text": "Instala en primer lugar los prerequisitos necesarios para la correcta instalaci\u00f3n\nde Leshan (pueden variar en funci\u00f3n de tu distribuci\u00f3n Linux):  sudo apt-get update\nsudo apt-get install openjdk-14-jdk maven git-core  Clona el repositorio oficial de Leshan desde la siguiente direcci\u00f3n:  git clone https://github.com/eclipse/leshan.git  Por \u00faltimo, compila el proyecto:  cd leshan\nmvn clean install  Tras la fase de instalaci\u00f3n, podr\u00e1s lanzar tanto el servidor LWM2M:  java -jar leshan-server-demo/target/leshan-server-demo-*-SNAPSHOT-jar-with-dependencies.jar   La opci\u00f3n  -h  te permitir\u00e1 observar la ayuda del servidor.  Como el servidor de  bootstrapping :  java -jar leshan-bsserver-demo/target/leshan-bsserver-demo-*-SNAPSHOT-jar-with-dependencies.jar  La opci\u00f3n  -h  te permitir\u00e1 observar la ayuda del servidor.  En ambos casos, la salida asociada a la ejecuci\u00f3n de los servidores nos \nindicar\u00e1n la URL que podremos consultar desde cualquier navegador para \nobtener informaci\u00f3n del mismo, as\u00ed como la URL y puerto de escucha de cada\nuno, que deberemos indicar en los clientes correspondientes.   Tarea  Instala Eclipse Leshan y arranca el servidor LWM2M. Accede a la p\u00e1gina\nweb de gesti\u00f3n y comprueba que efectivamente funciona. A continucaci\u00f3n,\ndetenlo y haz lo propio con el servidor de  bootstrapping .",
            "title": "Instalaci\u00f3n"
        },
        {
            "location": "/Subjects/NP2/P8/#eclipse-wakaama-cliente-y-servidor-lwm2m",
            "text": "El objetivo principal de esta parte de la pr\u00e1ctica ser\u00e1 disponer de un sistema\ncompleto LWM2M basado en un cliente y dos servidores (uno LWM2M, otro de bootstrapping ), todos funcionando bajo Eclipse Wakaama.  Para ello, en primer lugar, arrancaremos el servidor Wakaama en una de las\nterminales. Observa que el servidor, tras arrancar, expone una sencilla\nl\u00ednea de comandos que podemos aprovechar para interactuar con \u00e9l:  ./lwm2mserver \n\n> help\nhelp    Type 'help [COMMAND]' for more details on a command.\nlist    List registered clients.\nread    Read from a client.\ndisc    Discover resources of a client.\nwrite   Write to a client.\ntime    Write time-related attributes to a client.\nattr    Write value-related attributes to a client.\nclear   Clear attributes of a client.\nexec    Execute a client resource.\ndel Delete a client Object instance.\ncreate  Create an Object instance.\nobserve Observe from a client.\ncancel  Cancel an observe.\nq   Quit the server.  La orden  help  muestra la ayuda global, pudi\u00e9ndose especializar para cada\ncomando concreto:  > help read\n read CLIENT# URI\n   CLIENT#: client number as returned by command 'list'\n   URI: uri to read such as /3, /3/0/2, /1024/11, /1024/0/1\nResult will be displayed asynchronously.  Si en este instante listamos un los clientes registrados, veremos que no\nhay ninguno:  > list\nNo client.  En segundo lugar, vamos a arrancar el cliente Wakaama. Por defecto, este cliente\nintentar\u00e1 conectar con un servidor LWM2M existente en  localhost , puerto \n5683. En cualquier caso, estos valores pueden modificarse en la propia \ninvocaci\u00f3n (consulta la opci\u00f3n  -h  para m\u00e1s informaci\u00f3n sobre par\u00e1metros\ndisponibles):  ./lwm2mclient\nTrying to bind LWM2M Client to port 56830\nLWM2M Client \"testlwm2mclient\" started on port 56830\n> Opening connection to server at ::1:5683\n -> State: STATE_REGISTERING\n13 bytes received from [::1]:5683\n64 41 69 06  06 69 E8 86  82 72 64 01  30  dAi..i...rd.0\n -> State: STATE_READY\n\n\n> help\nhelp    Type 'help [COMMAND]' for more details on a command.\nlist    List known servers.\nchange  Change the value of resource.\nupdate  Trigger a registration update\nbootstrap   Initiate a DI bootstrap process\ndispb   Display current backup of objects/instances/resources\n        (only security and server objects are backupped)\nls  List Objects and Instances\ndisp    Display current objects/instances/resources\ndump    Dump an Object\nadd Add support of object 31024\nrm  Remove support of object 31024\nquit    Quit the client gracefully.\n^C  Quit the client abruptly (without sending a de-register message).\n\n>  -> State: STATE_READY  Al igual que el servidor, el cliente soporta la introducci\u00f3n de comandos\npor parte del usuario.  Observa que hemos ejecutado el comando  help \npara mostrar los comandos disponibles.   Adem\u00e1s, el cliente ha pasado desde un estado  STATE_REGISTERING  a un estado STATE_READY , lo que significa que se ha registrado correctamente en el \nservidor con el nombre  testlwm2mclient .  Observa ahora la salida del servidor, y ver\u00e1s que \u00e9ste ha realizado un \nproceso de descubrimiento de recursos en el cliente conectado. Concretamente,\nel servidor reporta la informaci\u00f3n relativa al nuevo cliente conectado:  New client #0 registered.\nClient #0:\n    name: \"testlwm2mclient\"\n    version: \"1.1\"\n    binding: \"UDP\"\n    lifetime: 300 sec\n    objects: /1/0, /2/0, /3/0, /4/0, /5/0, /6/0, /7/0, /31024/10, /31024/11, /31024/12,   Concretamente, el n\u00famero asociado al cliente es el  0 . Podemos recuperar\nesta informaci\u00f3n en todo momento con el comando  list  en el servidor.  En el cliente, puedes seleccionar el nombre que se utilizar\u00e1 en el proceso\nde registro con la opci\u00f3n  -n .   Tarea entregable  Observa, utilizando Wireshark, el proceso de registro de un cliente en un\nservidor, y analiza el contenido del mensaje o mensajes intercambiados entre\nambos. \u00bfQu\u00e9 protocolos se utilizan?   El cliente con el que estamos trabajando es suficientemente complejo en su\nfuncionamiento, y permite observar c\u00f3mo se implementa el soporte tanto para\nobjetos predefinidos por la OMA como para objetos propios. Concretamente,\nel cliente implementa nueve objetos distintos:   Security Object  ( id=0 ).  Server Object  ( id=1 ).  Access Control Object  ( id=2 ), como un simple esqueleto, sin funcionalidad asociada.  Device Object  ( id=3 ), que contiene (y devuelve) valores espec\u00edficos \ncodificados en base al ap\u00e9ndice E de la especificaci\u00f3n t\u00e9cnica de LWM2M.  Connectivity Monitoring Object  ( id=4 ), como un simple esqueleto, sin funcionalidad.  Firmware Update Object  ( id=5 ), como un simple esqueleto, sin funcionalidad.  Location Object  ( id=6 ), como un simple esqueleto, sin funcionalidad.  Connectivity Statistics Object  ( id=7 ), como un simple esqueleto, sin funcionalidad.  Test Object  ( id=31024 ), con la siguiente descripci\u00f3n:   Objetos:     Objeto  ID  Multiples Instancias  Obligatorio      Test  31024  S\u00ed  No     Recurso:     Nombre  ID  Operaciones  M\u00faltiples Instancias  Obligatorio  Tipo  Rango      test  1  R/W  No  Yes  Integer  0-255    exec  2  E  No  Yes      dec  3  R/W  No  Yes  Float      En el cliente, el comando  dump  nos permitir\u00e1 observar el contenido de una \ninstancia determinada de un objeto, o de todas ellas. En el servidor, el\ncomando  read  nos permitir\u00e1 hacer lo propio.   Tarea entregable  Analiza el valor actual de los objetos  /3  y el objeto de test, tanto desde\nel cliente (comando  dump ) como desde el servidor (comando  read ). En \n\u00faltimo caso, realiza una captura de tr\u00e1fico v\u00eda Wireshark y analiza los \nmensajes intercambiados entre ambos extremos.   Para escribir en un determinado recurso desde el servidor, podemos hacer\nuso del comando  write  de la siguiente forma:  write 0 /31024/10/1 91  As\u00ed, estar\u00edamos escribiendo en el recurso  1  de la instancia  10  del objeto 31024  el valor entero 91.   Tarea entregable  Realiza escrituras en objetos del cliente y analiza el nuevo valor, comprobando\nque efectivamente se han llevado a cabo. \nRealiza una captura de tr\u00e1fico v\u00eda Wireshark y analiza los \nmensajes intercambiados entre ambos extremos en el caso de una escritura.\nObserva tambi\u00e9n que el servidor permite la observaci\u00f3n de recursos espec\u00edficos\n(comando  observe ).\nExperimenta con esta opci\u00f3n y observa el tr\u00e1fico generado (puedes modificar\nel valor de un recurso desde el propio cliente y ver qu\u00e9 ocurre en el servidor).   Por \u00faltimo, con la orden  quit  desconectamos del servidor. Observa tambi\u00e9n\nlos mensajes CoAP que se generan en este caso.",
            "title": "Eclipse Wakaama. Cliente y servidor LWM2M"
        },
        {
            "location": "/Subjects/NP2/P8/#definicion-de-un-objeto-en-eclipse-wakaama",
            "text": "Como has podido observar, el ejemplo de cliente define una serie de objetos,\nalgunos especificados por la OMA, y otros personalizados. En este \u00faltimo\ncaso, al que nos referiremos como  test_object , se utilizan e ilustran \nalgunas de las funcionalidades b\u00e1sicas de Wakaama como infraestructura\npara el desarrollo de Smart Objects v\u00eda LWM2M.  Observa tanto el c\u00f3digo del cliente LWM2M (fichero fuente  lwm2mclient.c  del\nejemplo  client ) como la definici\u00f3n del objeto de test (fichero fuente test_object.c ).   El primer fichero implementa la l\u00f3gica principal del cliente, \nincluyendo gesti\u00f3n de la conexi\u00f3n, l\u00f3gica de an\u00e1lisis de comandos introducidos\npor el usuario, gesti\u00f3n de  bootstrapping , etc. Concretamente, nos interesa\nanalizar las l\u00edneas relativas a la invocaci\u00f3n de la funci\u00f3n  get_test_object ,\nen cuyo interior se definen tanto los recursos como el comportamiento de \nnuestro cliente ante distintos tipos de operaciones sobre ellos. Observa que,\nal igual que para nuestro objeto de test, existen funciones similares \npara el resto de objetos definidos (obviamente podr\u00edan existir m\u00e1s), con un\nfichero fuente donde se define el comportamiento de cada uno de ellos.  Uno de estos objetos es  test_object.c . La principal funci\u00f3n de entrada\na este m\u00f3dulo es precisamente  get_test_object() . Observa que, en ella, \nse define el identificador del objeto, as\u00ed como cada uno de los recursos que\nexpone (en este caso, tres), sus valores iniciales, \ny las funciones que se utilizar\u00e1n como  callbacks  asociados a cada posible operaci\u00f3n:    lwm2m_object_t * testObj;\n\n    testObj = (lwm2m_object_t *)lwm2m_malloc(sizeof(lwm2m_object_t));\n\n    if (NULL != testObj)\n    {\n        int i; \n        prv_instance_t * targetP;\n\n        memset(testObj, 0, sizeof(lwm2m_object_t));\n\n        testObj->objID = TEST_OBJECT_ID;\n        for (i=0 ; i < 3 ; i++)\n        {\n            targetP = (prv_instance_t *)lwm2m_malloc(sizeof(prv_instance_t));\n            if (NULL == targetP) return NULL;\n            memset(targetP, 0, sizeof(prv_instance_t));\n            targetP->shortID = 10 + i;\n            targetP->test    = 20 + i;\n            targetP->dec     = -30 + i + (double)i/100.0;\n            testObj->instanceList = LWM2M_LIST_ADD(testObj->instanceList, targetP);\n        }\n        /*\n         * From a single instance object, two more functions are available.\n         * - The first one (createFunc) create a new instance and filled it with the provided informations. If an ID is\n         *   provided a check is done for verifying his disponibility, or a new one is generated.\n         * - The other one (deleteFunc) delete an instance by removing it from the instance list (and freeing the memory\n         *   allocated to it)\n         */\n        testObj->readFunc = prv_read;\n        testObj->discoverFunc = prv_discover;\n        testObj->writeFunc = prv_write;\n        testObj->executeFunc = prv_exec;\n        testObj->createFunc = prv_create;\n        testObj->deleteFunc = prv_delete;\n    }\n\n    return testObj;  Estas funciones de  callback  est\u00e1n definidas en el propio fichero, y su \ncontenido es personalizable en funci\u00f3n del dise\u00f1o del objeto. Observemos, \npor ejemplo, el contenido de la funci\u00f3n asociada a la lectura,  prv_read :  static uint8_t prv_read(uint16_t instanceId,\n                        int * numDataP,\n                        lwm2m_data_t ** dataArrayP,\n                        lwm2m_object_t * objectP)\n{\n    prv_instance_t * targetP;\n    int i;\n\n    targetP = (prv_instance_t *)lwm2m_list_find(objectP->instanceList, instanceId);\n    if (NULL == targetP) return COAP_404_NOT_FOUND;\n\n    if (*numDataP == 0)\n    {\n        *dataArrayP = lwm2m_data_new(2);\n        if (*dataArrayP == NULL) return COAP_500_INTERNAL_SERVER_ERROR;\n        *numDataP = 2;\n        (*dataArrayP)[0].id = 1;\n        (*dataArrayP)[1].id = 3;\n    }\n\n    for (i = 0 ; i < *numDataP ; i++)\n    {\n        switch ((*dataArrayP)[i].id)\n        {\n        case 1:\n            lwm2m_data_encode_int(targetP->test, *dataArrayP + i);\n            break;\n        case 2:\n            return COAP_405_METHOD_NOT_ALLOWED;\n        case 3:\n            lwm2m_data_encode_float(targetP->dec, *dataArrayP + i);\n            break;\n        default:\n            return COAP_404_NOT_FOUND;\n        }\n    }\n\n    return COAP_205_CONTENT;\n}  Observa que en primer lugar se busca la instancia del objeto solicitada, \ndevolvi\u00e9ndose el error correspondiente en caso de no existir (puedes \ncomprobar esta funcionalidad solicitando desde el servidor la lectura de \nuna instancia inexistente).  El par\u00e1metro  numDataP  nos indica el recurso concreto que se desea leer, o\ntodos si dicho valor es 0.  Tras tomar el valor actual a servir, \u00e9ste se codifica en funci\u00f3n del tipo de\ndatos predefinido para el recurso espec\u00edfico solicitado. En caso de no \nestar soportado el m\u00e9todo para un recurso espec\u00edfico, se devuelve el error\ncorrespondiente (en este caso  405 ). En caso de solicitar un recurso inexistente,\nse devuelve el error  404 .   Tarea  Comprueba que el comportamiento del objeto de test es el esperado, interactuando\ncon \u00e9l desde el servidor utilizando todos los m\u00e9todos disponibles. Puedes modificar\nsu comportamiento, a\u00f1adir invocaciones a rutinas de  log , o lo que consideres\nde utilidad.",
            "title": "Definici\u00f3n de un objeto en Eclipse Wakaama"
        },
        {
            "location": "/Subjects/NP2/P8/#eclipse-wakaama-bootstrapping",
            "text": "En este punto, el cliente Wakaama se conecta directamente con el servidor \nque hemos lanzado, y cuya direcci\u00f3n IP y puerto son los proporcionados por \ndefecto en el c\u00f3digo. Llevado el cliente a un sensor, esto har\u00eda que nunca\npudiese variar, durante el ciclo de vida del mismo, el servidor (o servidores)\na los que conecta. Esto hace tambi\u00e9n que un cliente pueda \u00fanicamente conectar\ncon un servidor LWM2M, cuando en algunas ocasiones es deseable replicar los\nmensajes enviados a m\u00faltiples servidores, bien por razones de tolerancia\na fallos, o bien por necesidades de la aplicaci\u00f3n.  Para solucionar este problema, los  firmwares  de f\u00e1brica suelen conocer \u00fanicamente\nla direcci\u00f3n o direcciones fijas de uno o varios servidores de  bootstrap  que,\nante peticiones de provisionamiento, proporcionan al cliente las credenciales\nde seguridad y las direcciones de los servidores LWM2M en los que deben \nregistrarse. As\u00ed, resulta sencillo manejar din\u00e1micamente ambos aspectos sin necesitar reflashear  el  firmware  del sensor.  En nuestro caso, utilizaremos un sencillo servidor de  bootstrap  proporcionado\npor Wakaama, aunque Leshan ofrece mecanismos mucho m\u00e1s sofisticados para realizar\neste mismo proceso, con su propio esqueleto de servidor  bootstrap  e interfaces\nREST (con monitores web) para gestionar el proceso.  En primer lugar, dir\u00edgete al directorio que contiene el servidor  bootstrap  de\nWakaama. All\u00ed encontrar\u00e1s un fichero de configuraci\u00f3n \n( bootstrap_server.ini ) para el proceso de  bootstrapping , cuyo contenido es completamente estructurado. El servidor,\nante una petici\u00f3n de  bootstrapping  por parte de un cliente, responde en \nfunci\u00f3n del contenido del fichero, que sigue las siguientes directivas:  Las secciones soportadas son  [Server]  y  [Endpoint] .  [Server]  describe una cuenta en un servidor LWM2M:  Las claves soportadas en esta secci\u00f3n son:   id: Identificador del servidor. (OBLIGATORIO).  uri: URI del servidor LWM2M (OBLIGATORIO).  bootstrap: YES o NO. Determina si este servidor es un servidor de bootstrap. Su valor por defecto es NO.  lifetime: tiempo de vida del registro (opcional).  security: modo de seguridad. Valores soportados: NoSec, PSK, RPK and\n              Certificate (OBLIGATORIO).  public: clave p\u00fablica o identidad del cliente, definida por el recurso\n             /0/x/3 .  server: clave p\u00fablica del servidor, definida por el recurso  /0/x/4 .  secret: clave privada definida por el recurso  /0/x/5 .   [Endpoint]  contiene las operaciones de  bootstrapping  Si no se especifica\nun nombre (Name) las operaciones se enviar\u00e1n a cualquier cliente desconocido\nque solicite  bootstrapping \nSi se especifica, las operaciones se enviar\u00e1n s\u00f3lo al cliente con el correspondiente\nnombre. Las operaciones se env\u00edan en el orden definido en el fichero.  Las claves soportadas en esta secci\u00f3n son:\n  - Name: Nombre del cliente (OPCIONAL).\n  - Delete: Debe ser una URI LWM2M v\u00e1lida, incluida  / . Env\u00eda una operaci\u00f3n\ndelete en la URI indicada.\n  - Server: [Value] es un ID de servidor que debe existir en la secci\u00f3n correspondiente.\nEnv\u00eda operaciones de escritura sobre el objeto correspondiente del cliente para\ndefinir el servidor sobre el que debe conectar.   Tarea  Analiza e intenta entender el contenido por defecto del fichero de  bootstrapping  proporcionado. Puedes de momento obviar los par\u00e1metros referentes\na seguridad, ya que los trataremos en la pr\u00f3xima pr\u00e1ctica.    Tarea entregable  Modifica el fichero de configuraci\u00f3n para que, ante la petici\u00f3n de un cliente\ncon nombre determinado, conecte, por este orden, a un servidor LWM2M en la \nm\u00e1quina local, y al servidor de pruebas de Leshan en Internet. Adem\u00e1s, elimina\ncualquier intento de borrado de recursos en la informaci\u00f3n de  bootstrapping  \npara dicho cliente.   Para arrancar el servidor  bootstrap , basta con ejecutar (puedes utilizar\notro fichero de configuraci\u00f3n):  ./build/bootstrap_server -f bootstrap_server.ini  El servidor quedar\u00e1 a la espera de peticiones por parte del cualquier cliente\nen el puerto 5685, tal y como indica su salida. Se puede forzar un proceso\nde  bootstrapping  con el comando  boot , pero en este punto no es necesario.  A continuaci\u00f3n, lanzaremos un cliente indicando que deseamos un proceso de bootstrapping  contra el servidor local.  Aseg\u00farate de dar un nombre a tu\ndispositivo que te permita diferenciarlo de cualquier otro :   Nota importante  Antes de realizar este ejercicio, debes modificar una l\u00ednea del fichero lwm2mclient.c , reemplazando la l\u00ednea que contiene  data.addressFamily = AF_INET6; \npor  data.addressFamily = AF_INET; .   ./lwm2mclient -h localhost -p 5685 -b -c -n midispositivo\nTrying to bind LWM2M Client to port 56830\nLWM2M Client \"testlwm2mclient\" started on port 56830\n> New Battery Level: 38\nvalue changed!\nOpening connection to server at localhost:5685\n -> State: STATE_BOOTSTRAPPING\n -> State: STATE_BOOTSTRAPPING\n -> State: STATE_BOOTSTRAPPING  Observa que las opciones de invocaci\u00f3n han cambiado, y hemos usado  -b  para indicar\nque deseamos un proceso de  bootstrapping  contra el servidor proporcionado. Como\nnota adicional, la opci\u00f3n  -c  simplemente actualiza de forma peri\u00f3dica la lectura\ndel nivel de bater\u00eda (esto no es en absoluto obligatorio, pero as\u00ed podremos\nobservar sus cambios desde el servidor).  Si todo ha ido bien, el cliente estar\u00e1 ahora registrado en dos servidores:\nel local Wakaama (observa su salida) y el remoto Leshan, al que puedes acceder\na trav\u00e9s de la direcci\u00f3n  leshan.eclipseprojects.io .",
            "title": "Eclipse Wakaama. Bootstrapping"
        },
        {
            "location": "/Subjects/NP2/P8/#eclipse-leshan-despliegue-de-un-servidor-local",
            "text": "En este punto, tu cliente deber\u00eda estar conectado tanto a tu servidor LWM2M Wakaama\nlocal, como a un servidor Leshan en la nube. Aprovecha esta situaci\u00f3n para observar\nlas funcionalides del servidor Leshan. Deber\u00edas, para un dispositivo con nombre \"foo\"  observar algo como esto:   Observa que todos y cada uno de los objetos de los que hablamos anteriormente\nse muestran ahora en pantalla tras el proceso de registro. Adem\u00e1s, para aquellos\nque son bien conocidos (estandarizados por la OMA), se muestran nombres legibles,\nno s\u00f3lo URIs.    Tarea  Busca y observa el recurso que te indica el nivel de bater\u00eda del cliente, y \nobserva c\u00f3mo se actualiza autom\u00e1ticamente cuando var\u00eda en el cliente (ver\u00e1s \na la vez un cambio en el servidor y un mensaje en el cliente). Interact\u00faa\ncon el objeto de  test  que se defini\u00f3 anteriormente. En todos los casos,\nobserva que, efectivamente, el tr\u00e1fico generado corresponde al esperado.   Para replicar dicha instalaci\u00f3n en tu m\u00e1quina local, rescata la instalaci\u00f3n\nde Leshan que realizaste en la primera parte de la pr\u00e1ctica, y arranca el \nservidor LWM2M usando la siguiente orden:  java -jar leshan-server-demo/target/leshan-server-demo-*-SNAPSHOT-jar-with-dependencies.jar   Tarea entregable  Arranca el servidor Leshan para que escuche en un puerto diferente al que \nest\u00e1 escuchando ya el servidor Wakaama, para que puedan convivir en la misma \nm\u00e1quina. Modifica tu proceso de provisionamiento para que el cliente o clientes\nse conecten a ambos servidores.    Tarea entregable  El principal objetivo de esta parte es que seas capaz de definir un objeto \ne instanciarlo, con una cantidad de recursos suficientemente rica como para\nobservar y ejercitar las capacidades de LWM2M en general, y de Eclipse\nWakaama en particular. Por ello, se pide que definas, en primer lugar, \nuno o m\u00faltiples objetos y sus recursos que podr\u00edan formar parte de un \nhipot\u00e9tico sensor IoT. En segundo lugar, se pide que, siguiendo las \ndirectivas del c\u00f3digo analizado, lo implementes en Eclipse Wakaama y seas\ncapaz de interactuar con \u00e9l desde un servidor Leshan y/o Wakaama utilizando\nadem\u00e1s un proceso de provisionamiento o  bootstrapping .",
            "title": "Eclipse Leshan. Despliegue de un servidor local"
        },
        {
            "location": "/Subjects/NP2/P9/",
            "text": "Laboratory 5. Node-RED\n\n\nIntroduction and goals\n\n\nNode-RED is an open-source tool initially developed by IBM and, being oriented\nto data flow construction, offers mechanisms to associate hardware devices, APIs\nand online services within an IoT ecosystem.\nNode-RED is a graphical tool, usable from within any web browser, that allows\nfor the creation and edition of data flows that take input data (via input nodes)\nprocess them (via processing nodes) and provide outputs (via output nodes).\nAll elements, including complex flows defined by the user, can be stored\nin JSON format and can be imported in other setups. Node-RED allows the interconnection\nof software and hardware elements virtually via any known network protocol, \naccelerating the deployment of IoT infrastructures.\n\n\nThe development of the laboratory differs from that used in previous labs. \nIn this case, this handout includes only information and instructions for the\ninstallation of the Node-RED tool in the Virtual Machine (you can install it \nin any physical machine), and an exercise proposal that you need to design and\nimplement.\n\n\nDuring the first laboratoriy session, the professor will demonstrate the main\nfeatures of Node-RED and a guide for basic use of the tool.\n\n\nInstallation and setup\n\n\nTo install Node-RED in the Virtual Machine, you can use the \nnpm\n package\nmanager:\n\n\nsudo npm install -g --unsafe-perm node-red\n\n\n\n\nIf everything is fine, you should see an output similar to this:\n\n\n+ node-red@1.1.0\nadded 332 packages from 341 contributors in 18.494s\nfound 0 vulnerabilities\n\n\n\n\nIn order to execute Node-RED, once installed, it is possible to use\nthe order \nnode-red\n from any terminal. To stop the process, just use\n\nCtrl-C\n:\n\n\n$ node-red\n\nWelcome to Node-RED\n===================\n\n30 Jun 23:43:39 - [info] Node-RED version: v1.1.0\n30 Jun 23:43:39 - [info] Node.js  version: v10.21.0\n30 Jun 23:43:39 - [info] Darwin 18.7.0 x64 LE\n30 Jun 23:43:39 - [info] Loading palette nodes\n30 Jun 23:43:44 - [warn] rpi-gpio : Raspberry Pi specific node set inactive\n30 Jun 23:43:44 - [info] Settings file  : /Users/nol/.node-red/settings.js\n30 Jun 23:43:44 - [info] HTTP Static    : /Users/nol/node-red/web\n30 Jun 23:43:44 - [info] Context store  : 'default' [module=localfilesystem]\n30 Jun 23:43:44 - [info] User directory : /Users/nol/.node-red\n30 Jun 23:43:44 - [warn] Projects disabled : set editorTheme.projects.enabled=true to enable\n30 Jun 23:43:44 - [info] Creating new flows file : flows_noltop.json\n30 Jun 23:43:44 - [info] Starting flows\n30 Jun 23:43:44 - [info] Started flows\n30 Jun 23:43:44 - [info] Server now running at http://127.0.0.1:1880/red/\n\n\n\n\nWith the software started, it is possible to access to the Node-RED editor\nvia the address \nhttp://localhost:1880\n from any browser.\n\n\nUpon boot, you will observe four areas in the editor:\n\n\n\n\n\n\nMain bar\n, in the upper part, with buttons \nDeploy\n and \nMain Menu\n.\n\n\n\n\n\n\nNode panel\n, on the left side, that gives direct access to all nodes available\nin Node-RED. It is possible to install new nodes via the Node Palette, \navailable via the Main Menu (\nManage Palette\n). \nThese nodes can be dragged to the editor to conform new data flows.\n\n\n\n\n\n\nEdit panel or workspace\n, on the middle of the screen, where you will be able\nto drag and drop new nodes. It is possible to create new flows in independent\ntabs.\n\n\n\n\n\n\nInformation panel\n, on the right part of the screen, where the most\nuseful button is \nDebug\n, with which you will see the output of the \n\nDebug\n in our flows.\n\n\n\n\n\n\nExample 1\n\n\nIn the following, we show a basic use example for the Node-RED editor, including the\nuse of nodes \nInject\n, \nDebug\n and \nFunction\n.\n\n\nNode \nInject\n\n\nThe \nInject\n node can inject messages in a flow, pushing on the button\nassociated to the node, or establishing an interval of time between injections.\nLook in the left panel for a node of type \nInject\n and drag it to the\nworkspace. In the information panel, you can check the data associated to the \nnode, and help information to use it.\n\n\nNode \nDebug\n\n\nThe \nDebug\n node permits that any incoming message is shown in the debug panel, \non the right of the screen. By default, it just shows the message \npayload\n\neven thout it can be configured to show the complete message. Drag a\nnode \nDebug\n the workspace and keep it prepared.\n\n\nLink and deployment (\nDeploy\n)\n\n\nConnect the nodes \nInject\n and \nDebug\n establishing a link (\nWire\n) between both.\nDeploy the flow using the button \nDeploy\n from the main bar. This will deploy the\nflow on the server.\n\n\nSelect the option \nDebug\n on the information panel, and press the button \nInject\n.\nYou should see numbers appearing on the panel. By default, the \nInject\n node emits\nthe numbre of milliseconds from 1/1/1970 as the \npayload\n.\n\n\nModify (temporarily) the node \nDebug\n so that it just shows all the message\ninstead of only the \npayload\n. Deploy the flow again and observe the differences.\n\n\nConfigure again the \nDebug\n node as was when you inserted it.\n\n\nNode \nFunction\n\n\nThe \nFunction\n node can process the input message via a JavaScript function. \nDelete the \nWire\n you created, and add a \nFunction\n node between nodes \nInject\n and\n\nDebug\n.\n\n\nDouble-click on the new node to open the edition dialog. Copy the following code in\nthe \nFunction\n field:\n\n\n// Create a Date object from the payload\nvar date = new Date(msg.payload);\n// Change the payload to be a formatted Date string\nmsg.payload = date.toString();\n// Return the message so it can be sent on\nreturn msg;\n\n\n\n\nClick on \nDone\n and deploy the flow. Observe that, now, the debug messages show\ntimestamps in a visible format. Take into account that a node always receives a \nmessage (\nmsg\n) as an input, and returns a message (\nmsg\n) as an output. Both objects\ncontain a field \npayload\n.\n\n\nFor more information about the use of functions and work with messages,\ninluding multiple return values, and work with global values for the flow, \nthe student is requested to study the following documentation:\n\n\n\n\nWorking with messages\n: \nlink to documentation\n.\n\n\nWorking with functions\n: \nlink to documentation\n.\n\n\n\n\nExample 2\n\n\nNode \nInject\n\n\nIn the last example, we showed how to create an \nInject\n node to activate the\nflow when the associated button was pressed. In this example, we will configure the\n\nInject\n node to activate the flow at regular intervals.\n\n\nDrag a new \nInject\n node in the workspace. Double-click on it and, on the edit\ndialog, use the option \nRepeat interval\n, fixing a regular interval. Close the\nedition dialog.\n\n\nNode \nHTTP Request\n\n\nThe node of type \nHTTP Request\n can be used to download a webpage or HTTP resource.\nAdd une to the workspace and edit it so that its \nURL\n property targets to\n\nhttps://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.csv\n.\n\n\nThis URL is a repository of earthquakes in the last month, published by the official\nentity in charge, returned in a CSV format.\n\n\nNode \nCSV\n\n\nAdd a new \nCSV\n node and edit its properties. Activate the option \n\nFirst row contains column names\n and finish the edition.\n\n\nNode \nDebug\n and wiring\n\n\nAdd a \nDebug\n node and link the nodes:\n\n\n\n\nConnect the output of the \nInject\n node to the input of the \nHTTP Request\n node.\n\n\nConnect the output of the \nHTTP Request\n node to the input to the node \nCSV\n.\n\n\nConnect the output of the \nCSV\n node to the input of the node \nDebug\n.\n\n\n\n\nNode \nSwitch\n\n\nAdd a \nSwitch\n node to the workspace. Edit its properties and configure it \nto check the property \nmsg.payload.mag\n, using the operation \n>=\n on a numeric value and\nthe value \n6.2\n, for example.\n\n\nAdd a second \nWire\n between the node \nCSV\n and the node \nSwitch\n.\n\n\nNode \nChange\n\n\nAdd a node \nChange\n, connected to the output of the \nSwitch\n node. Configure it to establish\na value of \nmsg.payload\n to \nALARM\n.\n\n\nNode \nDebug\n\n\nAdd a \nDebug\n node and deploy the flow. On the \nDebug\n panel you should\nobserve, for eac activatio of the \nInject\n node, an output similar to this:\n\n\nmsg.payload : Object\n{\"time\":\"2017-11-19T15:09:03.120Z\",\"latitude\":-21.5167,\"longitude\":168.5426,\"depth\":14.19,\"mag\":6.6,\"magType\":\"mww\",\"gap\":21,\"dmin\":0.478,\"rms\":0.86,\"net\":\"us\",\"id\":\"us2000brgk\",\"updated\":\"2017-11-19T17:10:58.449Z\",\"place\":\"68km E of Tadine, New Caledonia\",\"type\":\"earthquake\",\"horizontalError\":6.2,\"depthError\":2.8,\"magError\":0.037,\"magNst\":72,\"status\":\"reviewed\",\"locationSource\":\"us\",\"magSource\":\"us\"}\n\n\n\n\nYou can click on the small arrow on the left of each property to expand it and\nto examine the contents.\n\n\nIf there is any earthquake with a magnitude higher than \n6.2\n, you will observe\nan additional output:\n\n\nmsg.payload : string(6)\n\"ALARM\"\n\n\n\n\nFor more information on the basic nodes in Node-RED, you can check:\n\n\n\n\nThe Core Nodes\n: \nlink to documentation\n.\n\n\n\n\nMQTT client and deployment of a control panel (dashboard)\n\n\nThe node \nMQTT in\n can perform subscriptions to \ntopics\n on MQTT brokers.\n\n\nDrag a new \nMQTT in\n node in your workspace and configure the associated\nbroker to \nlocalhost\n, using the default port. Establish a \ntopic\n \nof interest. Connect a \nDebug\n node and deploy the flow.\n\n\nFrom your console, publish messages via \nmosquitto_pub\n and see how, effectively,\nthey can be viewed from Node-RED.\n\n\nNext, we will create a small control panel to graphically represent the\npublished value. First, install the node \n\nnode-red-dashboard\n from the main many, option    \n\n\nManage palette\n. Upon a successful installation, you will see that new nodes\nappear in the control panel; these nodes will let us design and implement a basic\ncontrol based on widgets.\n\n\nDrag a node of type \nGauge\n to the workspace, and configure its default values. Connect\nthe output of your \nMQTT in\n node to the input of the new \nGauge\n node. \n\n\nDeploy the flow, and navigate to \nhttp://localhost:1880/ui\n, where you will \nobserve the control panel with the \nwidget\n you just created. Interat with it \npublishin messages via MQTT.\n\n\nFor more information on the deployment of control panels, you can check:\n\n\n\n\nNode-Red-Dashboard\n: \nlink to documentation\n.\n\n\n\n\nAdditional documentation\n\n\nThe official user guides from Node-RED are a good starting point to further\nstudy on the use of the infrastructures. Between them, the most important\npart to commence is that that introduces the basic concepts of Node-RED, including\nthe work with nodes, flows, contexts (important to work with global and shared values\nacross nodes in a flow, for example), messages, \nwires\n, etc:\n\n\n\n\nNode-RED Concepts\n: \nlink to documentation\n.\n\n\n\n\nThe guide \nNode-RED Guide\n contains interesting documentation (additional and advanced)\nfor the deployment of flows and for the use of control panels (local or using remote\nservices (e.g. \nFreeboard\n)):\n\n\n\n\nNode-RED Guide\n: \nlink to documentation\n.\n\n\n\n\nEjercicio entregable\n\n\nStudy the documentation associatd to Node-RED, both in its webpage\nand on the programming guide \nNode-RED Guide\n (specifically on the first\nfour parts). Together with the demos offered by the professor and previous\nexamples, this study will help you on the development of the exercise.\n\n\n\n\nDeliverable task\n\n\nThe exercise consists on the design and development of a system based on\ndata flows built on top of Node-RED, that implements a mechanism to monitor\nambient parameters (e.g. temperature) and notify (alarm) on given circumstances (e.g.\nif the sensed temperature is higher than a threshold).\n\n\nThe students will design the system and implement it, meeting the following conditions:\n\n\n\n\n\n\n(2/10 points)\n. The system will use, \nat least\n one external device (e.g. ESP32, mobile phone, ...)\nfor data gathering. We will evaluate positively the use of more than one device or type of device.\n\n\n\n\n\n\n(2/10 points)\n. The system will store or interact with, \nat least\n, \none external system (mail server, Twitter, WeChat, Telegram, IBM Bluemix, ...).\n\n\n\n\n\n\n(2/10 points)\n. The system will store observed data on a persisten media (e.g. NoSQL database, files, ...)\nto allow further analysis of them.\n\n\n\n\n\n\n (2/10 points)\n. The system will act as an alarm system only upon certain \ninput conditions (E.g. when receiving a value from a sensor higher than a pre-established\nthreshold; that value could, for example, be configured via MQTT or via a control panel).\n\n\n\n\n\n\n(2/10 points)\n. The system will use, at least, one node type not installed by default\nwith the basic Node-RED installation.\n\n\n\n\n\n\nThe studenst will deliver the JSON file or files that describe the nodes, and a short report\ndescribing the designed system and the developed work, highlighting the difficulties found and \nthose additional aspects considered of interest by the students.\n\n\n\n\n\n\nAdditional task: add to your control panel the capability of simultaneously showing data gathered from \nmultiple\n ESP32s, and demonstrate to the professor that this data is actually gathered from multiple devices (remotely).\n\n\n\n\n\n\nAdditional task: investigate and implement in your Control Panel the ability of communicating with a specific ESP32. For example, you can investigate in how to add a button that, when pressed, activates or deactivates the submission of data from a specific ESP32.",
            "title": "Home"
        },
        {
            "location": "/Subjects/NP2/P9/#laboratory-5-node-red",
            "text": "",
            "title": "Laboratory 5. Node-RED"
        },
        {
            "location": "/Subjects/NP2/P9/#introduction-and-goals",
            "text": "Node-RED is an open-source tool initially developed by IBM and, being oriented\nto data flow construction, offers mechanisms to associate hardware devices, APIs\nand online services within an IoT ecosystem.\nNode-RED is a graphical tool, usable from within any web browser, that allows\nfor the creation and edition of data flows that take input data (via input nodes)\nprocess them (via processing nodes) and provide outputs (via output nodes).\nAll elements, including complex flows defined by the user, can be stored\nin JSON format and can be imported in other setups. Node-RED allows the interconnection\nof software and hardware elements virtually via any known network protocol, \naccelerating the deployment of IoT infrastructures.  The development of the laboratory differs from that used in previous labs. \nIn this case, this handout includes only information and instructions for the\ninstallation of the Node-RED tool in the Virtual Machine (you can install it \nin any physical machine), and an exercise proposal that you need to design and\nimplement.  During the first laboratoriy session, the professor will demonstrate the main\nfeatures of Node-RED and a guide for basic use of the tool.",
            "title": "Introduction and goals"
        },
        {
            "location": "/Subjects/NP2/P9/#installation-and-setup",
            "text": "To install Node-RED in the Virtual Machine, you can use the  npm  package\nmanager:  sudo npm install -g --unsafe-perm node-red  If everything is fine, you should see an output similar to this:  + node-red@1.1.0\nadded 332 packages from 341 contributors in 18.494s\nfound 0 vulnerabilities  In order to execute Node-RED, once installed, it is possible to use\nthe order  node-red  from any terminal. To stop the process, just use Ctrl-C :  $ node-red\n\nWelcome to Node-RED\n===================\n\n30 Jun 23:43:39 - [info] Node-RED version: v1.1.0\n30 Jun 23:43:39 - [info] Node.js  version: v10.21.0\n30 Jun 23:43:39 - [info] Darwin 18.7.0 x64 LE\n30 Jun 23:43:39 - [info] Loading palette nodes\n30 Jun 23:43:44 - [warn] rpi-gpio : Raspberry Pi specific node set inactive\n30 Jun 23:43:44 - [info] Settings file  : /Users/nol/.node-red/settings.js\n30 Jun 23:43:44 - [info] HTTP Static    : /Users/nol/node-red/web\n30 Jun 23:43:44 - [info] Context store  : 'default' [module=localfilesystem]\n30 Jun 23:43:44 - [info] User directory : /Users/nol/.node-red\n30 Jun 23:43:44 - [warn] Projects disabled : set editorTheme.projects.enabled=true to enable\n30 Jun 23:43:44 - [info] Creating new flows file : flows_noltop.json\n30 Jun 23:43:44 - [info] Starting flows\n30 Jun 23:43:44 - [info] Started flows\n30 Jun 23:43:44 - [info] Server now running at http://127.0.0.1:1880/red/  With the software started, it is possible to access to the Node-RED editor\nvia the address  http://localhost:1880  from any browser.  Upon boot, you will observe four areas in the editor:    Main bar , in the upper part, with buttons  Deploy  and  Main Menu .    Node panel , on the left side, that gives direct access to all nodes available\nin Node-RED. It is possible to install new nodes via the Node Palette, \navailable via the Main Menu ( Manage Palette ). \nThese nodes can be dragged to the editor to conform new data flows.    Edit panel or workspace , on the middle of the screen, where you will be able\nto drag and drop new nodes. It is possible to create new flows in independent\ntabs.    Information panel , on the right part of the screen, where the most\nuseful button is  Debug , with which you will see the output of the  Debug  in our flows.",
            "title": "Installation and setup"
        },
        {
            "location": "/Subjects/NP2/P9/#example-1",
            "text": "In the following, we show a basic use example for the Node-RED editor, including the\nuse of nodes  Inject ,  Debug  and  Function .",
            "title": "Example 1"
        },
        {
            "location": "/Subjects/NP2/P9/#node-inject",
            "text": "The  Inject  node can inject messages in a flow, pushing on the button\nassociated to the node, or establishing an interval of time between injections.\nLook in the left panel for a node of type  Inject  and drag it to the\nworkspace. In the information panel, you can check the data associated to the \nnode, and help information to use it.",
            "title": "Node Inject"
        },
        {
            "location": "/Subjects/NP2/P9/#node-debug",
            "text": "The  Debug  node permits that any incoming message is shown in the debug panel, \non the right of the screen. By default, it just shows the message  payload \neven thout it can be configured to show the complete message. Drag a\nnode  Debug  the workspace and keep it prepared.",
            "title": "Node Debug"
        },
        {
            "location": "/Subjects/NP2/P9/#link-and-deployment-deploy",
            "text": "Connect the nodes  Inject  and  Debug  establishing a link ( Wire ) between both.\nDeploy the flow using the button  Deploy  from the main bar. This will deploy the\nflow on the server.  Select the option  Debug  on the information panel, and press the button  Inject .\nYou should see numbers appearing on the panel. By default, the  Inject  node emits\nthe numbre of milliseconds from 1/1/1970 as the  payload .  Modify (temporarily) the node  Debug  so that it just shows all the message\ninstead of only the  payload . Deploy the flow again and observe the differences.  Configure again the  Debug  node as was when you inserted it.",
            "title": "Link and deployment (Deploy)"
        },
        {
            "location": "/Subjects/NP2/P9/#node-function",
            "text": "The  Function  node can process the input message via a JavaScript function. \nDelete the  Wire  you created, and add a  Function  node between nodes  Inject  and Debug .  Double-click on the new node to open the edition dialog. Copy the following code in\nthe  Function  field:  // Create a Date object from the payload\nvar date = new Date(msg.payload);\n// Change the payload to be a formatted Date string\nmsg.payload = date.toString();\n// Return the message so it can be sent on\nreturn msg;  Click on  Done  and deploy the flow. Observe that, now, the debug messages show\ntimestamps in a visible format. Take into account that a node always receives a \nmessage ( msg ) as an input, and returns a message ( msg ) as an output. Both objects\ncontain a field  payload .  For more information about the use of functions and work with messages,\ninluding multiple return values, and work with global values for the flow, \nthe student is requested to study the following documentation:   Working with messages :  link to documentation .  Working with functions :  link to documentation .",
            "title": "Node Function"
        },
        {
            "location": "/Subjects/NP2/P9/#example-2",
            "text": "",
            "title": "Example 2"
        },
        {
            "location": "/Subjects/NP2/P9/#node-inject_1",
            "text": "In the last example, we showed how to create an  Inject  node to activate the\nflow when the associated button was pressed. In this example, we will configure the Inject  node to activate the flow at regular intervals.  Drag a new  Inject  node in the workspace. Double-click on it and, on the edit\ndialog, use the option  Repeat interval , fixing a regular interval. Close the\nedition dialog.",
            "title": "Node Inject"
        },
        {
            "location": "/Subjects/NP2/P9/#node-http-request",
            "text": "The node of type  HTTP Request  can be used to download a webpage or HTTP resource.\nAdd une to the workspace and edit it so that its  URL  property targets to https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.csv .  This URL is a repository of earthquakes in the last month, published by the official\nentity in charge, returned in a CSV format.",
            "title": "Node HTTP Request"
        },
        {
            "location": "/Subjects/NP2/P9/#node-csv",
            "text": "Add a new  CSV  node and edit its properties. Activate the option  First row contains column names  and finish the edition.",
            "title": "Node CSV"
        },
        {
            "location": "/Subjects/NP2/P9/#node-debug-and-wiring",
            "text": "Add a  Debug  node and link the nodes:   Connect the output of the  Inject  node to the input of the  HTTP Request  node.  Connect the output of the  HTTP Request  node to the input to the node  CSV .  Connect the output of the  CSV  node to the input of the node  Debug .",
            "title": "Node Debug and wiring"
        },
        {
            "location": "/Subjects/NP2/P9/#node-switch",
            "text": "Add a  Switch  node to the workspace. Edit its properties and configure it \nto check the property  msg.payload.mag , using the operation  >=  on a numeric value and\nthe value  6.2 , for example.  Add a second  Wire  between the node  CSV  and the node  Switch .",
            "title": "Node Switch"
        },
        {
            "location": "/Subjects/NP2/P9/#node-change",
            "text": "Add a node  Change , connected to the output of the  Switch  node. Configure it to establish\na value of  msg.payload  to  ALARM .",
            "title": "Node Change"
        },
        {
            "location": "/Subjects/NP2/P9/#node-debug_1",
            "text": "Add a  Debug  node and deploy the flow. On the  Debug  panel you should\nobserve, for eac activatio of the  Inject  node, an output similar to this:  msg.payload : Object\n{\"time\":\"2017-11-19T15:09:03.120Z\",\"latitude\":-21.5167,\"longitude\":168.5426,\"depth\":14.19,\"mag\":6.6,\"magType\":\"mww\",\"gap\":21,\"dmin\":0.478,\"rms\":0.86,\"net\":\"us\",\"id\":\"us2000brgk\",\"updated\":\"2017-11-19T17:10:58.449Z\",\"place\":\"68km E of Tadine, New Caledonia\",\"type\":\"earthquake\",\"horizontalError\":6.2,\"depthError\":2.8,\"magError\":0.037,\"magNst\":72,\"status\":\"reviewed\",\"locationSource\":\"us\",\"magSource\":\"us\"}  You can click on the small arrow on the left of each property to expand it and\nto examine the contents.  If there is any earthquake with a magnitude higher than  6.2 , you will observe\nan additional output:  msg.payload : string(6)\n\"ALARM\"  For more information on the basic nodes in Node-RED, you can check:   The Core Nodes :  link to documentation .",
            "title": "Node Debug"
        },
        {
            "location": "/Subjects/NP2/P9/#mqtt-client-and-deployment-of-a-control-panel-dashboard",
            "text": "The node  MQTT in  can perform subscriptions to  topics  on MQTT brokers.  Drag a new  MQTT in  node in your workspace and configure the associated\nbroker to  localhost , using the default port. Establish a  topic  \nof interest. Connect a  Debug  node and deploy the flow.  From your console, publish messages via  mosquitto_pub  and see how, effectively,\nthey can be viewed from Node-RED.  Next, we will create a small control panel to graphically represent the\npublished value. First, install the node  node-red-dashboard  from the main many, option      Manage palette . Upon a successful installation, you will see that new nodes\nappear in the control panel; these nodes will let us design and implement a basic\ncontrol based on widgets.  Drag a node of type  Gauge  to the workspace, and configure its default values. Connect\nthe output of your  MQTT in  node to the input of the new  Gauge  node.   Deploy the flow, and navigate to  http://localhost:1880/ui , where you will \nobserve the control panel with the  widget  you just created. Interat with it \npublishin messages via MQTT.  For more information on the deployment of control panels, you can check:   Node-Red-Dashboard :  link to documentation .",
            "title": "MQTT client and deployment of a control panel (dashboard)"
        },
        {
            "location": "/Subjects/NP2/P9/#additional-documentation",
            "text": "The official user guides from Node-RED are a good starting point to further\nstudy on the use of the infrastructures. Between them, the most important\npart to commence is that that introduces the basic concepts of Node-RED, including\nthe work with nodes, flows, contexts (important to work with global and shared values\nacross nodes in a flow, for example), messages,  wires , etc:   Node-RED Concepts :  link to documentation .   The guide  Node-RED Guide  contains interesting documentation (additional and advanced)\nfor the deployment of flows and for the use of control panels (local or using remote\nservices (e.g.  Freeboard )):   Node-RED Guide :  link to documentation .",
            "title": "Additional documentation"
        },
        {
            "location": "/Subjects/NP2/P9/#ejercicio-entregable",
            "text": "Study the documentation associatd to Node-RED, both in its webpage\nand on the programming guide  Node-RED Guide  (specifically on the first\nfour parts). Together with the demos offered by the professor and previous\nexamples, this study will help you on the development of the exercise.   Deliverable task  The exercise consists on the design and development of a system based on\ndata flows built on top of Node-RED, that implements a mechanism to monitor\nambient parameters (e.g. temperature) and notify (alarm) on given circumstances (e.g.\nif the sensed temperature is higher than a threshold).  The students will design the system and implement it, meeting the following conditions:    (2/10 points) . The system will use,  at least  one external device (e.g. ESP32, mobile phone, ...)\nfor data gathering. We will evaluate positively the use of more than one device or type of device.    (2/10 points) . The system will store or interact with,  at least , \none external system (mail server, Twitter, WeChat, Telegram, IBM Bluemix, ...).    (2/10 points) . The system will store observed data on a persisten media (e.g. NoSQL database, files, ...)\nto allow further analysis of them.     (2/10 points) . The system will act as an alarm system only upon certain \ninput conditions (E.g. when receiving a value from a sensor higher than a pre-established\nthreshold; that value could, for example, be configured via MQTT or via a control panel).    (2/10 points) . The system will use, at least, one node type not installed by default\nwith the basic Node-RED installation.    The studenst will deliver the JSON file or files that describe the nodes, and a short report\ndescribing the designed system and the developed work, highlighting the difficulties found and \nthose additional aspects considered of interest by the students.    Additional task: add to your control panel the capability of simultaneously showing data gathered from  multiple  ESP32s, and demonstrate to the professor that this data is actually gathered from multiple devices (remotely).    Additional task: investigate and implement in your Control Panel the ability of communicating with a specific ESP32. For example, you can investigate in how to add a button that, when pressed, activates or deactivates the submission of data from a specific ESP32.",
            "title": "Ejercicio entregable"
        },
        {
            "location": "/Subjects/SEC/groups/",
            "text": "Groups for lecture assignments\n\n\nWe will be using the stable groups from NP1 to work during lectures (and after\nclass).\n\n\nGroup 1\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nZHOU Ping\n\n\n\n\n\n\n\n\nGroup 2\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nLiu Jinhua\n\n\n\n\n\n\nRecorder\n\n\nHu Haho\n\n\n\n\n\n\nAuditor\n\n\nWeilin Zhang\n\n\n\n\n\n\nContributor\n\n\nDuan Zhen\n\n\n\n\n\n\nContributor\n\n\nYouran Tian\n\n\n\n\n\n\nContributor\n\n\nHuang Yujuan\n\n\n\n\n\n\nContributor\n\n\nJun Shou\n\n\n\n\n\n\n\n\nGroup 3\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nGuanJIE Xiao\n\n\n\n\n\n\nSpeaker (2)\n\n\nDongYang Xu\n\n\n\n\n\n\nRecorder\n\n\nYuanShuang Sha\n\n\n\n\n\n\nAuditor\n\n\nJunyan Guo\n\n\n\n\n\n\nContributor\n\n\nZhijun Hao\n\n\n\n\n\n\nContributor\n\n\nXueqing Zhao\n\n\n\n\n\n\nContributor\n\n\nJiali Gao\n\n\n\n\n\n\nContributor\n\n\nLIAO  Yinghua\n\n\n\n\n\n\nContributor\n\n\nPAN Jiayun\n\n\n\n\n\n\nContributor\n\n\nZHANG  Yi\n\n\n\n\n\n\nContributor\n\n\nWEI REN\n\n\n\n\n\n\n\n\nGroup 4\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nJIEPING YOU\n\n\n\n\n\n\nRecorder\n\n\nQINGHONG YU\n\n\n\n\n\n\nAuditor\n\n\nSUIZHI LIU\n\n\n\n\n\n\nContributor\n\n\nTIANFENG LI\n\n\n\n\n\n\nContributor\n\n\nXIAZU HU\n\n\n\n\n\n\n\n\nGroup 5\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nShuishi Zhou\n\n\n\n\n\n\nContributor\n\n\nYang Chu\n\n\n\n\n\n\nAuditor\n\n\nWENYAN LIAO\n\n\n\n\n\n\nContributor\n\n\nFENGFENG GU\n\n\n\n\n\n\nContributor\n\n\nBIN ZHANG\n\n\n\n\n\n\nContributor\n\n\nHONGBIAO CAO\n\n\n\n\n\n\nContributor\n\n\nGONGLU ZOU\n\n\n\n\n\n\n\n\nGroup 6\n\n\n\n\n\n\n\n\nRol\n\n\nFull name\n\n\n\n\n\n\n\n\n\n\nSpeaker\n\n\nXiaolan Li\n\n\n\n\n\n\nRecorder\n\n\nXionglan Luo\n\n\n\n\n\n\nAuditor\n\n\nQiuji Chen\n\n\n\n\n\n\nContributor\n\n\nJianchuang Zhang\n\n\n\n\n\n\nContributor\n\n\nYan Zhao\n\n\n\n\n\n\nContributor\n\n\nYongtao He\n\n\n\n\n\n\nContributor\n\n\nZhao Hu",
            "title": "Groups"
        },
        {
            "location": "/Subjects/SEC/groups/#groups-for-lecture-assignments",
            "text": "We will be using the stable groups from NP1 to work during lectures (and after\nclass).",
            "title": "Groups for lecture assignments"
        },
        {
            "location": "/Subjects/SEC/groups/#group-1",
            "text": "Rol  Full name      Speaker  ZHOU Ping",
            "title": "Group 1"
        },
        {
            "location": "/Subjects/SEC/groups/#group-2",
            "text": "Rol  Full name      Speaker  Liu Jinhua    Recorder  Hu Haho    Auditor  Weilin Zhang    Contributor  Duan Zhen    Contributor  Youran Tian    Contributor  Huang Yujuan    Contributor  Jun Shou",
            "title": "Group 2"
        },
        {
            "location": "/Subjects/SEC/groups/#group-3",
            "text": "Rol  Full name      Speaker  GuanJIE Xiao    Speaker (2)  DongYang Xu    Recorder  YuanShuang Sha    Auditor  Junyan Guo    Contributor  Zhijun Hao    Contributor  Xueqing Zhao    Contributor  Jiali Gao    Contributor  LIAO  Yinghua    Contributor  PAN Jiayun    Contributor  ZHANG  Yi    Contributor  WEI REN",
            "title": "Group 3"
        },
        {
            "location": "/Subjects/SEC/groups/#group-4",
            "text": "Rol  Full name      Speaker  JIEPING YOU    Recorder  QINGHONG YU    Auditor  SUIZHI LIU    Contributor  TIANFENG LI    Contributor  XIAZU HU",
            "title": "Group 4"
        },
        {
            "location": "/Subjects/SEC/groups/#group-5",
            "text": "Rol  Full name      Speaker  Shuishi Zhou    Contributor  Yang Chu    Auditor  WENYAN LIAO    Contributor  FENGFENG GU    Contributor  BIN ZHANG    Contributor  HONGBIAO CAO    Contributor  GONGLU ZOU",
            "title": "Group 5"
        },
        {
            "location": "/Subjects/SEC/groups/#group-6",
            "text": "Rol  Full name      Speaker  Xiaolan Li    Recorder  Xionglan Luo    Auditor  Qiuji Chen    Contributor  Jianchuang Zhang    Contributor  Yan Zhao    Contributor  Yongtao He    Contributor  Zhao Hu",
            "title": "Group 6"
        },
        {
            "location": "/Subjects/SEC/",
            "text": "Security in IoT\n\n\nGeneral information\n\n\nThis course is a practical introduction to security in IoT systems. During the course, penetration test, or \npentest\n, practices of different real IoT devices will be carried out in order to know their vulnerabilities and thus learn to create more secure devices.\n\n\nSubject program and evaluation methodology\n\n\nProgram and evaluation\n\n\nProfessors\n\n\nGuillemo Botella (gbotella@ucm.es) and Joaqu\u00edn Recas (recas@ucm.es)\n\n\nWork groups (for regular lab assignments)\n\n\nHere you can find the current work groups\n\n\nSchedule\n\n\n\n\n\n\n\n\nDay\n\n\nTopic\n\n\nSlides\n\n\nExtra\n\n\n\n\n\n\n\n\n\n\n19/4\n\n\nIntroduction Security in IoT\n\n\nM1-IoT-Security\n\n\n\n\n\n\n\n\n20/4\n\n\nIntroduction to IoT Pentest\n\n\nM2-Pentest\n\n\n\n\n\n\n\n\n21/4\n\n\nPentest example: IP Camera (I)\n\n\nM3-IPCam\n\n\nMaterial P1\n\n\n\n\n\n\n26/4\n\n\nCryptography (I): Introduction\n\n\nM4-Crypto (1)\n\n\n\n\n\n\n\n\n27/4\n\n\nCryptography (I): Introduction\n\n\nM4-Crypto (2)\n\n\n\n\n\n\n\n\n28/4\n\n\nCryptography (I): Introduction\n\n\nM4-Crypto (2) Cont.\n\n\nM4-Crypto (3) Assignments\n\n\n\n\n\n\n3/5\n\n\nPentest example: IP Camera (II)\n\n\nM3-IPCam (Cont.)\n\n\nMaterial P1 (Cont.)\n\n\n\n\n\n\n4/5\n\n\nPentest example: Smart Bulb (I)\n\n\nM5-SmartBulb\n\n\nMaterial P2\n\n\n\n\n\n\n5/5\n\n\nPentest project: Smart Socket Setup\n\n\nSmartSocket Setup\n\n\nMaterial P3\n\n\n\n\n\n\n10/5\n\n\nCryptography (II)\n\n\nM4-Crypto (4) Lab1\n\n\n\n\n\n\n\n\n11/5\n\n\nCryptography (II)\n\n\nM4-Crypto (4) Lab1 (Cont.)\n\n\n\n\n\n\n\n\n12/5\n\n\nCryptography (II)\n\n\nM4-Crypto (5) Lab2\n\n\nMPPP (Personal Paper Project)\n\n\n\n\n\n\n17/5\n\n\nPentest project: Smart Socket (II)\n\n\nM7-SmartSocket2\n\n\nMaterial P3\n\n\n\n\n\n\n18/5\n\n\nPentest project: Smart Socket (III)\n\n\nM7-SmartSocket3\n\n\nMaterial P3\n\n\n\n\n\n\n19/5\n\n\nPentest project: Smart Socket (IV)\n\n\nM7-SmartSocket4\n\n\nMaterial P3\n\n\n\n\n\n\n24/5\n\n\nCryptography (III)\n\n\nM6-Crypto (6)\n\n\n\n\n\n\n\n\n25/5\n\n\nCryptography (III)\n\n\nM6-Crypto (6)\n (Cont)\n\n\n\n\n\n\n\n\n26/5\n\n\nCryptography (III)\n\n\nM8-Crypto (7)\n\n\n\n\n\n\n\n\n31/5\n\n\nFinal Project (I)\n\n\n\n\n\n\n\n\n\n\n1/6\n\n\nFinal Project (II)\n\n\n\n\n\n\n\n\n\n\n2/6\n\n\nFinal Project (III)",
            "title": "Home"
        },
        {
            "location": "/Subjects/SEC/#security-in-iot",
            "text": "",
            "title": "Security in IoT"
        },
        {
            "location": "/Subjects/SEC/#general-information",
            "text": "This course is a practical introduction to security in IoT systems. During the course, penetration test, or  pentest , practices of different real IoT devices will be carried out in order to know their vulnerabilities and thus learn to create more secure devices.",
            "title": "General information"
        },
        {
            "location": "/Subjects/SEC/#subject-program-and-evaluation-methodology",
            "text": "Program and evaluation",
            "title": "Subject program and evaluation methodology"
        },
        {
            "location": "/Subjects/SEC/#professors",
            "text": "Guillemo Botella (gbotella@ucm.es) and Joaqu\u00edn Recas (recas@ucm.es)",
            "title": "Professors"
        },
        {
            "location": "/Subjects/SEC/#work-groups-for-regular-lab-assignments",
            "text": "Here you can find the current work groups",
            "title": "Work groups (for regular lab assignments)"
        },
        {
            "location": "/Subjects/SEC/#schedule",
            "text": "Day  Topic  Slides  Extra      19/4  Introduction Security in IoT  M1-IoT-Security     20/4  Introduction to IoT Pentest  M2-Pentest     21/4  Pentest example: IP Camera (I)  M3-IPCam  Material P1    26/4  Cryptography (I): Introduction  M4-Crypto (1)     27/4  Cryptography (I): Introduction  M4-Crypto (2)     28/4  Cryptography (I): Introduction  M4-Crypto (2) Cont.  M4-Crypto (3) Assignments    3/5  Pentest example: IP Camera (II)  M3-IPCam (Cont.)  Material P1 (Cont.)    4/5  Pentest example: Smart Bulb (I)  M5-SmartBulb  Material P2    5/5  Pentest project: Smart Socket Setup  SmartSocket Setup  Material P3    10/5  Cryptography (II)  M4-Crypto (4) Lab1     11/5  Cryptography (II)  M4-Crypto (4) Lab1 (Cont.)     12/5  Cryptography (II)  M4-Crypto (5) Lab2  MPPP (Personal Paper Project)    17/5  Pentest project: Smart Socket (II)  M7-SmartSocket2  Material P3    18/5  Pentest project: Smart Socket (III)  M7-SmartSocket3  Material P3    19/5  Pentest project: Smart Socket (IV)  M7-SmartSocket4  Material P3    24/5  Cryptography (III)  M6-Crypto (6)     25/5  Cryptography (III)  M6-Crypto (6)  (Cont)     26/5  Cryptography (III)  M8-Crypto (7)     31/5  Final Project (I)      1/6  Final Project (II)      2/6  Final Project (III)",
            "title": "Schedule"
        },
        {
            "location": "/Subjects/SEC/P1/",
            "text": "Laboratory 1. IP Camera Pentest\n\n\nIntroduction\n\n\nThe objective of this laboratory session is to put into practice the knowledge on how to carry out a penetration test (\npentest\n) on a specific device, such as an IP camera. \n\n\n\n\nTask 0\n\n\nTo carry out the laboratory we will need the following software elements:\n\n\n\n\n\n\n\n\nIOTNA Ubuntu Virtual Machine (\nDownload & Instructions\n)\n\n\n\n\n\n\nIP Camera firmware:\n\n\n\n\nSPI extracted version (\nspi_firmware.bin\n)\n\n\nMicro SD extracted version (\nusd_firmware.zip\n)\n\n\n\n\n\n\n\n\nBinwalk\n\n\n\n\n\n\nGhidra\n\n\n\n\n\n\nGhex\n: \n\n\n\n\n\n\nsudo apt-get install ghex\n\n\n\n\nBinwalk\n\n\nBinwalk\n is a fast, easy to use tool for analyzing, reverse engineering, and extracting firmware images.\n\n\nMinimal installation instructions inside Ubuntu VM:\n\n\ngit clone https://github.com/ReFirmLabs/binwalk.git\ncd binwalk\nsudo python3 setup.py install\n\n\n\n\nDependencies:\n\n\n# Install sasquatch to extract non-standard SquashFS images\nsudo apt-get install zlib1g-dev liblzma-dev liblzo2-dev\ngit clone https://github.com/devttys0/sasquatch\n(cd sasquatch && ./build.sh)\n\n# Install jefferson to extract JFFS2 file systems\nsudo apt-get install pip\nsudo pip install cstruct\ngit clone https://github.com/sviehb/jefferson\n(cd jefferson && sudo python3 setup.py install)\n\n# Entropy study\nsudo pip install matplotlib\n\n\n\n\nGhidra\n\n\nGhidra\n: A Software Reverse Engineering (SRE) suite of tools developed by NSA's Research Directorate in support of the Cybersecurity mission.\n\n\nDependencies:\n\n\nsudo apt-get install default-jre default-jdk\n\n\n\n\nDownload \nHidra 10.1.2\n, unzip and execute (\n./ghidraRun\n).\n\n\nFamiliarise with Ghidra: \neasy_reverse\n\n\n\n\nTask 1.1\n\n\nOnce we have Ghidra installed in the Virtual Machine, we will follow the \ntutorial\n example to reverse engineer a linux executable file to obtain a secret password: \n\n\n\n\n\n\n\n\nGet the executable file from \neasy_reverse\n (zip password: \ncrackmes.one\n) or use directly the binary inside file \nrev50.zip\n\n\n\n\n\n\nExecute the binary:\n\n\n\n\n\n\n\n\nCreate a new Ghidra project by executing \n./ghidraRun\n in the command line inside hidra folder(\nFile -> New Project -> Non-Shared Project\n:\n\n\n\n\n\n\n\n\nAdd the binary file (\nFile -> Import File\n):\n\n\n\n\n\n\nDouble click in the binary file to start the code browser and select analyze the file now using the default parameters.\n\n\n\n\n\n\nLocate the \nmain\n function\n\n\n\n\n\n\n\n\nFor a better understanding of the code, modify the prototype of the \nmain\n function, by right-clicking on it and selecting \nEdit Function Signature\n, to use the standard definition:\n\n\nint main(int argc, char **argv)\n\n\n\n\n\n\nAnalyse the code and extract the password\n\n\n\n\n\n\nTry again \n./rev50_linux64-bit\n to see if you know a valid password.\n\n\n\n\n\n\n\n\nTask 2.1: Patch \neasy_reverse\n\n\nModify the binary file to accept any password of length 10 without an \n@\n at the fifth position:\n\n\n\n\n\n\n\n\nLocate the line in which the content of the password is checked:\n\n\n\n\n\n\n\n\nRight click on the interaction that rejects the password located in \n0x0010-1206\n (\nJNZ LAB_00101235\n) to \nPatch Instruction\n and change it to \nJZ LAB_00101235\n. And analyse the code again (\nAnalysis->Auto Analyse...\n):\n\n\n \n\n\n\n\n\n\nThe bytecode of the instruction located in \n0x0010-1206\n has changed from \n0x752d\n to \n0x742d\n and also the decompiled code has changed. Now the program rejects passwords that do \nNOT\n contain an \n@\n ant the fifth position. \n\n\nThe patching functionality of Ghidra does not work correctly, so we will patch it using a binary editor as Ghex:\n\n\n\n\n\n\nInstall Ghex: \nsudo apt-get install ghex\n\n\n\n\n\n\nOpen the binary file and locate the line (\n0x1206\n) that contains the instruction \n0x752D\n:\n\n\n \n\n\n\n\n\n\nChange it for \n0x742d\n, save as \nrev50_linux64-bit_hacked\n and test it:\n\n\n\n\n\n\nbuntu@ubuntu2004:~/Downloads$ ./rev50_linux64-bit_hacked 1234567890\nNice Job!!\nflag{1234567890}\n\n\n\n\nIs it possible to completely remove the password verification? Explain how and patch the binary to do it. \n\n\n\n\nTask 2.1\n\n\nOnce we have Binwalk installed in the Virtual Machine:\n\n\n\n\n\n\n\n\nDownload the firmware \nip_cam_attify.bin\n and use \nbinwalk\n to extract its content.\n\n\n\n\n\n\nLocate the \nnpc.tar.gz\n and extract its content\n\n\n\n\n\n\n\n\nTask 2.1\n\n\nAnalyze the \nnpc\n binary file with Ghidra:\n\n\n\n\n\n\n\n\nExecute \nghidra_10.1.2_PUBLIC/ghidraRun\n\n\n\n\n\n\nCreate a project, import the \nnpc\n file and analyse it.\n\n\n\n\n\n\nThe camera rejects modified Firmwares with the message: \nMd5 err!\n. Find the string and locate the functions in which it is used.\n\n\n\n\n\n\nWhich line should we modify to accept any firmware?\n\n\n\n\n\n\n\n\nReport: Create a report (one per class group) with screenshots and comments, send it to \nrecas@ucm.es\n. Due Date: May 17.",
            "title": "Home"
        },
        {
            "location": "/Subjects/SEC/P1/#laboratory-1-ip-camera-pentest",
            "text": "",
            "title": "Laboratory 1. IP Camera Pentest"
        },
        {
            "location": "/Subjects/SEC/P1/#introduction",
            "text": "The objective of this laboratory session is to put into practice the knowledge on how to carry out a penetration test ( pentest ) on a specific device, such as an IP camera.    Task 0  To carry out the laboratory we will need the following software elements:     IOTNA Ubuntu Virtual Machine ( Download & Instructions )    IP Camera firmware:   SPI extracted version ( spi_firmware.bin )  Micro SD extracted version ( usd_firmware.zip )     Binwalk    Ghidra    Ghex :     sudo apt-get install ghex",
            "title": "Introduction"
        },
        {
            "location": "/Subjects/SEC/P1/#binwalk",
            "text": "Binwalk  is a fast, easy to use tool for analyzing, reverse engineering, and extracting firmware images.  Minimal installation instructions inside Ubuntu VM:  git clone https://github.com/ReFirmLabs/binwalk.git\ncd binwalk\nsudo python3 setup.py install  Dependencies:  # Install sasquatch to extract non-standard SquashFS images\nsudo apt-get install zlib1g-dev liblzma-dev liblzo2-dev\ngit clone https://github.com/devttys0/sasquatch\n(cd sasquatch && ./build.sh)\n\n# Install jefferson to extract JFFS2 file systems\nsudo apt-get install pip\nsudo pip install cstruct\ngit clone https://github.com/sviehb/jefferson\n(cd jefferson && sudo python3 setup.py install)\n\n# Entropy study\nsudo pip install matplotlib",
            "title": "Binwalk"
        },
        {
            "location": "/Subjects/SEC/P1/#ghidra",
            "text": "Ghidra : A Software Reverse Engineering (SRE) suite of tools developed by NSA's Research Directorate in support of the Cybersecurity mission.  Dependencies:  sudo apt-get install default-jre default-jdk  Download  Hidra 10.1.2 , unzip and execute ( ./ghidraRun ).",
            "title": "Ghidra"
        },
        {
            "location": "/Subjects/SEC/P1/#familiarise-with-ghidra-easy_reverse",
            "text": "Task 1.1  Once we have Ghidra installed in the Virtual Machine, we will follow the  tutorial  example to reverse engineer a linux executable file to obtain a secret password:      Get the executable file from  easy_reverse  (zip password:  crackmes.one ) or use directly the binary inside file  rev50.zip    Execute the binary:     Create a new Ghidra project by executing  ./ghidraRun  in the command line inside hidra folder( File -> New Project -> Non-Shared Project :     Add the binary file ( File -> Import File ):    Double click in the binary file to start the code browser and select analyze the file now using the default parameters.    Locate the  main  function     For a better understanding of the code, modify the prototype of the  main  function, by right-clicking on it and selecting  Edit Function Signature , to use the standard definition:  int main(int argc, char **argv)    Analyse the code and extract the password    Try again  ./rev50_linux64-bit  to see if you know a valid password.     Task 2.1: Patch  easy_reverse  Modify the binary file to accept any password of length 10 without an  @  at the fifth position:     Locate the line in which the content of the password is checked:     Right click on the interaction that rejects the password located in  0x0010-1206  ( JNZ LAB_00101235 ) to  Patch Instruction  and change it to  JZ LAB_00101235 . And analyse the code again ( Analysis->Auto Analyse... ):       The bytecode of the instruction located in  0x0010-1206  has changed from  0x752d  to  0x742d  and also the decompiled code has changed. Now the program rejects passwords that do  NOT  contain an  @  ant the fifth position.   The patching functionality of Ghidra does not work correctly, so we will patch it using a binary editor as Ghex:    Install Ghex:  sudo apt-get install ghex    Open the binary file and locate the line ( 0x1206 ) that contains the instruction  0x752D :       Change it for  0x742d , save as  rev50_linux64-bit_hacked  and test it:    buntu@ubuntu2004:~/Downloads$ ./rev50_linux64-bit_hacked 1234567890\nNice Job!!\nflag{1234567890}  Is it possible to completely remove the password verification? Explain how and patch the binary to do it.    Task 2.1  Once we have Binwalk installed in the Virtual Machine:     Download the firmware  ip_cam_attify.bin  and use  binwalk  to extract its content.    Locate the  npc.tar.gz  and extract its content     Task 2.1  Analyze the  npc  binary file with Ghidra:     Execute  ghidra_10.1.2_PUBLIC/ghidraRun    Create a project, import the  npc  file and analyse it.    The camera rejects modified Firmwares with the message:  Md5 err! . Find the string and locate the functions in which it is used.    Which line should we modify to accept any firmware?     Report: Create a report (one per class group) with screenshots and comments, send it to  recas@ucm.es . Due Date: May 17.",
            "title": "Familiarise with Ghidra: easy_reverse"
        },
        {
            "location": "/Subjects/SEC/P2/",
            "text": "Laboratory 2. IP Smart Bulb Pentest\n\n\n\n\nOn Off sequence file:\n\n\nbtsnoop_hci_onoff.log\n \n\n\n\n\n\n\nGroup 1 file: \n\n\nbtsnoop_hci_1.log\n \n\n\n\n\n\n\nGroup 2 file: \n\n\nbtsnoop_hci_2.log\n \n\n\n\n\n\n\nGroup 3 file: \n\n\nbtsnoop_hci_3.log\n \n\n\n\n\n\n\nGroup 4 file: \n\n\nbtsnoop_hci_4.log\n \n\n\n\n\n\n\nGroup 5 file: \n\n\nbtsnoop_hci_5.log\n \n\n\n\n\n\n\nGroup 6 file: \n\n\nbtsnoop_hci_6.log",
            "title": "Home"
        },
        {
            "location": "/Subjects/SEC/P2/#laboratory-2-ip-smart-bulb-pentest",
            "text": "On Off sequence file:  btsnoop_hci_onoff.log      Group 1 file:   btsnoop_hci_1.log      Group 2 file:   btsnoop_hci_2.log      Group 3 file:   btsnoop_hci_3.log      Group 4 file:   btsnoop_hci_4.log      Group 5 file:   btsnoop_hci_5.log      Group 6 file:   btsnoop_hci_6.log",
            "title": "Laboratory 2. IP Smart Bulb Pentest"
        },
        {
            "location": "/Subjects/SEC/P3/",
            "text": "Laboratory 3. Smart Socket Pentest\n\n\nDuring this lab you are going to perform a PenTest of a real device, the Smartsocket Orvibo S30C. This work will be done in pairs. For this you can use the groups available in NP \nFinal programming project\n (\nlink\n). \n\n\n\n\nRemember that this practice represents a total of 30% of the grade. You can send me the corresponding memory until June 3 (\nrecas@ucm.es\n).\n\n\n\n\nMaterial\n\n\nApp that should be used to control the Smart Plug: \nHome Mate Apk\n \n\n\nIn case you are not able to record an On/Off sequence, use these files (\nonly for synchronous class, not valid for Pentest Project\n):\n\n\n\n\nGroup 1 file: \n\n\nTrace1.pcapng\n \n\n\n\n\n\n\nGroup 2 file: \n\n\nTrace2.pcapng\n \n\n\n\n\n\n\nGroup 3 file: \n\n\nTrace3.pcapng\n \n\n\n\n\n\n\nGroup 4 file: \n\n\nTrace4.pcapng\n \n\n\n\n\n\n\nGroup 5 file: \n\n\nTrace5.pcapng\n \n\n\n\n\n\n\nGroup 6 file: \n\n\nTrace6.pcapng\n \n\n\n\n\n\n\n\n\nPython script for AES-ECB description:\n\n\n\n\ndecrypt_AES_ECB.py\n\n\n\n\nPython script to control the Smartplug:\n\n\n\n\norvibocontrol.py",
            "title": "Home"
        },
        {
            "location": "/Subjects/SEC/P3/#laboratory-3-smart-socket-pentest",
            "text": "During this lab you are going to perform a PenTest of a real device, the Smartsocket Orvibo S30C. This work will be done in pairs. For this you can use the groups available in NP  Final programming project  ( link ).    Remember that this practice represents a total of 30% of the grade. You can send me the corresponding memory until June 3 ( recas@ucm.es ).",
            "title": "Laboratory 3. Smart Socket Pentest"
        },
        {
            "location": "/Subjects/SEC/P3/#material",
            "text": "App that should be used to control the Smart Plug:  Home Mate Apk    In case you are not able to record an On/Off sequence, use these files ( only for synchronous class, not valid for Pentest Project ):   Group 1 file:   Trace1.pcapng      Group 2 file:   Trace2.pcapng      Group 3 file:   Trace3.pcapng      Group 4 file:   Trace4.pcapng      Group 5 file:   Trace5.pcapng      Group 6 file:   Trace6.pcapng       Python script for AES-ECB description:   decrypt_AES_ECB.py   Python script to control the Smartplug:   orvibocontrol.py",
            "title": "Material"
        },
        {
            "location": "/Subjects/SID/",
            "text": "Smart Infrastructure Design\n\n\nAll the information and documentation about Smart Infrastructure Design (SID) can be found in \nthis link",
            "title": "Home"
        },
        {
            "location": "/Subjects/SID/#smart-infrastructure-design",
            "text": "All the information and documentation about Smart Infrastructure Design (SID) can be found in  this link",
            "title": "Smart Infrastructure Design"
        }
    ]
}